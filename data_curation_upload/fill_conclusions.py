import os
import re
import time
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed
from threading import Lock
from api_call import call_model_claude
import logging

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(threadName)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Lock for thread-safe file operations
file_lock = Lock()

CONCLUSION_SYSTEM_PROMPT = """You are an expert at synthesizing mathematical reasoning. Given parallel reasoning paths that explore different approaches to a problem, write a clear and concise conclusion that:

1. Summarizes the key findings from the parallel paths
2. Verifies that the different approaches agree (or explains any discrepancies)
3. States the final answer clearly
4. Provides a brief justification of why this answer is correct

Keep the conclusion focused and concise."""


def extract_parallel_blocks_with_positions(text):
    """Extract all <Parallel>...</Parallel> blocks with their positions and conclusion positions."""
    blocks_info = []
    
    # Find all parallel blocks with their positions
    parallel_pattern = r'<Parallel>(.*?)</Parallel>'
    
    for match in re.finditer(parallel_pattern, text, re.DOTALL):
        parallel_content = match.group(1)
        parallel_start = match.start()
        parallel_end = match.end()
        
        # Find the conclusion INSIDE this parallel block
        # Look for <Conclusion>[Leave this blank]</Conclusion> within the parallel content
        conclusion_pattern = r'<Conclusion>\s*\[Leave this blank\]\s*</Conclusion>'
        conclusion_match = re.search(conclusion_pattern, parallel_content, re.DOTALL)
        
        if conclusion_match:
            # Calculate absolute positions in the original text
            # parallel_start points to '<', we need to add offset to get to the content
            content_offset = parallel_start + len('<Parallel>')
            conclusion_start = content_offset + conclusion_match.start()
            conclusion_end = content_offset + conclusion_match.end()
            
            blocks_info.append({
                'parallel_content': parallel_content,
                'parallel_start': parallel_start,
                'parallel_end': parallel_end,
                'conclusion_start': conclusion_start,
                'conclusion_end': conclusion_end,
                'has_blank_conclusion': True
            })
    
    return blocks_info


def extract_paths_from_parallel(parallel_block):
    """Extract all Path contents from a Parallel block."""
    path_pattern = r'<Path>(.*?)</Path>'
    paths = re.findall(path_pattern, parallel_block, re.DOTALL)
    return [path.strip() for path in paths]


def check_if_conclusion_exists(text):
    """Check if conclusion is already filled."""
    conclusion_pattern = r'<Conclusion>\s*\[Leave this blank\]\s*</Conclusion>'
    # If we find the blank placeholder, conclusion doesn't exist
    if re.search(conclusion_pattern, text, re.DOTALL):
        return False
    
    # Check if there's actual content in conclusion
    conclusion_pattern_content = r'<Conclusion>(.*?)</Conclusion>'
    match = re.search(conclusion_pattern_content, text, re.DOTALL)
    if match:
        content = match.group(1).strip()
        return len(content) > 10  # Consider filled if more than 10 chars
    
    return False


def generate_conclusion_prompt(parallel_content):
    """Generate prompt for LLM to fill conclusion for a single parallel block."""
    paths = extract_paths_from_parallel(parallel_content)
    
    prompt = """Here are parallel reasoning paths exploring different approaches:

"""
    
    for j, path in enumerate(paths, 1):
        prompt += f"\nPath {j}:\n{path}\n"
    
    prompt += """
Based on these parallel reasoning paths, write a clear conclusion that:
1. Summarizes the key findings from all paths
2. Confirms the approaches agree on the answer (or explains discrepancies)
3. States the final result clearly
4. Provides brief justification

Write ONLY the conclusion text (do not include <Conclusion> tags).

IMPORTANT: Your answer should be natural and act as if it is generated by the model itself, without any sentences like "Path 1 has done ..." or "Block 1 has concluded ..." or similar phrases. Do not explicitly refer to the paths, just conclude their findings.

IMPORTANT: You should only summarize the key points relevant to this parallel stage, do not include unrelated information from previous reasoning.
"""
    
    return prompt


def fill_conclusions_in_text(original_text, blocks_info, conclusions):
    """Replace each blank conclusion with its corresponding generated content.
    
    Args:
        original_text: Original file content
        blocks_info: List of block information from extract_parallel_blocks_with_positions
        conclusions: List of conclusion texts corresponding to each block
    
    Returns:
        Updated text with all conclusions filled
    """
    # Process from end to start to maintain position indices
    updated_text = original_text
    
    for block_info, conclusion_content in reversed(list(zip(blocks_info, conclusions))):
        # Replace the specific conclusion for this block
        before = updated_text[:block_info['conclusion_start']]
        after = updated_text[block_info['conclusion_end']:]
        new_conclusion = f'<Conclusion>\n{conclusion_content}\n</Conclusion>'
        updated_text = before + new_conclusion + after
    
    return updated_text


def process_file(input_file, output_dir, model="gemini-2.5-flash", copy_skipped=False):
    """Process a single file to fill its conclusion.
    
    Args:
        input_file: Path to input file
        output_dir: Path to output directory
        model: Model name for API calls
        copy_skipped: If True, copy skipped files to output directory
    """
    try:
        logger.info(f"Processing: {input_file.name}")
        
        # Read the file
        with open(input_file, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # Extract parallel blocks with their conclusion positions
        blocks_info = extract_parallel_blocks_with_positions(content)
        
        if not blocks_info:
            logger.warning(f"No parallel blocks with blank conclusions found in {input_file.name}")
            
            # Copy file to output if requested
            if copy_skipped:
                output_file = output_dir / input_file.name
                with open(output_file, 'w', encoding='utf-8') as f:
                    f.write(content)
                logger.info(f"Copied skipped file to output: {input_file.name}")
            
            return {
                'file': input_file.name,
                'status': 'skipped',
                'reason': 'no parallel blocks with blank conclusions'
            }
        
        logger.info(f"Found {len(blocks_info)} parallel blocks to process in {input_file.name}")
        
        # Generate conclusion for each parallel block
        conclusions = []
        for i, block_info in enumerate(blocks_info, 1):
            logger.info(f"Generating conclusion {i}/{len(blocks_info)} for {input_file.name}")
            
            # Generate prompt for this specific block
            user_prompt = generate_conclusion_prompt(block_info['parallel_content'])
            
            # Call LLM API
            response = call_model_claude(
                user_prompt=user_prompt,
                system_prompt=CONCLUSION_SYSTEM_PROMPT,
                model=model,
                max_retries=6,
                retry_delay=2
            )
            
            if not response:
                logger.error(f"Failed to get LLM response for block {i} in {input_file.name}")
                return {
                    'file': input_file.name,
                    'status': 'failed',
                    'reason': f'LLM API error for block {i}'
                }
            
            # Extract conclusion from response
            conclusion_text = response['choices'][0]['message']['content'].strip()
            conclusions.append(conclusion_text)
        
        # Fill all conclusions in original text
        updated_content = fill_conclusions_in_text(content, blocks_info, conclusions)
        
        # Save to output directory
        output_file = output_dir / input_file.name
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(updated_content)
        
        logger.info(f"Successfully processed: {input_file.name}")
        return {
            'file': input_file.name,
            'status': 'success'
        }
        
    except Exception as e:
        logger.error(f"Error processing {input_file.name}: {str(e)}")
        return {
            'file': input_file.name,
            'status': 'error',
            'reason': str(e)
        }


def process_directory(input_dir, output_dir, num_threads=5, model="gemini-2.5-flash", copy_skipped=False, test_file=None):
    """Process all files in a directory using multiple threads.
    
    Args:
        input_dir: Input directory path
        output_dir: Output directory path
        num_threads: Number of parallel threads
        model: Model name for API calls
        copy_skipped: If True, copy skipped files to output
        test_file: If provided, only process this single file (for testing)
    """
    input_path = Path(input_dir)
    output_path = Path(output_dir)
    
    # Create output directory if it doesn't exist
    output_path.mkdir(parents=True, exist_ok=True)
    
    # Get files to process
    if test_file:
        # Test mode: process only the specified file
        test_file_path = input_path / test_file
        if not test_file_path.exists():
            logger.error(f"Test file not found: {test_file}")
            return
        input_files = [test_file_path]
        logger.info(f"TEST MODE: Processing single file: {test_file}")
    else:
        # Normal mode: process all .txt files
        input_files = list(input_path.glob('*.txt'))
        logger.info(f"Found {len(input_files)} files to process")
    
    if not input_files:
        logger.warning("No .txt files found in input directory")
        return
    
    # Process files in parallel
    results = {
        'success': 0,
        'skipped': 0,
        'failed': 0,
        'error': 0
    }
    
    with ThreadPoolExecutor(max_workers=num_threads) as executor:
        # Submit all tasks
        future_to_file = {
            executor.submit(process_file, file, output_path, model, copy_skipped): file 
            for file in input_files
        }
        
        # Process completed tasks
        for future in as_completed(future_to_file):
            result = future.result()
            results[result['status']] += 1
            
            # Log progress
            total_processed = sum(results.values())
            logger.info(f"Progress: {total_processed}/{len(input_files)} files processed")
    
    # Print summary
    logger.info("\n" + "="*50)
    logger.info("Processing Summary:")
    logger.info(f"Total files: {len(input_files)}")
    logger.info(f"Successfully processed: {results['success']}")
    logger.info(f"Skipped: {results['skipped']}")
    logger.info(f"Failed: {results['failed']}")
    logger.info(f"Errors: {results['error']}")
    logger.info("="*50)


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description='Fill conclusions in parallel reasoning files')
    parser.add_argument(
        '--input-dir',
        type=str,
        default='new_result_parallel_formatted',
        help='Input directory containing files to process'
    )
    parser.add_argument(
        '--output-dir',
        type=str,
        default='new_result_with_conclusions_new_different_results',
        help='Output directory for processed files'
    )
    parser.add_argument(
        '--threads',
        type=int,
        default=15,
        help='Number of parallel threads to use'
    )
    parser.add_argument(
        '--model',
        type=str,
        default='gemini-2.5-flash',
        help='Model to use for LLM API calls'
    )
    parser.add_argument(
        '--copy-skipped',
        action='store_true',
        help='Copy skipped files to output directory'
    )
    parser.add_argument(
        '--test-file',
        type=str,
        default=None,
        help='Process only this file (for testing). Provide just the filename, not the full path.'
    )
    
    args = parser.parse_args()
    
    logger.info(f"Starting processing with {args.threads} threads")
    logger.info(f"Input: {args.input_dir}")
    logger.info(f"Output: {args.output_dir}")
    logger.info(f"Model: {args.model}")
    logger.info(f"Copy skipped files: {args.copy_skipped}")
    if args.test_file:
        logger.info(f"TEST MODE: Only processing {args.test_file}")
    
    process_directory(
        input_dir=args.input_dir,
        output_dir=args.output_dir,
        num_threads=args.threads,
        model=args.model,
        copy_skipped=args.copy_skipped,
        test_file=args.test_file
    )
