experiment_name: arealite-mini-offpolicy
trial_name: trial0822-0
allocation_mode: "gen:d4t8p1,train:d32t1p1,ref:d16t1p1"
seed: 42
total_train_epochs: 10
total_train_steps: 11450
train_bs_n_seqs: 256
weight_update_type: "nccl"
tokenizer_path: "/storage/yuyan/liuyongkang.lyk/output_models/b1-ml-32k-r10528-1p5e4_bs256_release_general_longcot200w_700w_clean_v2_0725/hf_ckpts/9853"
train_dataset:
  path: "/storage/yuyan/xukuan.xk/repos/antnlp/personal/llm/benchmark/train_0731_adeng_new_0726_areal_train.jsonl"
  shuffle: true
  max_prompt_len: 1024
scheduler:
  endpoint: "http://asystem-scheduler.asystem-cluster-prod-1.svc:8081"
  deploy_mode: "separation"
  functioncall_service_domain: "http://110.75.237.19:8080"
  reward_model_path: "/storage/jiulin.jl/Skywork-Reward-V2-Qwen3-8B"
  reward_model_service_url: "http://reward-model-service.asystem-test.svc.et15-02-aidc.sh.s-aidc.local:33000/classify"

stats_logger:
  experiment_name: ${experiment_name}
  trial_name: ${trial_name}
  fileroot: "/storage/openpsi/experiments"
  wandb:
    mode: "online"
    wandb_base_url: "http://8.150.1.98:8080"
    wandb_api_key: "local-3bca3d5f00a980f3075b3e8ff2e16adc4ef43ffe"

gconfig:
  n_samples: 8
  min_new_tokens: 0
  max_new_tokens: 31744
  greedy: false
  temperature: 1.0
  top_k: 1000000
  top_p: 1.0

rollout:
  experiment_name: ${experiment_name}
  trial_name: ${trial_name}
  model_path: ${tokenizer_path}
  storage_path: "/storage/openpsi/checkpoints"
  engine_config:
    attention_backend: "triton"
    disable_custom_all_reduce: true
    enable_metrics: true
    mem_fraction_static: 0.7
    triton_attention_num_kv_splits: 16
    disable_shared_experts_fusion: true
    tokenizer_mode: "auto"
    load_format: "auto"
    is_embedding: false
    kv_cache_dtype: "auto"
    max_prefill_tokens: 32768
    schedule_policy: "fcfs"
    schedule_conservativeness: 1.0
    disable_cuda_graph: false
    disable_radix_cache: true
    disable_cuda_graph_padding: false
    enable_nccl_nvls: false
    disable_outlines_disk_cache: false
    disable_overlap_schedule: false
    enable_mixed_chunk: false
    enable_dp_attention: false
    enable_ep_moe: false
    enable_torch_compile: false
    torch_compile_max_bs: 32
    triton_attention_reduce_in_fp32: false
    cuda_graph_bs: [ 1, 2, 4, 8, 16, 32, 64, 128, 256, 384, 512 ]
    num_continuous_decode_steps: 1
    enable_nan_detection: false
    allow_auto_truncate: false
    enable_p2p_check: false
    enable_memory_saver: false
    chunked_prefill_size: null
    context_length: null
    cpu_offload_gb: 0
    dp_size: 1
    dtype: "auto"
    sampling_backend: "pytorch"
    log_level: "info"
    log_level_http: null
    log_requests: false
    log_requests_level: 0
    max_running_requests: null
    show_time_cost: false

actor:
  hybrid_engine:
    experiment_name: ${experiment_name}
    trial_name: ${trial_name}
    group_size: ${gconfig.n_samples}
    train_bs_n_seqs: ${train_bs_n_seqs}
    max_tokens_per_mb: 32768
    wrap_policy:
      n_minibatches: 8
      kl_ctl: 0.001
      recompute_logp: true
      adv_norm: false
      discount: 1.0
      gae_lambda: 1.0
      eps_clip: 0.2
      clip_ratio_low: 0.2
      clip_ratio_high: 0.28
      c_clip: null
      value_eps_clip: 0.2
      max_reward_clip: 5.0
      disable_value: true
      early_stop_kl: null
      early_stop_imp_ratio: null
      adaptive_kl_ctl: false
      adaptive_kl_target: 6
      adaptive_kl_horizon: 10000
      enable_save: true
      value_norm: true
      value_norm_type: "exp"
      value_norm_beta: 0.99995
      value_norm_eps: 1e-5
      group_size: 8
      generation_size: null
      mask_no_eos_with_zero: false
      group_adv_norm: true
      mask_too_long: false
      use_dense_reward: false
      reward_delta: true
      token_normalize_scope: "global"
      sample_reuse: 1
      temperature: 1.0
      reward_output_scaling: 0.5
      reward_output_bias: -1.0
    remote_megatron_config:
      adam_beta1: 0.9
      adam_beta2: 0.999
      adam_eps: 1.0e-08
      add_bias_linear: false
      add_position_embedding: true
      apply_rope_fusion: true
      async_save: false
      attention_backend: "flash"
      attention_dropout: 0.0
      attention_softmax_in_fp32: true
      auto_detect_ckpt_format: true
      bf16: true
      clip_grad: 1.0
      context_parallel_size: 1
      cp_comm_type: "p2p"
      cross_entropy_loss_fusion: false
      distributed_backend: "nccl"
      distributed_timeout_minutes: 600
      enable_one_logger: false
      expert_model_parallel_size: 8
      ffn_hidden_size: 1408
      global_batch_size: 256
      gradient_accumulation_fusion: true
      group_query_attention: true
      hidden_dropout: 0.0
      hidden_size: 2048
      init_method_std: 0.006
      load: "/storage/yuyan/liuyongkang.lyk/output_models/b1-ml-32k-r10528-1p5e4_bs256_release_general_longcot200w_700w_clean_v2_0725/history/iter_0009853"
      log_loss_scale_to_tensorboard: false
      log_num_zeros_in_grad: true
      log_params_norm: true
      log_throughput: true
      log_timers_to_tensorboard: true
      log_validation_ppl_to_tensorboard: true
      lr: 2.0e-06
      lr_decay_style: "constant"
      lr_warmup_iters: 10
      make_vocab_size_divisible_by: 128
      masked_softmax_fusion: true
      max_position_embeddings: 32768
      micro_batch_size: 1
      moe_grouped_gemm: true
      moe_permute_fusion: true
      moe_router_dtype: "fp32"
      moe_router_load_balancing_type: "aux_loss"
      moe_router_topk: 6
      moe_shared_expert_intermediate_size: 2816
      moe_shared_expert_overlap: true
      moe_token_dispatcher_type: "alltoall"
      norm_epsilon: 1.0e-06
      normalization: "RMSNorm"
      num_attention_heads: 16
      num_experts: 64
      num_layers: 28
      num_query_groups: 4
      num_workers: 16
      optim_normhead_bwd_alltoall: false
      optim_normhead_fwd_alltoall: true
      optimizer: "adam"
      overlap_grad_reduce: true
      overlap_p2p_comm: true
      overlap_param_gather: false
      pipeline_model_parallel_size: 1
      position_embedding_type: "rope"
      qk_layernorm: false
      recompute_granularity: "full"
      recompute_method: "uniform"
      recompute_num_layers: 1
      resume_dataloader: false
      rotary_base: 600000
      router_warmup_step: 0
      save: "/mnt/asystem-m/common/users/user_name_placeholder/models/mcore_ckpt/"
      save_interval: 1
      seed: 42
      seq_length: 32768
      sequence_parallel: true
      swiglu: true
      tensor_model_parallel_size: 1
      tensorboard_log_interval: 1
      tokenizer_model: ${tokenizer_path}
      tokenizer_type: "HuggingFaceTokenizer"
      train_iters: 100000
      untie_embeddings_and_output_weights: true
      use_distributed_optimizer: true
      use_flash_attn: true
      use_legacy_models: false
      use_mcore_models: true
      use_random_logits: true
      vocab_size: 126464
      weight_decay: 0.01
    loss_configs:
      kl_ctl: 0.001
      adaptive_kl_target: 6
      adaptive_kl_horizon: 10000
      eps_clip: 0.2
      temperature: 1
      token_normalize_scope: "dp"
      enable_offpolicy: true

ref:
  hybrid_engine:
    experiment_name: ${experiment_name}
    trial_name: ${trial_name}
    group_size: ${gconfig.n_samples}
    train_bs_n_seqs: ${train_bs_n_seqs}
    max_tokens_per_mb: 32768
    wrap_policy:
      n_minibatches: 8
      kl_ctl: 0.001
      recompute_logp: true
      adv_norm: false
      discount: 1.0
      gae_lambda: 1.0
      eps_clip: 0.2
      clip_ratio_low: 0.2
      clip_ratio_high: 0.28
      c_clip: null
      value_eps_clip: 0.2
      max_reward_clip: 5.0
      disable_value: true
      early_stop_kl: null
      early_stop_imp_ratio: null
      adaptive_kl_ctl: false
      adaptive_kl_target: 6
      adaptive_kl_horizon: 10000
      enable_save: true
      value_norm: true
      value_norm_type: "exp"
      value_norm_beta: 0.99995
      value_norm_eps: 1e-5
      group_size: 8
      generation_size: null
      mask_no_eos_with_zero: false
      group_adv_norm: true
      mask_too_long: false
      use_dense_reward: false
      reward_delta: true
      token_normalize_scope: "global"
      sample_reuse: 1
      temperature: 1.0
      reward_output_scaling: 0.5
      reward_output_bias: -1.0
    remote_megatron_config:
      adam_beta1: 0.9
      adam_beta2: 0.999
      adam_eps: 1.0e-08
      add_bias_linear: false
      add_position_embedding: true
      apply_rope_fusion: true
      async_save: false
      attention_backend: "flash"
      attention_dropout: 0.0
      attention_softmax_in_fp32: true
      auto_detect_ckpt_format: true
      bf16: true
      clip_grad: 1.0
      context_parallel_size: 1
      cp_comm_type: "p2p"
      cross_entropy_loss_fusion: false
      distributed_backend: "nccl"
      distributed_timeout_minutes: 600
      enable_one_logger: false
      expert_model_parallel_size: 8
      ffn_hidden_size: 1408
      global_batch_size: 256
      gradient_accumulation_fusion: true
      group_query_attention: true
      hidden_dropout: 0.0
      hidden_size: 2048
      init_method_std: 0.006
      load: "/storage/yuyan/liuyongkang.lyk/output_models/b1-ml-32k-r10528-1p5e4_bs256_release_general_longcot200w_700w_clean_v2_0725/history/iter_0009853"
      log_loss_scale_to_tensorboard: false
      log_num_zeros_in_grad: true
      log_params_norm: true
      log_throughput: true
      log_timers_to_tensorboard: true
      log_validation_ppl_to_tensorboard: true
      lr: 2.0e-06
      lr_decay_style: "constant"
      lr_warmup_iters: 10
      make_vocab_size_divisible_by: 128
      masked_softmax_fusion: true
      max_position_embeddings: 32768
      micro_batch_size: 1
      moe_grouped_gemm: true
      moe_permute_fusion: true
      moe_router_dtype: "fp32"
      moe_router_load_balancing_type: "aux_loss"
      moe_router_topk: 6
      moe_shared_expert_intermediate_size: 2816
      moe_shared_expert_overlap: true
      moe_token_dispatcher_type: "alltoall"
      norm_epsilon: 1.0e-06
      normalization: "RMSNorm"
      num_attention_heads: 16
      num_experts: 64
      num_layers: 28
      num_query_groups: 4
      num_workers: 16
      optim_normhead_bwd_alltoall: false
      optim_normhead_fwd_alltoall: true
      optimizer: "adam"
      overlap_grad_reduce: true
      overlap_p2p_comm: true
      overlap_param_gather: false
      pipeline_model_parallel_size: 1
      position_embedding_type: "rope"
      qk_layernorm: false
      recompute_granularity: "full"
      recompute_method: "uniform"
      recompute_num_layers: 1
      resume_dataloader: false
      rotary_base: 600000
      router_warmup_step: 0
      save: "/mnt/asystem-m/common/users/user_name_placeholder/models/mcore_ckpt/"
      save_interval: 1
      seed: 42
      seq_length: 32768
      sequence_parallel: true
      swiglu: true
      tensor_model_parallel_size: 1
      tensorboard_log_interval: 1
      tokenizer_model: ${tokenizer_path}
      tokenizer_type: "HuggingFaceTokenizer"
      train_iters: 100000
      untie_embeddings_and_output_weights: true
      use_distributed_optimizer: true
      use_flash_attn: true
      use_legacy_models: false
      use_mcore_models: true
      use_random_logits: true
      vocab_size: 126464
      weight_decay: 0.01
    loss_configs:
      kl_ctl: 0.001
      adaptive_kl_target: 6
      adaptive_kl_horizon: 10000
      eps_clip: 0.2
      temperature: 1
      token_normalize_scope: "dp"
      enable_offpolicy: true

recover:
  recover_meta_info_path: ""
  enable_recover: true
  freq_epochs: 1
  freq_steps: 20
  fileroot: "/storage/openpsi"