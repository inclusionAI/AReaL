{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37c1b1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install datasets\n",
    "# ! pip install transformers\n",
    "# ! pip install accelerate\n",
    "# ! pip install trl\n",
    "# ! pip install peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6aa9f26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer, DataCollatorForLanguageModeling\n",
    "from datasets import Dataset, DatasetDict\n",
    "import torch\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "816ddd9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-08-04 13:51:53.567\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtau2.utils.utils\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mUsing data directory from source: /lambda/nfs/victor-north-tx/tau2-bench-private/data\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-08-04 13:51:54.626\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtau2.utils.llm_utils\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mVLLM_API_BASE: http://127.0.0.1:8000/v1\u001b[0m\n",
      "\u001b[32m2025-08-04 13:51:54.627\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtau2.utils.llm_utils\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m44\u001b[0m - \u001b[1mOLLAMA_API_BASE: http://127.0.0.1:11434\u001b[0m\n",
      "\u001b[32m2025-08-04 13:51:54.627\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtau2.utils.llm_utils\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m78\u001b[0m - \u001b[1mLiteLLM: Cache is disabled\u001b[0m\n",
      "\u001b[32m2025-08-04 13:51:54.627\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mtau2.utils.llm_utils\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m85\u001b[0m - \u001b[33m\u001b[1mSonnet thinking is disabled\u001b[0m\n",
      "\u001b[32m2025-08-04 13:51:54.710\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtau2.registry\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m194\u001b[0m - \u001b[34m\u001b[1mRegistering default components...\u001b[0m\n",
      "\u001b[32m2025-08-04 13:51:54.710\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtau2.registry\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m236\u001b[0m - \u001b[34m\u001b[1mDefault components registered successfully. Registry info: {\n",
      "  \"domains\": [\n",
      "    \"mock\",\n",
      "    \"airline\",\n",
      "    \"retail\",\n",
      "    \"telecom\",\n",
      "    \"telecom-workflow\"\n",
      "  ],\n",
      "  \"agents\": [\n",
      "    \"llm_agent\",\n",
      "    \"llm_agent_gt\",\n",
      "    \"llm_agent_solo\",\n",
      "    \"llm_agent_completion\",\n",
      "    \"llm_agent_gt_completion\",\n",
      "    \"llm_agent_solo_completion\"\n",
      "  ],\n",
      "  \"users\": [\n",
      "    \"user_simulator\",\n",
      "    \"dummy_user\"\n",
      "  ],\n",
      "  \"task_sets\": [\n",
      "    \"mock\",\n",
      "    \"airline\",\n",
      "    \"retail\",\n",
      "    \"telecom\",\n",
      "    \"telecom-workflow\"\n",
      "  ]\n",
      "}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1107\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "from experiments.model_training.prepare_dataset import OpenAICompletionDataPoint\n",
    "dataset_path = \"data/test_full-v1.jsonl\"\n",
    "dataset = []\n",
    "with open(dataset_path, \"r\") as f:\n",
    "    for line in f:\n",
    "        datapoint = OpenAICompletionDataPoint.model_validate_json(line)\n",
    "        dataset.append(datapoint)\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d13164c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'experiments.model_training.prepare_dataset.OpenAICompletionDataPoint'>\n",
      "True\n",
      "18\n",
      "14\n",
      "1 assistant: Hi! How can I help you today?\n",
      "2 user: Hi, I need to change my upcoming flight from JFK. My cat is really sick and I need to get home sooner. Can you help me look into changing my flight to an earlier nonstop option?\n",
      "3 assistant: To assist you with changing your flight, I need to know your user ID and the reservation ID for the flight you want to change. Could you please provide those? If you don't know your reservation ID, I can help you locate it.\n",
      "4 user: I don‚Äôt have my reservation ID handy, but my user ID is daiki_lee_6144. Can you look up my reservation with that?\n",
      "5 assistant: tool call...\n",
      "7 assistant: You have three reservations under your user ID daiki_lee_6144: DF89BM, COVE6R, and IIHXDG.\n",
      "\n",
      "Could you please specify which reservation you want to change? If you are not sure, you can provide more details about the flight such as the destination or date, and I can help identify the correct reservation.\n",
      "8 user: I‚Äôm not sure which one it is, but the flight I want to change is departing from JFK on May 17. Can you check which reservation matches that?\n",
      "9 assistant: tool call...\n",
      "13 assistant: The reservation DF89BM has a flight departing from JFK on May 17. It is a round trip with basic economy cabin. The flights are JFK to ORD on May 17, ORD to DTW on May 17, and DTW to JFK on May 24.\n",
      "\n",
      "Would you like to change this reservation to an earlier nonstop flight from JFK? If yes, please confirm and provide the preferred date for the earlier flight. Note that basic economy flights cannot be modified to change flights, only cabin changes are allowed. Would you like me to check for available nonstop flights from JFK on your preferred date?\n",
      "14 user: Yes, that‚Äôs the reservation I want to change. I‚Äôd like to switch to an earlier nonstop flight from JFK to my destination on May 17. Can you check what nonstop options are available that day? Also, I only want to make the change if it costs less than $100. I don‚Äôt want to buy a new ticket‚Äîjust change my existing one if possible.\n",
      "15 assistant: Since your current reservation DF89BM is booked in basic economy cabin, changing flights is not allowed under the policy. Only cabin changes are allowed for basic economy, but not changing the flights themselves.\n",
      "\n",
      "Would you like me to check for available nonstop flights from JFK to your destination on May 17 anyway, or assist you with any other request?\n",
      "16 user: If I can‚Äôt change to an earlier nonstop flight without buying a new ticket, then I don‚Äôt want to proceed. I‚Äôm not interested in upgrading the cabin or purchasing a new flight. Thanks for checking for me.\n",
      "17 assistant: You're welcome. If you need any further assistance in the future, feel free to reach out. Have a good day!\n"
     ]
    }
   ],
   "source": [
    "dp0: OpenAICompletionDataPoint = dataset[0]\n",
    "print(type(dp0))\n",
    "print(dp0.parallel_tool_calls)\n",
    "print(len(dp0.messages))\n",
    "print(len(dp0.tools))\n",
    "for i, message in enumerate(dp0.messages):\n",
    "    if message[\"role\"] in [\"system\", \"tool\"]:\n",
    "        continue\n",
    "    print(f\"{i} {message['role']}: {message.get('content', 'tool call...')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7f9c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted existing model and tokenizer\n",
      "Loading tokenizer and model for /home/ubuntu/victor-north-tx/models/Qwen2.5-0.5B-instruct\n",
      "Tokenizer has a chat template.\n",
      "Tokenizer eos_token_id: 151645, pad_token_id: 151643\n",
      "Model loaded in 1.03 seconds\n"
     ]
    }
   ],
   "source": [
    "# Load model and tokenizer\n",
    "\n",
    "# Model checkpoint\n",
    "# MODEL_NAME = \"Qwen/Qwen2.5-3B-Instruct\"\n",
    "# MODEL_NAME = \"Qwen/Qwen2.5-0.5B\"\n",
    "\n",
    "\n",
    "## NOTE: Use instruct models! Non instruct models require better generation stopping strategies.\n",
    "# MODEL_NAME = \"/home/ubuntu/victor-north-tx/models/Qwen2.5-0.5B\"\n",
    "# MODEL_NAME = \"/home/ubuntu/victor-north-tx/models/Qwen2.5-3B\"\n",
    "# MODEL_NAME = \"/home/ubuntu/victor-north-tx/models/Qwen2.5-7B\"\n",
    "MODEL_NAME = \"/home/ubuntu/victor-north-tx/models/Qwen2.5-0.5B-instruct\"\n",
    "# MODEL_NAME = \"/home/ubuntu/victor-north-tx/models/Qwen2.5-3B-instruct\"\n",
    "# MODEL_NAME = \"/home/ubuntu/victor-north-tx/models/Qwen2.5-7B-instruct\"\n",
    "\n",
    "\n",
    "\n",
    "def get_model_and_tokenizer(model_name, torch_dtype=\"auto\", device_map=\"auto\"):\n",
    "    try:\n",
    "        global model, tokenizer # Just to be sure that we don't have any old model or tokenizer\n",
    "        del model, tokenizer\n",
    "        print(\"Deleted existing model and tokenizer\")\n",
    "    except:\n",
    "        pass\n",
    "    start_time = time.time()\n",
    "    # Load tokenizer and model (4-bit optional)\n",
    "    print(f\"Loading tokenizer and model for {model_name}\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "    if tokenizer.chat_template is None:\n",
    "        raise ValueError(f\"Tokenizer for model {model_name} does not have a chat template.\")\n",
    "    else:\n",
    "        print(\"Tokenizer has a chat template.\")\n",
    "    print(f\"Tokenizer eos_token_id: {tokenizer.eos_token_id}, pad_token_id: {tokenizer.pad_token_id}\")\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        torch_dtype=torch_dtype, # Automatically determines the best dtype (e.g., float16, bfloat16)\n",
    "        device_map=device_map   # Automatically distributes the model across available devices (e.g., GPUs)\n",
    "    )\n",
    "    print(f\"Model loaded in {time.time() - start_time:.2f} seconds\")\n",
    "    return model, tokenizer\n",
    "\n",
    "\n",
    "model, tokenizer = get_model_and_tokenizer(MODEL_NAME, torch_dtype=\"auto\", device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a8b1cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:\n",
      "<|im_start|>system\n",
      "You are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n",
      "<|im_start|>user\n",
      "What is the capital of France?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n",
      "****************************************************************************************************\n",
      "Full output:\n",
      "<|im_start|>system\n",
      "You are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n",
      "<|im_start|>user\n",
      "What is the capital of France?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "The capital of France is Paris.<|im_end|>\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Full generated output:\n",
      "The capital of France is Paris.<|im_end|>\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "Thinking content: \n",
      "Content: The capital of France is Paris.\n",
      "****************************************************************************************************\n",
      "Testing parse_tool_calls_qwen\n",
      "[{'name': 'get_capital', 'arguments': {'country': 'France'}}]\n"
     ]
    }
   ],
   "source": [
    "# Load gemnerate response function\n",
    "# GPU_BACKEND = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# GPU_BACKEND = \"mps\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "def generate_response_qwen(messages, tools, tokenizer, model, temperature=0.5, add_generation_prompt=True, enable_thinking=False, max_new_tokens=32768, verbose=False, gpu_backend=None):\n",
    "    \"\"\"\n",
    "    Generate completion response for a given prompt.\n",
    "    Args:\n",
    "        messages: List of messages in the chat format.\n",
    "        tools: List of tools to use for the completion.\n",
    "        tokenizer: Tokenizer to use for the completion.\n",
    "        model: Model to use for the completion.\n",
    "        max_new_tokens: Maximum number of new tokens to generate.\n",
    "    \"\"\"\n",
    "    prompt = tokenizer.apply_chat_template(messages, tools=tools, tokenize=False, add_generation_prompt=add_generation_prompt, enable_thinking=enable_thinking)\n",
    "    if verbose:\n",
    "        print(f\"Prompt:\\n{prompt}\")\n",
    "    if gpu_backend is not None:\n",
    "        print(\"NOTE: If model was loaded using auto device map, you shouldn't specify gpu_backend\")\n",
    "    if gpu_backend is not None:\n",
    "        model.to(gpu_backend)\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    # inputs.pop('token_type_ids', None)\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(**inputs, \n",
    "                                  max_new_tokens=max_new_tokens,\n",
    "                                  temperature=temperature\n",
    "                                  )\n",
    "        if verbose:\n",
    "            print(\"*\"*100)\n",
    "            print(f\"Full output:\\n{tokenizer.decode(outputs[0], skip_special_tokens=False)}\")\n",
    "            print(\"*\"*100)\n",
    "    input_length = inputs.input_ids.shape[1]\n",
    "    generated_token_ids = outputs[0][input_length:]\n",
    "    if verbose:\n",
    "        print(\"*\"*100)\n",
    "        print(f\"Full generated output:\\n{tokenizer.decode(generated_token_ids, skip_special_tokens=False)}\")\n",
    "        print(\"*\"*100)\n",
    "    # parsing thinking content\n",
    "    try:\n",
    "        # rindex finding 151668 (</think>)\n",
    "        index = len(generated_token_ids) - generated_token_ids[::-1].index(151668)\n",
    "    except ValueError:\n",
    "        index = 0\n",
    "\n",
    "    thinking_content = tokenizer.decode(generated_token_ids[:index], skip_special_tokens=True).strip(\"\\n\")\n",
    "    content = tokenizer.decode(generated_token_ids[index:], skip_special_tokens=True).strip(\"\\n\")\n",
    "    if verbose:\n",
    "        print(\"*\"*100)\n",
    "        print(f\"Thinking content: {thinking_content}\")\n",
    "        print(f\"Content: {content}\")\n",
    "        print(\"*\"*100)\n",
    "    return content, thinking_content\n",
    "\n",
    "\n",
    "test_messages = [\n",
    "    {\"role\": \"user\", \"content\": \"What is the capital of France?\"}\n",
    "]\n",
    "test_tools = None\n",
    "test_response, test_thinking_content = generate_response_qwen(test_messages, test_tools, tokenizer, model, add_generation_prompt=True, enable_thinking=False, verbose=True)\n",
    "# print(\"thinking content:\", test_thinking_content)\n",
    "# print(\"content:\", test_response)\n",
    "\n",
    "# Parse tool calls\n",
    "import json\n",
    "import re\n",
    "\n",
    "def parse_tool_calls_qwen(response: str) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Parse tool calls from a response.\n",
    "    System instructions in Qwen2.5:\n",
    "    ```\n",
    "    For each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:\n",
    "    <tool_call>\n",
    "    {\"name\": <function-name>, \"arguments\": <args-json-object>}\n",
    "    </tool_call>\n",
    "    ```\n",
    "    \"\"\"\n",
    "    pattern = r\"<tool_call>(.*?)</tool_call>\"\n",
    "    matches = re.findall(pattern, response, re.DOTALL)\n",
    "    tool_calls = []\n",
    "    \n",
    "    for match in matches:\n",
    "        # Process each line of the tool call content\n",
    "        lines = match.strip().split('\\n')\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if line:  # Skip empty lines\n",
    "                try:\n",
    "                    tool_call = json.loads(line)\n",
    "                    tool_calls.append(tool_call)\n",
    "                except json.JSONDecodeError:\n",
    "                    continue  # Skip lines that aren't valid JSON\n",
    "    \n",
    "    return tool_calls\n",
    "\n",
    "print(\"Testing parse_tool_calls_qwen\")\n",
    "test_response = \"I'm thinking about the capital of France. <tool_call>{\\\"name\\\": \\\"get_capital\\\", \\\"arguments\\\": {\\\"country\\\": \\\"France\\\"}}</tool_call>\"\n",
    "tool_calls = parse_tool_calls_qwen(test_response)\n",
    "print(tool_calls)\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad19ff98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üéØ PARTIAL TRAJECTORY 0 (2 messages).\n",
      "Generation time: 1.09 seconds\n",
      "================================================================================\n",
      "\n",
      "üìù ORIGINAL RESPONSE:\n",
      "----------------------------------------\n",
      "Hi! How can I help you today?\n",
      "\n",
      "üõ†Ô∏è ORIGINAL TOOL CALLS: None\n",
      "\n",
      "üîÑ REPLAY RESPONSE:\n",
      "----------------------------------------\n",
      "```json\n",
      "{\n",
      "  \"name\": \"book_reservation\",\n",
      "  \"arguments\": {\n",
      "    \"flight_number\": \"HAT001\",\n",
      "    \"date\": \"2024-05-01\"\n",
      "  }\n",
      "}\n",
      "```\n",
      "\n",
      "üõ†Ô∏è REPLAY TOOL CALLS: None\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üéØ PARTIAL TRAJECTORY 1 (4 messages).\n",
      "Generation time: 0.85 seconds\n",
      "================================================================================\n",
      "\n",
      "üìù ORIGINAL RESPONSE:\n",
      "----------------------------------------\n",
      "To assist you with changing your flight, I need to know your user ID and the reservation ID for the flight you want to change. Could you please provide those? If you don't know your reservation ID, I can help you locate it.\n",
      "\n",
      "üõ†Ô∏è ORIGINAL TOOL CALLS: None\n",
      "\n",
      "üîÑ REPLAY RESPONSE:\n",
      "----------------------------------------\n",
      "Sure thing! Could you please tell me your preferred departure and arrival dates? Also, let me know if there are any special requirements like early morning departures or any restrictions related to the flight?\n",
      "\n",
      "üõ†Ô∏è REPLAY TOOL CALLS: None\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üéØ PARTIAL TRAJECTORY 2 (6 messages).\n",
      "Generation time: 0.48 seconds\n",
      "================================================================================\n",
      "\n",
      "üìù ORIGINAL RESPONSE:\n",
      "----------------------------------------\n",
      "No content\n",
      "\n",
      "üõ†Ô∏è ORIGINAL TOOL CALLS:\n",
      "----------------------------------------\n",
      "  1. get_user_details: {\"user_id\": \"daiki_lee_6144\"}\n",
      "\n",
      "üîÑ REPLAY RESPONSE:\n",
      "----------------------------------------\n",
      "Sure thing! Please provide me with the flight number and the date of your flight so we can proceed.\n",
      "\n",
      "üõ†Ô∏è REPLAY TOOL CALLS: None\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üéØ PARTIAL TRAJECTORY 3 (8 messages).\n",
      "Generation time: 0.56 seconds\n",
      "================================================================================\n",
      "\n",
      "üìù ORIGINAL RESPONSE:\n",
      "----------------------------------------\n",
      "You have three reservations under your user ID daiki_lee_6144: DF89BM, COVE6R, and IIHXDG.\n",
      "\n",
      "Could you please specify which reservation you want to change? If you are not sure, you can provide more details about the flight such as the destination or date, and I can help identify the correct reservation.\n",
      "\n",
      "üõ†Ô∏è ORIGINAL TOOL CALLS: None\n",
      "\n",
      "üîÑ REPLAY RESPONSE:\n",
      "----------------------------------------\n",
      "Sure, let's start by getting your reservation details. Please provide the reservation ID for the flight you're interested in changing.\n",
      "\n",
      "üõ†Ô∏è REPLAY TOOL CALLS: None\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üéØ PARTIAL TRAJECTORY 4 (10 messages).\n",
      "Generation time: 1.05 seconds\n",
      "================================================================================\n",
      "\n",
      "üìù ORIGINAL RESPONSE:\n",
      "----------------------------------------\n",
      "No content\n",
      "\n",
      "üõ†Ô∏è ORIGINAL TOOL CALLS:\n",
      "----------------------------------------\n",
      "  1. get_reservation_details: {\"reservation_id\": \"DF89BM\"}\n",
      "  2. get_reservation_details: {\"reservation_id\": \"COVE6R\"}\n",
      "  3. get_reservation_details: {\"reservation_id\": \"IIHXDG\"}\n",
      "\n",
      "üîÑ REPLAY RESPONSE:\n",
      "----------------------------------------\n",
      "Sure thing! Let me see what I can find. Based on the information you've provided, it seems like the reservation ID for the flight you're interested in is COVE6R. Could you confirm if this is the correct one?\n",
      "\n",
      "üõ†Ô∏è REPLAY TOOL CALLS: None\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üéØ PARTIAL TRAJECTORY 5 (14 messages).\n",
      "Generation time: 1.66 seconds\n",
      "================================================================================\n",
      "\n",
      "üìù ORIGINAL RESPONSE:\n",
      "----------------------------------------\n",
      "The reservation DF89BM has a flight departing from JFK on May 17. It is a round trip with basic economy cabin. The flights are JFK to ORD on May 17, ORD to DTW on May 17, and DTW to JFK on May 24.\n",
      "\n",
      "Would you like to change this reservation to an earlier nonstop flight from JFK? If yes, please confirm and provide the preferred date for the earlier flight. Note that basic economy flights cannot be modified to change flights, only cabin changes are allowed. Would you like me to check for available nonstop flights from JFK on your preferred date?\n",
      "\n",
      "üõ†Ô∏è ORIGINAL TOOL CALLS: None\n",
      "\n",
      "üîÑ REPLAY RESPONSE:\n",
      "----------------------------------------\n",
      "Based on the details you provided, here are the changes you can make:\n",
      "\n",
      "1. Change the flight from JFK to DTW on May 17.\n",
      "2. Adjust the price of the flight from $63 to $78.\n",
      "3. Update the total baggage allowance to 2 bags.\n",
      "\n",
      "Would you like to proceed with these changes?\n",
      "\n",
      "üõ†Ô∏è REPLAY TOOL CALLS: None\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üéØ PARTIAL TRAJECTORY 6 (16 messages).\n",
      "Generation time: 5.38 seconds\n",
      "================================================================================\n",
      "\n",
      "üìù ORIGINAL RESPONSE:\n",
      "----------------------------------------\n",
      "Since your current reservation DF89BM is booked in basic economy cabin, changing flights is not allowed under the policy. Only cabin changes are allowed for basic economy, but not changing the flights themselves.\n",
      "\n",
      "Would you like me to check for available nonstop flights from JFK to your destination on May 17 anyway, or assist you with any other request?\n",
      "\n",
      "üõ†Ô∏è ORIGINAL TOOL CALLS: None\n",
      "\n",
      "üîÑ REPLAY RESPONSE:\n",
      "----------------------------------------\n",
      "<tool_call>\n",
      "{\"name\": \"search_onestop_flight\", \"arguments\": {\"origin\": \"JFK\", \"destination\": \"DTW\", \"date\": \"2024-05-17\"}}\n",
      "</tool_call>\n",
      "<tool_call>\n",
      "{\"name\": \"cancel_reservation\", \"arguments\": {\"reservation_id\": \"DF89BM\"}}\n",
      "</tool_call>\n",
      "<tool_call>\n",
      "{\"name\": \"update_reservation_baggages\", \"arguments\": {\"reservation_id\": \"DF89BM\", \"total_baggages\": 0, \"nonfree_baggages\": 0, \"payment_id\": \"gift_card_3112961\", \"amount\": 100}}\n",
      "</tool_call>\n",
      "<tool_call>\n",
      "{\"name\": \"cancel_reservation\", \"arguments\": {\"reservation_id\": \"COVE6R\"}}\n",
      "</tool_call>\n",
      "<tool_call>\n",
      "{\"name\": \"update_reservation_baggages\", \"arguments\": {\"reservation_id\": \"COVE6R\", \"total_baggages\": 2, \"nonfree_baggages\": 0, \"payment_id\": \"gift_card_5128346\", \"amount\": 100}}\n",
      "</tool_call>\n",
      "<tool_call>\n",
      "{\"name\": \"cancel_reservation\", \"arguments\": {\"reservation_id\": \"IIHXDG\"}}\n",
      "</tool_call>\n",
      "\n",
      "üõ†Ô∏è REPLAY TOOL CALLS:\n",
      "----------------------------------------\n",
      "  1. search_onestop_flight: {'origin': 'JFK', 'destination': 'DTW', 'date': '2024-05-17'}\n",
      "  2. cancel_reservation: {'reservation_id': 'DF89BM'}\n",
      "  3. update_reservation_baggages: {'reservation_id': 'DF89BM', 'total_baggages': 0, 'nonfree_baggages': 0, 'payment_id': 'gift_card_3112961', 'amount': 100}\n",
      "  4. cancel_reservation: {'reservation_id': 'COVE6R'}\n",
      "  5. update_reservation_baggages: {'reservation_id': 'COVE6R', 'total_baggages': 2, 'nonfree_baggages': 0, 'payment_id': 'gift_card_5128346', 'amount': 100}\n",
      "  6. cancel_reservation: {'reservation_id': 'IIHXDG'}\n",
      "\n",
      "\n",
      "================================================================================\n",
      "üéØ PARTIAL TRAJECTORY 7 (18 messages).\n",
      "Generation time: 0.60 seconds\n",
      "================================================================================\n",
      "\n",
      "üìù ORIGINAL RESPONSE:\n",
      "----------------------------------------\n",
      "You're welcome. If you need any further assistance in the future, feel free to reach out. Have a good day!\n",
      "\n",
      "üõ†Ô∏è ORIGINAL TOOL CALLS: None\n",
      "\n",
      "üîÑ REPLAY RESPONSE:\n",
      "----------------------------------------\n",
      "Sure thing! Let me know when you're ready to proceed with the change.\n",
      "\n",
      "üõ†Ô∏è REPLAY TOOL CALLS: None\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def create_partial_trajectories(datapoint: OpenAICompletionDataPoint) -> list[OpenAICompletionDataPoint]:\n",
    "    messages = datapoint.messages\n",
    "    tools = datapoint.tools\n",
    "    partial_trajectories = []\n",
    "    for i, message in enumerate(messages):\n",
    "        if message[\"role\"] == \"assistant\":\n",
    "\n",
    "            partial_trajectories.append(OpenAICompletionDataPoint(messages=messages[:i+1], tools=tools, parallel_tool_calls=datapoint.parallel_tool_calls))\n",
    "    return partial_trajectories\n",
    "\n",
    "partial_trajectories = create_partial_trajectories(dataset[0])\n",
    "\n",
    "def replay(datapoint, max_new_tokens=32768, enable_thinking=False, verbose=False, add_generation_prompt=True):\n",
    "    partial_trajectories = create_partial_trajectories(datapoint)\n",
    "    for i, partial_trajectory in enumerate(partial_trajectories):\n",
    "        original_response = partial_trajectory.messages[-1]\n",
    "        convo_history = partial_trajectory.messages[:-1]\n",
    "        start_time = time.perf_counter()\n",
    "\n",
    "        replay_response, thinking_content = generate_response_qwen(convo_history, partial_trajectory.tools, tokenizer, model, add_generation_prompt=add_generation_prompt, max_new_tokens=max_new_tokens, enable_thinking=enable_thinking, verbose=verbose)\n",
    "        print(\"=\" * 80)\n",
    "        print(f\"üéØ PARTIAL TRAJECTORY {i} ({len(partial_trajectory.messages)} messages).\\nGeneration time: {time.perf_counter() - start_time:.2f} seconds\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        print(\"\\nüìù ORIGINAL RESPONSE:\")\n",
    "        print(\"-\" * 40)\n",
    "        print(original_response.get('content', \"No content\"))\n",
    "        \n",
    "        # Show original tool calls\n",
    "        if original_response.get('tool_calls'):\n",
    "            print(\"\\nüõ†Ô∏è ORIGINAL TOOL CALLS:\")\n",
    "            print(\"-\" * 40)\n",
    "            for j, tool_call in enumerate(original_response.get('tool_calls', [])):\n",
    "                print(f\"  {j+1}. {tool_call['function']['name']}: {tool_call['function']['arguments']}\")\n",
    "        else:\n",
    "            print(\"\\nüõ†Ô∏è ORIGINAL TOOL CALLS: None\")\n",
    "        \n",
    "        if thinking_content:\n",
    "            print(\"\\nüí≠ THINKING CONTENT:\")\n",
    "            print(\"-\" * 40)\n",
    "            print(thinking_content)\n",
    "        \n",
    "        print(\"\\nüîÑ REPLAY RESPONSE:\")\n",
    "        print(\"-\" * 40)\n",
    "        print(replay_response)\n",
    "        \n",
    "        tool_calls = parse_tool_calls_qwen(replay_response)\n",
    "        if tool_calls:\n",
    "            print(\"\\nüõ†Ô∏è REPLAY TOOL CALLS:\")\n",
    "            print(\"-\" * 40)\n",
    "            for j, tool_call in enumerate(tool_calls):\n",
    "                print(f\"  {j+1}. {tool_call['name']}: {tool_call['arguments']}\")\n",
    "        else:\n",
    "            print(\"\\nüõ†Ô∏è REPLAY TOOL CALLS: None\")\n",
    "        \n",
    "        print(\"\\n\")\n",
    "\n",
    "replay(dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7a2135",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "375bcf9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1107 datapoints\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "from experiments.model_training.prepare_dataset import OpenAICompletionDataPoint\n",
    "import json\n",
    "dataset_path = \"data/test_full-v1.jsonl\"\n",
    "dataset = []\n",
    "with open(dataset_path, \"r\") as f:\n",
    "    for line in f:\n",
    "        datapoint = OpenAICompletionDataPoint.model_validate_json(line)\n",
    "        dataset.append(datapoint)\n",
    "print(f\"Loaded {len(dataset)} datapoints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "43e061f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "train_dataset = Dataset.from_list([dp.model_dump() for dp in dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3b519e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"function\": {\n",
      "        \"description\": \"Book a reservation.\",\n",
      "        \"name\": \"book_reservation\",\n",
      "        \"parameters\": {\n",
      "            \"$defs\": {\n",
      "                \"APNNames\": null,\n",
      "                \"APNSettings\": null,\n",
      "                \"FlightInfo\": {\n",
      "                    \"properties\": {\n",
      "                        \"date\": {\n",
      "                            \"description\": \"The date for the flight in the format 'YYYY-MM-DD', such as '2024-05-01'.\",\n",
      "                            \"title\": \"Date\",\n",
      "                            \"type\": \"string\"\n",
      "                        },\n",
      "                        \"flight_number\": {\n",
      "                            \"description\": \"Flight number, such as 'HAT001'.\",\n",
      "                            \"title\": \"Flight Number\",\n",
      "                            \"type\": \"string\"\n",
      "                        }\n",
      "                    },\n",
      "                    \"required\": [\n",
      "                        \"flight_number\",\n",
      "                        \"date\"\n",
      "                    ],\n",
      "                    \"title\": \"FlightInfo\",\n",
      "                    \"type\": \"object\"\n",
      "                },\n",
      "                \"NetworkModePreference\": null,\n",
      "                \"Passenger\": {\n",
      "                    \"properties\": {\n",
      "                        \"dob\": {\n",
      "                            \"description\": \"Date of birth in YYYY-MM-DD format\",\n",
      "                            \"title\": \"Dob\",\n",
      "                            \"type\": \"string\"\n",
      "                        },\n",
      "                        \"first_name\": {\n",
      "                            \"description\": \"Passenger's first name\",\n",
      "                            \"title\": \"First Name\",\n",
      "                            \"type\": \"string\"\n",
      "                        },\n",
      "                        \"last_name\": {\n",
      "                            \"description\": \"Passenger's last name\",\n",
      "                            \"title\": \"Last Name\",\n",
      "                            \"type\": \"string\"\n",
      "                        }\n",
      "                    },\n",
      "                    \"required\": [\n",
      "                        \"first_name\",\n",
      "                        \"last_name\",\n",
      "                        \"dob\"\n",
      "                    ],\n",
      "                    \"title\": \"Passenger\",\n",
      "                    \"type\": \"object\"\n",
      "                },\n",
      "                \"Payment\": {\n",
      "                    \"properties\": {\n",
      "                        \"amount\": {\n",
      "                            \"description\": \"Payment amount in dollars\",\n",
      "                            \"title\": \"Amount\",\n",
      "                            \"type\": \"integer\"\n",
      "                        },\n",
      "                        \"payment_id\": {\n",
      "                            \"description\": \"Unique identifier for the payment\",\n",
      "                            \"title\": \"Payment Id\",\n",
      "                            \"type\": \"string\"\n",
      "                        }\n",
      "                    },\n",
      "                    \"required\": [\n",
      "                        \"payment_id\",\n",
      "                        \"amount\"\n",
      "                    ],\n",
      "                    \"title\": \"Payment\",\n",
      "                    \"type\": \"object\"\n",
      "                }\n",
      "            },\n",
      "            \"properties\": {\n",
      "                \"address1\": null,\n",
      "                \"address2\": null,\n",
      "                \"amount\": null,\n",
      "                \"apn_settings\": null,\n",
      "                \"app_name\": null,\n",
      "                \"bill_id\": null,\n",
      "                \"cabin\": {\n",
      "                    \"description\": \"The cabin class such as 'basic_economy', 'economy', or 'business'.\",\n",
      "                    \"enum\": [\n",
      "                        \"business\",\n",
      "                        \"economy\",\n",
      "                        \"basic_economy\"\n",
      "                    ],\n",
      "                    \"title\": \"Cabin\",\n",
      "                    \"type\": \"string\"\n",
      "                },\n",
      "                \"city\": null,\n",
      "                \"country\": null,\n",
      "                \"customer_id\": null,\n",
      "                \"date\": null,\n",
      "                \"destination\": {\n",
      "                    \"description\": \"The IATA code for the destination city such as 'JFK'.\",\n",
      "                    \"title\": \"Destination\",\n",
      "                    \"type\": \"string\"\n",
      "                },\n",
      "                \"dob\": null,\n",
      "                \"email\": null,\n",
      "                \"expression\": null,\n",
      "                \"first_name\": null,\n",
      "                \"flight_number\": null,\n",
      "                \"flight_type\": {\n",
      "                    \"description\": \"The type of flight such as 'one_way' or 'round_trip'.\",\n",
      "                    \"enum\": [\n",
      "                        \"round_trip\",\n",
      "                        \"one_way\"\n",
      "                    ],\n",
      "                    \"title\": \"Flight Type\",\n",
      "                    \"type\": \"string\"\n",
      "                },\n",
      "                \"flights\": {\n",
      "                    \"description\": \"An array of objects containing details about each piece of flight.\",\n",
      "                    \"items\": {\n",
      "                        \"anyOf\": [\n",
      "                            {\n",
      "                                \"$ref\": \"#/$defs/FlightInfo\",\n",
      "                                \"additionalProperties\": null,\n",
      "                                \"type\": null\n",
      "                            },\n",
      "                            {\n",
      "                                \"$ref\": null,\n",
      "                                \"additionalProperties\": true,\n",
      "                                \"type\": \"object\"\n",
      "                            }\n",
      "                        ]\n",
      "                    },\n",
      "                    \"title\": \"Flights\",\n",
      "                    \"type\": \"array\"\n",
      "                },\n",
      "                \"full_name\": null,\n",
      "                \"gb_amount\": null,\n",
      "                \"id\": null,\n",
      "                \"insurance\": {\n",
      "                    \"description\": \"Whether the reservation has insurance.\",\n",
      "                    \"enum\": [\n",
      "                        \"yes\",\n",
      "                        \"no\"\n",
      "                    ],\n",
      "                    \"title\": \"Insurance\",\n",
      "                    \"type\": \"string\"\n",
      "                },\n",
      "                \"item_ids\": null,\n",
      "                \"last_name\": null,\n",
      "                \"limit\": null,\n",
      "                \"line_id\": null,\n",
      "                \"mode\": null,\n",
      "                \"new_item_ids\": null,\n",
      "                \"nonfree_baggages\": {\n",
      "                    \"description\": \"The number of non-free baggage items to book the reservation.\",\n",
      "                    \"title\": \"Nonfree Baggages\",\n",
      "                    \"type\": \"integer\"\n",
      "                },\n",
      "                \"order_id\": null,\n",
      "                \"origin\": {\n",
      "                    \"description\": \"The IATA code for the origin city such as 'SFO'.\",\n",
      "                    \"title\": \"Origin\",\n",
      "                    \"type\": \"string\"\n",
      "                },\n",
      "                \"passengers\": {\n",
      "                    \"description\": \"An array of objects containing details about each passenger.\",\n",
      "                    \"items\": {\n",
      "                        \"anyOf\": [\n",
      "                            {\n",
      "                                \"$ref\": \"#/$defs/Passenger\",\n",
      "                                \"additionalProperties\": null,\n",
      "                                \"type\": null\n",
      "                            },\n",
      "                            {\n",
      "                                \"$ref\": null,\n",
      "                                \"additionalProperties\": true,\n",
      "                                \"type\": \"object\"\n",
      "                            }\n",
      "                        ]\n",
      "                    },\n",
      "                    \"title\": \"Passengers\",\n",
      "                    \"type\": \"array\"\n",
      "                },\n",
      "                \"payment_id\": null,\n",
      "                \"payment_method_id\": null,\n",
      "                \"payment_methods\": {\n",
      "                    \"description\": \"An array of objects containing details about each payment method.\",\n",
      "                    \"items\": {\n",
      "                        \"anyOf\": [\n",
      "                            {\n",
      "                                \"$ref\": \"#/$defs/Payment\",\n",
      "                                \"additionalProperties\": null,\n",
      "                                \"type\": null\n",
      "                            },\n",
      "                            {\n",
      "                                \"$ref\": null,\n",
      "                                \"additionalProperties\": true,\n",
      "                                \"type\": \"object\"\n",
      "                            }\n",
      "                        ]\n",
      "                    },\n",
      "                    \"title\": \"Payment Methods\",\n",
      "                    \"type\": \"array\"\n",
      "                },\n",
      "                \"permission\": null,\n",
      "                \"phone_number\": null,\n",
      "                \"product_id\": null,\n",
      "                \"reason\": null,\n",
      "                \"reservation_id\": null,\n",
      "                \"state\": null,\n",
      "                \"summary\": null,\n",
      "                \"total_baggages\": {\n",
      "                    \"description\": \"The total number of baggage items to book the reservation.\",\n",
      "                    \"title\": \"Total Baggages\",\n",
      "                    \"type\": \"integer\"\n",
      "                },\n",
      "                \"user_id\": {\n",
      "                    \"description\": \"The ID of the user to book the reservation such as 'sara_doe_496'`.\",\n",
      "                    \"title\": \"User Id\",\n",
      "                    \"type\": \"string\"\n",
      "                },\n",
      "                \"zip\": null\n",
      "            },\n",
      "            \"required\": [\n",
      "                \"user_id\",\n",
      "                \"origin\",\n",
      "                \"destination\",\n",
      "                \"flight_type\",\n",
      "                \"cabin\",\n",
      "                \"flights\",\n",
      "                \"passengers\",\n",
      "                \"payment_methods\",\n",
      "                \"total_baggages\",\n",
      "                \"nonfree_baggages\",\n",
      "                \"insurance\"\n",
      "            ],\n",
      "            \"title\": \"parameters\",\n",
      "            \"type\": \"object\"\n",
      "        }\n",
      "    },\n",
      "    \"type\": \"function\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# from experiments.model_training.prepare_dataset import remove_none_values\n",
    "\n",
    "print(json.dumps(train_dataset[0][\"tools\"][0], indent=4))\n",
    "\n",
    "# remove_none_values(train_dataset[0])\n",
    "\n",
    "# print(json.dumps(train_dataset[0][\"tools\"][0], indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09b0944",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Your setup doesn't support bf16/gpu.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     17\u001b[39m     learning_rate = \u001b[32m8e-5\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m sft_config = \u001b[43mSFTConfig\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43massistant_only_loss\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# Only compute the loss on the assistant messages\u001b[39;49;00m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreport_to\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mnone\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                        \u001b[49m\u001b[38;5;66;43;03m# disable logging to W&B\u001b[39;49;00m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlogging_strategy\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msteps\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m                      \u001b[49m\u001b[38;5;66;43;03m# Learning rate for training. \u001b[39;49;00m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_train_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                     \u001b[49m\u001b[38;5;66;43;03m#  Set the number of epochs to train the model.\u001b[39;49;00m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43mper_device_train_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m           \u001b[49m\u001b[38;5;66;43;03m# Batch size for each device (e.g., GPU) during training. \u001b[39;49;00m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgradient_accumulation_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m           \u001b[49m\u001b[38;5;66;43;03m# Number of steps before performing a backward/update pass to accumulate gradients.\u001b[39;49;00m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgradient_checkpointing\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m             \u001b[49m\u001b[38;5;66;43;03m# Enable gradient checkpointing to reduce memory usage during training at the cost of slower training speed.\u001b[39;49;00m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlogging_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                         \u001b[49m\u001b[38;5;66;43;03m# Frequency of logging training progress (log every 2 steps).\u001b[39;49;00m\n\u001b[32m     29\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_strategy\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mepoch\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                   \u001b[49m\u001b[38;5;66;43;03m# evaluate at end of each epoch\u001b[39;49;00m\n\u001b[32m     30\u001b[39m \u001b[43m    \u001b[49m\u001b[43msave_strategy\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mepoch\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                   \u001b[49m\u001b[38;5;66;43;03m# save checkpoint at end of each epoch\u001b[39;49;00m\n\u001b[32m     31\u001b[39m \u001b[43m    \u001b[49m\u001b[43msave_total_limit\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                      \u001b[49m\u001b[38;5;66;43;03m# keep only the best/latest model\u001b[39;49;00m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[43mload_best_model_at_end\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m             \u001b[49m\u001b[38;5;66;43;03m# load best model according to eval loss\u001b[39;49;00m\n\u001b[32m     33\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetric_for_best_model\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meval_loss\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;66;43;03m# use eval loss for best model selection\u001b[39;49;00m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgreater_is_better\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m                 \u001b[49m\u001b[38;5;66;43;03m# lower eval_loss is better\u001b[39;49;00m\n\u001b[32m     35\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m               \u001b[49m\u001b[38;5;66;43;03m# directory to save checkpoints\u001b[39;49;00m\n\u001b[32m     36\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# Instantiate early stopping callback\u001b[39;00m\n\u001b[32m     40\u001b[39m early_stopping_callback = EarlyStoppingCallback(\n\u001b[32m     41\u001b[39m     early_stopping_patience=\u001b[32m2\u001b[39m  \u001b[38;5;66;03m# Stop if no improvement for 2 evals (epochs)\u001b[39;00m\n\u001b[32m     42\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:149\u001b[39m, in \u001b[36m__init__\u001b[39m\u001b[34m(self, output_dir, overwrite_output_dir, do_train, do_eval, do_predict, eval_strategy, prediction_loss_only, per_device_train_batch_size, per_device_eval_batch_size, per_gpu_train_batch_size, per_gpu_eval_batch_size, gradient_accumulation_steps, eval_accumulation_steps, eval_delay, torch_empty_cache_steps, learning_rate, weight_decay, adam_beta1, adam_beta2, adam_epsilon, max_grad_norm, num_train_epochs, max_steps, lr_scheduler_type, lr_scheduler_kwargs, warmup_ratio, warmup_steps, log_level, log_level_replica, log_on_each_node, logging_dir, logging_strategy, logging_first_step, logging_steps, logging_nan_inf_filter, save_strategy, save_steps, save_total_limit, save_safetensors, save_on_each_node, save_only_model, restore_callback_states_from_checkpoint, no_cuda, use_cpu, use_mps_device, seed, data_seed, jit_mode_eval, use_ipex, bf16, fp16, fp16_opt_level, half_precision_backend, bf16_full_eval, fp16_full_eval, tf32, local_rank, ddp_backend, tpu_num_cores, tpu_metrics_debug, debug, dataloader_drop_last, eval_steps, dataloader_num_workers, dataloader_prefetch_factor, past_index, run_name, disable_tqdm, remove_unused_columns, label_names, load_best_model_at_end, metric_for_best_model, greater_is_better, ignore_data_skip, fsdp, fsdp_min_num_params, fsdp_config, fsdp_transformer_layer_cls_to_wrap, accelerator_config, deepspeed, label_smoothing_factor, optim, optim_args, adafactor, group_by_length, length_column_name, report_to, ddp_find_unused_parameters, ddp_bucket_cap_mb, ddp_broadcast_buffers, dataloader_pin_memory, dataloader_persistent_workers, skip_memory_metrics, use_legacy_prediction_loop, push_to_hub, resume_from_checkpoint, hub_model_id, hub_strategy, hub_token, hub_private_repo, hub_always_push, hub_revision, gradient_checkpointing, gradient_checkpointing_kwargs, include_inputs_for_metrics, include_for_metrics, eval_do_concat_batches, fp16_backend, push_to_hub_model_id, push_to_hub_organization, push_to_hub_token, mp_parameters, auto_find_batch_size, full_determinism, torchdynamo, ray_scope, ddp_timeout, torch_compile, torch_compile_backend, torch_compile_mode, include_tokens_per_second, include_num_input_tokens_seen, neftune_noise_alpha, optim_target_modules, batch_eval_metrics, eval_on_start, use_liger_kernel, liger_kernel_config, eval_use_gather_object, average_tokens_across_devices, model_init_kwargs, chat_template_path, dataset_text_field, dataset_kwargs, dataset_num_proc, eos_token, pad_token, max_length, packing, packing_strategy, padding_free, pad_to_multiple_of, eval_packing, completion_only_loss, assistant_only_loss, activation_offloading)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/tau2-bench-private/.venv/lib/python3.13/site-packages/trl/trainer/sft_config.py:247\u001b[39m, in \u001b[36mSFTConfig.__post_init__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__post_init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    246\u001b[39m     \u001b[38;5;28mself\u001b[39m.bf16 = \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.fp16) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.bf16 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.bf16\n\u001b[32m--> \u001b[39m\u001b[32m247\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m__post_init__\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/tau2-bench-private/.venv/lib/python3.13/site-packages/transformers/training_args.py:1731\u001b[39m, in \u001b[36mTrainingArguments.__post_init__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1729\u001b[39m                     error_message += \u001b[33m\"\u001b[39m\u001b[33m You need Ampere+ GPU with cuda>=11.0\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1730\u001b[39m                 \u001b[38;5;66;03m# gpu\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1731\u001b[39m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(error_message)\n\u001b[32m   1733\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fp16 \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.bf16:\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mAt most one of fp16 and bf16 can be True, but not both\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: Your setup doesn't support bf16/gpu."
     ]
    }
   ],
   "source": [
    "from trl import SFTConfig, SFTTrainer\n",
    "from transformers import EarlyStoppingCallback\n",
    "from peft import LoraConfig, TaskType, get_peft_model\n",
    "\n",
    "MODEL_NAME = \"/home/ubuntu/victor-north-tx/models/Qwen2.5-0.5B-instruct\"\n",
    "\n",
    "\n",
    "## NOTE\n",
    "## Tabular backends like Arrow/Parquet insert `None` for mismatched keys in nested structures.\n",
    "## Those are cleaned up by SFTTraining using remove_non_values\n",
    "## https://github.com/huggingface/trl/blob/30576d2ddcf2c0e17c399399e2465fbe81446ade/trl/trainer/sft_trainer.py#L71\n",
    "## Pushed to prepare_dataset.py -> remove_none_values\n",
    "## Warning: Those None values will make generation fail if not cleaned up.\n",
    "\n",
    "output_dir = \"./data/SFTcheckpoints\"\n",
    "\n",
    "USE_PEFT = True\n",
    "if USE_PEFT:\n",
    "    learning_rate = 1e-4 # Higher learning rate for PEFT?\n",
    "else:\n",
    "    learning_rate = 8e-5\n",
    "\n",
    "sft_config = SFTConfig(\n",
    "    assistant_only_loss=True,                # Only compute the loss on the assistant messages\n",
    "    report_to=\"none\",                        # disable logging to W&B\n",
    "    logging_strategy=\"steps\",\n",
    "    learning_rate=learning_rate,                      # Learning rate for training. \n",
    "    num_train_epochs=20,                     #  Set the number of epochs to train the model.\n",
    "    per_device_train_batch_size=2,           # Batch size for each device (e.g., GPU) during training. \n",
    "    gradient_accumulation_steps=8,           # Number of steps before performing a backward/update pass to accumulate gradients.\n",
    "    gradient_checkpointing=True,             # Enable gradient checkpointing to reduce memory usage during training at the cost of slower training speed.\n",
    "    logging_steps=2,                         # Frequency of logging training progress (log every 2 steps).\n",
    "    eval_strategy=\"epoch\",                   # evaluate at end of each epoch\n",
    "    save_strategy=\"epoch\",                   # save checkpoint at end of each epoch\n",
    "    save_total_limit=1,                      # keep only the best/latest model\n",
    "    load_best_model_at_end=True,             # load best model according to eval loss\n",
    "    metric_for_best_model=\"eval_loss\",       # use eval loss for best model selection\n",
    "    greater_is_better=False,                 # lower eval_loss is better\n",
    "    output_dir=output_dir               # directory to save checkpoints\n",
    ")\n",
    "\n",
    "\n",
    "# Instantiate early stopping callback\n",
    "early_stopping_callback = EarlyStoppingCallback(\n",
    "    early_stopping_patience=2  # Stop if no improvement for 2 evals (epochs)\n",
    ")\n",
    "\n",
    "tokenizer, model = get_model_and_tokenizer(MODEL_NAME, torch_dtype=\"auto\", device_map=\"auto\")\n",
    "\n",
    "if USE_PEFT: # FIXME: Check what's the right config.\n",
    "    # lora_config = LoraConfig(\n",
    "    #     r=64,\n",
    "    #     lora_alpha=16,\n",
    "    #     target_modules=[\"c_attn\", \"q_proj\", \"v_proj\"],  # adjust to Qwen architecture\n",
    "    #     lora_dropout=0.05,\n",
    "    #     bias=\"none\",\n",
    "    #     task_type=TaskType.CAUSAL_LM,\n",
    "    # )\n",
    "    lora_config = LoraConfig()\n",
    "else:\n",
    "    lora_config = None\n",
    "\n",
    "sft_trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=sft_config,\n",
    "    train_dataset=train_dataset,\n",
    "    processing_class=tokenizer,\n",
    "    callbacks=[early_stopping_callback],\n",
    "    peft_config=lora_config \n",
    "    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b057d3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tau2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
