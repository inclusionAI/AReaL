{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b50d1f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/tau2/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\u001b[32m2025-08-05 11:55:35.502\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtau2.utils.utils\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mUsing data directory from source: /lambda/nfs/victor-north-tx/tau2-bench-private/data\u001b[0m\n",
      "\u001b[32m2025-08-05 11:55:36.722\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtau2.utils.llm_utils\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mVLLM_API_BASE: http://127.0.0.1:8000/v1\u001b[0m\n",
      "\u001b[32m2025-08-05 11:55:36.722\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtau2.utils.llm_utils\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m44\u001b[0m - \u001b[1mOLLAMA_API_BASE: http://127.0.0.1:11434\u001b[0m\n",
      "\u001b[32m2025-08-05 11:55:36.723\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtau2.utils.llm_utils\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m78\u001b[0m - \u001b[1mLiteLLM: Cache is disabled\u001b[0m\n",
      "\u001b[32m2025-08-05 11:55:36.723\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mtau2.utils.llm_utils\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m85\u001b[0m - \u001b[33m\u001b[1mSonnet thinking is disabled\u001b[0m\n",
      "\u001b[32m2025-08-05 11:55:36.797\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtau2.registry\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m194\u001b[0m - \u001b[34m\u001b[1mRegistering default components...\u001b[0m\n",
      "\u001b[32m2025-08-05 11:55:36.798\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtau2.registry\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m236\u001b[0m - \u001b[34m\u001b[1mDefault components registered successfully. Registry info: {\n",
      "  \"domains\": [\n",
      "    \"mock\",\n",
      "    \"airline\",\n",
      "    \"retail\",\n",
      "    \"telecom\",\n",
      "    \"telecom-workflow\"\n",
      "  ],\n",
      "  \"agents\": [\n",
      "    \"llm_agent\",\n",
      "    \"llm_agent_gt\",\n",
      "    \"llm_agent_solo\",\n",
      "    \"llm_agent_completion\",\n",
      "    \"llm_agent_gt_completion\",\n",
      "    \"llm_agent_solo_completion\"\n",
      "  ],\n",
      "  \"users\": [\n",
      "    \"user_simulator\",\n",
      "    \"dummy_user\"\n",
      "  ],\n",
      "  \"task_sets\": [\n",
      "    \"mock\",\n",
      "    \"airline\",\n",
      "    \"retail\",\n",
      "    \"telecom\",\n",
      "    \"telecom-workflow\"\n",
      "  ]\n",
      "}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from experiments.model_training.train_qwen import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7753721a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset length: 1722\n",
      "Test dataset length: 1107\n",
      "Loading tokenizer and model for /home/ubuntu/victor-north-tx/models/Qwen2.5-3B-instruct\n",
      "Tokenizer has a chat template.\n",
      "Tokenizer eos_token_id: 151645, pad_token_id: 151643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded in 12.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing train dataset: 100%|██████████| 1722/1722 [00:35<00:00, 49.00 examples/s]\n",
      "Truncating train dataset: 100%|██████████| 1722/1722 [00:00<00:00, 7020.18 examples/s]\n",
      "Tokenizing eval dataset: 100%|██████████| 1107/1107 [00:22<00:00, 48.90 examples/s]\n",
      "Truncating eval dataset: 100%|██████████| 1107/1107 [00:00<00:00, 9212.11 examples/s] \n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='371' max='2160' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 371/2160 11:33 < 56:03, 0.53 it/s, Epoch 3.43/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>0.001436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>0.001415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.001359</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "model_name = \"Qwen2.5-3B-instruct\"\n",
    "qwen_model = f\"/home/ubuntu/victor-north-tx/models/{model_name}\"\n",
    "train_dataset_path = \"data/train_full-v1.jsonl\"\n",
    "test_dataset_path = \"data/test_full-v1.jsonl\"\n",
    "trained_model_name = f\"{model_name}-sft-full-tau2-v1\"\n",
    "output_dir = f\"./data/{trained_model_name}\"\n",
    "report_to_wandb = True\n",
    "run_name = f\"{trained_model_name}\"\n",
    "if Path(output_dir).exists():\n",
    "    raise ValueError(f\"Output directory {output_dir} already exists. Please delete it or choose a different output directory.\")\n",
    "\n",
    "max_train_datapoints = None\n",
    "max_test_datapoints = None\n",
    "use_peft = False\n",
    "patience = 2\n",
    "\n",
    "train(\n",
    "    qwen_model=qwen_model, \n",
    "    train_dataset_path=train_dataset_path, \n",
    "    test_dataset_path=test_dataset_path, \n",
    "    output_dir=output_dir, \n",
    "    max_train_datapoints=max_train_datapoints, \n",
    "    max_test_datapoints=max_test_datapoints, \n",
    "    use_peft=use_peft,\n",
    "    patience=patience,\n",
    "    report_to_wandb=report_to_wandb,\n",
    "    run_name=run_name\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "327a8a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/tau2/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\u001b[32m2025-08-05 12:12:24.497\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtau2.utils.utils\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mUsing data directory from source: /lambda/nfs/victor-north-tx/tau2-bench-private/data\u001b[0m\n",
      "\u001b[32m2025-08-05 12:12:25.726\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtau2.utils.llm_utils\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mVLLM_API_BASE: http://127.0.0.1:8000/v1\u001b[0m\n",
      "\u001b[32m2025-08-05 12:12:25.727\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtau2.utils.llm_utils\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m44\u001b[0m - \u001b[1mOLLAMA_API_BASE: http://127.0.0.1:11434\u001b[0m\n",
      "\u001b[32m2025-08-05 12:12:25.728\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtau2.utils.llm_utils\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m78\u001b[0m - \u001b[1mLiteLLM: Cache is disabled\u001b[0m\n",
      "\u001b[32m2025-08-05 12:12:25.728\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mtau2.utils.llm_utils\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m85\u001b[0m - \u001b[33m\u001b[1mSonnet thinking is disabled\u001b[0m\n",
      "\u001b[32m2025-08-05 12:12:25.807\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtau2.registry\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m194\u001b[0m - \u001b[34m\u001b[1mRegistering default components...\u001b[0m\n",
      "\u001b[32m2025-08-05 12:12:25.807\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtau2.registry\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m236\u001b[0m - \u001b[34m\u001b[1mDefault components registered successfully. Registry info: {\n",
      "  \"domains\": [\n",
      "    \"mock\",\n",
      "    \"airline\",\n",
      "    \"retail\",\n",
      "    \"telecom\",\n",
      "    \"telecom-workflow\"\n",
      "  ],\n",
      "  \"agents\": [\n",
      "    \"llm_agent\",\n",
      "    \"llm_agent_gt\",\n",
      "    \"llm_agent_solo\",\n",
      "    \"llm_agent_completion\",\n",
      "    \"llm_agent_gt_completion\",\n",
      "    \"llm_agent_solo_completion\"\n",
      "  ],\n",
      "  \"users\": [\n",
      "    \"user_simulator\",\n",
      "    \"dummy_user\"\n",
      "  ],\n",
      "  \"task_sets\": [\n",
      "    \"mock\",\n",
      "    \"airline\",\n",
      "    \"retail\",\n",
      "    \"telecom\",\n",
      "    \"telecom-workflow\"\n",
      "  ]\n",
      "}\u001b[0m\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'output_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexperiments\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_training\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtrain_qwen\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_model_and_tokenizer\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m model, tokenizer = get_model_and_tokenizer(model_name=\u001b[43moutput_dir\u001b[49m)\n\u001b[32m      3\u001b[39m model\n",
      "\u001b[31mNameError\u001b[39m: name 'output_dir' is not defined"
     ]
    }
   ],
   "source": [
    "from experiments.model_training.train_qwen import get_model_and_tokenizer\n",
    "model, tokenizer = get_model_and_tokenizer(model_name=output_dir)\n",
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22e6ad21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer and model for /home/ubuntu/victor-north-tx/models/Qwen2.5-3B-instruct\n",
      "Tokenizer has a chat template.\n",
      "Tokenizer eos_token = <|im_end|>\n",
      "Tokenizer eos_token_id: 151645, pad_token_id: 151643\n",
      "Tokenizer chat_template supports assistant only loss: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded in 7.04 seconds\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from experiments.model_training.train_qwen import get_model_and_tokenizer, QWEN25_TEMPLATE, check_chat_template_supports_assistant_only_loss\n",
    "\n",
    "model_name = \"Qwen2.5-3B-instruct\"\n",
    "qwen_model = f\"/home/ubuntu/victor-north-tx/models/{model_name}\"\n",
    "tokenizer = get_model_and_tokenizer(qwen_model)[1]\n",
    "tokenizer.chat_template = QWEN25_TEMPLATE\n",
    "tokenizer.eos_token\n",
    "tokenizer.eos_token_id\n",
    "tokenizer.pad_token_id\n",
    "tokenizer.chat_template\n",
    "\n",
    "print(check_chat_template_supports_assistant_only_loss(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97b2ac88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 3838, 374, 279, 6722, 315, 9625, 30, 151645, 198, 151644, 77091, 198, 785, 6722, 315, 9625, 374, 12095, 13, 151645, 271], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'assistant_masks': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['<|im_start|>',\n",
       " 'assistant',\n",
       " '\\n',\n",
       " 'The',\n",
       " ' capital',\n",
       " ' of',\n",
       " ' France',\n",
       " ' is',\n",
       " ' Paris',\n",
       " '.',\n",
       " '<|im_end|>',\n",
       " '\\n\\n']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is the capital of France?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"The capital of France is Paris.\"}\n",
    "]\n",
    "\n",
    "res = tokenizer.apply_chat_template(messages, tokenize=True, return_dict=True, add_generation_prompt=False, return_assistant_tokens_mask=True)\n",
    "print(res)\n",
    "[tokenizer.decode(token_id) for i, token_id in enumerate(res['input_ids']) if res['assistant_masks'][i]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tau2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
