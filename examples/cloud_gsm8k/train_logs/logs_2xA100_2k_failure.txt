2025-11-26T16:55:15.795568224Z ==========
2025-11-26T16:55:15.795572290Z == CUDA ==
2025-11-26T16:55:15.795574593Z ==========
2025-11-26T16:55:15.799810598Z CUDA Version 12.9.1
2025-11-26T16:55:15.805304888Z Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
2025-11-26T16:55:15.805310486Z This container image and its contents are governed by the NVIDIA Deep Learning Container License.
2025-11-26T16:55:15.805313751Z By pulling and using the container, you accept the terms and conditions of this license:
2025-11-26T16:55:15.805315874Z https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license
2025-11-26T16:55:15.805320261Z A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
2025-11-26T16:55:15.966775414Z Writing to /root/.config/pip/pip.conf
2025-11-26T16:55:16.123406401Z Writing to /root/.config/pip/pip.conf
2025-11-26T16:55:16.152815573Z Cloning into 'AReaL'...
2025-11-26T16:55:18.109752923Z Checking AReaL installation...
2025-11-26T16:55:18.173207701Z AReaL already installed. Skipping installation.
2025-11-26T16:55:18.173239499Z Cleaning up any leftover GPU processes...
2025-11-26T16:55:18.173403835Z Installing cleanup tools (psmisc, lsof)...
2025-11-26T16:55:18.306504226Z Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]
2025-11-26T16:55:18.694661105Z Get:3 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]
2025-11-26T16:55:18.913426011Z Get:4 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [38.5 kB]
2025-11-26T16:55:19.000041623Z Get:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [2,153 kB]
2025-11-26T16:55:19.419188281Z Hit:6 https://mirrors.tuna.tsinghua.edu.cn/ubuntu jammy InRelease
2025-11-26T16:55:19.483347825Z Ign:1 https://developer.download.nvidia.com/devtools/repos/ubuntu2004/amd64  InRelease
2025-11-26T16:55:19.728926127Z Get:7 https://developer.download.nvidia.com/devtools/repos/ubuntu2004/amd64  Release [496 B]
2025-11-26T16:55:19.774382896Z Get:8 https://mirrors.tuna.tsinghua.edu.cn/ubuntu jammy-updates InRelease [128 kB]
2025-11-26T16:55:19.922057747Z Get:9 https://developer.download.nvidia.com/devtools/repos/ubuntu2004/amd64  Release.gpg [833 B]
2025-11-26T16:55:20.337439747Z Get:10 https://developer.download.nvidia.com/devtools/repos/ubuntu2004/amd64  Packages [18.8 kB]
2025-11-26T16:55:20.818036050Z Get:11 https://mirrors.tuna.tsinghua.edu.cn/ubuntu jammy-backports InRelease [127 kB]
2025-11-26T16:55:21.292521240Z Get:12 https://mirrors.tuna.tsinghua.edu.cn/ubuntu jammy-security InRelease [129 kB]
2025-11-26T16:55:21.738387512Z Get:13 https://mirrors.tuna.tsinghua.edu.cn/ubuntu jammy-updates/universe amd64 Packages [1,596 kB]
2025-11-26T16:55:22.694581942Z Get:14 https://mirrors.tuna.tsinghua.edu.cn/ubuntu jammy-updates/restricted amd64 Packages [6,222 kB]
2025-11-26T16:55:23.429587855Z Get:15 https://mirrors.tuna.tsinghua.edu.cn/ubuntu jammy-updates/multiverse amd64 Packages [69.2 kB]
2025-11-26T16:55:23.431549073Z Get:16 https://mirrors.tuna.tsinghua.edu.cn/ubuntu jammy-updates/main amd64 Packages [3,876 kB]
2025-11-26T16:55:23.746735119Z Get:17 https://mirrors.tuna.tsinghua.edu.cn/ubuntu jammy-backports/universe amd64 Packages [35.2 kB]
2025-11-26T16:55:23.747053126Z Get:18 https://mirrors.tuna.tsinghua.edu.cn/ubuntu jammy-backports/main amd64 Packages [83.9 kB]
2025-11-26T16:55:23.749962443Z Get:19 https://mirrors.tuna.tsinghua.edu.cn/ubuntu jammy-security/multiverse amd64 Packages [60.9 kB]
2025-11-26T16:55:23.874317113Z Get:20 https://mirrors.tuna.tsinghua.edu.cn/ubuntu jammy-security/universe amd64 Packages [1,290 kB]
2025-11-26T16:55:23.913061909Z Get:21 https://mirrors.tuna.tsinghua.edu.cn/ubuntu jammy-security/restricted amd64 Packages [6,008 kB]
2025-11-26T16:55:24.484186865Z Get:22 https://mirrors.tuna.tsinghua.edu.cn/ubuntu jammy-security/main amd64 Packages [3,539 kB]
2025-11-26T16:55:24.997469569Z Fetched 25.4 MB in 7s (3,765 kB/s)
2025-11-26T16:55:25.805196591Z Reading package lists...
2025-11-26T16:55:25.826707843Z W: http://developer.download.nvidia.com/devtools/repos/ubuntu2004/amd64/Release.gpg: Key is stored in legacy trusted.gpg keyring (/etc/apt/trusted.gpg), see the DEPRECATION section in apt-key(8) for details.
2025-11-26T16:55:26.659442243Z Reading package lists...
2025-11-26T16:55:26.853974341Z Building dependency tree...
2025-11-26T16:55:26.854316814Z Reading state information...
2025-11-26T16:55:27.001366400Z lsof is already the newest version (4.93.2+dfsg-1.1build2).
2025-11-26T16:55:27.001406139Z The following NEW packages will be installed:
2025-11-26T16:55:27.001409203Z   psmisc
2025-11-26T16:55:29.170963572Z 0 upgraded, 1 newly installed, 0 to remove and 70 not upgraded.
2025-11-26T16:55:29.171009471Z Need to get 119 kB of archives.
2025-11-26T16:55:29.171012155Z After this operation, 463 kB of additional disk space will be used.
2025-11-26T16:55:29.171014839Z Get:1 https://mirrors.tuna.tsinghua.edu.cn/ubuntu jammy/main amd64 psmisc amd64 23.4-2build3 [119 kB]
2025-11-26T16:55:29.880749128Z debconf: delaying package configuration, since apt-utils is not installed
2025-11-26T16:55:29.926210453Z Fetched 119 kB in 3s (43.6 kB/s)
2025-11-26T16:55:29.955264483Z Selecting previously unselected package psmisc.
2025-11-26T16:55:29.997288011Z (Reading database ... (Reading database ... 5%(Reading database ... 10%(Reading database ... 15%(Reading database ... 20%(Reading database ... 25%(Reading database ... 30%(Reading database ... 35%(Reading database ... 40%(Reading database ... 45%(Reading database ... 50%(Reading database ... 55%(Reading database ... 60%(Reading database ... 65%(Reading database ... 70%(Reading database ... 75%(Reading database ... 80%(Reading database ... 85%(Reading database ... 90%(Reading database ... 95%(Reading database ... 100%(Reading database ... 70438 files and directories currently installed.)
2025-11-26T16:55:29.998392725Z Preparing to unpack .../psmisc_23.4-2build3_amd64.deb ...
2025-11-26T16:55:30.001273069Z Unpacking psmisc (23.4-2build3) ...
2025-11-26T16:55:30.066324540Z Setting up psmisc (23.4-2build3) ...
2025-11-26T16:55:30.076876746Z Processing triggers for man-db (2.10.2-1) ...
2025-11-26T16:55:33.203328327Z Checking for processes holding GPU device files...
2025-11-26T16:55:35.314842457Z Found processes holding GPU devices: 1
2025-11-26T16:55:35.314900844Z 20
2025-11-26T16:55:35.314903689Z 544
2025-11-26T16:55:35.314905761Z 545
2025-11-26T16:55:35.314907885Z Killing process 1...
2025-11-26T16:55:35.314910659Z Killing process 544...
2025-11-26T16:55:35.314967714Z Killing process 545...
2025-11-26T16:55:37.317973850Z Using fuser to kill processes on GPU devices...
2025-11-26T16:55:39.341516438Z Checking GPU...
2025-11-26T16:55:39.376972137Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T16:55:39.376997756Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T16:55:39.394394343Z Set PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True for better memory management
2025-11-26T16:55:39.394413853Z Detected 2 GPU(s)
2025-11-26T16:55:39.394417127Z Checking GPU status...
2025-11-26T16:55:39.422398471Z index, name, utilization.gpu [%], memory.used [MiB], compute_mode
2025-11-26T16:55:39.423857286Z 0, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T16:55:39.424163264Z 1, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T16:55:39.466255284Z Verifying GPU accessibility...
2025-11-26T16:55:39.991369491Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T16:55:39.991402631Z   import pynvml  # type: ignore[import]
2025-11-26T16:55:41.103224174Z GPU accessibility verified on attempt 1
2025-11-26T16:55:41.553533801Z Starting training...
2025-11-26T16:55:44.556226884Z Using STANDARD 2000 SAMPLES 2 GPUs configuration
2025-11-26T16:55:44.556265933Z Note: GRPO only (no reasoning XML). Dataset capped at 2000 samples (~6 hours).
2025-11-26T16:55:44.556269318Z GPU count: 2 (required: 2)
2025-11-26T16:55:44.558576303Z ==========================================
2025-11-26T16:55:44.558590044Z Starting GRPO Training (Cloud)
2025-11-26T16:55:44.558592868Z ==========================================
2025-11-26T16:55:44.558594871Z Config: standard_2000samples_2GPUs
2025-11-26T16:55:44.558596905Z Config file: examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml
2025-11-26T16:55:44.558599418Z Training script: examples/cloud_gsm8k/gsm8k_grpo_train.py
2025-11-26T16:55:44.558601541Z Experiment: gsm8k-grpo-cloud-2gpu-2000samples
2025-11-26T16:55:44.558603624Z Trial: trial_20251126_165544
2025-11-26T16:55:44.558605658Z GPU: NVIDIA A100 80GB PCIe NVIDIA A100 80GB PCIe (81920 MB)
2025-11-26T16:55:44.558607661Z WandB API key: e1adc5be02...
2025-11-26T16:55:44.558609624Z ==========================================
2025-11-26T16:55:45.255571751Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T16:55:45.255611430Z   import pynvml  # type: ignore[import]
2025-11-26T16:55:49.385480587Z [37m20251126-16:55:49.384 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T16:55:49.385524232Z [37m20251126-16:55:49.385 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T16:55:49.385824842Z [37m20251126-16:55:49.385 name-resolve INFO: No such name resolve path: ./tmp/areal/name_resolve/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_165544[0m
2025-11-26T16:55:49.490804582Z [37m20251126-16:55:49.490 Local Scheduler INFO: LocalLauncher: experiment_name=gsm8k-grpo-cloud-2gpu-2000samples, trial_name=trial_20251126_165544, fileroot=/workspace/outputs/grpo, run_id=0, is_recover_run=False[0m
2025-11-26T16:55:49.498519187Z [37m20251126-16:55:49.498 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL CUDA_VISIBLE_DEVICES=0 stdbuf -oL python3 -m areal.launcher.sglang_server examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_165544 sglang.random_seed=1 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_165544/llm_server.log[0m
2025-11-26T16:55:50.233674504Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T16:55:50.233712241Z   import pynvml  # type: ignore[import]
2025-11-26T16:55:51.737988400Z [37m20251126-16:55:51.737 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T16:55:51.738706376Z [37m20251126-16:55:51.737 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T16:55:51.856095523Z [37m20251126-16:55:51.855 SGLangServer Wrapper INFO: Launch command: python3 -m sglang.launch_server --host 172.21.0.2 --port 12101 --tokenizer-path Qwen/Qwen2.5-0.5B-Instruct --tokenizer-mode auto --load-format auto --trust-remote-code --device cuda --tp-size 1 --base-gpu-id 0 --nnodes 1 --node-rank 0 --dist-init-addr localhost:23825 --model-path Qwen/Qwen2.5-0.5B-Instruct --random-seed 1 --skip-tokenizer-init --disable-radix-cache --torch-compile-max-bs 32 --triton-attention-num-kv-splits 8 --num-continuous-decode-steps 1 --attention-backend flashinfer --context-length 4096 --mem-fraction-static 0.6 --chunked-prefill-size -1 --max-prefill-tokens 32768 --schedule-policy lpm --schedule-conservativeness 1.0 --cpu-offload-gb 0 --dtype bfloat16 --kv-cache-dtype auto --dp-size 1 --ep-size 1 --max-loaded-loras 1 --max-loras-per-batch 1 --lora-backend triton --log-level warning --log-level-http warning --log-requests-level 0 --enable-metrics --decode-log-interval 1[0m
2025-11-26T16:55:52.905845480Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T16:55:52.905897317Z   import pynvml  # type: ignore[import]
2025-11-26T16:55:58.486108777Z INFO 11-26 16:55:58 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T16:55:59.392339457Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T16:56:00.380486028Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T16:56:00.380514651Z   import pynvml  # type: ignore[import]
2025-11-26T16:56:00.416610358Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T16:56:00.416636167Z   import pynvml  # type: ignore[import]
2025-11-26T16:56:05.547579299Z INFO 11-26 16:56:05 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T16:56:05.937332729Z INFO 11-26 16:56:05 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T16:56:06.161809532Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T16:56:06.405635339Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T16:56:06.415896439Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T16:56:06.416776186Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T16:56:06.417598999Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T16:56:06.471853887Z [2025-11-26 16:56:06] MOE_RUNNER_BACKEND is not initialized, using triton backend
2025-11-26T16:56:07.002349365Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T16:56:07.002390325Z   warnings.warn(
2025-11-26T16:56:07.002393310Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T16:56:07.002395763Z   warnings.warn(
2025-11-26T16:56:09.343803060Z Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
2025-11-26T16:56:09.450610106Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  9.38it/s]
2025-11-26T16:56:09.451175763Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  9.36it/s]
2025-11-26T16:56:45.234328244Z   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   4%|â–         | 1/23 [00:33<12:25, 33.89s/it]Capturing batches (bs=152 avail_mem=30.62 GB):   4%|â–         | 1/23 [00:33<12:25, 33.89s/it]Capturing batches (bs=144 avail_mem=30.60 GB):   4%|â–         | 1/23 [00:33<12:25, 33.89s/it]Capturing batches (bs=136 avail_mem=30.59 GB):   4%|â–         | 1/23 [00:33<12:25, 33.89s/it]Capturing batches (bs=136 avail_mem=30.59 GB):  17%|â–ˆâ–‹        | 4/23 [00:34<02:02,  6.45s/it]Capturing batches (bs=128 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:34<02:02,  6.45s/it]Capturing batches (bs=120 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:34<02:02,  6.45s/it]Capturing batches (bs=112 avail_mem=30.56 GB):  17%|â–ˆâ–‹        | 4/23 [00:34<02:02,  6.45s/it]Capturing batches (bs=112 avail_mem=30.56 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:34<00:48,  3.01s/it]Capturing batches (bs=104 avail_mem=30.54 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:34<00:48,  3.01s/it]Capturing batches (bs=96 avail_mem=30.53 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:34<00:48,  3.01s/it] Capturing batches (bs=88 avail_mem=30.51 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:34<00:48,  3.01s/it]Capturing batches (bs=88 avail_mem=30.51 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:34<00:22,  1.72s/it]Capturing batches (bs=80 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:34<00:22,  1.72s/it]Capturing batches (bs=72 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:34<00:22,  1.72s/it]Capturing batches (bs=64 avail_mem=30.47 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:34<00:22,  1.72s/it]Capturing batches (bs=64 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:34<00:10,  1.08s/it]Capturing batches (bs=56 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:34<00:10,  1.08s/it]Capturing batches (bs=48 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:34<00:10,  1.08s/it]Capturing batches (bs=40 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:34<00:10,  1.08s/it]Capturing batches (bs=40 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:34<00:04,  1.41it/s]Capturing batches (bs=32 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:34<00:04,  1.41it/s]Capturing batches (bs=24 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:34<00:04,  1.41it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:34<00:04,  1.41it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:34<00:01,  2.02it/s]Capturing batches (bs=8 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:34<00:01,  2.02it/s] Capturing batches (bs=4 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:34<00:01,  2.02it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:34<00:01,  2.02it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:34<00:00,  2.88it/s]Capturing batches (bs=1 avail_mem=30.35 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:34<00:00,  2.88it/s]Capturing batches (bs=1 avail_mem=30.35 GB): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:34<00:00,  1.52s/it]
2025-11-26T16:56:50.926726818Z [37m20251126-16:56:50.926 SGLangServer Wrapper INFO: SGLang server launched at: http://172.21.0.2:12101[0m
2025-11-26T16:56:51.514624928Z [37m20251126-16:56:51.514 Launcher Utils INFO: Found 1 rollout servers: 172.21.0.2:12101[0m
2025-11-26T16:56:51.514663306Z [37m20251126-16:56:51.514 Local Scheduler INFO: LLM inference server launched at: AREAL_LLM_SERVER_ADDRS=172.21.0.2:12101[0m
2025-11-26T16:56:51.517728958Z [37m20251126-16:56:51.517 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL AREAL_LLM_SERVER_ADDRS=172.21.0.2:12101 AREAL_RECOVER_RUN=0 NCCL_CUMEM_ENABLE=0 NCCL_NVLS_ENABLE=0 CUDA_VISIBLE_DEVICES=1 stdbuf -oL torchrun --nnodes 1 --nproc-per-node 1 --master-addr localhost --master-port 37324 examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_165544 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_165544/trainer.log[0m
2025-11-26T16:56:51.518551069Z [37m20251126-16:56:51.518 Local Scheduler INFO: Waiting for 2 local running processes, pids: 788 1866[0m
2025-11-26T16:56:52.086677333Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T16:56:52.086724354Z   import pynvml  # type: ignore[import]
2025-11-26T16:56:53.298403825Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T16:56:53.298441241Z   import pynvml  # type: ignore[import]
2025-11-26T16:57:01.212960221Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T16:57:01.212998589Z   warnings.warn(
2025-11-26T16:57:01.213001543Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T16:57:01.213003846Z   warnings.warn(
2025-11-26T16:57:01.833109661Z Traceback (most recent call last):
2025-11-26T16:57:01.833184303Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 665, in <module>
2025-11-26T16:57:01.833646495Z     main(sys.argv[1:])
2025-11-26T16:57:01.833650090Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 102, in main
2025-11-26T16:57:01.833652674Z     config, _ = load_expr_config(args_with_overrides, GRPOConfig)
2025-11-26T16:57:01.834223069Z                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T16:57:01.834234596Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1282, in load_expr_config
2025-11-26T16:57:01.834236880Z     cfg = to_structured_cfg(cfg, config_cls=config_cls)
2025-11-26T16:57:01.834634656Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T16:57:01.834638051Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1276, in to_structured_cfg
2025-11-26T16:57:01.834640084Z     cfg = OmegaConf.merge(default_cfg, cfg)
2025-11-26T16:57:01.835146292Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T16:57:01.835151490Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/omegaconf.py", line 274, in merge
2025-11-26T16:57:01.835154143Z     target.merge_with(
2025-11-26T16:57:01.835156707Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 507, in merge_with
2025-11-26T16:57:01.835159191Z     self._format_and_raise(key=None, value=None, cause=e)
2025-11-26T16:57:01.835161144Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T16:57:01.835163147Z     format_and_raise(
2025-11-26T16:57:01.835165360Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T16:57:01.835605539Z     _raise(ex, cause)
2025-11-26T16:57:01.835627432Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T16:57:01.835630467Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T16:57:01.836024477Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T16:57:01.836028453Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 502, in merge_with
2025-11-26T16:57:01.836030476Z     self._merge_with(
2025-11-26T16:57:01.836032559Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T16:57:01.836034593Z     BaseContainer._map_merge(
2025-11-26T16:57:01.836037176Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T16:57:01.836039189Z     dest_node._merge_with(
2025-11-26T16:57:01.836371948Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T16:57:01.836392649Z     BaseContainer._map_merge(
2025-11-26T16:57:01.836395503Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T16:57:01.836397556Z     dest_node._merge_with(
2025-11-26T16:57:01.836399529Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T16:57:01.836687511Z     BaseContainer._map_merge(
2025-11-26T16:57:01.836691036Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 432, in _map_merge
2025-11-26T16:57:01.836693349Z     dest[key] = src._get_node(key)
2025-11-26T16:57:01.836695292Z     ~~~~^^^^^
2025-11-26T16:57:01.836698047Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 308, in __setitem__
2025-11-26T16:57:01.837265997Z     self._format_and_raise(
2025-11-26T16:57:01.837272056Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T16:57:01.837275061Z     format_and_raise(
2025-11-26T16:57:01.837277054Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T16:57:01.837279077Z     _raise(ex, cause)
2025-11-26T16:57:01.837281060Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T16:57:01.837283032Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T16:57:01.837622491Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T16:57:01.837627048Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 306, in __setitem__
2025-11-26T16:57:01.837629922Z     self.__set_impl(key=key, value=value)
2025-11-26T16:57:01.837631985Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 316, in __set_impl
2025-11-26T16:57:01.837634238Z     self._set_item_impl(key, value)
2025-11-26T16:57:01.837636231Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 579, in _set_item_impl
2025-11-26T16:57:01.838034388Z     target_node_ref = self._get_node(key)
2025-11-26T16:57:01.838037963Z                       ^^^^^^^^^^^^^^^^^^^
2025-11-26T16:57:01.838040036Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 473, in _get_node
2025-11-26T16:57:01.838419274Z     self._validate_get(key)
2025-11-26T16:57:01.838425614Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 163, in _validate_get
2025-11-26T16:57:01.838427727Z     self._format_and_raise(
2025-11-26T16:57:01.838429670Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T16:57:01.838431633Z     format_and_raise(
2025-11-26T16:57:01.838434217Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 906, in format_and_raise
2025-11-26T16:57:01.838815157Z     _raise(ex, cause)
2025-11-26T16:57:01.838819203Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T16:57:01.838826093Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T16:57:01.839085623Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T16:57:01.839088587Z omegaconf.errors.ConfigKeyError: Key 'max_new_tokens' not in 'NormConfig'
2025-11-26T16:57:01.839090530Z     full_key: actor.adv_norm.max_new_tokens
2025-11-26T16:57:01.839092602Z     reference_type=Optional[NormConfig]
2025-11-26T16:57:01.839094685Z     object_type=NormConfig
2025-11-26T16:57:04.298333250Z E1126 16:57:04.297000 1867 torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 0 (pid: 1933) of binary: /usr/bin/python3
2025-11-26T16:57:04.298944125Z Traceback (most recent call last):
2025-11-26T16:57:04.298951687Z   File "/usr/local/bin/torchrun", line 7, in <module>
2025-11-26T16:57:04.298954721Z     sys.exit(main())
2025-11-26T16:57:04.298961431Z              ^^^^^^
2025-11-26T16:57:04.298963675Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
2025-11-26T16:57:04.298966319Z     return f(*args, **kwargs)
2025-11-26T16:57:04.298968873Z            ^^^^^^^^^^^^^^^^^^
2025-11-26T16:57:04.299515381Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 901, in main
2025-11-26T16:57:04.299522692Z     run(args)
2025-11-26T16:57:04.299525346Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 892, in run
2025-11-26T16:57:04.299527459Z     elastic_launch(
2025-11-26T16:57:04.299529853Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 143, in __call__
2025-11-26T16:57:04.299532657Z     return launch_agent(self._config, self._entrypoint, list(args))
2025-11-26T16:57:04.299536152Z            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T16:57:04.299538255Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 277, in launch_agent
2025-11-26T16:57:04.299540619Z     raise ChildFailedError(
2025-11-26T16:57:04.299543494Z torch.distributed.elastic.multiprocessing.errors.ChildFailedError:
2025-11-26T16:57:04.299545657Z ============================================================
2025-11-26T16:57:04.299548221Z examples/cloud_gsm8k/gsm8k_grpo_train.py FAILED
2025-11-26T16:57:04.299550574Z ------------------------------------------------------------
2025-11-26T16:57:04.299552527Z Failures:
2025-11-26T16:57:04.299554460Z   <NO_OTHER_FAILURES>
2025-11-26T16:57:04.299556413Z ------------------------------------------------------------
2025-11-26T16:57:04.299558386Z Root Cause (first observed failure):
2025-11-26T16:57:04.299560339Z [0]:
2025-11-26T16:57:04.299562402Z   time      : 2025-11-26_16:57:04
2025-11-26T16:57:04.299564435Z   host      : cef7c503fdea
2025-11-26T16:57:04.299566418Z   rank      : 0 (local_rank: 0)
2025-11-26T16:57:04.299568341Z   exitcode  : 1 (pid: 1933)
2025-11-26T16:57:04.299570294Z   error_file: <N/A>
2025-11-26T16:57:04.299572246Z   traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
2025-11-26T16:57:04.299574249Z ============================================================
2025-11-26T16:57:05.523217331Z [37m20251126-16:57:05.522 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [788][0m
2025-11-26T16:57:05.675672272Z Killed
2025-11-26T16:57:05.687913489Z [37m20251126-16:57:05.687 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [1866][0m
2025-11-26T16:57:05.689396891Z Traceback (most recent call last):
2025-11-26T16:57:05.689410761Z   File "<frozen runpy>", line 198, in _run_module_as_main
2025-11-26T16:57:05.689413886Z   File "<frozen runpy>", line 88, in _run_code
2025-11-26T16:57:05.689416029Z   File "/workspace/AReaL/areal/launcher/local.py", line 405, in <module>
2025-11-26T16:57:05.689549989Z     main()
2025-11-26T16:57:05.689555808Z   File "/workspace/AReaL/areal/launcher/local.py", line 260, in main
2025-11-26T16:57:05.689630120Z     local_main(config, run_id=0)
2025-11-26T16:57:05.689634366Z   File "/workspace/AReaL/areal/launcher/local.py", line 399, in local_main
2025-11-26T16:57:05.689729169Z     raise e
2025-11-26T16:57:05.689731592Z   File "/workspace/AReaL/areal/launcher/local.py", line 375, in local_main
2025-11-26T16:57:05.689800895Z     launcher.wait(
2025-11-26T16:57:05.689806183Z   File "/workspace/AReaL/areal/launcher/local.py", line 235, in wait
2025-11-26T16:57:05.689864791Z     raise JobException(
2025-11-26T16:57:05.689868967Z areal.utils.launcher.JobException: Job gsm8k-grpo-cloud-2gpu-2000samples_trial_20251126_165544:trainer JobState.COMPLETED at node local
2025-11-26T16:57:05.973565966Z [37m20251126-16:57:05.972 Local Scheduler INFO: Waiting for 0 local running processes, pids: [0m
2025-11-26T16:57:20.828502204Z ==========
2025-11-26T16:57:20.828505479Z == CUDA ==
2025-11-26T16:57:20.828521303Z ==========
2025-11-26T16:57:20.833056977Z CUDA Version 12.9.1
2025-11-26T16:57:20.834916172Z Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
2025-11-26T16:57:20.836794045Z This container image and its contents are governed by the NVIDIA Deep Learning Container License.
2025-11-26T16:57:20.836797099Z By pulling and using the container, you accept the terms and conditions of this license:
2025-11-26T16:57:20.836799663Z https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license
2025-11-26T16:57:20.836804140Z A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
2025-11-26T16:57:21.003774904Z Writing to /root/.config/pip/pip.conf
2025-11-26T16:57:21.160535045Z Writing to /root/.config/pip/pip.conf
2025-11-26T16:57:21.362012598Z Branch 'feature/reasoning_model' set up to track remote branch 'feature/reasoning_model' from 'origin'.
2025-11-26T16:57:21.362063194Z Your branch is up to date with 'origin/feature/reasoning_model'.
2025-11-26T16:57:21.439813515Z Checking AReaL installation...
2025-11-26T16:57:21.499031077Z AReaL already installed. Skipping installation.
2025-11-26T16:57:21.499065489Z Cleaning up any leftover GPU processes...
2025-11-26T16:57:24.519093048Z Checking for processes holding GPU device files...
2025-11-26T16:57:27.210157765Z Found processes holding GPU devices: 1
2025-11-26T16:57:27.210205005Z 21
2025-11-26T16:57:27.210208260Z 72
2025-11-26T16:57:27.210210343Z 73
2025-11-26T16:57:27.210212386Z Killing process 1...
2025-11-26T16:57:27.210214930Z Killing process 72...
2025-11-26T16:57:27.210414209Z Killing process 73...
2025-11-26T16:57:29.212958353Z Using fuser to kill processes on GPU devices...
2025-11-26T16:57:31.236723163Z Checking GPU...
2025-11-26T16:57:31.277828515Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T16:57:31.277860252Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T16:57:31.294865984Z Set PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True for better memory management
2025-11-26T16:57:31.294885474Z Detected 2 GPU(s)
2025-11-26T16:57:31.294888598Z Checking GPU status...
2025-11-26T16:57:31.322699327Z index, name, utilization.gpu [%], memory.used [MiB], compute_mode
2025-11-26T16:57:31.324169629Z 0, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T16:57:31.324504651Z 1, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T16:57:31.368415414Z Verifying GPU accessibility...
2025-11-26T16:57:31.947666272Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T16:57:31.947726241Z   import pynvml  # type: ignore[import]
2025-11-26T16:57:33.073132575Z GPU accessibility verified on attempt 1
2025-11-26T16:57:33.620303429Z Starting training...
2025-11-26T16:57:36.623110755Z Using STANDARD 2000 SAMPLES 2 GPUs configuration
2025-11-26T16:57:36.623195882Z Note: GRPO only (no reasoning XML). Dataset capped at 2000 samples (~6 hours).
2025-11-26T16:57:36.623199006Z GPU count: 2 (required: 2)
2025-11-26T16:57:36.625961044Z ==========================================
2025-11-26T16:57:36.625964579Z Starting GRPO Training (Cloud)
2025-11-26T16:57:36.625967434Z ==========================================
2025-11-26T16:57:36.625985240Z Config: standard_2000samples_2GPUs
2025-11-26T16:57:36.625987564Z Config file: examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml
2025-11-26T16:57:36.625990598Z Training script: examples/cloud_gsm8k/gsm8k_grpo_train.py
2025-11-26T16:57:36.625992932Z Experiment: gsm8k-grpo-cloud-2gpu-2000samples
2025-11-26T16:57:36.625994945Z Trial: trial_20251126_165736
2025-11-26T16:57:36.625996988Z GPU: NVIDIA A100 80GB PCIe NVIDIA A100 80GB PCIe (81920 MB)
2025-11-26T16:57:36.625998971Z WandB API key: e1adc5be02...
2025-11-26T16:57:36.626001305Z ==========================================
2025-11-26T16:57:37.309815327Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T16:57:37.309852933Z   import pynvml  # type: ignore[import]
2025-11-26T16:57:41.216000778Z [37m20251126-16:57:41.215 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T16:57:41.216046287Z [37m20251126-16:57:41.215 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T16:57:41.216364814Z [37m20251126-16:57:41.216 name-resolve INFO: No such name resolve path: ./tmp/areal/name_resolve/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_165736[0m
2025-11-26T16:57:41.321375879Z [37m20251126-16:57:41.320 Local Scheduler INFO: LocalLauncher: experiment_name=gsm8k-grpo-cloud-2gpu-2000samples, trial_name=trial_20251126_165736, fileroot=/workspace/outputs/grpo, run_id=0, is_recover_run=False[0m
2025-11-26T16:57:41.328798558Z [37m20251126-16:57:41.328 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL CUDA_VISIBLE_DEVICES=0 stdbuf -oL python3 -m areal.launcher.sglang_server examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_165736 sglang.random_seed=1 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_165736/llm_server.log[0m
2025-11-26T16:57:42.050678399Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T16:57:42.050710948Z   import pynvml  # type: ignore[import]
2025-11-26T16:57:43.507887678Z [37m20251126-16:57:43.507 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T16:57:43.507921058Z [37m20251126-16:57:43.507 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T16:57:43.612639776Z [37m20251126-16:57:43.612 SGLangServer Wrapper INFO: Launch command: python3 -m sglang.launch_server --host 172.21.0.2 --port 10898 --tokenizer-path Qwen/Qwen2.5-0.5B-Instruct --tokenizer-mode auto --load-format auto --trust-remote-code --device cuda --tp-size 1 --base-gpu-id 0 --nnodes 1 --node-rank 0 --dist-init-addr localhost:15647 --model-path Qwen/Qwen2.5-0.5B-Instruct --random-seed 1 --skip-tokenizer-init --disable-radix-cache --torch-compile-max-bs 32 --triton-attention-num-kv-splits 8 --num-continuous-decode-steps 1 --attention-backend flashinfer --context-length 4096 --mem-fraction-static 0.6 --chunked-prefill-size -1 --max-prefill-tokens 32768 --schedule-policy lpm --schedule-conservativeness 1.0 --cpu-offload-gb 0 --dtype bfloat16 --kv-cache-dtype auto --dp-size 1 --ep-size 1 --max-loaded-loras 1 --max-loras-per-batch 1 --lora-backend triton --log-level warning --log-level-http warning --log-requests-level 0 --enable-metrics --decode-log-interval 1[0m
2025-11-26T16:57:44.653718074Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T16:57:44.653768970Z   import pynvml  # type: ignore[import]
2025-11-26T16:57:49.934257175Z INFO 11-26 16:57:49 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T16:57:50.589676035Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T16:57:51.660456022Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T16:57:51.660491825Z   import pynvml  # type: ignore[import]
2025-11-26T16:57:51.668394343Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T16:57:51.668426571Z   import pynvml  # type: ignore[import]
2025-11-26T16:57:57.219817560Z INFO 11-26 16:57:57 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T16:57:57.330888373Z INFO 11-26 16:57:57 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T16:57:57.909313725Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T16:57:58.129334172Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T16:57:58.132869808Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T16:57:58.133653693Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T16:57:58.134498278Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T16:57:58.167514913Z [2025-11-26 16:57:58] MOE_RUNNER_BACKEND is not initialized, using triton backend
2025-11-26T16:57:58.655762788Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T16:57:58.655801376Z   warnings.warn(
2025-11-26T16:57:58.655804861Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T16:57:58.655807024Z   warnings.warn(
2025-11-26T16:57:59.927427891Z Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
2025-11-26T16:58:00.030217409Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  9.75it/s]
2025-11-26T16:58:00.030564579Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  9.72it/s]
2025-11-26T16:58:02.526453432Z   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   4%|â–         | 1/23 [00:00<00:11,  1.86it/s]Capturing batches (bs=152 avail_mem=30.62 GB):   4%|â–         | 1/23 [00:00<00:11,  1.86it/s]Capturing batches (bs=144 avail_mem=30.60 GB):   4%|â–         | 1/23 [00:00<00:11,  1.86it/s]Capturing batches (bs=136 avail_mem=30.59 GB):   4%|â–         | 1/23 [00:00<00:11,  1.86it/s]Capturing batches (bs=136 avail_mem=30.59 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.31it/s]Capturing batches (bs=128 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.31it/s]Capturing batches (bs=120 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.31it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.31it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.65it/s]Capturing batches (bs=104 avail_mem=30.54 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.65it/s]Capturing batches (bs=96 avail_mem=30.53 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.65it/s] Capturing batches (bs=88 avail_mem=30.51 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.65it/s]Capturing batches (bs=88 avail_mem=30.51 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.97it/s]Capturing batches (bs=80 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.97it/s]Capturing batches (bs=72 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.97it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:01<00:00, 14.97it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.40it/s]Capturing batches (bs=56 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.40it/s]Capturing batches (bs=48 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.40it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.40it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.42it/s]Capturing batches (bs=32 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.42it/s]Capturing batches (bs=24 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.42it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.42it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.88it/s]Capturing batches (bs=8 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.88it/s] Capturing batches (bs=4 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.88it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.88it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.71it/s]Capturing batches (bs=1 avail_mem=30.35 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.71it/s]Capturing batches (bs=1 avail_mem=30.35 GB): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00, 15.05it/s]
2025-11-26T16:58:08.639812982Z [37m20251126-16:58:08.639 SGLangServer Wrapper INFO: SGLang server launched at: http://172.21.0.2:10898[0m
2025-11-26T16:58:09.335242224Z [37m20251126-16:58:09.334 Launcher Utils INFO: Found 1 rollout servers: 172.21.0.2:10898[0m
2025-11-26T16:58:09.335281873Z [37m20251126-16:58:09.334 Local Scheduler INFO: LLM inference server launched at: AREAL_LLM_SERVER_ADDRS=172.21.0.2:10898[0m
2025-11-26T16:58:09.338586182Z [37m20251126-16:58:09.338 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL AREAL_LLM_SERVER_ADDRS=172.21.0.2:10898 AREAL_RECOVER_RUN=0 NCCL_CUMEM_ENABLE=0 NCCL_NVLS_ENABLE=0 CUDA_VISIBLE_DEVICES=1 stdbuf -oL torchrun --nnodes 1 --nproc-per-node 1 --master-addr localhost --master-port 16357 examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_165736 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_165736/trainer.log[0m
2025-11-26T16:58:09.339154343Z [37m20251126-16:58:09.338 Local Scheduler INFO: Waiting for 2 local running processes, pids: 316 966[0m
2025-11-26T16:58:09.847831980Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T16:58:09.847873111Z   import pynvml  # type: ignore[import]
2025-11-26T16:58:11.030909267Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T16:58:11.030947215Z   import pynvml  # type: ignore[import]
2025-11-26T16:58:17.964454591Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T16:58:17.964501110Z   warnings.warn(
2025-11-26T16:58:17.964504315Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T16:58:17.964506839Z   warnings.warn(
2025-11-26T16:58:18.608678492Z Traceback (most recent call last):
2025-11-26T16:58:18.608717090Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 665, in <module>
2025-11-26T16:58:18.609304690Z     main(sys.argv[1:])
2025-11-26T16:58:18.609310579Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 102, in main
2025-11-26T16:58:18.609313433Z     config, _ = load_expr_config(args_with_overrides, GRPOConfig)
2025-11-26T16:58:18.609723126Z                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T16:58:18.609727052Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1282, in load_expr_config
2025-11-26T16:58:18.609729406Z     cfg = to_structured_cfg(cfg, config_cls=config_cls)
2025-11-26T16:58:18.610235775Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T16:58:18.610240462Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1276, in to_structured_cfg
2025-11-26T16:58:18.610242585Z     cfg = OmegaConf.merge(default_cfg, cfg)
2025-11-26T16:58:18.611057796Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T16:58:18.611060440Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/omegaconf.py", line 274, in merge
2025-11-26T16:58:18.611062713Z     target.merge_with(
2025-11-26T16:58:18.611065197Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 507, in merge_with
2025-11-26T16:58:18.611067741Z     self._format_and_raise(key=None, value=None, cause=e)
2025-11-26T16:58:18.611069734Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T16:58:18.611071687Z     format_and_raise(
2025-11-26T16:58:18.611073700Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T16:58:18.611075943Z     _raise(ex, cause)
2025-11-26T16:58:18.611092628Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T16:58:18.611095032Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T16:58:18.611592577Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T16:58:18.611635762Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 502, in merge_with
2025-11-26T16:58:18.611639107Z     self._merge_with(
2025-11-26T16:58:18.611642141Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T16:58:18.611644335Z     BaseContainer._map_merge(
2025-11-26T16:58:18.611918335Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T16:58:18.611923393Z     dest_node._merge_with(
2025-11-26T16:58:18.611926277Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T16:58:18.611928500Z     BaseContainer._map_merge(
2025-11-26T16:58:18.611930513Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T16:58:18.612236942Z     dest_node._merge_with(
2025-11-26T16:58:18.612245004Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T16:58:18.612247808Z     BaseContainer._map_merge(
2025-11-26T16:58:18.612249782Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 432, in _map_merge
2025-11-26T16:58:18.612251825Z     dest[key] = src._get_node(key)
2025-11-26T16:58:18.612856831Z     ~~~~^^^^^
2025-11-26T16:58:18.612861648Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 308, in __setitem__
2025-11-26T16:58:18.612864532Z     self._format_and_raise(
2025-11-26T16:58:18.612867096Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T16:58:18.612869149Z     format_and_raise(
2025-11-26T16:58:18.612871833Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T16:58:18.612874077Z     _raise(ex, cause)
2025-11-26T16:58:18.612876100Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T16:58:18.612883471Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T16:58:18.613288987Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T16:58:18.613295597Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 306, in __setitem__
2025-11-26T16:58:18.613297961Z     self.__set_impl(key=key, value=value)
2025-11-26T16:58:18.613300094Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 316, in __set_impl
2025-11-26T16:58:18.613648306Z     self._set_item_impl(key, value)
2025-11-26T16:58:18.613650850Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 579, in _set_item_impl
2025-11-26T16:58:18.613653033Z     target_node_ref = self._get_node(key)
2025-11-26T16:58:18.614047825Z                       ^^^^^^^^^^^^^^^^^^^
2025-11-26T16:58:18.614050348Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 473, in _get_node
2025-11-26T16:58:18.614052983Z     self._validate_get(key)
2025-11-26T16:58:18.614055236Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 163, in _validate_get
2025-11-26T16:58:18.614057309Z     self._format_and_raise(
2025-11-26T16:58:18.614059252Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T16:58:18.614061305Z     format_and_raise(
2025-11-26T16:58:18.614063809Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 906, in format_and_raise
2025-11-26T16:58:18.614441063Z     _raise(ex, cause)
2025-11-26T16:58:18.614449866Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T16:58:18.614452280Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T16:58:18.614728744Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T16:58:18.614749455Z omegaconf.errors.ConfigKeyError: Key 'max_new_tokens' not in 'NormConfig'
2025-11-26T16:58:18.614752580Z     full_key: actor.adv_norm.max_new_tokens
2025-11-26T16:58:18.614754573Z     reference_type=Optional[NormConfig]
2025-11-26T16:58:18.614756546Z     object_type=NormConfig
2025-11-26T16:58:21.435866246Z E1126 16:58:21.434000 967 torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 0 (pid: 1033) of binary: /usr/bin/python3
2025-11-26T16:58:21.436541258Z Traceback (most recent call last):
2025-11-26T16:58:21.436547477Z   File "/usr/local/bin/torchrun", line 7, in <module>
2025-11-26T16:58:21.436550081Z     sys.exit(main())
2025-11-26T16:58:21.436552495Z              ^^^^^^
2025-11-26T16:58:21.436554618Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
2025-11-26T16:58:21.436558073Z     return f(*args, **kwargs)
2025-11-26T16:58:21.436561297Z            ^^^^^^^^^^^^^^^^^^
2025-11-26T16:58:21.436564012Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 901, in main
2025-11-26T16:58:21.437028547Z     run(args)
2025-11-26T16:58:21.437031722Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 892, in run
2025-11-26T16:58:21.437034216Z     elastic_launch(
2025-11-26T16:58:21.437036960Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 143, in __call__
2025-11-26T16:58:21.437039504Z     return launch_agent(self._config, self._entrypoint, list(args))
2025-11-26T16:58:21.437042088Z            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T16:58:21.437044180Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 277, in launch_agent
2025-11-26T16:58:21.437046174Z     raise ChildFailedError(
2025-11-26T16:58:21.437049739Z torch.distributed.elastic.multiprocessing.errors.ChildFailedError:
2025-11-26T16:58:21.437053024Z ============================================================
2025-11-26T16:58:21.437055968Z examples/cloud_gsm8k/gsm8k_grpo_train.py FAILED
2025-11-26T16:58:21.437059353Z ------------------------------------------------------------
2025-11-26T16:58:21.437062398Z Failures:
2025-11-26T16:58:21.437065142Z   <NO_OTHER_FAILURES>
2025-11-26T16:58:21.437067726Z ------------------------------------------------------------
2025-11-26T16:58:21.437070280Z Root Cause (first observed failure):
2025-11-26T16:58:21.437072794Z [0]:
2025-11-26T16:58:21.437075608Z   time      : 2025-11-26_16:58:21
2025-11-26T16:58:21.437078723Z   host      : cef7c503fdea
2025-11-26T16:58:21.437081376Z   rank      : 0 (local_rank: 0)
2025-11-26T16:58:21.437083850Z   exitcode  : 1 (pid: 1033)
2025-11-26T16:58:21.437086324Z   error_file: <N/A>
2025-11-26T16:58:21.437088807Z   traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
2025-11-26T16:58:21.437091602Z ============================================================
2025-11-26T16:58:23.346209624Z [37m20251126-16:58:23.345 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [316][0m
2025-11-26T16:58:23.470858534Z Killed
2025-11-26T16:58:23.482435085Z [37m20251126-16:58:23.482 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [966][0m
2025-11-26T16:58:23.483414852Z Traceback (most recent call last):
2025-11-26T16:58:23.483427000Z   File "<frozen runpy>", line 198, in _run_module_as_main
2025-11-26T16:58:23.483429364Z   File "<frozen runpy>", line 88, in _run_code
2025-11-26T16:58:23.483431457Z   File "/workspace/AReaL/areal/launcher/local.py", line 405, in <module>
2025-11-26T16:58:23.483559019Z     main()
2025-11-26T16:58:23.483564146Z   File "/workspace/AReaL/areal/launcher/local.py", line 260, in main
2025-11-26T16:58:23.483650405Z     local_main(config, run_id=0)
2025-11-26T16:58:23.483654262Z   File "/workspace/AReaL/areal/launcher/local.py", line 399, in local_main
2025-11-26T16:58:23.483746319Z     raise e
2025-11-26T16:58:23.483748883Z   File "/workspace/AReaL/areal/launcher/local.py", line 375, in local_main
2025-11-26T16:58:23.483808802Z     launcher.wait(
2025-11-26T16:58:23.483811577Z   File "/workspace/AReaL/areal/launcher/local.py", line 235, in wait
2025-11-26T16:58:23.483871396Z     raise JobException(
2025-11-26T16:58:23.483877375Z areal.utils.launcher.JobException: Job gsm8k-grpo-cloud-2gpu-2000samples_trial_20251126_165736:trainer JobState.COMPLETED at node local
2025-11-26T16:58:23.775821047Z [37m20251126-16:58:23.775 Local Scheduler INFO: Waiting for 0 local running processes, pids: [0m
2025-11-26T16:58:39.370434844Z ==========
2025-11-26T16:58:39.370438200Z == CUDA ==
2025-11-26T16:58:39.370443688Z ==========
2025-11-26T16:58:39.374639142Z CUDA Version 12.9.1
2025-11-26T16:58:39.376263475Z Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
2025-11-26T16:58:39.377948880Z This container image and its contents are governed by the NVIDIA Deep Learning Container License.
2025-11-26T16:58:39.377953467Z By pulling and using the container, you accept the terms and conditions of this license:
2025-11-26T16:58:39.377957152Z https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license
2025-11-26T16:58:39.377962860Z A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
2025-11-26T16:58:39.544906655Z Writing to /root/.config/pip/pip.conf
2025-11-26T16:58:39.703420762Z Writing to /root/.config/pip/pip.conf
2025-11-26T16:58:39.894571698Z Branch 'feature/reasoning_model' set up to track remote branch 'feature/reasoning_model' from 'origin'.
2025-11-26T16:58:39.894610365Z Your branch is up to date with 'origin/feature/reasoning_model'.
2025-11-26T16:58:39.964462256Z Checking AReaL installation...
2025-11-26T16:58:40.022950896Z AReaL already installed. Skipping installation.
2025-11-26T16:58:40.022995032Z Cleaning up any leftover GPU processes...
2025-11-26T16:58:43.041765158Z Checking for processes holding GPU device files...
2025-11-26T16:58:45.045813625Z Found processes holding GPU devices: 1
2025-11-26T16:58:45.045845783Z 20
2025-11-26T16:58:45.045848567Z 71
2025-11-26T16:58:45.045850781Z 72
2025-11-26T16:58:45.045852834Z Killing process 1...
2025-11-26T16:58:45.045859594Z Killing process 71...
2025-11-26T16:58:45.045936969Z Killing process 72...
2025-11-26T16:58:47.048412511Z Using fuser to kill processes on GPU devices...
2025-11-26T16:58:49.070324686Z Checking GPU...
2025-11-26T16:58:49.105385304Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T16:58:49.105413907Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T16:58:49.121237478Z Set PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True for better memory management
2025-11-26T16:58:49.121253913Z Detected 2 GPU(s)
2025-11-26T16:58:49.121257308Z Checking GPU status...
2025-11-26T16:58:49.149072001Z index, name, utilization.gpu [%], memory.used [MiB], compute_mode
2025-11-26T16:58:49.150555704Z 0, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T16:58:49.150850475Z 1, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T16:58:49.200715138Z Verifying GPU accessibility...
2025-11-26T16:58:49.720192721Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T16:58:49.720248565Z   import pynvml  # type: ignore[import]
2025-11-26T16:58:50.825099697Z GPU accessibility verified on attempt 1
2025-11-26T16:58:51.277344924Z Starting training...
2025-11-26T16:58:54.280030977Z Using STANDARD 2000 SAMPLES 2 GPUs configuration
2025-11-26T16:58:54.280074132Z Note: GRPO only (no reasoning XML). Dataset capped at 2000 samples (~6 hours).
2025-11-26T16:58:54.280077317Z GPU count: 2 (required: 2)
2025-11-26T16:58:54.282340217Z ==========================================
2025-11-26T16:58:54.282343741Z Starting GRPO Training (Cloud)
2025-11-26T16:58:54.282346736Z ==========================================
2025-11-26T16:58:54.282348779Z Config: standard_2000samples_2GPUs
2025-11-26T16:58:54.282351142Z Config file: examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml
2025-11-26T16:58:54.282374247Z Training script: examples/cloud_gsm8k/gsm8k_grpo_train.py
2025-11-26T16:58:54.282376901Z Experiment: gsm8k-grpo-cloud-2gpu-2000samples
2025-11-26T16:58:54.282378934Z Trial: trial_20251126_165854
2025-11-26T16:58:54.282380947Z GPU: NVIDIA A100 80GB PCIe NVIDIA A100 80GB PCIe (81920 MB)
2025-11-26T16:58:54.282382900Z WandB API key: e1adc5be02...
2025-11-26T16:58:54.282384963Z ==========================================
2025-11-26T16:58:54.954572190Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T16:58:54.954606312Z   import pynvml  # type: ignore[import]
2025-11-26T16:58:58.873755682Z [37m20251126-16:58:58.873 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T16:58:58.873792537Z [37m20251126-16:58:58.873 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T16:58:58.874071004Z [37m20251126-16:58:58.873 name-resolve INFO: No such name resolve path: ./tmp/areal/name_resolve/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_165854[0m
2025-11-26T16:58:58.979921427Z [37m20251126-16:58:58.979 Local Scheduler INFO: LocalLauncher: experiment_name=gsm8k-grpo-cloud-2gpu-2000samples, trial_name=trial_20251126_165854, fileroot=/workspace/outputs/grpo, run_id=0, is_recover_run=False[0m
2025-11-26T16:58:58.988271354Z [37m20251126-16:58:58.988 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL CUDA_VISIBLE_DEVICES=0 stdbuf -oL python3 -m areal.launcher.sglang_server examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_165854 sglang.random_seed=1 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_165854/llm_server.log[0m
2025-11-26T16:58:59.712540314Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T16:58:59.712584971Z   import pynvml  # type: ignore[import]
2025-11-26T16:59:01.179515892Z [37m20251126-16:59:01.178 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T16:59:01.180256792Z [37m20251126-16:59:01.179 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T16:59:01.283457645Z [37m20251126-16:59:01.282 SGLangServer Wrapper INFO: Launch command: python3 -m sglang.launch_server --host 172.21.0.2 --port 17162 --tokenizer-path Qwen/Qwen2.5-0.5B-Instruct --tokenizer-mode auto --load-format auto --trust-remote-code --device cuda --tp-size 1 --base-gpu-id 0 --nnodes 1 --node-rank 0 --dist-init-addr localhost:27556 --model-path Qwen/Qwen2.5-0.5B-Instruct --random-seed 1 --skip-tokenizer-init --disable-radix-cache --torch-compile-max-bs 32 --triton-attention-num-kv-splits 8 --num-continuous-decode-steps 1 --attention-backend flashinfer --context-length 4096 --mem-fraction-static 0.6 --chunked-prefill-size -1 --max-prefill-tokens 32768 --schedule-policy lpm --schedule-conservativeness 1.0 --cpu-offload-gb 0 --dtype bfloat16 --kv-cache-dtype auto --dp-size 1 --ep-size 1 --max-loaded-loras 1 --max-loras-per-batch 1 --lora-backend triton --log-level warning --log-level-http warning --log-requests-level 0 --enable-metrics --decode-log-interval 1[0m
2025-11-26T16:59:02.367936494Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T16:59:02.367993008Z   import pynvml  # type: ignore[import]
2025-11-26T16:59:07.889995827Z INFO 11-26 16:59:07 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T16:59:08.558537673Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T16:59:09.925350878Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T16:59:09.925399581Z   import pynvml  # type: ignore[import]
2025-11-26T16:59:09.929508636Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T16:59:09.929530749Z   import pynvml  # type: ignore[import]
2025-11-26T16:59:15.683709032Z INFO 11-26 16:59:15 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T16:59:15.843547524Z INFO 11-26 16:59:15 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T16:59:16.328185131Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T16:59:16.590698800Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T16:59:16.594291702Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T16:59:16.595077599Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T16:59:16.596001182Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T16:59:16.629045109Z [2025-11-26 16:59:16] MOE_RUNNER_BACKEND is not initialized, using triton backend
2025-11-26T16:59:17.146357068Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T16:59:17.146413262Z   warnings.warn(
2025-11-26T16:59:17.146416757Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T16:59:17.146419331Z   warnings.warn(
2025-11-26T16:59:18.437130304Z Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
2025-11-26T16:59:18.559431387Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  8.19it/s]
2025-11-26T16:59:18.559915122Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  8.17it/s]
2025-11-26T16:59:21.114776530Z   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   4%|â–         | 1/23 [00:00<00:12,  1.81it/s]Capturing batches (bs=152 avail_mem=30.62 GB):   4%|â–         | 1/23 [00:00<00:12,  1.81it/s]Capturing batches (bs=144 avail_mem=30.60 GB):   4%|â–         | 1/23 [00:00<00:12,  1.81it/s]Capturing batches (bs=136 avail_mem=30.59 GB):   4%|â–         | 1/23 [00:00<00:12,  1.81it/s]Capturing batches (bs=136 avail_mem=30.59 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.14it/s]Capturing batches (bs=128 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.14it/s]Capturing batches (bs=120 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.14it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.14it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.42it/s]Capturing batches (bs=104 avail_mem=30.54 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.42it/s]Capturing batches (bs=96 avail_mem=30.53 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.42it/s] Capturing batches (bs=88 avail_mem=30.51 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.42it/s]Capturing batches (bs=88 avail_mem=30.51 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.71it/s]Capturing batches (bs=80 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.71it/s]Capturing batches (bs=72 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.71it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:01<00:00, 14.71it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.21it/s]Capturing batches (bs=56 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.21it/s]Capturing batches (bs=48 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.21it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.21it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.17it/s]Capturing batches (bs=32 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.17it/s]Capturing batches (bs=24 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.17it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.17it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.58it/s]Capturing batches (bs=8 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.58it/s] Capturing batches (bs=4 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.58it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.58it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.39it/s]Capturing batches (bs=1 avail_mem=30.35 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.39it/s]Capturing batches (bs=1 avail_mem=30.35 GB): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00, 14.78it/s]
2025-11-26T16:59:26.308842864Z [37m20251126-16:59:26.308 SGLangServer Wrapper INFO: SGLang server launched at: http://172.21.0.2:17162[0m
2025-11-26T16:59:26.995226827Z [37m20251126-16:59:26.994 Launcher Utils INFO: Found 1 rollout servers: 172.21.0.2:17162[0m
2025-11-26T16:59:26.995266847Z [37m20251126-16:59:26.994 Local Scheduler INFO: LLM inference server launched at: AREAL_LLM_SERVER_ADDRS=172.21.0.2:17162[0m
2025-11-26T16:59:26.998464496Z [37m20251126-16:59:26.998 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL AREAL_LLM_SERVER_ADDRS=172.21.0.2:17162 AREAL_RECOVER_RUN=0 NCCL_CUMEM_ENABLE=0 NCCL_NVLS_ENABLE=0 CUDA_VISIBLE_DEVICES=1 stdbuf -oL torchrun --nnodes 1 --nproc-per-node 1 --master-addr localhost --master-port 11784 examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_165854 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_165854/trainer.log[0m
2025-11-26T16:59:26.999146438Z [37m20251126-16:59:26.998 Local Scheduler INFO: Waiting for 2 local running processes, pids: 315 965[0m
2025-11-26T16:59:27.561847626Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T16:59:27.561879744Z   import pynvml  # type: ignore[import]
2025-11-26T16:59:28.763789070Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T16:59:28.763821258Z   import pynvml  # type: ignore[import]
2025-11-26T16:59:36.003986407Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T16:59:36.004033528Z   warnings.warn(
2025-11-26T16:59:36.004036933Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T16:59:36.004039166Z   warnings.warn(
2025-11-26T16:59:36.432522969Z Traceback (most recent call last):
2025-11-26T16:59:36.433237430Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 665, in <module>
2025-11-26T16:59:36.433248207Z     main(sys.argv[1:])
2025-11-26T16:59:36.433251692Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 102, in main
2025-11-26T16:59:36.433253945Z     config, _ = load_expr_config(args_with_overrides, GRPOConfig)
2025-11-26T16:59:36.433257180Z                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T16:59:36.433259183Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1282, in load_expr_config
2025-11-26T16:59:36.433631169Z     cfg = to_structured_cfg(cfg, config_cls=config_cls)
2025-11-26T16:59:36.433654535Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T16:59:36.433657188Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1276, in to_structured_cfg
2025-11-26T16:59:36.433999922Z     cfg = OmegaConf.merge(default_cfg, cfg)
2025-11-26T16:59:36.434003938Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T16:59:36.434006011Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/omegaconf.py", line 274, in merge
2025-11-26T16:59:36.434008034Z     target.merge_with(
2025-11-26T16:59:36.434010017Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 507, in merge_with
2025-11-26T16:59:36.434012591Z     self._format_and_raise(key=None, value=None, cause=e)
2025-11-26T16:59:36.434015205Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T16:59:36.434553862Z     format_and_raise(
2025-11-26T16:59:36.434580131Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T16:59:36.434583776Z     _raise(ex, cause)
2025-11-26T16:59:36.434585930Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T16:59:36.434588914Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T16:59:36.434602364Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T16:59:36.434605219Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 502, in merge_with
2025-11-26T16:59:36.435016175Z     self._merge_with(
2025-11-26T16:59:36.435020631Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T16:59:36.435027011Z     BaseContainer._map_merge(
2025-11-26T16:59:36.435030136Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T16:59:36.435032179Z     dest_node._merge_with(
2025-11-26T16:59:36.435034151Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T16:59:36.435036085Z     BaseContainer._map_merge(
2025-11-26T16:59:36.435038177Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T16:59:36.435041052Z     dest_node._merge_with(
2025-11-26T16:59:36.435043025Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T16:59:36.435044978Z     BaseContainer._map_merge(
2025-11-26T16:59:36.435046981Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 432, in _map_merge
2025-11-26T16:59:36.435390815Z     dest[key] = src._get_node(key)
2025-11-26T16:59:36.435396904Z     ~~~~^^^^^
2025-11-26T16:59:36.435399538Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 308, in __setitem__
2025-11-26T16:59:36.435402453Z     self._format_and_raise(
2025-11-26T16:59:36.435405407Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T16:59:36.435407600Z     format_and_raise(
2025-11-26T16:59:36.435410014Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T16:59:36.435412428Z     _raise(ex, cause)
2025-11-26T16:59:36.435414420Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T16:59:36.436352696Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T16:59:36.436359326Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T16:59:36.436361619Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 306, in __setitem__
2025-11-26T16:59:36.436363943Z     self.__set_impl(key=key, value=value)
2025-11-26T16:59:36.436365916Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 316, in __set_impl
2025-11-26T16:59:36.436367899Z     self._set_item_impl(key, value)
2025-11-26T16:59:36.436370012Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 579, in _set_item_impl
2025-11-26T16:59:36.436372206Z     target_node_ref = self._get_node(key)
2025-11-26T16:59:36.436374329Z                       ^^^^^^^^^^^^^^^^^^^
2025-11-26T16:59:36.436376392Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 473, in _get_node
2025-11-26T16:59:36.436378445Z     self._validate_get(key)
2025-11-26T16:59:36.436380698Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 163, in _validate_get
2025-11-26T16:59:36.436382641Z     self._format_and_raise(
2025-11-26T16:59:36.436384574Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T16:59:36.436386477Z     format_and_raise(
2025-11-26T16:59:36.436388690Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 906, in format_and_raise
2025-11-26T16:59:36.436390683Z     _raise(ex, cause)
2025-11-26T16:59:36.436674168Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T16:59:36.436677673Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T16:59:36.436680016Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T16:59:36.436682220Z omegaconf.errors.ConfigKeyError: Key 'max_new_tokens' not in 'NormConfig'
2025-11-26T16:59:36.436689120Z     full_key: actor.adv_norm.max_new_tokens
2025-11-26T16:59:36.436691384Z     reference_type=Optional[NormConfig]
2025-11-26T16:59:36.436693807Z     object_type=NormConfig
2025-11-26T16:59:39.269708580Z E1126 16:59:39.268000 966 torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 0 (pid: 1032) of binary: /usr/bin/python3
2025-11-26T16:59:39.270356742Z Traceback (most recent call last):
2025-11-26T16:59:39.270367538Z   File "/usr/local/bin/torchrun", line 7, in <module>
2025-11-26T16:59:39.270371224Z     sys.exit(main())
2025-11-26T16:59:39.270374998Z              ^^^^^^
2025-11-26T16:59:39.270377893Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
2025-11-26T16:59:39.270386105Z     return f(*args, **kwargs)
2025-11-26T16:59:39.270388799Z            ^^^^^^^^^^^^^^^^^^
2025-11-26T16:59:39.270392254Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 901, in main
2025-11-26T16:59:39.271190010Z     run(args)
2025-11-26T16:59:39.271202829Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 892, in run
2025-11-26T16:59:39.271205603Z     elastic_launch(
2025-11-26T16:59:39.271207817Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 143, in __call__
2025-11-26T16:59:39.271210441Z     return launch_agent(self._config, self._entrypoint, list(args))
2025-11-26T16:59:39.271212944Z            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T16:59:39.271214967Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 277, in launch_agent
2025-11-26T16:59:39.271216950Z     raise ChildFailedError(
2025-11-26T16:59:39.271218983Z torch.distributed.elastic.multiprocessing.errors.ChildFailedError:
2025-11-26T16:59:39.271220956Z ============================================================
2025-11-26T16:59:39.271222969Z examples/cloud_gsm8k/gsm8k_grpo_train.py FAILED
2025-11-26T16:59:39.271225072Z ------------------------------------------------------------
2025-11-26T16:59:39.271229770Z Failures:
2025-11-26T16:59:39.271231802Z   <NO_OTHER_FAILURES>
2025-11-26T16:59:39.271233776Z ------------------------------------------------------------
2025-11-26T16:59:39.271235768Z Root Cause (first observed failure):
2025-11-26T16:59:39.271237771Z [0]:
2025-11-26T16:59:39.271239805Z   time      : 2025-11-26_16:59:39
2025-11-26T16:59:39.271241788Z   host      : cef7c503fdea
2025-11-26T16:59:39.271243799Z   rank      : 0 (local_rank: 0)
2025-11-26T16:59:39.271245773Z   exitcode  : 1 (pid: 1032)
2025-11-26T16:59:39.271247785Z   error_file: <N/A>
2025-11-26T16:59:39.271249748Z   traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
2025-11-26T16:59:39.271251771Z ============================================================
2025-11-26T16:59:41.002755436Z [37m20251126-16:59:41.002 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [315][0m
2025-11-26T16:59:41.118828290Z Killed
2025-11-26T16:59:41.129872243Z [37m20251126-16:59:41.129 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [965][0m
2025-11-26T16:59:41.131038580Z Traceback (most recent call last):
2025-11-26T16:59:41.131052201Z   File "<frozen runpy>", line 198, in _run_module_as_main
2025-11-26T16:59:41.131055195Z   File "<frozen runpy>", line 88, in _run_code
2025-11-26T16:59:41.131057248Z   File "/workspace/AReaL/areal/launcher/local.py", line 405, in <module>
2025-11-26T16:59:41.131211659Z     main()
2025-11-26T16:59:41.131218920Z   File "/workspace/AReaL/areal/launcher/local.py", line 260, in main
2025-11-26T16:59:41.131319200Z     local_main(config, run_id=0)
2025-11-26T16:59:41.131323026Z   File "/workspace/AReaL/areal/launcher/local.py", line 399, in local_main
2025-11-26T16:59:41.131414684Z     raise e
2025-11-26T16:59:41.131417047Z   File "/workspace/AReaL/areal/launcher/local.py", line 375, in local_main
2025-11-26T16:59:41.131474332Z     launcher.wait(
2025-11-26T16:59:41.131477147Z   File "/workspace/AReaL/areal/launcher/local.py", line 235, in wait
2025-11-26T16:59:41.131542245Z     raise JobException(
2025-11-26T16:59:41.131545089Z areal.utils.launcher.JobException: Job gsm8k-grpo-cloud-2gpu-2000samples_trial_20251126_165854:trainer JobState.COMPLETED at node local
2025-11-26T16:59:41.426619380Z [37m20251126-16:59:41.425 Local Scheduler INFO: Waiting for 0 local running processes, pids: [0m
2025-11-26T16:59:57.729632577Z ==========
2025-11-26T16:59:57.729636413Z == CUDA ==
2025-11-26T16:59:57.729683203Z ==========
2025-11-26T16:59:57.734666818Z CUDA Version 12.9.1
2025-11-26T16:59:57.736355347Z Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
2025-11-26T16:59:57.737817177Z This container image and its contents are governed by the NVIDIA Deep Learning Container License.
2025-11-26T16:59:57.737820942Z By pulling and using the container, you accept the terms and conditions of this license:
2025-11-26T16:59:57.737824007Z https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license
2025-11-26T16:59:57.737828764Z A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
2025-11-26T16:59:57.904213662Z Writing to /root/.config/pip/pip.conf
2025-11-26T16:59:58.062566869Z Writing to /root/.config/pip/pip.conf
2025-11-26T16:59:58.250930207Z Branch 'feature/reasoning_model' set up to track remote branch 'feature/reasoning_model' from 'origin'.
2025-11-26T16:59:58.250968695Z Your branch is up to date with 'origin/feature/reasoning_model'.
2025-11-26T16:59:58.322247864Z Checking AReaL installation...
2025-11-26T16:59:58.387956409Z AReaL already installed. Skipping installation.
2025-11-26T16:59:58.387989388Z Cleaning up any leftover GPU processes...
2025-11-26T17:00:01.406390190Z Checking for processes holding GPU device files...
2025-11-26T17:00:03.334976473Z Found processes holding GPU devices: 1
2025-11-26T17:00:03.335031296Z 20
2025-11-26T17:00:03.335035111Z 71
2025-11-26T17:00:03.335038696Z 72
2025-11-26T17:00:03.335041571Z Killing process 1...
2025-11-26T17:00:03.335044936Z Killing process 71...
2025-11-26T17:00:03.335094169Z Killing process 72...
2025-11-26T17:00:05.337887497Z Using fuser to kill processes on GPU devices...
2025-11-26T17:00:07.359966742Z Checking GPU...
2025-11-26T17:00:07.393713772Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:00:07.393741633Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:00:07.410202490Z Set PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True for better memory management
2025-11-26T17:00:07.410216702Z Detected 2 GPU(s)
2025-11-26T17:00:07.410219626Z Checking GPU status...
2025-11-26T17:00:07.438757923Z index, name, utilization.gpu [%], memory.used [MiB], compute_mode
2025-11-26T17:00:07.440070821Z 0, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:00:07.440393853Z 1, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:00:07.484562303Z Verifying GPU accessibility...
2025-11-26T17:00:08.029950569Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:00:08.030022076Z   import pynvml  # type: ignore[import]
2025-11-26T17:00:09.150807126Z GPU accessibility verified on attempt 1
2025-11-26T17:00:09.696314529Z Starting training...
2025-11-26T17:00:12.699289766Z Using STANDARD 2000 SAMPLES 2 GPUs configuration
2025-11-26T17:00:12.699324798Z Note: GRPO only (no reasoning XML). Dataset capped at 2000 samples (~6 hours).
2025-11-26T17:00:12.699328363Z GPU count: 2 (required: 2)
2025-11-26T17:00:12.701896731Z ==========================================
2025-11-26T17:00:12.701900346Z Starting GRPO Training (Cloud)
2025-11-26T17:00:12.701903591Z ==========================================
2025-11-26T17:00:12.701905634Z Config: standard_2000samples_2GPUs
2025-11-26T17:00:12.701907738Z Config file: examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml
2025-11-26T17:00:12.701923440Z Training script: examples/cloud_gsm8k/gsm8k_grpo_train.py
2025-11-26T17:00:12.701926114Z Experiment: gsm8k-grpo-cloud-2gpu-2000samples
2025-11-26T17:00:12.701936760Z Trial: trial_20251126_170012
2025-11-26T17:00:12.701938894Z GPU: NVIDIA A100 80GB PCIe NVIDIA A100 80GB PCIe (81920 MB)
2025-11-26T17:00:12.701940946Z WandB API key: e1adc5be02...
2025-11-26T17:00:12.701942949Z ==========================================
2025-11-26T17:00:13.400720987Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:00:13.400767857Z   import pynvml  # type: ignore[import]
2025-11-26T17:00:17.924465398Z [37m20251126-17:00:17.923 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:00:17.924511568Z [37m20251126-17:00:17.924 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:00:17.924863235Z [37m20251126-17:00:17.924 name-resolve INFO: No such name resolve path: ./tmp/areal/name_resolve/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_170012[0m
2025-11-26T17:00:18.032365691Z [37m20251126-17:00:18.031 Local Scheduler INFO: LocalLauncher: experiment_name=gsm8k-grpo-cloud-2gpu-2000samples, trial_name=trial_20251126_170012, fileroot=/workspace/outputs/grpo, run_id=0, is_recover_run=False[0m
2025-11-26T17:00:18.039675822Z [37m20251126-17:00:18.039 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL CUDA_VISIBLE_DEVICES=0 stdbuf -oL python3 -m areal.launcher.sglang_server examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_170012 sglang.random_seed=1 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_170012/llm_server.log[0m
2025-11-26T17:00:18.749363671Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:00:18.749410350Z   import pynvml  # type: ignore[import]
2025-11-26T17:00:20.217487338Z [37m20251126-17:00:20.216 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:00:20.218291322Z [37m20251126-17:00:20.217 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:00:20.320675222Z [37m20251126-17:00:20.320 SGLangServer Wrapper INFO: Launch command: python3 -m sglang.launch_server --host 172.21.0.2 --port 15507 --tokenizer-path Qwen/Qwen2.5-0.5B-Instruct --tokenizer-mode auto --load-format auto --trust-remote-code --device cuda --tp-size 1 --base-gpu-id 0 --nnodes 1 --node-rank 0 --dist-init-addr localhost:15795 --model-path Qwen/Qwen2.5-0.5B-Instruct --random-seed 1 --skip-tokenizer-init --disable-radix-cache --torch-compile-max-bs 32 --triton-attention-num-kv-splits 8 --num-continuous-decode-steps 1 --attention-backend flashinfer --context-length 4096 --mem-fraction-static 0.6 --chunked-prefill-size -1 --max-prefill-tokens 32768 --schedule-policy lpm --schedule-conservativeness 1.0 --cpu-offload-gb 0 --dtype bfloat16 --kv-cache-dtype auto --dp-size 1 --ep-size 1 --max-loaded-loras 1 --max-loras-per-batch 1 --lora-backend triton --log-level warning --log-level-http warning --log-requests-level 0 --enable-metrics --decode-log-interval 1[0m
2025-11-26T17:00:21.358160428Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:00:21.358201239Z   import pynvml  # type: ignore[import]
2025-11-26T17:00:26.691073100Z INFO 11-26 17:00:26 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:00:27.391992155Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:00:28.406639360Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:00:28.406673351Z   import pynvml  # type: ignore[import]
2025-11-26T17:00:28.408730844Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:00:28.408743603Z   import pynvml  # type: ignore[import]
2025-11-26T17:00:33.982388826Z INFO 11-26 17:00:33 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:00:34.062079846Z INFO 11-26 17:00:34 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:00:34.739695314Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:00:35.021743512Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:00:35.025331917Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:00:35.026291104Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:00:35.027027587Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:00:35.060661308Z [2025-11-26 17:00:35] MOE_RUNNER_BACKEND is not initialized, using triton backend
2025-11-26T17:00:35.558464655Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:00:35.558501951Z   warnings.warn(
2025-11-26T17:00:35.558505186Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:00:35.558507359Z   warnings.warn(
2025-11-26T17:00:36.793421613Z Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
2025-11-26T17:00:36.898416564Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  9.55it/s]
2025-11-26T17:00:36.898864165Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  9.52it/s]
2025-11-26T17:00:39.505329480Z   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   4%|â–         | 1/23 [00:00<00:12,  1.81it/s]Capturing batches (bs=152 avail_mem=30.62 GB):   4%|â–         | 1/23 [00:00<00:12,  1.81it/s]Capturing batches (bs=144 avail_mem=30.60 GB):   4%|â–         | 1/23 [00:00<00:12,  1.81it/s]Capturing batches (bs=136 avail_mem=30.59 GB):   4%|â–         | 1/23 [00:00<00:12,  1.81it/s]Capturing batches (bs=136 avail_mem=30.59 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.12it/s]Capturing batches (bs=128 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.12it/s]Capturing batches (bs=120 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.12it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.12it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.30it/s]Capturing batches (bs=104 avail_mem=30.54 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.30it/s]Capturing batches (bs=96 avail_mem=30.53 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.30it/s] Capturing batches (bs=88 avail_mem=30.51 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.30it/s]Capturing batches (bs=88 avail_mem=30.51 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.49it/s]Capturing batches (bs=80 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.49it/s]Capturing batches (bs=72 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.49it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:01<00:00, 14.49it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 16.90it/s]Capturing batches (bs=56 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 16.90it/s]Capturing batches (bs=48 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 16.90it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 16.90it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 18.85it/s]Capturing batches (bs=32 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 18.85it/s]Capturing batches (bs=24 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 18.85it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 18.85it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.35it/s]Capturing batches (bs=8 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.35it/s] Capturing batches (bs=4 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.35it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.35it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.09it/s]Capturing batches (bs=1 avail_mem=30.35 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.09it/s]Capturing batches (bs=1 avail_mem=30.35 GB): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00, 14.60it/s]
2025-11-26T17:00:45.347469242Z [37m20251126-17:00:45.346 SGLangServer Wrapper INFO: SGLang server launched at: http://172.21.0.2:15507[0m
2025-11-26T17:00:46.047033926Z [37m20251126-17:00:46.046 Launcher Utils INFO: Found 1 rollout servers: 172.21.0.2:15507[0m
2025-11-26T17:00:46.047063361Z [37m20251126-17:00:46.046 Local Scheduler INFO: LLM inference server launched at: AREAL_LLM_SERVER_ADDRS=172.21.0.2:15507[0m
2025-11-26T17:00:46.050014631Z [37m20251126-17:00:46.049 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL AREAL_LLM_SERVER_ADDRS=172.21.0.2:15507 AREAL_RECOVER_RUN=0 NCCL_CUMEM_ENABLE=0 NCCL_NVLS_ENABLE=0 CUDA_VISIBLE_DEVICES=1 stdbuf -oL torchrun --nnodes 1 --nproc-per-node 1 --master-addr localhost --master-port 26618 examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_170012 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_170012/trainer.log[0m
2025-11-26T17:00:46.050714190Z [37m20251126-17:00:46.050 Local Scheduler INFO: Waiting for 2 local running processes, pids: 315 1005[0m
2025-11-26T17:00:46.570409709Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:00:46.570445833Z   import pynvml  # type: ignore[import]
2025-11-26T17:00:47.759972662Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:00:47.760013943Z   import pynvml  # type: ignore[import]
2025-11-26T17:00:54.398393249Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:00:54.398438887Z   warnings.warn(
2025-11-26T17:00:54.398443054Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:00:54.398446068Z   warnings.warn(
2025-11-26T17:00:54.854745748Z Traceback (most recent call last):
2025-11-26T17:00:54.854783604Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 665, in <module>
2025-11-26T17:00:54.855451876Z     main(sys.argv[1:])
2025-11-26T17:00:54.855493599Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 102, in main
2025-11-26T17:00:54.855497444Z     config, _ = load_expr_config(args_with_overrides, GRPOConfig)
2025-11-26T17:00:54.855501160Z                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:00:54.855503754Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1282, in load_expr_config
2025-11-26T17:00:54.856205685Z     cfg = to_structured_cfg(cfg, config_cls=config_cls)
2025-11-26T17:00:54.856213496Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:00:54.856215720Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1276, in to_structured_cfg
2025-11-26T17:00:54.856218304Z     cfg = OmegaConf.merge(default_cfg, cfg)
2025-11-26T17:00:54.856220417Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:00:54.856222379Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/omegaconf.py", line 274, in merge
2025-11-26T17:00:54.856224593Z     target.merge_with(
2025-11-26T17:00:54.856227347Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 507, in merge_with
2025-11-26T17:00:54.856230051Z     self._format_and_raise(key=None, value=None, cause=e)
2025-11-26T17:00:54.856232825Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:00:54.856680537Z     format_and_raise(
2025-11-26T17:00:54.856688148Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:00:54.856691563Z     _raise(ex, cause)
2025-11-26T17:00:54.856694307Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:00:54.856697642Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:00:54.856700677Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:00:54.856712944Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 502, in merge_with
2025-11-26T17:00:54.857077831Z     self._merge_with(
2025-11-26T17:00:54.857085122Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:00:54.857088417Z     BaseContainer._map_merge(
2025-11-26T17:00:54.857090871Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:00:54.857092963Z     dest_node._merge_with(
2025-11-26T17:00:54.857094937Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:00:54.857097150Z     BaseContainer._map_merge(
2025-11-26T17:00:54.857099083Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:00:54.857101226Z     dest_node._merge_with(
2025-11-26T17:00:54.857103319Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:00:54.857546043Z     BaseContainer._map_merge(
2025-11-26T17:00:54.857560224Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 432, in _map_merge
2025-11-26T17:00:54.857563479Z     dest[key] = src._get_node(key)
2025-11-26T17:00:54.857566904Z     ~~~~^^^^^
2025-11-26T17:00:54.857570349Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 308, in __setitem__
2025-11-26T17:00:54.857573715Z     self._format_and_raise(
2025-11-26T17:00:54.857576288Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:00:54.857579092Z     format_and_raise(
2025-11-26T17:00:54.857581967Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:00:54.857584911Z     _raise(ex, cause)
2025-11-26T17:00:54.857587565Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:00:54.858234013Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:00:54.858245480Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:00:54.858248645Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 306, in __setitem__
2025-11-26T17:00:54.858252000Z     self.__set_impl(key=key, value=value)
2025-11-26T17:00:54.858254263Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 316, in __set_impl
2025-11-26T17:00:54.858256396Z     self._set_item_impl(key, value)
2025-11-26T17:00:54.858258469Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 579, in _set_item_impl
2025-11-26T17:00:54.858263627Z     target_node_ref = self._get_node(key)
2025-11-26T17:00:54.858266011Z                       ^^^^^^^^^^^^^^^^^^^
2025-11-26T17:00:54.858268044Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 473, in _get_node
2025-11-26T17:00:54.858519320Z     self._validate_get(key)
2025-11-26T17:00:54.858526821Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 163, in _validate_get
2025-11-26T17:00:54.858530307Z     self._format_and_raise(
2025-11-26T17:00:54.858532850Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:00:54.858535404Z     format_and_raise(
2025-11-26T17:00:54.858538068Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 906, in format_and_raise
2025-11-26T17:00:54.858860030Z     _raise(ex, cause)
2025-11-26T17:00:54.858865349Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:00:54.858868583Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:00:54.858871748Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:00:54.858873831Z omegaconf.errors.ConfigKeyError: Key 'max_new_tokens' not in 'NormConfig'
2025-11-26T17:00:54.858875965Z     full_key: actor.adv_norm.max_new_tokens
2025-11-26T17:00:54.858878128Z     reference_type=Optional[NormConfig]
2025-11-26T17:00:54.858882414Z     object_type=NormConfig
2025-11-26T17:00:57.970808778Z E1126 17:00:57.969000 1006 torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 0 (pid: 1072) of binary: /usr/bin/python3
2025-11-26T17:00:57.971416138Z Traceback (most recent call last):
2025-11-26T17:00:57.971459683Z   File "/usr/local/bin/torchrun", line 7, in <module>
2025-11-26T17:00:57.971463199Z     sys.exit(main())
2025-11-26T17:00:57.971466033Z              ^^^^^^
2025-11-26T17:00:57.971468196Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
2025-11-26T17:00:57.971475948Z     return f(*args, **kwargs)
2025-11-26T17:00:57.971478842Z            ^^^^^^^^^^^^^^^^^^
2025-11-26T17:00:57.971480805Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 901, in main
2025-11-26T17:00:57.971878470Z     run(args)
2025-11-26T17:00:57.971886342Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 892, in run
2025-11-26T17:00:57.971889386Z     elastic_launch(
2025-11-26T17:00:57.971893343Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 143, in __call__
2025-11-26T17:00:57.971896277Z     return launch_agent(self._config, self._entrypoint, list(args))
2025-11-26T17:00:57.971899181Z            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:00:57.971901234Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 277, in launch_agent
2025-11-26T17:00:57.971903718Z     raise ChildFailedError(
2025-11-26T17:00:57.972306782Z torch.distributed.elastic.multiprocessing.errors.ChildFailedError:
2025-11-26T17:00:57.972317668Z ============================================================
2025-11-26T17:00:57.972320432Z examples/cloud_gsm8k/gsm8k_grpo_train.py FAILED
2025-11-26T17:00:57.972322676Z ------------------------------------------------------------
2025-11-26T17:00:57.972325099Z Failures:
2025-11-26T17:00:57.972329697Z   <NO_OTHER_FAILURES>
2025-11-26T17:00:57.972332641Z ------------------------------------------------------------
2025-11-26T17:00:57.972334904Z Root Cause (first observed failure):
2025-11-26T17:00:57.972337158Z [0]:
2025-11-26T17:00:57.972339551Z   time      : 2025-11-26_17:00:57
2025-11-26T17:00:57.972341564Z   host      : cef7c503fdea
2025-11-26T17:00:57.972343918Z   rank      : 0 (local_rank: 0)
2025-11-26T17:00:57.972346041Z   exitcode  : 1 (pid: 1072)
2025-11-26T17:00:57.972347984Z   error_file: <N/A>
2025-11-26T17:00:57.972350177Z   traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
2025-11-26T17:00:57.972365260Z ============================================================
2025-11-26T17:01:00.054219732Z [37m20251126-17:01:00.053 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [315][0m
2025-11-26T17:01:00.176396320Z Killed
2025-11-26T17:01:00.180671924Z [37m20251126-17:01:00.180 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [1005][0m
2025-11-26T17:01:00.181744882Z Traceback (most recent call last):
2025-11-26T17:01:00.181753986Z   File "<frozen runpy>", line 198, in _run_module_as_main
2025-11-26T17:01:00.181756850Z   File "<frozen runpy>", line 88, in _run_code
2025-11-26T17:01:00.181758973Z   File "/workspace/AReaL/areal/launcher/local.py", line 405, in <module>
2025-11-26T17:01:00.181908096Z     main()
2025-11-26T17:01:00.181923108Z   File "/workspace/AReaL/areal/launcher/local.py", line 260, in main
2025-11-26T17:01:00.182020986Z     local_main(config, run_id=0)
2025-11-26T17:01:00.182026334Z   File "/workspace/AReaL/areal/launcher/local.py", line 399, in local_main
2025-11-26T17:01:00.182096669Z     raise e
2025-11-26T17:01:00.182099834Z   File "/workspace/AReaL/areal/launcher/local.py", line 375, in local_main
2025-11-26T17:01:00.182216778Z     launcher.wait(
2025-11-26T17:01:00.182224210Z   File "/workspace/AReaL/areal/launcher/local.py", line 235, in wait
2025-11-26T17:01:00.182255256Z     raise JobException(
2025-11-26T17:01:00.182258591Z areal.utils.launcher.JobException: Job gsm8k-grpo-cloud-2gpu-2000samples_trial_20251126_170012:trainer JobState.COMPLETED at node local
2025-11-26T17:01:00.449416837Z [37m20251126-17:01:00.448 Local Scheduler INFO: Waiting for 0 local running processes, pids: [0m
2025-11-26T17:01:16.116915218Z ==========
2025-11-26T17:01:16.116917832Z == CUDA ==
2025-11-26T17:01:16.116959835Z ==========
2025-11-26T17:01:16.121656811Z CUDA Version 12.9.1
2025-11-26T17:01:16.123552550Z Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
2025-11-26T17:01:16.125526728Z This container image and its contents are governed by the NVIDIA Deep Learning Container License.
2025-11-26T17:01:16.125529211Z By pulling and using the container, you accept the terms and conditions of this license:
2025-11-26T17:01:16.125531905Z https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license
2025-11-26T17:01:16.125535951Z A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
2025-11-26T17:01:16.289485300Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:01:16.446187644Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:01:16.655371901Z Branch 'feature/reasoning_model' set up to track remote branch 'feature/reasoning_model' from 'origin'.
2025-11-26T17:01:16.655410308Z Your branch is up to date with 'origin/feature/reasoning_model'.
2025-11-26T17:01:16.727136877Z Checking AReaL installation...
2025-11-26T17:01:16.786055000Z AReaL already installed. Skipping installation.
2025-11-26T17:01:16.786091535Z Cleaning up any leftover GPU processes...
2025-11-26T17:01:19.807506592Z Checking for processes holding GPU device files...
2025-11-26T17:01:22.499360520Z Found processes holding GPU devices: 1
2025-11-26T17:01:22.499405077Z 20
2025-11-26T17:01:22.499408012Z 71
2025-11-26T17:01:22.499410195Z 72
2025-11-26T17:01:22.499412258Z Killing process 1...
2025-11-26T17:01:22.499415062Z Killing process 71...
2025-11-26T17:01:22.499470436Z Killing process 72...
2025-11-26T17:01:24.502158165Z Using fuser to kill processes on GPU devices...
2025-11-26T17:01:26.526296394Z Checking GPU...
2025-11-26T17:01:26.561203822Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:01:26.561236181Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:01:26.577746451Z Set PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True for better memory management
2025-11-26T17:01:26.577779160Z Detected 2 GPU(s)
2025-11-26T17:01:26.577784428Z Checking GPU status...
2025-11-26T17:01:26.606067293Z index, name, utilization.gpu [%], memory.used [MiB], compute_mode
2025-11-26T17:01:26.607542763Z 0, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:01:26.607837284Z 1, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:01:26.654717175Z Verifying GPU accessibility...
2025-11-26T17:01:27.178024315Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:01:27.178057635Z   import pynvml  # type: ignore[import]
2025-11-26T17:01:28.279199872Z GPU accessibility verified on attempt 1
2025-11-26T17:01:28.748892263Z Starting training...
2025-11-26T17:01:31.752028840Z Using STANDARD 2000 SAMPLES 2 GPUs configuration
2025-11-26T17:01:31.752070443Z Note: GRPO only (no reasoning XML). Dataset capped at 2000 samples (~6 hours).
2025-11-26T17:01:31.752074339Z GPU count: 2 (required: 2)
2025-11-26T17:01:31.754783818Z ==========================================
2025-11-26T17:01:31.754787103Z Starting GRPO Training (Cloud)
2025-11-26T17:01:31.754789716Z ==========================================
2025-11-26T17:01:31.754791779Z Config: standard_2000samples_2GPUs
2025-11-26T17:01:31.754793883Z Config file: examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml
2025-11-26T17:01:31.754800092Z Training script: examples/cloud_gsm8k/gsm8k_grpo_train.py
2025-11-26T17:01:31.754802696Z Experiment: gsm8k-grpo-cloud-2gpu-2000samples
2025-11-26T17:01:31.754804729Z Trial: trial_20251126_170131
2025-11-26T17:01:31.754806732Z GPU: NVIDIA A100 80GB PCIe NVIDIA A100 80GB PCIe (81920 MB)
2025-11-26T17:01:31.754819681Z WandB API key: e1adc5be02...
2025-11-26T17:01:31.754821945Z ==========================================
2025-11-26T17:01:32.468383065Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:01:32.468423045Z   import pynvml  # type: ignore[import]
2025-11-26T17:01:36.539349953Z [37m20251126-17:01:36.538 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:01:36.539395852Z [37m20251126-17:01:36.539 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:01:36.539692516Z [37m20251126-17:01:36.539 name-resolve INFO: No such name resolve path: ./tmp/areal/name_resolve/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_170131[0m
2025-11-26T17:01:36.646663026Z [37m20251126-17:01:36.646 Local Scheduler INFO: LocalLauncher: experiment_name=gsm8k-grpo-cloud-2gpu-2000samples, trial_name=trial_20251126_170131, fileroot=/workspace/outputs/grpo, run_id=0, is_recover_run=False[0m
2025-11-26T17:01:36.654280066Z [37m20251126-17:01:36.654 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL CUDA_VISIBLE_DEVICES=0 stdbuf -oL python3 -m areal.launcher.sglang_server examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_170131 sglang.random_seed=1 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_170131/llm_server.log[0m
2025-11-26T17:01:37.381752164Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:01:37.381791303Z   import pynvml  # type: ignore[import]
2025-11-26T17:01:38.853549595Z [37m20251126-17:01:38.853 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:01:38.854074270Z [37m20251126-17:01:38.853 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:01:38.960164332Z [37m20251126-17:01:38.959 SGLangServer Wrapper INFO: Launch command: python3 -m sglang.launch_server --host 172.21.0.2 --port 24000 --tokenizer-path Qwen/Qwen2.5-0.5B-Instruct --tokenizer-mode auto --load-format auto --trust-remote-code --device cuda --tp-size 1 --base-gpu-id 0 --nnodes 1 --node-rank 0 --dist-init-addr localhost:24614 --model-path Qwen/Qwen2.5-0.5B-Instruct --random-seed 1 --skip-tokenizer-init --disable-radix-cache --torch-compile-max-bs 32 --triton-attention-num-kv-splits 8 --num-continuous-decode-steps 1 --attention-backend flashinfer --context-length 4096 --mem-fraction-static 0.6 --chunked-prefill-size -1 --max-prefill-tokens 32768 --schedule-policy lpm --schedule-conservativeness 1.0 --cpu-offload-gb 0 --dtype bfloat16 --kv-cache-dtype auto --dp-size 1 --ep-size 1 --max-loaded-loras 1 --max-loras-per-batch 1 --lora-backend triton --log-level warning --log-level-http warning --log-requests-level 0 --enable-metrics --decode-log-interval 1[0m
2025-11-26T17:01:40.053177222Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:01:40.053226896Z   import pynvml  # type: ignore[import]
2025-11-26T17:01:45.618417828Z INFO 11-26 17:01:45 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:01:46.274151979Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:01:47.289925453Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:01:47.289977621Z   import pynvml  # type: ignore[import]
2025-11-26T17:01:47.296327182Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:01:47.296368003Z   import pynvml  # type: ignore[import]
2025-11-26T17:01:52.431215342Z INFO 11-26 17:01:52 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:01:52.858993571Z INFO 11-26 17:01:52 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:01:53.012682210Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:01:53.245902991Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:01:53.249402553Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:01:53.250234749Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:01:53.251045664Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:01:53.283331655Z [2025-11-26 17:01:53] MOE_RUNNER_BACKEND is not initialized, using triton backend
2025-11-26T17:01:53.757975342Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:01:53.758012678Z   warnings.warn(
2025-11-26T17:01:53.758015973Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:01:53.758018136Z   warnings.warn(
2025-11-26T17:01:54.871580558Z Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
2025-11-26T17:01:54.976091233Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  9.59it/s]
2025-11-26T17:01:54.976684292Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  9.57it/s]
2025-11-26T17:01:57.390081792Z   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   4%|â–         | 1/23 [00:00<00:11,  1.87it/s]Capturing batches (bs=152 avail_mem=30.62 GB):   4%|â–         | 1/23 [00:00<00:11,  1.87it/s]Capturing batches (bs=144 avail_mem=30.60 GB):   4%|â–         | 1/23 [00:00<00:11,  1.87it/s]Capturing batches (bs=136 avail_mem=30.59 GB):   4%|â–         | 1/23 [00:00<00:11,  1.87it/s]Capturing batches (bs=136 avail_mem=30.59 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.34it/s]Capturing batches (bs=128 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.34it/s]Capturing batches (bs=120 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.34it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.34it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.68it/s]Capturing batches (bs=104 avail_mem=30.54 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.68it/s]Capturing batches (bs=96 avail_mem=30.53 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.68it/s] Capturing batches (bs=88 avail_mem=30.51 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.68it/s]Capturing batches (bs=88 avail_mem=30.51 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 15.04it/s]Capturing batches (bs=80 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 15.04it/s]Capturing batches (bs=72 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 15.04it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 15.04it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.56it/s]Capturing batches (bs=56 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.56it/s]Capturing batches (bs=48 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.56it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.56it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.57it/s]Capturing batches (bs=32 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.57it/s]Capturing batches (bs=24 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.57it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.57it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.96it/s]Capturing batches (bs=8 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.96it/s] Capturing batches (bs=4 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.96it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.96it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.81it/s]Capturing batches (bs=1 avail_mem=30.35 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.81it/s]Capturing batches (bs=1 avail_mem=30.35 GB): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00, 15.12it/s]
2025-11-26T17:02:02.985247882Z [37m20251126-17:02:02.984 SGLangServer Wrapper INFO: SGLang server launched at: http://172.21.0.2:24000[0m
2025-11-26T17:02:03.661486447Z [37m20251126-17:02:03.661 Launcher Utils INFO: Found 1 rollout servers: 172.21.0.2:24000[0m
2025-11-26T17:02:03.661516763Z [37m20251126-17:02:03.661 Local Scheduler INFO: LLM inference server launched at: AREAL_LLM_SERVER_ADDRS=172.21.0.2:24000[0m
2025-11-26T17:02:03.664369055Z [37m20251126-17:02:03.664 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL AREAL_LLM_SERVER_ADDRS=172.21.0.2:24000 AREAL_RECOVER_RUN=0 NCCL_CUMEM_ENABLE=0 NCCL_NVLS_ENABLE=0 CUDA_VISIBLE_DEVICES=1 stdbuf -oL torchrun --nnodes 1 --nproc-per-node 1 --master-addr localhost --master-port 33305 examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_170131 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_170131/trainer.log[0m
2025-11-26T17:02:03.665021272Z [37m20251126-17:02:03.664 Local Scheduler INFO: Waiting for 2 local running processes, pids: 315 965[0m
2025-11-26T17:02:04.169224305Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:02:04.169282503Z   import pynvml  # type: ignore[import]
2025-11-26T17:02:05.345718683Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:02:05.345756059Z   import pynvml  # type: ignore[import]
2025-11-26T17:02:12.378202035Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:02:12.378246482Z   warnings.warn(
2025-11-26T17:02:12.378249677Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:02:12.378254344Z   warnings.warn(
2025-11-26T17:02:12.829793824Z Traceback (most recent call last):
2025-11-26T17:02:12.829829126Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 665, in <module>
2025-11-26T17:02:12.830412099Z     main(sys.argv[1:])
2025-11-26T17:02:12.830423116Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 102, in main
2025-11-26T17:02:12.830426481Z     config, _ = load_expr_config(args_with_overrides, GRPOConfig)
2025-11-26T17:02:12.830429025Z                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:02:12.830431077Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1282, in load_expr_config
2025-11-26T17:02:12.831233010Z     cfg = to_structured_cfg(cfg, config_cls=config_cls)
2025-11-26T17:02:12.831243505Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:02:12.831246129Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1276, in to_structured_cfg
2025-11-26T17:02:12.831248783Z     cfg = OmegaConf.merge(default_cfg, cfg)
2025-11-26T17:02:12.831251017Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:02:12.831253320Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/omegaconf.py", line 274, in merge
2025-11-26T17:02:12.831255664Z     target.merge_with(
2025-11-26T17:02:12.831258578Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 507, in merge_with
2025-11-26T17:02:12.831261101Z     self._format_and_raise(key=None, value=None, cause=e)
2025-11-26T17:02:12.831263144Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:02:12.831265188Z     format_and_raise(
2025-11-26T17:02:12.831267210Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:02:12.831663554Z     _raise(ex, cause)
2025-11-26T17:02:12.831686799Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:02:12.831690124Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:02:12.831692297Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:02:12.831695171Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 502, in merge_with
2025-11-26T17:02:12.832159878Z     self._merge_with(
2025-11-26T17:02:12.832176462Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:02:12.832179326Z     BaseContainer._map_merge(
2025-11-26T17:02:12.832182030Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:02:12.832184374Z     dest_node._merge_with(
2025-11-26T17:02:12.832186377Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:02:12.832188460Z     BaseContainer._map_merge(
2025-11-26T17:02:12.832190443Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:02:12.832192646Z     dest_node._merge_with(
2025-11-26T17:02:12.832194619Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:02:12.832196622Z     BaseContainer._map_merge(
2025-11-26T17:02:12.832198605Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 432, in _map_merge
2025-11-26T17:02:12.832543833Z     dest[key] = src._get_node(key)
2025-11-26T17:02:12.832548800Z     ~~~~^^^^^
2025-11-26T17:02:12.832551724Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 308, in __setitem__
2025-11-26T17:02:12.832554038Z     self._format_and_raise(
2025-11-26T17:02:12.832556782Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:02:12.832558975Z     format_and_raise(
2025-11-26T17:02:12.832561159Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:02:12.833246776Z     _raise(ex, cause)
2025-11-26T17:02:12.833252724Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:02:12.833254978Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:02:12.833257191Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:02:12.833259414Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 306, in __setitem__
2025-11-26T17:02:12.833266235Z     self.__set_impl(key=key, value=value)
2025-11-26T17:02:12.833268438Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 316, in __set_impl
2025-11-26T17:02:12.833270421Z     self._set_item_impl(key, value)
2025-11-26T17:02:12.833272414Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 579, in _set_item_impl
2025-11-26T17:02:12.833274457Z     target_node_ref = self._get_node(key)
2025-11-26T17:02:12.833276410Z                       ^^^^^^^^^^^^^^^^^^^
2025-11-26T17:02:12.833637130Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 473, in _get_node
2025-11-26T17:02:12.833640815Z     self._validate_get(key)
2025-11-26T17:02:12.833642848Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 163, in _validate_get
2025-11-26T17:02:12.833645572Z     self._format_and_raise(
2025-11-26T17:02:12.833647746Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:02:12.833649849Z     format_and_raise(
2025-11-26T17:02:12.833651982Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 906, in format_and_raise
2025-11-26T17:02:12.833654456Z     _raise(ex, cause)
2025-11-26T17:02:12.833656709Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:02:12.834013514Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:02:12.834017300Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:02:12.834019513Z omegaconf.errors.ConfigKeyError: Key 'max_new_tokens' not in 'NormConfig'
2025-11-26T17:02:12.834021536Z     full_key: actor.adv_norm.max_new_tokens
2025-11-26T17:02:12.834023499Z     reference_type=Optional[NormConfig]
2025-11-26T17:02:12.834025492Z     object_type=NormConfig
2025-11-26T17:02:15.460561021Z E1126 17:02:15.459000 966 torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 0 (pid: 1032) of binary: /usr/bin/python3
2025-11-26T17:02:15.461592476Z Traceback (most recent call last):
2025-11-26T17:02:15.461620237Z   File "/usr/local/bin/torchrun", line 7, in <module>
2025-11-26T17:02:15.461623912Z     sys.exit(main())
2025-11-26T17:02:15.461626326Z              ^^^^^^
2025-11-26T17:02:15.461628590Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
2025-11-26T17:02:15.461632075Z     return f(*args, **kwargs)
2025-11-26T17:02:15.461634719Z            ^^^^^^^^^^^^^^^^^^
2025-11-26T17:02:15.461636942Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 901, in main
2025-11-26T17:02:15.461639376Z     run(args)
2025-11-26T17:02:15.461642290Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 892, in run
2025-11-26T17:02:15.461644343Z     elastic_launch(
2025-11-26T17:02:15.461646336Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 143, in __call__
2025-11-26T17:02:15.462066735Z     return launch_agent(self._config, self._entrypoint, list(args))
2025-11-26T17:02:15.462074998Z            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:02:15.462077522Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 277, in launch_agent
2025-11-26T17:02:15.462080366Z     raise ChildFailedError(
2025-11-26T17:02:15.462083170Z torch.distributed.elastic.multiprocessing.errors.ChildFailedError:
2025-11-26T17:02:15.462085303Z ============================================================
2025-11-26T17:02:15.462088348Z examples/cloud_gsm8k/gsm8k_grpo_train.py FAILED
2025-11-26T17:02:15.462090661Z ------------------------------------------------------------
2025-11-26T17:02:15.462092714Z Failures:
2025-11-26T17:02:15.462094978Z   <NO_OTHER_FAILURES>
2025-11-26T17:02:15.462097352Z ------------------------------------------------------------
2025-11-26T17:02:15.462099415Z Root Cause (first observed failure):
2025-11-26T17:02:15.462101447Z [0]:
2025-11-26T17:02:15.462105233Z   time      : 2025-11-26_17:02:15
2025-11-26T17:02:15.462107236Z   host      : cef7c503fdea
2025-11-26T17:02:15.462109229Z   rank      : 0 (local_rank: 0)
2025-11-26T17:02:15.462111182Z   exitcode  : 1 (pid: 1032)
2025-11-26T17:02:15.462124372Z   error_file: <N/A>
2025-11-26T17:02:15.462131132Z   traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
2025-11-26T17:02:15.462133546Z ============================================================
2025-11-26T17:02:17.668866003Z [37m20251126-17:02:17.668 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [315][0m
2025-11-26T17:02:17.795380608Z Killed
2025-11-26T17:02:17.808813420Z [37m20251126-17:02:17.808 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [965][0m
2025-11-26T17:02:17.810177833Z Traceback (most recent call last):
2025-11-26T17:02:17.810192435Z   File "<frozen runpy>", line 198, in _run_module_as_main
2025-11-26T17:02:17.810195119Z   File "<frozen runpy>", line 88, in _run_code
2025-11-26T17:02:17.810197232Z   File "/workspace/AReaL/areal/launcher/local.py", line 405, in <module>
2025-11-26T17:02:17.810325856Z     main()
2025-11-26T17:02:17.810331694Z   File "/workspace/AReaL/areal/launcher/local.py", line 260, in main
2025-11-26T17:02:17.810441989Z     local_main(config, run_id=0)
2025-11-26T17:02:17.810445614Z   File "/workspace/AReaL/areal/launcher/local.py", line 399, in local_main
2025-11-26T17:02:17.810561618Z     raise e
2025-11-26T17:02:17.810563922Z   File "/workspace/AReaL/areal/launcher/local.py", line 375, in local_main
2025-11-26T17:02:17.810658202Z     launcher.wait(
2025-11-26T17:02:17.810660997Z   File "/workspace/AReaL/areal/launcher/local.py", line 235, in wait
2025-11-26T17:02:17.810724492Z     raise JobException(
2025-11-26T17:02:17.810727166Z areal.utils.launcher.JobException: Job gsm8k-grpo-cloud-2gpu-2000samples_trial_20251126_170131:trainer JobState.COMPLETED at node local
2025-11-26T17:02:18.104212607Z [37m20251126-17:02:18.103 Local Scheduler INFO: Waiting for 0 local running processes, pids: [0m
2025-11-26T17:02:34.552523145Z ==========
2025-11-26T17:02:34.552526350Z == CUDA ==
2025-11-26T17:02:34.552529265Z ==========
2025-11-26T17:02:34.557283246Z CUDA Version 12.9.1
2025-11-26T17:02:34.558796573Z Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
2025-11-26T17:02:34.560217811Z This container image and its contents are governed by the NVIDIA Deep Learning Container License.
2025-11-26T17:02:34.560220886Z By pulling and using the container, you accept the terms and conditions of this license:
2025-11-26T17:02:34.560223279Z https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license
2025-11-26T17:02:34.560228047Z A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
2025-11-26T17:02:34.724977704Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:02:34.883045273Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:02:35.069102968Z Branch 'feature/reasoning_model' set up to track remote branch 'feature/reasoning_model' from 'origin'.
2025-11-26T17:02:35.069153965Z Your branch is up to date with 'origin/feature/reasoning_model'.
2025-11-26T17:02:35.140291962Z Checking AReaL installation...
2025-11-26T17:02:35.200886838Z AReaL already installed. Skipping installation.
2025-11-26T17:02:35.200916912Z Cleaning up any leftover GPU processes...
2025-11-26T17:02:38.219352717Z Checking for processes holding GPU device files...
2025-11-26T17:02:40.428603537Z Found processes holding GPU devices: 1
2025-11-26T17:02:40.428644787Z 20
2025-11-26T17:02:40.428648112Z 71
2025-11-26T17:02:40.428650226Z 72
2025-11-26T17:02:40.428652619Z Killing process 1...
2025-11-26T17:02:40.428655523Z Killing process 71...
2025-11-26T17:02:40.428657577Z Killing process 72...
2025-11-26T17:02:42.430923454Z Using fuser to kill processes on GPU devices...
2025-11-26T17:02:44.452276511Z Checking GPU...
2025-11-26T17:02:44.486788337Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:02:44.486817821Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:02:44.503887189Z Set PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True for better memory management
2025-11-26T17:02:44.503905066Z Detected 2 GPU(s)
2025-11-26T17:02:44.503909252Z Checking GPU status...
2025-11-26T17:02:44.535576045Z index, name, utilization.gpu [%], memory.used [MiB], compute_mode
2025-11-26T17:02:44.536922633Z 0, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:02:44.537235021Z 1, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:02:44.582074025Z Verifying GPU accessibility...
2025-11-26T17:02:45.104209860Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:02:45.104275029Z   import pynvml  # type: ignore[import]
2025-11-26T17:02:46.206336001Z GPU accessibility verified on attempt 1
2025-11-26T17:02:46.667432065Z Starting training...
2025-11-26T17:02:49.670087122Z Using STANDARD 2000 SAMPLES 2 GPUs configuration
2025-11-26T17:02:49.670135905Z Note: GRPO only (no reasoning XML). Dataset capped at 2000 samples (~6 hours).
2025-11-26T17:02:49.670141053Z GPU count: 2 (required: 2)
2025-11-26T17:02:49.673124372Z ==========================================
2025-11-26T17:02:49.673129500Z Starting GRPO Training (Cloud)
2025-11-26T17:02:49.673132574Z ==========================================
2025-11-26T17:02:49.673134788Z Config: standard_2000samples_2GPUs
2025-11-26T17:02:49.673136871Z Config file: examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml
2025-11-26T17:02:49.673139625Z Training script: examples/cloud_gsm8k/gsm8k_grpo_train.py
2025-11-26T17:02:49.673142169Z Experiment: gsm8k-grpo-cloud-2gpu-2000samples
2025-11-26T17:02:49.673144192Z Trial: trial_20251126_170249
2025-11-26T17:02:49.673146134Z GPU: NVIDIA A100 80GB PCIe NVIDIA A100 80GB PCIe (81920 MB)
2025-11-26T17:02:49.673148108Z WandB API key: e1adc5be02...
2025-11-26T17:02:49.673150051Z ==========================================
2025-11-26T17:02:50.361538645Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:02:50.361576171Z   import pynvml  # type: ignore[import]
2025-11-26T17:02:54.312294559Z [37m20251126-17:02:54.311 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:02:54.312337694Z [37m20251126-17:02:54.312 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:02:54.312582921Z [37m20251126-17:02:54.312 name-resolve INFO: No such name resolve path: ./tmp/areal/name_resolve/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_170249[0m
2025-11-26T17:02:54.418040546Z [37m20251126-17:02:54.417 Local Scheduler INFO: LocalLauncher: experiment_name=gsm8k-grpo-cloud-2gpu-2000samples, trial_name=trial_20251126_170249, fileroot=/workspace/outputs/grpo, run_id=0, is_recover_run=False[0m
2025-11-26T17:02:54.425560139Z [37m20251126-17:02:54.425 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL CUDA_VISIBLE_DEVICES=0 stdbuf -oL python3 -m areal.launcher.sglang_server examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_170249 sglang.random_seed=1 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_170249/llm_server.log[0m
2025-11-26T17:02:55.149184163Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:02:55.149225085Z   import pynvml  # type: ignore[import]
2025-11-26T17:02:56.604341678Z [37m20251126-17:02:56.603 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:02:56.605266253Z [37m20251126-17:02:56.603 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:02:56.704395508Z [37m20251126-17:02:56.703 SGLangServer Wrapper INFO: Launch command: python3 -m sglang.launch_server --host 172.21.0.2 --port 15556 --tokenizer-path Qwen/Qwen2.5-0.5B-Instruct --tokenizer-mode auto --load-format auto --trust-remote-code --device cuda --tp-size 1 --base-gpu-id 0 --nnodes 1 --node-rank 0 --dist-init-addr localhost:22391 --model-path Qwen/Qwen2.5-0.5B-Instruct --random-seed 1 --skip-tokenizer-init --disable-radix-cache --torch-compile-max-bs 32 --triton-attention-num-kv-splits 8 --num-continuous-decode-steps 1 --attention-backend flashinfer --context-length 4096 --mem-fraction-static 0.6 --chunked-prefill-size -1 --max-prefill-tokens 32768 --schedule-policy lpm --schedule-conservativeness 1.0 --cpu-offload-gb 0 --dtype bfloat16 --kv-cache-dtype auto --dp-size 1 --ep-size 1 --max-loaded-loras 1 --max-loras-per-batch 1 --lora-backend triton --log-level warning --log-level-http warning --log-requests-level 0 --enable-metrics --decode-log-interval 1[0m
2025-11-26T17:02:57.742873071Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:02:57.742913562Z   import pynvml  # type: ignore[import]
2025-11-26T17:03:03.393536550Z INFO 11-26 17:03:03 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:03:04.068726124Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:03:05.108059988Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:03:05.108133629Z   import pynvml  # type: ignore[import]
2025-11-26T17:03:05.170246608Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:03:05.170288541Z   import pynvml  # type: ignore[import]
2025-11-26T17:03:10.318069344Z INFO 11-26 17:03:10 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:03:10.612823605Z INFO 11-26 17:03:10 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:03:10.888087181Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:03:11.108896010Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:03:11.112364766Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:03:11.113252005Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:03:11.114065864Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:03:11.146504504Z [2025-11-26 17:03:11] MOE_RUNNER_BACKEND is not initialized, using triton backend
2025-11-26T17:03:11.625000271Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:03:11.625040792Z   warnings.warn(
2025-11-26T17:03:11.625043967Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:03:11.625046250Z   warnings.warn(
2025-11-26T17:03:12.718586450Z Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
2025-11-26T17:03:12.824474359Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  9.46it/s]
2025-11-26T17:03:12.824975010Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  9.44it/s]
2025-11-26T17:03:15.246445411Z   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   4%|â–         | 1/23 [00:00<00:11,  1.84it/s]Capturing batches (bs=152 avail_mem=30.62 GB):   4%|â–         | 1/23 [00:00<00:11,  1.84it/s]Capturing batches (bs=144 avail_mem=30.60 GB):   4%|â–         | 1/23 [00:00<00:11,  1.84it/s]Capturing batches (bs=136 avail_mem=30.59 GB):   4%|â–         | 1/23 [00:00<00:11,  1.84it/s]Capturing batches (bs=136 avail_mem=30.59 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.28it/s]Capturing batches (bs=128 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.28it/s]Capturing batches (bs=120 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.28it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.28it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.62it/s]Capturing batches (bs=104 avail_mem=30.54 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.62it/s]Capturing batches (bs=96 avail_mem=30.53 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.62it/s] Capturing batches (bs=88 avail_mem=30.51 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.62it/s]Capturing batches (bs=88 avail_mem=30.51 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.99it/s]Capturing batches (bs=80 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.99it/s]Capturing batches (bs=72 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.99it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:01<00:00, 14.99it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.53it/s]Capturing batches (bs=56 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.53it/s]Capturing batches (bs=48 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.53it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.53it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.56it/s]Capturing batches (bs=32 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.56it/s]Capturing batches (bs=24 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.56it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.56it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.71it/s]Capturing batches (bs=8 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.71it/s] Capturing batches (bs=4 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.71it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.71it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.51it/s]Capturing batches (bs=1 avail_mem=30.35 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.51it/s]Capturing batches (bs=1 avail_mem=30.35 GB): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00, 14.97it/s]
2025-11-26T17:03:20.730340849Z [37m20251126-17:03:20.729 SGLangServer Wrapper INFO: SGLang server launched at: http://172.21.0.2:15556[0m
2025-11-26T17:03:21.432353772Z [37m20251126-17:03:21.431 Launcher Utils INFO: Found 1 rollout servers: 172.21.0.2:15556[0m
2025-11-26T17:03:21.432396946Z [37m20251126-17:03:21.432 Local Scheduler INFO: LLM inference server launched at: AREAL_LLM_SERVER_ADDRS=172.21.0.2:15556[0m
2025-11-26T17:03:21.434737272Z [37m20251126-17:03:21.434 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL AREAL_LLM_SERVER_ADDRS=172.21.0.2:15556 AREAL_RECOVER_RUN=0 NCCL_CUMEM_ENABLE=0 NCCL_NVLS_ENABLE=0 CUDA_VISIBLE_DEVICES=1 stdbuf -oL torchrun --nnodes 1 --nproc-per-node 1 --master-addr localhost --master-port 30338 examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_170249 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_170249/trainer.log[0m
2025-11-26T17:03:21.435394456Z [37m20251126-17:03:21.435 Local Scheduler INFO: Waiting for 2 local running processes, pids: 315 965[0m
2025-11-26T17:03:21.949354846Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:03:21.949409498Z   import pynvml  # type: ignore[import]
2025-11-26T17:03:23.120058089Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:03:23.120096576Z   import pynvml  # type: ignore[import]
2025-11-26T17:03:30.347662643Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:03:30.347704245Z   warnings.warn(
2025-11-26T17:03:30.347707420Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:03:30.347709703Z   warnings.warn(
2025-11-26T17:03:30.787277991Z Traceback (most recent call last):
2025-11-26T17:03:30.787322737Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 665, in <module>
2025-11-26T17:03:30.787953001Z     main(sys.argv[1:])
2025-11-26T17:03:30.787960703Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 102, in main
2025-11-26T17:03:30.787963287Z     config, _ = load_expr_config(args_with_overrides, GRPOConfig)
2025-11-26T17:03:30.787965991Z                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:03:30.787967994Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1282, in load_expr_config
2025-11-26T17:03:30.788471058Z     cfg = to_structured_cfg(cfg, config_cls=config_cls)
2025-11-26T17:03:30.788478409Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:03:30.788481344Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1276, in to_structured_cfg
2025-11-26T17:03:30.788484278Z     cfg = OmegaConf.merge(default_cfg, cfg)
2025-11-26T17:03:30.788938268Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:03:30.788941182Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/omegaconf.py", line 274, in merge
2025-11-26T17:03:30.788943335Z     target.merge_with(
2025-11-26T17:03:30.788945408Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 507, in merge_with
2025-11-26T17:03:30.788948092Z     self._format_and_raise(key=None, value=None, cause=e)
2025-11-26T17:03:30.788953701Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:03:30.788955784Z     format_and_raise(
2025-11-26T17:03:30.788957887Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:03:30.789439809Z     _raise(ex, cause)
2025-11-26T17:03:30.789447039Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:03:30.789450134Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:03:30.789453279Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:03:30.789456153Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 502, in merge_with
2025-11-26T17:03:30.789458387Z     self._merge_with(
2025-11-26T17:03:30.789460610Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:03:30.789865477Z     BaseContainer._map_merge(
2025-11-26T17:03:30.789868631Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:03:30.789870694Z     dest_node._merge_with(
2025-11-26T17:03:30.789872628Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:03:30.789874600Z     BaseContainer._map_merge(
2025-11-26T17:03:30.789876574Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:03:30.789878526Z     dest_node._merge_with(
2025-11-26T17:03:30.789880549Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:03:30.789882532Z     BaseContainer._map_merge(
2025-11-26T17:03:30.789884635Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 432, in _map_merge
2025-11-26T17:03:30.790257434Z     dest[key] = src._get_node(key)
2025-11-26T17:03:30.790264024Z     ~~~~^^^^^
2025-11-26T17:03:30.790267939Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 308, in __setitem__
2025-11-26T17:03:30.790270753Z     self._format_and_raise(
2025-11-26T17:03:30.790273958Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:03:30.790276642Z     format_and_raise(
2025-11-26T17:03:30.790278916Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:03:30.791094017Z     _raise(ex, cause)
2025-11-26T17:03:30.791096822Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:03:30.791098845Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:03:30.791100837Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:03:30.791102820Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 306, in __setitem__
2025-11-26T17:03:30.791104793Z     self.__set_impl(key=key, value=value)
2025-11-26T17:03:30.791106846Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 316, in __set_impl
2025-11-26T17:03:30.791108799Z     self._set_item_impl(key, value)
2025-11-26T17:03:30.791122309Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 579, in _set_item_impl
2025-11-26T17:03:30.791130061Z     target_node_ref = self._get_node(key)
2025-11-26T17:03:30.791132074Z                       ^^^^^^^^^^^^^^^^^^^
2025-11-26T17:03:30.791134016Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 473, in _get_node
2025-11-26T17:03:30.791136099Z     self._validate_get(key)
2025-11-26T17:03:30.791138132Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 163, in _validate_get
2025-11-26T17:03:30.791417161Z     self._format_and_raise(
2025-11-26T17:03:30.791421408Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:03:30.791424202Z     format_and_raise(
2025-11-26T17:03:30.791427146Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 906, in format_and_raise
2025-11-26T17:03:30.791430121Z     _raise(ex, cause)
2025-11-26T17:03:30.791432795Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:03:30.791773695Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:03:30.791776529Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:03:30.791778592Z omegaconf.errors.ConfigKeyError: Key 'max_new_tokens' not in 'NormConfig'
2025-11-26T17:03:30.791780595Z     full_key: actor.adv_norm.max_new_tokens
2025-11-26T17:03:30.791782578Z     reference_type=Optional[NormConfig]
2025-11-26T17:03:30.791784551Z     object_type=NormConfig
2025-11-26T17:03:33.639040857Z E1126 17:03:33.638000 966 torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 0 (pid: 1032) of binary: /usr/bin/python3
2025-11-26T17:03:33.639728436Z Traceback (most recent call last):
2025-11-26T17:03:33.639766944Z   File "/usr/local/bin/torchrun", line 7, in <module>
2025-11-26T17:03:33.639795367Z     sys.exit(main())
2025-11-26T17:03:33.639798061Z              ^^^^^^
2025-11-26T17:03:33.639800154Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
2025-11-26T17:03:33.639804881Z     return f(*args, **kwargs)
2025-11-26T17:03:33.639807776Z            ^^^^^^^^^^^^^^^^^^
2025-11-26T17:03:33.639810119Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 901, in main
2025-11-26T17:03:33.640182647Z     run(args)
2025-11-26T17:03:33.640195987Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 892, in run
2025-11-26T17:03:33.640199082Z     elastic_launch(
2025-11-26T17:03:33.640202026Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 143, in __call__
2025-11-26T17:03:33.640205001Z     return launch_agent(self._config, self._entrypoint, list(args))
2025-11-26T17:03:33.640207785Z            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:03:33.640209958Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 277, in launch_agent
2025-11-26T17:03:33.640212041Z     raise ChildFailedError(
2025-11-26T17:03:33.640214826Z torch.distributed.elastic.multiprocessing.errors.ChildFailedError:
2025-11-26T17:03:33.640216858Z ============================================================
2025-11-26T17:03:33.640219012Z examples/cloud_gsm8k/gsm8k_grpo_train.py FAILED
2025-11-26T17:03:33.640221315Z ------------------------------------------------------------
2025-11-26T17:03:33.640223298Z Failures:
2025-11-26T17:03:33.640225310Z   <NO_OTHER_FAILURES>
2025-11-26T17:03:33.640227363Z ------------------------------------------------------------
2025-11-26T17:03:33.640229356Z Root Cause (first observed failure):
2025-11-26T17:03:33.640231389Z [0]:
2025-11-26T17:03:33.640233533Z   time      : 2025-11-26_17:03:33
2025-11-26T17:03:33.640235545Z   host      : cef7c503fdea
2025-11-26T17:03:33.640237548Z   rank      : 0 (local_rank: 0)
2025-11-26T17:03:33.640239511Z   exitcode  : 1 (pid: 1032)
2025-11-26T17:03:33.640241594Z   error_file: <N/A>
2025-11-26T17:03:33.640243638Z   traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
2025-11-26T17:03:33.640245701Z ============================================================
2025-11-26T17:03:35.439021131Z [37m20251126-17:03:35.438 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [315][0m
2025-11-26T17:03:35.568088770Z Killed
2025-11-26T17:03:35.573092565Z [37m20251126-17:03:35.572 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [965][0m
2025-11-26T17:03:35.574469208Z Traceback (most recent call last):
2025-11-26T17:03:35.574480765Z   File "<frozen runpy>", line 198, in _run_module_as_main
2025-11-26T17:03:35.574483560Z   File "<frozen runpy>", line 88, in _run_code
2025-11-26T17:03:35.574485984Z   File "/workspace/AReaL/areal/launcher/local.py", line 405, in <module>
2025-11-26T17:03:35.574650860Z     main()
2025-11-26T17:03:35.574655767Z   File "/workspace/AReaL/areal/launcher/local.py", line 260, in main
2025-11-26T17:03:35.574730990Z     local_main(config, run_id=0)
2025-11-26T17:03:35.574734836Z   File "/workspace/AReaL/areal/launcher/local.py", line 399, in local_main
2025-11-26T17:03:35.574849537Z     raise e
2025-11-26T17:03:35.574852101Z   File "/workspace/AReaL/areal/launcher/local.py", line 375, in local_main
2025-11-26T17:03:35.574946573Z     launcher.wait(
2025-11-26T17:03:35.574949407Z   File "/workspace/AReaL/areal/launcher/local.py", line 235, in wait
2025-11-26T17:03:35.574988065Z     raise JobException(
2025-11-26T17:03:35.574991040Z areal.utils.launcher.JobException: Job gsm8k-grpo-cloud-2gpu-2000samples_trial_20251126_170249:trainer JobState.COMPLETED at node local
2025-11-26T17:03:35.866974862Z [37m20251126-17:03:35.866 Local Scheduler INFO: Waiting for 0 local running processes, pids: [0m
2025-11-26T17:03:52.926356251Z ==========
2025-11-26T17:03:52.926363471Z == CUDA ==
2025-11-26T17:03:52.926404713Z ==========
2025-11-26T17:03:52.931244313Z CUDA Version 12.9.1
2025-11-26T17:03:52.932967494Z Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
2025-11-26T17:03:52.934750915Z This container image and its contents are governed by the NVIDIA Deep Learning Container License.
2025-11-26T17:03:52.934754500Z By pulling and using the container, you accept the terms and conditions of this license:
2025-11-26T17:03:52.934757656Z https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license
2025-11-26T17:03:52.934763625Z A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
2025-11-26T17:03:53.100567261Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:03:53.260196629Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:03:53.447137997Z Branch 'feature/reasoning_model' set up to track remote branch 'feature/reasoning_model' from 'origin'.
2025-11-26T17:03:53.447177647Z Your branch is up to date with 'origin/feature/reasoning_model'.
2025-11-26T17:03:53.517444730Z Checking AReaL installation...
2025-11-26T17:03:53.575281534Z AReaL already installed. Skipping installation.
2025-11-26T17:03:53.575315724Z Cleaning up any leftover GPU processes...
2025-11-26T17:03:56.593575775Z Checking for processes holding GPU device files...
2025-11-26T17:03:58.747803646Z Found processes holding GPU devices: 1
2025-11-26T17:03:58.747845960Z 20
2025-11-26T17:03:58.747848504Z 71
2025-11-26T17:03:58.747850927Z 72
2025-11-26T17:03:58.747853311Z Killing process 1...
2025-11-26T17:03:58.747856416Z Killing process 71...
2025-11-26T17:03:58.748022244Z Killing process 72...
2025-11-26T17:04:00.750681550Z Using fuser to kill processes on GPU devices...
2025-11-26T17:04:02.774549896Z Checking GPU...
2025-11-26T17:04:02.808558167Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:04:02.808588602Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:04:02.825027005Z Set PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True for better memory management
2025-11-26T17:04:02.825049859Z Detected 2 GPU(s)
2025-11-26T17:04:02.825053384Z Checking GPU status...
2025-11-26T17:04:02.852484023Z index, name, utilization.gpu [%], memory.used [MiB], compute_mode
2025-11-26T17:04:02.853898772Z 0, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:04:02.854216118Z 1, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:04:02.896963129Z Verifying GPU accessibility...
2025-11-26T17:04:03.428409890Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:04:03.428454367Z   import pynvml  # type: ignore[import]
2025-11-26T17:04:04.542818569Z GPU accessibility verified on attempt 1
2025-11-26T17:04:05.000419188Z Starting training...
2025-11-26T17:04:08.002949026Z Using STANDARD 2000 SAMPLES 2 GPUs configuration
2025-11-26T17:04:08.002989076Z Note: GRPO only (no reasoning XML). Dataset capped at 2000 samples (~6 hours).
2025-11-26T17:04:08.002992762Z GPU count: 2 (required: 2)
2025-11-26T17:04:08.005056103Z ==========================================
2025-11-26T17:04:08.005059187Z Starting GRPO Training (Cloud)
2025-11-26T17:04:08.005062182Z ==========================================
2025-11-26T17:04:08.005064475Z Config: standard_2000samples_2GPUs
2025-11-26T17:04:08.005066488Z Config file: examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml
2025-11-26T17:04:08.005068962Z Training script: examples/cloud_gsm8k/gsm8k_grpo_train.py
2025-11-26T17:04:08.005071556Z Experiment: gsm8k-grpo-cloud-2gpu-2000samples
2025-11-26T17:04:08.005073569Z Trial: trial_20251126_170408
2025-11-26T17:04:08.005075532Z GPU: NVIDIA A100 80GB PCIe NVIDIA A100 80GB PCIe (81920 MB)
2025-11-26T17:04:08.005077505Z WandB API key: e1adc5be02...
2025-11-26T17:04:08.005079538Z ==========================================
2025-11-26T17:04:08.684401602Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:04:08.684461391Z   import pynvml  # type: ignore[import]
2025-11-26T17:04:12.603828618Z [37m20251126-17:04:12.603 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:04:12.603873145Z [37m20251126-17:04:12.603 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:04:12.604063029Z [37m20251126-17:04:12.603 name-resolve INFO: No such name resolve path: ./tmp/areal/name_resolve/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_170408[0m
2025-11-26T17:04:12.709700554Z [37m20251126-17:04:12.709 Local Scheduler INFO: LocalLauncher: experiment_name=gsm8k-grpo-cloud-2gpu-2000samples, trial_name=trial_20251126_170408, fileroot=/workspace/outputs/grpo, run_id=0, is_recover_run=False[0m
2025-11-26T17:04:12.717609170Z [37m20251126-17:04:12.717 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL CUDA_VISIBLE_DEVICES=0 stdbuf -oL python3 -m areal.launcher.sglang_server examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_170408 sglang.random_seed=1 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_170408/llm_server.log[0m
2025-11-26T17:04:13.428313432Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:04:13.428353120Z   import pynvml  # type: ignore[import]
2025-11-26T17:04:14.892081254Z [37m20251126-17:04:14.891 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:04:14.892785919Z [37m20251126-17:04:14.891 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:04:14.995428939Z [37m20251126-17:04:14.994 SGLangServer Wrapper INFO: Launch command: python3 -m sglang.launch_server --host 172.21.0.2 --port 19759 --tokenizer-path Qwen/Qwen2.5-0.5B-Instruct --tokenizer-mode auto --load-format auto --trust-remote-code --device cuda --tp-size 1 --base-gpu-id 0 --nnodes 1 --node-rank 0 --dist-init-addr localhost:21736 --model-path Qwen/Qwen2.5-0.5B-Instruct --random-seed 1 --skip-tokenizer-init --disable-radix-cache --torch-compile-max-bs 32 --triton-attention-num-kv-splits 8 --num-continuous-decode-steps 1 --attention-backend flashinfer --context-length 4096 --mem-fraction-static 0.6 --chunked-prefill-size -1 --max-prefill-tokens 32768 --schedule-policy lpm --schedule-conservativeness 1.0 --cpu-offload-gb 0 --dtype bfloat16 --kv-cache-dtype auto --dp-size 1 --ep-size 1 --max-loaded-loras 1 --max-loras-per-batch 1 --lora-backend triton --log-level warning --log-level-http warning --log-requests-level 0 --enable-metrics --decode-log-interval 1[0m
2025-11-26T17:04:16.104011891Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:04:16.104060153Z   import pynvml  # type: ignore[import]
2025-11-26T17:04:21.652653111Z INFO 11-26 17:04:21 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:04:22.284586212Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:04:23.317630816Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:04:23.317678007Z   import pynvml  # type: ignore[import]
2025-11-26T17:04:23.334492633Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:04:23.334514746Z   import pynvml  # type: ignore[import]
2025-11-26T17:04:28.911779131Z INFO 11-26 17:04:28 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:04:28.920908486Z INFO 11-26 17:04:28 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:04:29.782521663Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:04:29.998910131Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:04:30.002528130Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:04:30.005386452Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:04:30.005398320Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:04:30.037181899Z [2025-11-26 17:04:30] MOE_RUNNER_BACKEND is not initialized, using triton backend
2025-11-26T17:04:30.523168957Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:04:30.523207695Z   warnings.warn(
2025-11-26T17:04:30.523210879Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:04:30.523213043Z   warnings.warn(
2025-11-26T17:04:31.825861995Z Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
2025-11-26T17:04:31.929049851Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  9.70it/s]
2025-11-26T17:04:31.929458523Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  9.68it/s]
2025-11-26T17:04:34.419282221Z   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   4%|â–         | 1/23 [00:00<00:11,  1.85it/s]Capturing batches (bs=152 avail_mem=30.62 GB):   4%|â–         | 1/23 [00:00<00:11,  1.85it/s]Capturing batches (bs=144 avail_mem=30.60 GB):   4%|â–         | 1/23 [00:00<00:11,  1.85it/s]Capturing batches (bs=136 avail_mem=30.59 GB):   4%|â–         | 1/23 [00:00<00:11,  1.85it/s]Capturing batches (bs=136 avail_mem=30.59 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.28it/s]Capturing batches (bs=128 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.28it/s]Capturing batches (bs=120 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.28it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.28it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.61it/s]Capturing batches (bs=104 avail_mem=30.54 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.61it/s]Capturing batches (bs=96 avail_mem=30.53 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.61it/s] Capturing batches (bs=88 avail_mem=30.51 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.61it/s]Capturing batches (bs=88 avail_mem=30.51 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.95it/s]Capturing batches (bs=80 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.95it/s]Capturing batches (bs=72 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.95it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:01<00:00, 14.95it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.46it/s]Capturing batches (bs=56 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.46it/s]Capturing batches (bs=48 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.46it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.46it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.49it/s]Capturing batches (bs=32 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.49it/s]Capturing batches (bs=24 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.49it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.49it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.91it/s]Capturing batches (bs=8 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.91it/s] Capturing batches (bs=4 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.91it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.91it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.73it/s]Capturing batches (bs=1 avail_mem=30.35 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.73it/s]Capturing batches (bs=1 avail_mem=30.35 GB): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00, 15.04it/s]
2025-11-26T17:04:40.028796834Z [37m20251126-17:04:40.028 SGLangServer Wrapper INFO: SGLang server launched at: http://172.21.0.2:19759[0m
2025-11-26T17:04:40.724477211Z [37m20251126-17:04:40.724 Launcher Utils INFO: Found 1 rollout servers: 172.21.0.2:19759[0m
2025-11-26T17:04:40.724516039Z [37m20251126-17:04:40.724 Local Scheduler INFO: LLM inference server launched at: AREAL_LLM_SERVER_ADDRS=172.21.0.2:19759[0m
2025-11-26T17:04:40.727236725Z [37m20251126-17:04:40.727 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL AREAL_LLM_SERVER_ADDRS=172.21.0.2:19759 AREAL_RECOVER_RUN=0 NCCL_CUMEM_ENABLE=0 NCCL_NVLS_ENABLE=0 CUDA_VISIBLE_DEVICES=1 stdbuf -oL torchrun --nnodes 1 --nproc-per-node 1 --master-addr localhost --master-port 41710 examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_170408 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_170408/trainer.log[0m
2025-11-26T17:04:40.727965316Z [37m20251126-17:04:40.727 Local Scheduler INFO: Waiting for 2 local running processes, pids: 315 965[0m
2025-11-26T17:04:41.263827241Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:04:41.263863806Z   import pynvml  # type: ignore[import]
2025-11-26T17:04:42.452325078Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:04:42.452385018Z   import pynvml  # type: ignore[import]
2025-11-26T17:04:49.697619129Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:04:49.697661963Z   warnings.warn(
2025-11-26T17:04:49.697665178Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:04:49.697667502Z   warnings.warn(
2025-11-26T17:04:50.323178633Z Traceback (most recent call last):
2025-11-26T17:04:50.323732011Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 665, in <module>
2025-11-26T17:04:50.323755998Z     main(sys.argv[1:])
2025-11-26T17:04:50.323758892Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 102, in main
2025-11-26T17:04:50.323761315Z     config, _ = load_expr_config(args_with_overrides, GRPOConfig)
2025-11-26T17:04:50.324148936Z                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:04:50.324156057Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1282, in load_expr_config
2025-11-26T17:04:50.324160624Z     cfg = to_structured_cfg(cfg, config_cls=config_cls)
2025-11-26T17:04:50.324702556Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:04:50.324727473Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1276, in to_structured_cfg
2025-11-26T17:04:50.324731048Z     cfg = OmegaConf.merge(default_cfg, cfg)
2025-11-26T17:04:50.324947402Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:04:50.324953932Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/omegaconf.py", line 274, in merge
2025-11-26T17:04:50.324956716Z     target.merge_with(
2025-11-26T17:04:50.324959330Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 507, in merge_with
2025-11-26T17:04:50.325333591Z     self._format_and_raise(key=None, value=None, cause=e)
2025-11-26T17:04:50.325353311Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:04:50.325356205Z     format_and_raise(
2025-11-26T17:04:50.325358208Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:04:50.325603165Z     _raise(ex, cause)
2025-11-26T17:04:50.325609154Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:04:50.325613069Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:04:50.326092948Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:04:50.326096152Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 502, in merge_with
2025-11-26T17:04:50.326099778Z     self._merge_with(
2025-11-26T17:04:50.326102742Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:04:50.326104886Z     BaseContainer._map_merge(
2025-11-26T17:04:50.326107570Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:04:50.326432447Z     dest_node._merge_with(
2025-11-26T17:04:50.326442351Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:04:50.326444955Z     BaseContainer._map_merge(
2025-11-26T17:04:50.326447178Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:04:50.326668810Z     dest_node._merge_with(
2025-11-26T17:04:50.326673067Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:04:50.326675080Z     BaseContainer._map_merge(
2025-11-26T17:04:50.326677063Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 432, in _map_merge
2025-11-26T17:04:50.326928279Z     dest[key] = src._get_node(key)
2025-11-26T17:04:50.326931423Z     ~~~~^^^^^
2025-11-26T17:04:50.326934298Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 308, in __setitem__
2025-11-26T17:04:50.326936751Z     self._format_and_raise(
2025-11-26T17:04:50.326938754Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:04:50.327583801Z     format_and_raise(
2025-11-26T17:04:50.327590391Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:04:50.327592654Z     _raise(ex, cause)
2025-11-26T17:04:50.327594817Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:04:50.327597672Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:04:50.327599835Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:04:50.327603361Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 306, in __setitem__
2025-11-26T17:04:50.327841096Z     self.__set_impl(key=key, value=value)
2025-11-26T17:04:50.327847867Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 316, in __set_impl
2025-11-26T17:04:50.327851212Z     self._set_item_impl(key, value)
2025-11-26T17:04:50.328102167Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 579, in _set_item_impl
2025-11-26T17:04:50.328105593Z     target_node_ref = self._get_node(key)
2025-11-26T17:04:50.328404530Z                       ^^^^^^^^^^^^^^^^^^^
2025-11-26T17:04:50.328423829Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 473, in _get_node
2025-11-26T17:04:50.328426493Z     self._validate_get(key)
2025-11-26T17:04:50.328429447Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 163, in _validate_get
2025-11-26T17:04:50.328770078Z     self._format_and_raise(
2025-11-26T17:04:50.328774645Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:04:50.328777119Z     format_and_raise(
2025-11-26T17:04:50.328779202Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 906, in format_and_raise
2025-11-26T17:04:50.328781245Z     _raise(ex, cause)
2025-11-26T17:04:50.328783598Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:04:50.329086502Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:04:50.329335114Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:04:50.329342285Z omegaconf.errors.ConfigKeyError: Key 'max_new_tokens' not in 'NormConfig'
2025-11-26T17:04:50.329345089Z     full_key: actor.adv_norm.max_new_tokens
2025-11-26T17:04:50.329347072Z     reference_type=Optional[NormConfig]
2025-11-26T17:04:50.329349626Z     object_type=NormConfig
2025-11-26T17:04:53.568425277Z E1126 17:04:53.567000 966 torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 0 (pid: 1032) of binary: /usr/bin/python3
2025-11-26T17:04:53.569023012Z Traceback (most recent call last):
2025-11-26T17:04:53.569030944Z   File "/usr/local/bin/torchrun", line 7, in <module>
2025-11-26T17:04:53.569034439Z     sys.exit(main())
2025-11-26T17:04:53.569037294Z              ^^^^^^
2025-11-26T17:04:53.569052226Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
2025-11-26T17:04:53.569055541Z     return f(*args, **kwargs)
2025-11-26T17:04:53.569603201Z            ^^^^^^^^^^^^^^^^^^
2025-11-26T17:04:53.569612885Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 901, in main
2025-11-26T17:04:53.569615800Z     run(args)
2025-11-26T17:04:53.569618144Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 892, in run
2025-11-26T17:04:53.569620297Z     elastic_launch(
2025-11-26T17:04:53.569623261Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 143, in __call__
2025-11-26T17:04:53.569625855Z     return launch_agent(self._config, self._entrypoint, list(args))
2025-11-26T17:04:53.569629550Z            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:04:53.569631664Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 277, in launch_agent
2025-11-26T17:04:53.569633647Z     raise ChildFailedError(
2025-11-26T17:04:53.569635660Z torch.distributed.elastic.multiprocessing.errors.ChildFailedError:
2025-11-26T17:04:53.569637633Z ============================================================
2025-11-26T17:04:53.569640166Z examples/cloud_gsm8k/gsm8k_grpo_train.py FAILED
2025-11-26T17:04:53.569642721Z ------------------------------------------------------------
2025-11-26T17:04:53.569644753Z Failures:
2025-11-26T17:04:53.569646787Z   <NO_OTHER_FAILURES>
2025-11-26T17:04:53.569648790Z ------------------------------------------------------------
2025-11-26T17:04:53.569650893Z Root Cause (first observed failure):
2025-11-26T17:04:53.569653036Z [0]:
2025-11-26T17:04:53.569655129Z   time      : 2025-11-26_17:04:53
2025-11-26T17:04:53.569657282Z   host      : cef7c503fdea
2025-11-26T17:04:53.569659326Z   rank      : 0 (local_rank: 0)
2025-11-26T17:04:53.569661329Z   exitcode  : 1 (pid: 1032)
2025-11-26T17:04:53.569663461Z   error_file: <N/A>
2025-11-26T17:04:53.569665455Z   traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
2025-11-26T17:04:53.569667518Z ============================================================
2025-11-26T17:04:54.731327303Z [37m20251126-17:04:54.730 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [315][0m
2025-11-26T17:04:54.912868504Z Killed
2025-11-26T17:04:54.923483183Z [37m20251126-17:04:54.923 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [965][0m
2025-11-26T17:04:54.924799865Z Traceback (most recent call last):
2025-11-26T17:04:54.924805834Z   File "<frozen runpy>", line 198, in _run_module_as_main
2025-11-26T17:04:54.924808238Z   File "<frozen runpy>", line 88, in _run_code
2025-11-26T17:04:54.924810631Z   File "/workspace/AReaL/areal/launcher/local.py", line 405, in <module>
2025-11-26T17:04:54.924919165Z     main()
2025-11-26T17:04:54.924921748Z   File "/workspace/AReaL/areal/launcher/local.py", line 260, in main
2025-11-26T17:04:54.925019464Z     local_main(config, run_id=0)
2025-11-26T17:04:54.925022379Z   File "/workspace/AReaL/areal/launcher/local.py", line 399, in local_main
2025-11-26T17:04:54.925127576Z     raise e
2025-11-26T17:04:54.925133325Z   File "/workspace/AReaL/areal/launcher/local.py", line 375, in local_main
2025-11-26T17:04:54.925210511Z     launcher.wait(
2025-11-26T17:04:54.925213325Z   File "/workspace/AReaL/areal/launcher/local.py", line 235, in wait
2025-11-26T17:04:54.925266945Z     raise JobException(
2025-11-26T17:04:54.925269569Z areal.utils.launcher.JobException: Job gsm8k-grpo-cloud-2gpu-2000samples_trial_20251126_170408:trainer JobState.COMPLETED at node local
2025-11-26T17:04:55.206609367Z [37m20251126-17:04:55.205 Local Scheduler INFO: Waiting for 0 local running processes, pids: [0m
2025-11-26T17:05:11.352950395Z ==========
2025-11-26T17:05:11.352953200Z == CUDA ==
2025-11-26T17:05:11.352955613Z ==========
2025-11-26T17:05:11.357551077Z CUDA Version 12.9.1
2025-11-26T17:05:11.359136892Z Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
2025-11-26T17:05:11.360981806Z This container image and its contents are governed by the NVIDIA Deep Learning Container License.
2025-11-26T17:05:11.360984299Z By pulling and using the container, you accept the terms and conditions of this license:
2025-11-26T17:05:11.360986733Z https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license
2025-11-26T17:05:11.360991110Z A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
2025-11-26T17:05:11.528516426Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:05:11.686897323Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:05:11.883367936Z Branch 'feature/reasoning_model' set up to track remote branch 'feature/reasoning_model' from 'origin'.
2025-11-26T17:05:11.883409237Z Your branch is up to date with 'origin/feature/reasoning_model'.
2025-11-26T17:05:11.953900627Z Checking AReaL installation...
2025-11-26T17:05:12.013693050Z AReaL already installed. Skipping installation.
2025-11-26T17:05:12.013726480Z Cleaning up any leftover GPU processes...
2025-11-26T17:05:15.032606109Z Checking for processes holding GPU device files...
2025-11-26T17:05:17.189373694Z Found processes holding GPU devices: 1
2025-11-26T17:05:17.189426733Z 20
2025-11-26T17:05:17.189429598Z 71
2025-11-26T17:05:17.189432201Z 72
2025-11-26T17:05:17.189434334Z Killing process 1...
2025-11-26T17:05:17.189436929Z Killing process 71...
2025-11-26T17:05:17.189582837Z Killing process 72...
2025-11-26T17:05:19.192834701Z Using fuser to kill processes on GPU devices...
2025-11-26T17:05:21.219505735Z Checking GPU...
2025-11-26T17:05:21.256799908Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:05:21.256827830Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:05:21.273098982Z Set PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True for better memory management
2025-11-26T17:05:21.273155316Z Detected 2 GPU(s)
2025-11-26T17:05:21.273160434Z Checking GPU status...
2025-11-26T17:05:21.301013425Z index, name, utilization.gpu [%], memory.used [MiB], compute_mode
2025-11-26T17:05:21.302443978Z 0, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:05:21.302738619Z 1, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:05:21.346380681Z Verifying GPU accessibility...
2025-11-26T17:05:21.883921692Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:05:21.883990704Z   import pynvml  # type: ignore[import]
2025-11-26T17:05:22.982672706Z GPU accessibility verified on attempt 1
2025-11-26T17:05:23.436430899Z Starting training...
2025-11-26T17:05:26.439418494Z Using STANDARD 2000 SAMPLES 2 GPUs configuration
2025-11-26T17:05:26.439459756Z Note: GRPO only (no reasoning XML). Dataset capped at 2000 samples (~6 hours).
2025-11-26T17:05:26.439462871Z GPU count: 2 (required: 2)
2025-11-26T17:05:26.442200852Z ==========================================
2025-11-26T17:05:26.442204217Z Starting GRPO Training (Cloud)
2025-11-26T17:05:26.442206771Z ==========================================
2025-11-26T17:05:26.442208814Z Config: standard_2000samples_2GPUs
2025-11-26T17:05:26.442210817Z Config file: examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml
2025-11-26T17:05:26.442215544Z Training script: examples/cloud_gsm8k/gsm8k_grpo_train.py
2025-11-26T17:05:26.442217827Z Experiment: gsm8k-grpo-cloud-2gpu-2000samples
2025-11-26T17:05:26.442219841Z Trial: trial_20251126_170526
2025-11-26T17:05:26.442221793Z GPU: NVIDIA A100 80GB PCIe NVIDIA A100 80GB PCIe (81920 MB)
2025-11-26T17:05:26.442223847Z WandB API key: e1adc5be02...
2025-11-26T17:05:26.442225799Z ==========================================
2025-11-26T17:05:27.130823567Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:05:27.130863858Z   import pynvml  # type: ignore[import]
2025-11-26T17:05:31.134249235Z [37m20251126-17:05:31.133 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:05:31.134283907Z [37m20251126-17:05:31.134 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:05:31.134592970Z [37m20251126-17:05:31.134 name-resolve INFO: No such name resolve path: ./tmp/areal/name_resolve/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_170526[0m
2025-11-26T17:05:31.240390374Z [37m20251126-17:05:31.239 Local Scheduler INFO: LocalLauncher: experiment_name=gsm8k-grpo-cloud-2gpu-2000samples, trial_name=trial_20251126_170526, fileroot=/workspace/outputs/grpo, run_id=0, is_recover_run=False[0m
2025-11-26T17:05:31.247954634Z [37m20251126-17:05:31.247 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL CUDA_VISIBLE_DEVICES=0 stdbuf -oL python3 -m areal.launcher.sglang_server examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_170526 sglang.random_seed=1 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_170526/llm_server.log[0m
2025-11-26T17:05:31.959385393Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:05:31.959417552Z   import pynvml  # type: ignore[import]
2025-11-26T17:05:33.415071752Z [37m20251126-17:05:33.414 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:05:33.415803817Z [37m20251126-17:05:33.414 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:05:33.516509955Z [37m20251126-17:05:33.515 SGLangServer Wrapper INFO: Launch command: python3 -m sglang.launch_server --host 172.21.0.2 --port 23063 --tokenizer-path Qwen/Qwen2.5-0.5B-Instruct --tokenizer-mode auto --load-format auto --trust-remote-code --device cuda --tp-size 1 --base-gpu-id 0 --nnodes 1 --node-rank 0 --dist-init-addr localhost:24273 --model-path Qwen/Qwen2.5-0.5B-Instruct --random-seed 1 --skip-tokenizer-init --disable-radix-cache --torch-compile-max-bs 32 --triton-attention-num-kv-splits 8 --num-continuous-decode-steps 1 --attention-backend flashinfer --context-length 4096 --mem-fraction-static 0.6 --chunked-prefill-size -1 --max-prefill-tokens 32768 --schedule-policy lpm --schedule-conservativeness 1.0 --cpu-offload-gb 0 --dtype bfloat16 --kv-cache-dtype auto --dp-size 1 --ep-size 1 --max-loaded-loras 1 --max-loras-per-batch 1 --lora-backend triton --log-level warning --log-level-http warning --log-requests-level 0 --enable-metrics --decode-log-interval 1[0m
2025-11-26T17:05:34.605892668Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:05:34.605943744Z   import pynvml  # type: ignore[import]
2025-11-26T17:05:40.133234333Z INFO 11-26 17:05:40 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:05:40.821424371Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:05:41.849933992Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:05:41.849969596Z   import pynvml  # type: ignore[import]
2025-11-26T17:05:41.873733612Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:05:41.873786020Z   import pynvml  # type: ignore[import]
2025-11-26T17:05:47.292858000Z INFO 11-26 17:05:47 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:05:47.528989230Z INFO 11-26 17:05:47 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:05:47.867802017Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:05:48.071014487Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:05:48.074537464Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:05:48.075438334Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:05:48.076288267Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:05:48.109623110Z [2025-11-26 17:05:48] MOE_RUNNER_BACKEND is not initialized, using triton backend
2025-11-26T17:05:48.590929477Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:05:48.590968565Z   warnings.warn(
2025-11-26T17:05:48.590971650Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:05:48.590974164Z   warnings.warn(
2025-11-26T17:05:49.690601981Z Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
2025-11-26T17:05:49.793777619Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  9.72it/s]
2025-11-26T17:05:49.794194422Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  9.69it/s]
2025-11-26T17:05:52.230347999Z   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   4%|â–         | 1/23 [00:00<00:11,  1.89it/s]Capturing batches (bs=152 avail_mem=30.62 GB):   4%|â–         | 1/23 [00:00<00:11,  1.89it/s]Capturing batches (bs=144 avail_mem=30.60 GB):   4%|â–         | 1/23 [00:00<00:11,  1.89it/s]Capturing batches (bs=136 avail_mem=30.59 GB):   4%|â–         | 1/23 [00:00<00:11,  1.89it/s]Capturing batches (bs=136 avail_mem=30.59 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.39it/s]Capturing batches (bs=128 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.39it/s]Capturing batches (bs=120 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.39it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.39it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.72it/s]Capturing batches (bs=104 avail_mem=30.54 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.72it/s]Capturing batches (bs=96 avail_mem=30.53 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.72it/s] Capturing batches (bs=88 avail_mem=30.51 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.72it/s]Capturing batches (bs=88 avail_mem=30.51 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 15.04it/s]Capturing batches (bs=80 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 15.04it/s]Capturing batches (bs=72 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 15.04it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 15.04it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.51it/s]Capturing batches (bs=56 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.51it/s]Capturing batches (bs=48 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.51it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.51it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.51it/s]Capturing batches (bs=32 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.51it/s]Capturing batches (bs=24 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.51it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.51it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.91it/s]Capturing batches (bs=8 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.91it/s] Capturing batches (bs=4 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.91it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.91it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.69it/s]Capturing batches (bs=1 avail_mem=30.35 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.69it/s]Capturing batches (bs=1 avail_mem=30.35 GB): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00, 15.11it/s]
2025-11-26T17:05:57.542428365Z [37m20251126-17:05:57.541 SGLangServer Wrapper INFO: SGLang server launched at: http://172.21.0.2:23063[0m
2025-11-26T17:05:58.254637802Z [37m20251126-17:05:58.254 Launcher Utils INFO: Found 1 rollout servers: 172.21.0.2:23063[0m
2025-11-26T17:05:58.254670230Z [37m20251126-17:05:58.254 Local Scheduler INFO: LLM inference server launched at: AREAL_LLM_SERVER_ADDRS=172.21.0.2:23063[0m
2025-11-26T17:05:58.257955751Z [37m20251126-17:05:58.257 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL AREAL_LLM_SERVER_ADDRS=172.21.0.2:23063 AREAL_RECOVER_RUN=0 NCCL_CUMEM_ENABLE=0 NCCL_NVLS_ENABLE=0 CUDA_VISIBLE_DEVICES=1 stdbuf -oL torchrun --nnodes 1 --nproc-per-node 1 --master-addr localhost --master-port 20038 examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_170526 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_170526/trainer.log[0m
2025-11-26T17:05:58.258651133Z [37m20251126-17:05:58.258 Local Scheduler INFO: Waiting for 2 local running processes, pids: 315 965[0m
2025-11-26T17:05:58.767954817Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:05:58.768001297Z   import pynvml  # type: ignore[import]
2025-11-26T17:05:59.943224270Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:05:59.943278331Z   import pynvml  # type: ignore[import]
2025-11-26T17:06:06.979741624Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:06:06.979786502Z   warnings.warn(
2025-11-26T17:06:06.979790808Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:06:06.979793822Z   warnings.warn(
2025-11-26T17:06:07.404542142Z Traceback (most recent call last):
2025-11-26T17:06:07.404583644Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 665, in <module>
2025-11-26T17:06:07.405317564Z     main(sys.argv[1:])
2025-11-26T17:06:07.405357904Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 102, in main
2025-11-26T17:06:07.405362631Z     config, _ = load_expr_config(args_with_overrides, GRPOConfig)
2025-11-26T17:06:07.405366777Z                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:06:07.405369631Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1282, in load_expr_config
2025-11-26T17:06:07.405372376Z     cfg = to_structured_cfg(cfg, config_cls=config_cls)
2025-11-26T17:06:07.405375791Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:06:07.405378565Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1276, in to_structured_cfg
2025-11-26T17:06:07.405649301Z     cfg = OmegaConf.merge(default_cfg, cfg)
2025-11-26T17:06:07.405656792Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:06:07.405659336Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/omegaconf.py", line 274, in merge
2025-11-26T17:06:07.405661749Z     target.merge_with(
2025-11-26T17:06:07.405664233Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 507, in merge_with
2025-11-26T17:06:07.406176610Z     self._format_and_raise(key=None, value=None, cause=e)
2025-11-26T17:06:07.406186445Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:06:07.406189369Z     format_and_raise(
2025-11-26T17:06:07.406192053Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:06:07.406194086Z     _raise(ex, cause)
2025-11-26T17:06:07.406196059Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:06:07.406198873Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:06:07.406200997Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:06:07.406203741Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 502, in merge_with
2025-11-26T17:06:07.406622979Z     self._merge_with(
2025-11-26T17:06:07.406629919Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:06:07.406632884Z     BaseContainer._map_merge(
2025-11-26T17:06:07.406635367Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:06:07.406637761Z     dest_node._merge_with(
2025-11-26T17:06:07.406639793Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:06:07.406651221Z     BaseContainer._map_merge(
2025-11-26T17:06:07.406653504Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:06:07.406655517Z     dest_node._merge_with(
2025-11-26T17:06:07.406657570Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:06:07.407062577Z     BaseContainer._map_merge(
2025-11-26T17:06:07.407067585Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 432, in _map_merge
2025-11-26T17:06:07.407069838Z     dest[key] = src._get_node(key)
2025-11-26T17:06:07.407071911Z     ~~~~^^^^^
2025-11-26T17:06:07.407074776Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 308, in __setitem__
2025-11-26T17:06:07.407076868Z     self._format_and_raise(
2025-11-26T17:06:07.407078851Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:06:07.407080874Z     format_and_raise(
2025-11-26T17:06:07.407083018Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:06:07.407742486Z     _raise(ex, cause)
2025-11-26T17:06:07.407754063Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:06:07.407757459Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:06:07.407759712Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:06:07.407762726Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 306, in __setitem__
2025-11-26T17:06:07.407764959Z     self.__set_impl(key=key, value=value)
2025-11-26T17:06:07.407767033Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 316, in __set_impl
2025-11-26T17:06:07.407769136Z     self._set_item_impl(key, value)
2025-11-26T17:06:07.407771099Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 579, in _set_item_impl
2025-11-26T17:06:07.407773292Z     target_node_ref = self._get_node(key)
2025-11-26T17:06:07.408056857Z                       ^^^^^^^^^^^^^^^^^^^
2025-11-26T17:06:07.408060923Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 473, in _get_node
2025-11-26T17:06:07.408063427Z     self._validate_get(key)
2025-11-26T17:06:07.408065380Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 163, in _validate_get
2025-11-26T17:06:07.408067513Z     self._format_and_raise(
2025-11-26T17:06:07.408069446Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:06:07.408071429Z     format_and_raise(
2025-11-26T17:06:07.408073662Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 906, in format_and_raise
2025-11-26T17:06:07.408398900Z     _raise(ex, cause)
2025-11-26T17:06:07.408404777Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:06:07.408407080Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:06:07.408409054Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:06:07.408411117Z omegaconf.errors.ConfigKeyError: Key 'max_new_tokens' not in 'NormConfig'
2025-11-26T17:06:07.408414121Z     full_key: actor.adv_norm.max_new_tokens
2025-11-26T17:06:07.408416184Z     reference_type=Optional[NormConfig]
2025-11-26T17:06:07.408418157Z     object_type=NormConfig
2025-11-26T17:06:10.059351752Z E1126 17:06:10.058000 966 torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 0 (pid: 1032) of binary: /usr/bin/python3
2025-11-26T17:06:10.060056938Z Traceback (most recent call last):
2025-11-26T17:06:10.060081074Z   File "/usr/local/bin/torchrun", line 7, in <module>
2025-11-26T17:06:10.060084149Z     sys.exit(main())
2025-11-26T17:06:10.060087394Z              ^^^^^^
2025-11-26T17:06:10.060089847Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
2025-11-26T17:06:10.060110778Z     return f(*args, **kwargs)
2025-11-26T17:06:10.060166522Z            ^^^^^^^^^^^^^^^^^^
2025-11-26T17:06:10.060169116Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 901, in main
2025-11-26T17:06:10.060521154Z     run(args)
2025-11-26T17:06:10.060529847Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 892, in run
2025-11-26T17:06:10.060532902Z     elastic_launch(
2025-11-26T17:06:10.060535525Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 143, in __call__
2025-11-26T17:06:10.060538680Z     return launch_agent(self._config, self._entrypoint, list(args))
2025-11-26T17:06:10.060541644Z            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:06:10.060543658Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 277, in launch_agent
2025-11-26T17:06:10.060545630Z     raise ChildFailedError(
2025-11-26T17:06:10.060548294Z torch.distributed.elastic.multiprocessing.errors.ChildFailedError:
2025-11-26T17:06:10.060550207Z ============================================================
2025-11-26T17:06:10.060552952Z examples/cloud_gsm8k/gsm8k_grpo_train.py FAILED
2025-11-26T17:06:10.060555616Z ------------------------------------------------------------
2025-11-26T17:06:10.060557619Z Failures:
2025-11-26T17:06:10.060559662Z   <NO_OTHER_FAILURES>
2025-11-26T17:06:10.060561614Z ------------------------------------------------------------
2025-11-26T17:06:10.060563798Z Root Cause (first observed failure):
2025-11-26T17:06:10.060566111Z [0]:
2025-11-26T17:06:10.060568164Z   time      : 2025-11-26_17:06:10
2025-11-26T17:06:10.060570218Z   host      : cef7c503fdea
2025-11-26T17:06:10.060572281Z   rank      : 0 (local_rank: 0)
2025-11-26T17:06:10.060574264Z   exitcode  : 1 (pid: 1032)
2025-11-26T17:06:10.060576267Z   error_file: <N/A>
2025-11-26T17:06:10.060578239Z   traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
2025-11-26T17:06:10.060580443Z ============================================================
2025-11-26T17:06:12.262193160Z [37m20251126-17:06:12.261 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [315][0m
2025-11-26T17:06:12.377868540Z Killed
2025-11-26T17:06:12.382734309Z [37m20251126-17:06:12.382 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [965][0m
2025-11-26T17:06:12.383689609Z Traceback (most recent call last):
2025-11-26T17:06:12.383698783Z   File "<frozen runpy>", line 198, in _run_module_as_main
2025-11-26T17:06:12.383701657Z   File "<frozen runpy>", line 88, in _run_code
2025-11-26T17:06:12.383704101Z   File "/workspace/AReaL/areal/launcher/local.py", line 405, in <module>
2025-11-26T17:06:12.383833546Z     main()
2025-11-26T17:06:12.383838443Z   File "/workspace/AReaL/areal/launcher/local.py", line 260, in main
2025-11-26T17:06:12.383925624Z     local_main(config, run_id=0)
2025-11-26T17:06:12.383929660Z   File "/workspace/AReaL/areal/launcher/local.py", line 399, in local_main
2025-11-26T17:06:12.384025753Z     raise e
2025-11-26T17:06:12.384028086Z   File "/workspace/AReaL/areal/launcher/local.py", line 375, in local_main
2025-11-26T17:06:12.384092093Z     launcher.wait(
2025-11-26T17:06:12.384094777Z   File "/workspace/AReaL/areal/launcher/local.py", line 235, in wait
2025-11-26T17:06:12.384167746Z     raise JobException(
2025-11-26T17:06:12.384174216Z areal.utils.launcher.JobException: Job gsm8k-grpo-cloud-2gpu-2000samples_trial_20251126_170526:trainer JobState.COMPLETED at node local
2025-11-26T17:06:12.572189052Z [37m20251126-17:06:12.571 Local Scheduler INFO: Waiting for 0 local running processes, pids: [0m
2025-11-26T17:06:29.857596095Z ==========
2025-11-26T17:06:29.857599380Z == CUDA ==
2025-11-26T17:06:29.857605238Z ==========
2025-11-26T17:06:29.862174292Z CUDA Version 12.9.1
2025-11-26T17:06:29.863720408Z Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
2025-11-26T17:06:29.865445092Z This container image and its contents are governed by the NVIDIA Deep Learning Container License.
2025-11-26T17:06:29.865453344Z By pulling and using the container, you accept the terms and conditions of this license:
2025-11-26T17:06:29.865456298Z https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license
2025-11-26T17:06:29.865461686Z A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
2025-11-26T17:06:30.030908799Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:06:30.189840152Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:06:30.378005294Z Branch 'feature/reasoning_model' set up to track remote branch 'feature/reasoning_model' from 'origin'.
2025-11-26T17:06:30.378046896Z Your branch is up to date with 'origin/feature/reasoning_model'.
2025-11-26T17:06:30.449335239Z Checking AReaL installation...
2025-11-26T17:06:30.508147213Z AReaL already installed. Skipping installation.
2025-11-26T17:06:30.508188965Z Cleaning up any leftover GPU processes...
2025-11-26T17:06:33.527407583Z Checking for processes holding GPU device files...
2025-11-26T17:06:35.465949167Z Found processes holding GPU devices: 1
2025-11-26T17:06:35.465993714Z 19
2025-11-26T17:06:35.465996558Z 70
2025-11-26T17:06:35.465999032Z 71
2025-11-26T17:06:35.466001025Z Killing process 1...
2025-11-26T17:06:35.466004130Z Killing process 70...
2025-11-26T17:06:35.466189077Z Killing process 71...
2025-11-26T17:06:37.468792981Z Using fuser to kill processes on GPU devices...
2025-11-26T17:06:39.492953824Z Checking GPU...
2025-11-26T17:06:39.528237275Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:06:39.528264976Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:06:39.546181213Z Set PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True for better memory management
2025-11-26T17:06:39.546202845Z Detected 2 GPU(s)
2025-11-26T17:06:39.546205960Z Checking GPU status...
2025-11-26T17:06:39.574548224Z index, name, utilization.gpu [%], memory.used [MiB], compute_mode
2025-11-26T17:06:39.575901020Z 0, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:06:39.576216172Z 1, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:06:39.620156140Z Verifying GPU accessibility...
2025-11-26T17:06:40.167411421Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:06:40.167472633Z   import pynvml  # type: ignore[import]
2025-11-26T17:06:41.270011753Z GPU accessibility verified on attempt 1
2025-11-26T17:06:41.745025864Z Starting training...
2025-11-26T17:06:44.747759339Z Using STANDARD 2000 SAMPLES 2 GPUs configuration
2025-11-26T17:06:44.747801823Z Note: GRPO only (no reasoning XML). Dataset capped at 2000 samples (~6 hours).
2025-11-26T17:06:44.747805057Z GPU count: 2 (required: 2)
2025-11-26T17:06:44.749984182Z ==========================================
2025-11-26T17:06:44.749987407Z Starting GRPO Training (Cloud)
2025-11-26T17:06:44.749990141Z ==========================================
2025-11-26T17:06:44.749992114Z Config: standard_2000samples_2GPUs
2025-11-26T17:06:44.749994437Z Config file: examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml
2025-11-26T17:06:44.749998583Z Training script: examples/cloud_gsm8k/gsm8k_grpo_train.py
2025-11-26T17:06:44.750000977Z Experiment: gsm8k-grpo-cloud-2gpu-2000samples
2025-11-26T17:06:44.750003381Z Trial: trial_20251126_170644
2025-11-26T17:06:44.750005444Z GPU: NVIDIA A100 80GB PCIe NVIDIA A100 80GB PCIe (81920 MB)
2025-11-26T17:06:44.750007477Z WandB API key: e1adc5be02...
2025-11-26T17:06:44.750009530Z ==========================================
2025-11-26T17:06:45.462198715Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:06:45.462230272Z   import pynvml  # type: ignore[import]
2025-11-26T17:06:49.518626675Z [37m20251126-17:06:49.518 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:06:49.518676349Z [37m20251126-17:06:49.518 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:06:49.518908837Z [37m20251126-17:06:49.518 name-resolve INFO: No such name resolve path: ./tmp/areal/name_resolve/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_170644[0m
2025-11-26T17:06:49.624541865Z [37m20251126-17:06:49.624 Local Scheduler INFO: LocalLauncher: experiment_name=gsm8k-grpo-cloud-2gpu-2000samples, trial_name=trial_20251126_170644, fileroot=/workspace/outputs/grpo, run_id=0, is_recover_run=False[0m
2025-11-26T17:06:49.632173817Z [37m20251126-17:06:49.631 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL CUDA_VISIBLE_DEVICES=0 stdbuf -oL python3 -m areal.launcher.sglang_server examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_170644 sglang.random_seed=1 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_170644/llm_server.log[0m
2025-11-26T17:06:50.347098980Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:06:50.347156877Z   import pynvml  # type: ignore[import]
2025-11-26T17:06:51.813587508Z [37m20251126-17:06:51.812 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:06:51.814218474Z [37m20251126-17:06:51.813 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:06:51.916186562Z [37m20251126-17:06:51.915 SGLangServer Wrapper INFO: Launch command: python3 -m sglang.launch_server --host 172.21.0.2 --port 10566 --tokenizer-path Qwen/Qwen2.5-0.5B-Instruct --tokenizer-mode auto --load-format auto --trust-remote-code --device cuda --tp-size 1 --base-gpu-id 0 --nnodes 1 --node-rank 0 --dist-init-addr localhost:20104 --model-path Qwen/Qwen2.5-0.5B-Instruct --random-seed 1 --skip-tokenizer-init --disable-radix-cache --torch-compile-max-bs 32 --triton-attention-num-kv-splits 8 --num-continuous-decode-steps 1 --attention-backend flashinfer --context-length 4096 --mem-fraction-static 0.6 --chunked-prefill-size -1 --max-prefill-tokens 32768 --schedule-policy lpm --schedule-conservativeness 1.0 --cpu-offload-gb 0 --dtype bfloat16 --kv-cache-dtype auto --dp-size 1 --ep-size 1 --max-loaded-loras 1 --max-loras-per-batch 1 --lora-backend triton --log-level warning --log-level-http warning --log-requests-level 0 --enable-metrics --decode-log-interval 1[0m
2025-11-26T17:06:52.968961259Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:06:52.969006697Z   import pynvml  # type: ignore[import]
2025-11-26T17:06:58.304074738Z INFO 11-26 17:06:58 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:06:58.941614346Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:07:00.278489916Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:07:00.278528394Z   import pynvml  # type: ignore[import]
2025-11-26T17:07:00.286044403Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:07:00.286069931Z   import pynvml  # type: ignore[import]
2025-11-26T17:07:05.570226130Z INFO 11-26 17:07:05 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:07:05.936883436Z INFO 11-26 17:07:05 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:07:06.139923118Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:07:06.363044019Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:07:06.366610542Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:07:06.367523800Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:07:06.368381414Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:07:06.400934805Z [2025-11-26 17:07:06] MOE_RUNNER_BACKEND is not initialized, using triton backend
2025-11-26T17:07:06.887205710Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:07:06.887243256Z   warnings.warn(
2025-11-26T17:07:06.887246080Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:07:06.887248364Z   warnings.warn(
2025-11-26T17:07:08.002040186Z Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
2025-11-26T17:07:08.106054158Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  9.64it/s]
2025-11-26T17:07:08.106575330Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  9.62it/s]
2025-11-26T17:07:10.533985729Z   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   4%|â–         | 1/23 [00:00<00:11,  1.87it/s]Capturing batches (bs=152 avail_mem=30.62 GB):   4%|â–         | 1/23 [00:00<00:11,  1.87it/s]Capturing batches (bs=144 avail_mem=30.60 GB):   4%|â–         | 1/23 [00:00<00:11,  1.87it/s]Capturing batches (bs=136 avail_mem=30.59 GB):   4%|â–         | 1/23 [00:00<00:11,  1.87it/s]Capturing batches (bs=136 avail_mem=30.59 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.36it/s]Capturing batches (bs=128 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.36it/s]Capturing batches (bs=120 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.36it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.36it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.72it/s]Capturing batches (bs=104 avail_mem=30.54 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.72it/s]Capturing batches (bs=96 avail_mem=30.53 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.72it/s] Capturing batches (bs=88 avail_mem=30.51 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.72it/s]Capturing batches (bs=88 avail_mem=30.51 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 15.09it/s]Capturing batches (bs=80 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 15.09it/s]Capturing batches (bs=72 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 15.09it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 15.09it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.61it/s]Capturing batches (bs=56 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.61it/s]Capturing batches (bs=48 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.61it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.61it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.64it/s]Capturing batches (bs=32 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.64it/s]Capturing batches (bs=24 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.64it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.64it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 18.02it/s]Capturing batches (bs=8 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 18.02it/s] Capturing batches (bs=4 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 18.02it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 18.02it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.85it/s]Capturing batches (bs=1 avail_mem=30.35 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.85it/s]Capturing batches (bs=1 avail_mem=30.35 GB): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00, 15.16it/s]
2025-11-26T17:07:15.940278436Z [37m20251126-17:07:15.939 SGLangServer Wrapper INFO: SGLang server launched at: http://172.21.0.2:10566[0m
2025-11-26T17:07:16.638823384Z [37m20251126-17:07:16.638 Launcher Utils INFO: Found 1 rollout servers: 172.21.0.2:10566[0m
2025-11-26T17:07:16.638871827Z [37m20251126-17:07:16.638 Local Scheduler INFO: LLM inference server launched at: AREAL_LLM_SERVER_ADDRS=172.21.0.2:10566[0m
2025-11-26T17:07:16.641935145Z [37m20251126-17:07:16.641 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL AREAL_LLM_SERVER_ADDRS=172.21.0.2:10566 AREAL_RECOVER_RUN=0 NCCL_CUMEM_ENABLE=0 NCCL_NVLS_ENABLE=0 CUDA_VISIBLE_DEVICES=1 stdbuf -oL torchrun --nnodes 1 --nproc-per-node 1 --master-addr localhost --master-port 44116 examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_170644 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_170644/trainer.log[0m
2025-11-26T17:07:16.642528213Z [37m20251126-17:07:16.642 Local Scheduler INFO: Waiting for 2 local running processes, pids: 314 964[0m
2025-11-26T17:07:17.163582148Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:07:17.163638362Z   import pynvml  # type: ignore[import]
2025-11-26T17:07:18.409891060Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:07:18.409953052Z   import pynvml  # type: ignore[import]
2025-11-26T17:07:25.665450237Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:07:25.665496177Z   warnings.warn(
2025-11-26T17:07:25.665499531Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:07:25.665502115Z   warnings.warn(
2025-11-26T17:07:26.092381957Z Traceback (most recent call last):
2025-11-26T17:07:26.092421536Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 665, in <module>
2025-11-26T17:07:26.093004560Z     main(sys.argv[1:])
2025-11-26T17:07:26.093008896Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 102, in main
2025-11-26T17:07:26.093011780Z     config, _ = load_expr_config(args_with_overrides, GRPOConfig)
2025-11-26T17:07:26.093014324Z                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:07:26.093016307Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1282, in load_expr_config
2025-11-26T17:07:26.093018290Z     cfg = to_structured_cfg(cfg, config_cls=config_cls)
2025-11-26T17:07:26.093536917Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:07:26.093543417Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1276, in to_structured_cfg
2025-11-26T17:07:26.093546121Z     cfg = OmegaConf.merge(default_cfg, cfg)
2025-11-26T17:07:26.093548134Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:07:26.093550047Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/omegaconf.py", line 274, in merge
2025-11-26T17:07:26.093552060Z     target.merge_with(
2025-11-26T17:07:26.093862225Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 507, in merge_with
2025-11-26T17:07:26.093865650Z     self._format_and_raise(key=None, value=None, cause=e)
2025-11-26T17:07:26.093867823Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:07:26.093869996Z     format_and_raise(
2025-11-26T17:07:26.093872029Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:07:26.093874082Z     _raise(ex, cause)
2025-11-26T17:07:26.093876035Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:07:26.094359118Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:07:26.094363725Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:07:26.094370235Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 502, in merge_with
2025-11-26T17:07:26.094373029Z     self._merge_with(
2025-11-26T17:07:26.094374992Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:07:26.094377025Z     BaseContainer._map_merge(
2025-11-26T17:07:26.094379759Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:07:26.094781281Z     dest_node._merge_with(
2025-11-26T17:07:26.094803975Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:07:26.094807280Z     BaseContainer._map_merge(
2025-11-26T17:07:26.094809604Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:07:26.094823333Z     dest_node._merge_with(
2025-11-26T17:07:26.094825456Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:07:26.094827600Z     BaseContainer._map_merge(
2025-11-26T17:07:26.094829593Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 432, in _map_merge
2025-11-26T17:07:26.095105396Z     dest[key] = src._get_node(key)
2025-11-26T17:07:26.095154440Z     ~~~~^^^^^
2025-11-26T17:07:26.095161851Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 308, in __setitem__
2025-11-26T17:07:26.095164394Z     self._format_and_raise(
2025-11-26T17:07:26.095166627Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:07:26.095168691Z     format_and_raise(
2025-11-26T17:07:26.095170684Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:07:26.095172687Z     _raise(ex, cause)
2025-11-26T17:07:26.095174760Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:07:26.096125664Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:07:26.096148479Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:07:26.096151483Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 306, in __setitem__
2025-11-26T17:07:26.096153677Z     self.__set_impl(key=key, value=value)
2025-11-26T17:07:26.096155700Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 316, in __set_impl
2025-11-26T17:07:26.096157692Z     self._set_item_impl(key, value)
2025-11-26T17:07:26.096159846Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 579, in _set_item_impl
2025-11-26T17:07:26.096162119Z     target_node_ref = self._get_node(key)
2025-11-26T17:07:26.096164162Z                       ^^^^^^^^^^^^^^^^^^^
2025-11-26T17:07:26.096166115Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 473, in _get_node
2025-11-26T17:07:26.096168178Z     self._validate_get(key)
2025-11-26T17:07:26.096170572Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 163, in _validate_get
2025-11-26T17:07:26.096172835Z     self._format_and_raise(
2025-11-26T17:07:26.096174788Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:07:26.096176791Z     format_and_raise(
2025-11-26T17:07:26.096179455Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 906, in format_and_raise
2025-11-26T17:07:26.096181619Z     _raise(ex, cause)
2025-11-26T17:07:26.096183591Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:07:26.096500366Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:07:26.096504532Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:07:26.096506996Z omegaconf.errors.ConfigKeyError: Key 'max_new_tokens' not in 'NormConfig'
2025-11-26T17:07:26.096509119Z     full_key: actor.adv_norm.max_new_tokens
2025-11-26T17:07:26.096511152Z     reference_type=Optional[NormConfig]
2025-11-26T17:07:26.096513155Z     object_type=NormConfig
2025-11-26T17:07:28.593991419Z E1126 17:07:28.592000 965 torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 0 (pid: 1031) of binary: /usr/bin/python3
2025-11-26T17:07:28.594480962Z Traceback (most recent call last):
2025-11-26T17:07:28.594489395Z   File "/usr/local/bin/torchrun", line 7, in <module>
2025-11-26T17:07:28.594492149Z     sys.exit(main())
2025-11-26T17:07:28.594494933Z              ^^^^^^
2025-11-26T17:07:28.594497066Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
2025-11-26T17:07:28.594924287Z     return f(*args, **kwargs)
2025-11-26T17:07:28.594928463Z            ^^^^^^^^^^^^^^^^^^
2025-11-26T17:07:28.594930466Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 901, in main
2025-11-26T17:07:28.594945377Z     run(args)
2025-11-26T17:07:28.594948252Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 892, in run
2025-11-26T17:07:28.594950565Z     elastic_launch(
2025-11-26T17:07:28.594953049Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 143, in __call__
2025-11-26T17:07:28.595471907Z     return launch_agent(self._config, self._entrypoint, list(args))
2025-11-26T17:07:28.595510565Z            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:07:28.595513059Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 277, in launch_agent
2025-11-26T17:07:28.595516614Z     raise ChildFailedError(
2025-11-26T17:07:28.595519589Z torch.distributed.elastic.multiprocessing.errors.ChildFailedError:
2025-11-26T17:07:28.595521632Z ============================================================
2025-11-26T17:07:28.595523975Z examples/cloud_gsm8k/gsm8k_grpo_train.py FAILED
2025-11-26T17:07:28.595526689Z ------------------------------------------------------------
2025-11-26T17:07:28.595528662Z Failures:
2025-11-26T17:07:28.595531817Z   <NO_OTHER_FAILURES>
2025-11-26T17:07:28.595534310Z ------------------------------------------------------------
2025-11-26T17:07:28.595536353Z Root Cause (first observed failure):
2025-11-26T17:07:28.595538446Z [0]:
2025-11-26T17:07:28.595540539Z   time      : 2025-11-26_17:07:28
2025-11-26T17:07:28.595542602Z   host      : cef7c503fdea
2025-11-26T17:07:28.595544635Z   rank      : 0 (local_rank: 0)
2025-11-26T17:07:28.595546588Z   exitcode  : 1 (pid: 1031)
2025-11-26T17:07:28.595548581Z   error_file: <N/A>
2025-11-26T17:07:28.595550564Z   traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
2025-11-26T17:07:28.595553318Z ============================================================
2025-11-26T17:07:30.646420815Z [37m20251126-17:07:30.646 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [314][0m
2025-11-26T17:07:30.769618734Z Killed
2025-11-26T17:07:30.782337384Z [37m20251126-17:07:30.782 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [964][0m
2025-11-26T17:07:30.783635730Z Traceback (most recent call last):
2025-11-26T17:07:30.783653296Z   File "<frozen runpy>", line 198, in _run_module_as_main
2025-11-26T17:07:30.783655790Z   File "<frozen runpy>", line 88, in _run_code
2025-11-26T17:07:30.783657913Z   File "/workspace/AReaL/areal/launcher/local.py", line 405, in <module>
2025-11-26T17:07:30.783826806Z     main()
2025-11-26T17:07:30.783840166Z   File "/workspace/AReaL/areal/launcher/local.py", line 260, in main
2025-11-26T17:07:30.783955479Z     local_main(config, run_id=0)
2025-11-26T17:07:30.783959325Z   File "/workspace/AReaL/areal/launcher/local.py", line 399, in local_main
2025-11-26T17:07:30.784085254Z     raise e
2025-11-26T17:07:30.784089209Z   File "/workspace/AReaL/areal/launcher/local.py", line 375, in local_main
2025-11-26T17:07:30.784200526Z     launcher.wait(
2025-11-26T17:07:30.784206524Z   File "/workspace/AReaL/areal/launcher/local.py", line 235, in wait
2025-11-26T17:07:30.784263961Z     raise JobException(
2025-11-26T17:07:30.784266865Z areal.utils.launcher.JobException: Job gsm8k-grpo-cloud-2gpu-2000samples_trial_20251126_170644:trainer JobState.COMPLETED at node local
2025-11-26T17:07:31.075174254Z [37m20251126-17:07:31.074 Local Scheduler INFO: Waiting for 0 local running processes, pids: [0m
2025-11-26T17:07:48.222726164Z ==========
2025-11-26T17:07:48.222729078Z == CUDA ==
2025-11-26T17:07:48.222745172Z ==========
2025-11-26T17:07:48.227072845Z CUDA Version 12.9.1
2025-11-26T17:07:48.229015434Z Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
2025-11-26T17:07:48.230648971Z This container image and its contents are governed by the NVIDIA Deep Learning Container License.
2025-11-26T17:07:48.230651465Z By pulling and using the container, you accept the terms and conditions of this license:
2025-11-26T17:07:48.230653778Z https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license
2025-11-26T17:07:48.230673899Z A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
2025-11-26T17:07:48.396660930Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:07:48.554190172Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:07:48.741878920Z Branch 'feature/reasoning_model' set up to track remote branch 'feature/reasoning_model' from 'origin'.
2025-11-26T17:07:48.741925530Z Your branch is up to date with 'origin/feature/reasoning_model'.
2025-11-26T17:07:48.812380405Z Checking AReaL installation...
2025-11-26T17:07:48.871349284Z AReaL already installed. Skipping installation.
2025-11-26T17:07:48.871377366Z Cleaning up any leftover GPU processes...
2025-11-26T17:07:51.891753177Z Checking for processes holding GPU device files...
2025-11-26T17:07:54.638420570Z Found processes holding GPU devices: 1
2025-11-26T17:07:54.638457235Z 20
2025-11-26T17:07:54.638459779Z 71
2025-11-26T17:07:54.638462403Z 72
2025-11-26T17:07:54.638464476Z Killing process 1...
2025-11-26T17:07:54.638467320Z Killing process 71...
2025-11-26T17:07:54.638690675Z Killing process 72...
2025-11-26T17:07:56.641487938Z Using fuser to kill processes on GPU devices...
2025-11-26T17:07:58.663279243Z Checking GPU...
2025-11-26T17:07:58.698641722Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:07:58.698669564Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:07:58.715797619Z Set PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True for better memory management
2025-11-26T17:07:58.715814044Z Detected 2 GPU(s)
2025-11-26T17:07:58.715817139Z Checking GPU status...
2025-11-26T17:07:58.743848497Z index, name, utilization.gpu [%], memory.used [MiB], compute_mode
2025-11-26T17:07:58.745344067Z 0, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:07:58.745646090Z 1, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:07:58.789076644Z Verifying GPU accessibility...
2025-11-26T17:07:59.316298978Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:07:59.316369093Z   import pynvml  # type: ignore[import]
2025-11-26T17:08:00.415509323Z GPU accessibility verified on attempt 1
2025-11-26T17:08:00.879049387Z Starting training...
2025-11-26T17:08:03.881880067Z Using STANDARD 2000 SAMPLES 2 GPUs configuration
2025-11-26T17:08:03.881929501Z Note: GRPO only (no reasoning XML). Dataset capped at 2000 samples (~6 hours).
2025-11-26T17:08:03.881932706Z GPU count: 2 (required: 2)
2025-11-26T17:08:03.884254273Z ==========================================
2025-11-26T17:08:03.884257508Z Starting GRPO Training (Cloud)
2025-11-26T17:08:03.884259912Z ==========================================
2025-11-26T17:08:03.884261925Z Config: standard_2000samples_2GPUs
2025-11-26T17:08:03.884264028Z Config file: examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml
2025-11-26T17:08:03.884266832Z Training script: examples/cloud_gsm8k/gsm8k_grpo_train.py
2025-11-26T17:08:03.884268955Z Experiment: gsm8k-grpo-cloud-2gpu-2000samples
2025-11-26T17:08:03.884271009Z Trial: trial_20251126_170803
2025-11-26T17:08:03.884273012Z GPU: NVIDIA A100 80GB PCIe NVIDIA A100 80GB PCIe (81920 MB)
2025-11-26T17:08:03.884275044Z WandB API key: e1adc5be02...
2025-11-26T17:08:03.884277047Z ==========================================
2025-11-26T17:08:04.565284316Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:08:04.565322723Z   import pynvml  # type: ignore[import]
2025-11-26T17:08:08.510760481Z [37m20251126-17:08:08.510 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:08:08.510805308Z [37m20251126-17:08:08.510 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:08:08.511034161Z [37m20251126-17:08:08.510 name-resolve INFO: No such name resolve path: ./tmp/areal/name_resolve/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_170803[0m
2025-11-26T17:08:08.615962874Z [37m20251126-17:08:08.615 Local Scheduler INFO: LocalLauncher: experiment_name=gsm8k-grpo-cloud-2gpu-2000samples, trial_name=trial_20251126_170803, fileroot=/workspace/outputs/grpo, run_id=0, is_recover_run=False[0m
2025-11-26T17:08:08.623207795Z [37m20251126-17:08:08.623 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL CUDA_VISIBLE_DEVICES=0 stdbuf -oL python3 -m areal.launcher.sglang_server examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_170803 sglang.random_seed=1 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_170803/llm_server.log[0m
2025-11-26T17:08:09.328177206Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:08:09.328214042Z   import pynvml  # type: ignore[import]
2025-11-26T17:08:10.784105206Z [37m20251126-17:08:10.783 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:08:10.784825425Z [37m20251126-17:08:10.783 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:08:10.885432113Z [37m20251126-17:08:10.884 SGLangServer Wrapper INFO: Launch command: python3 -m sglang.launch_server --host 172.21.0.2 --port 10397 --tokenizer-path Qwen/Qwen2.5-0.5B-Instruct --tokenizer-mode auto --load-format auto --trust-remote-code --device cuda --tp-size 1 --base-gpu-id 0 --nnodes 1 --node-rank 0 --dist-init-addr localhost:16648 --model-path Qwen/Qwen2.5-0.5B-Instruct --random-seed 1 --skip-tokenizer-init --disable-radix-cache --torch-compile-max-bs 32 --triton-attention-num-kv-splits 8 --num-continuous-decode-steps 1 --attention-backend flashinfer --context-length 4096 --mem-fraction-static 0.6 --chunked-prefill-size -1 --max-prefill-tokens 32768 --schedule-policy lpm --schedule-conservativeness 1.0 --cpu-offload-gb 0 --dtype bfloat16 --kv-cache-dtype auto --dp-size 1 --ep-size 1 --max-loaded-loras 1 --max-loras-per-batch 1 --lora-backend triton --log-level warning --log-level-http warning --log-requests-level 0 --enable-metrics --decode-log-interval 1[0m
2025-11-26T17:08:11.915633058Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:08:11.915669522Z   import pynvml  # type: ignore[import]
2025-11-26T17:08:17.414909104Z INFO 11-26 17:08:17 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:08:18.076427731Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:08:19.084916924Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:08:19.084962571Z   import pynvml  # type: ignore[import]
2025-11-26T17:08:19.102856115Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:08:19.102888583Z   import pynvml  # type: ignore[import]
2025-11-26T17:08:24.299400140Z INFO 11-26 17:08:24 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:08:24.403078039Z INFO 11-26 17:08:24 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:08:24.997069686Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:08:25.228478163Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:08:25.232085456Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:08:25.232940627Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:08:25.233844591Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:08:25.266678532Z [2025-11-26 17:08:25] MOE_RUNNER_BACKEND is not initialized, using triton backend
2025-11-26T17:08:25.750229152Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:08:25.750274490Z   warnings.warn(
2025-11-26T17:08:25.750278215Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:08:25.750280519Z   warnings.warn(
2025-11-26T17:08:26.862401511Z Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
2025-11-26T17:08:26.967884503Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  9.50it/s]
2025-11-26T17:08:26.968439814Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  9.48it/s]
2025-11-26T17:08:29.422515296Z   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   4%|â–         | 1/23 [00:00<00:12,  1.83it/s]Capturing batches (bs=152 avail_mem=30.62 GB):   4%|â–         | 1/23 [00:00<00:12,  1.83it/s]Capturing batches (bs=144 avail_mem=30.60 GB):   4%|â–         | 1/23 [00:00<00:12,  1.83it/s]Capturing batches (bs=136 avail_mem=30.59 GB):   4%|â–         | 1/23 [00:00<00:12,  1.83it/s]Capturing batches (bs=136 avail_mem=30.59 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.22it/s]Capturing batches (bs=128 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.22it/s]Capturing batches (bs=120 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.22it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.22it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.55it/s]Capturing batches (bs=104 avail_mem=30.54 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.55it/s]Capturing batches (bs=96 avail_mem=30.53 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.55it/s] Capturing batches (bs=88 avail_mem=30.51 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.55it/s]Capturing batches (bs=88 avail_mem=30.51 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.94it/s]Capturing batches (bs=80 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.94it/s]Capturing batches (bs=72 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.94it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:01<00:00, 14.94it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.49it/s]Capturing batches (bs=56 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.49it/s]Capturing batches (bs=48 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.49it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.49it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.56it/s]Capturing batches (bs=32 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.56it/s]Capturing batches (bs=24 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.56it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.56it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.92it/s]Capturing batches (bs=8 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.92it/s] Capturing batches (bs=4 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.92it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.92it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.79it/s]Capturing batches (bs=1 avail_mem=30.35 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.79it/s]Capturing batches (bs=1 avail_mem=30.35 GB): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00, 15.02it/s]
2025-11-26T17:08:34.910861952Z [37m20251126-17:08:34.910 SGLangServer Wrapper INFO: SGLang server launched at: http://172.21.0.2:10397[0m
2025-11-26T17:08:35.630366015Z [37m20251126-17:08:35.629 Launcher Utils INFO: Found 1 rollout servers: 172.21.0.2:10397[0m
2025-11-26T17:08:35.630412094Z [37m20251126-17:08:35.630 Local Scheduler INFO: LLM inference server launched at: AREAL_LLM_SERVER_ADDRS=172.21.0.2:10397[0m
2025-11-26T17:08:35.633498416Z [37m20251126-17:08:35.633 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL AREAL_LLM_SERVER_ADDRS=172.21.0.2:10397 AREAL_RECOVER_RUN=0 NCCL_CUMEM_ENABLE=0 NCCL_NVLS_ENABLE=0 CUDA_VISIBLE_DEVICES=1 stdbuf -oL torchrun --nnodes 1 --nproc-per-node 1 --master-addr localhost --master-port 28285 examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_170803 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_170803/trainer.log[0m
2025-11-26T17:08:35.633959718Z [37m20251126-17:08:35.633 Local Scheduler INFO: Waiting for 2 local running processes, pids: 315 965[0m
2025-11-26T17:08:36.140343879Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:08:36.140376478Z   import pynvml  # type: ignore[import]
2025-11-26T17:08:37.316622001Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:08:37.316673939Z   import pynvml  # type: ignore[import]
2025-11-26T17:08:45.031595233Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:08:45.031642675Z   warnings.warn(
2025-11-26T17:08:45.031646040Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:08:45.031648504Z   warnings.warn(
2025-11-26T17:08:45.646150824Z Traceback (most recent call last):
2025-11-26T17:08:45.646204434Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 665, in <module>
2025-11-26T17:08:45.646817573Z     main(sys.argv[1:])
2025-11-26T17:08:45.646840998Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 102, in main
2025-11-26T17:08:45.646844113Z     config, _ = load_expr_config(args_with_overrides, GRPOConfig)
2025-11-26T17:08:45.646849391Z                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:08:45.646851694Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1282, in load_expr_config
2025-11-26T17:08:45.647254428Z     cfg = to_structured_cfg(cfg, config_cls=config_cls)
2025-11-26T17:08:45.647266897Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:08:45.647269410Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1276, in to_structured_cfg
2025-11-26T17:08:45.647732143Z     cfg = OmegaConf.merge(default_cfg, cfg)
2025-11-26T17:08:45.647736009Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:08:45.647738552Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/omegaconf.py", line 274, in merge
2025-11-26T17:08:45.648191170Z     target.merge_with(
2025-11-26T17:08:45.648196669Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 507, in merge_with
2025-11-26T17:08:45.648199583Z     self._format_and_raise(key=None, value=None, cause=e)
2025-11-26T17:08:45.648201746Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:08:45.648203789Z     format_and_raise(
2025-11-26T17:08:45.648205842Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:08:45.648609768Z     _raise(ex, cause)
2025-11-26T17:08:45.648615677Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:08:45.648617840Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:08:45.648944389Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:08:45.648946913Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 502, in merge_with
2025-11-26T17:08:45.648948885Z     self._merge_with(
2025-11-26T17:08:45.648950909Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:08:45.648952942Z     BaseContainer._map_merge(
2025-11-26T17:08:45.648955616Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:08:45.649281033Z     dest_node._merge_with(
2025-11-26T17:08:45.649285690Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:08:45.649288554Z     BaseContainer._map_merge(
2025-11-26T17:08:45.649290658Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:08:45.649567042Z     dest_node._merge_with(
2025-11-26T17:08:45.649577768Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:08:45.649580151Z     BaseContainer._map_merge(
2025-11-26T17:08:45.649582245Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 432, in _map_merge
2025-11-26T17:08:45.649584458Z     dest[key] = src._get_node(key)
2025-11-26T17:08:45.650149695Z     ~~~~^^^^^
2025-11-26T17:08:45.650174041Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 308, in __setitem__
2025-11-26T17:08:45.650176835Z     self._format_and_raise(
2025-11-26T17:08:45.650179820Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:08:45.650181883Z     format_and_raise(
2025-11-26T17:08:45.650184126Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:08:45.650186079Z     _raise(ex, cause)
2025-11-26T17:08:45.650188102Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:08:45.650436754Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:08:45.650770164Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:08:45.650772597Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 306, in __setitem__
2025-11-26T17:08:45.650774691Z     self.__set_impl(key=key, value=value)
2025-11-26T17:08:45.650776824Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 316, in __set_impl
2025-11-26T17:08:45.650778977Z     self._set_item_impl(key, value)
2025-11-26T17:08:45.650781040Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 579, in _set_item_impl
2025-11-26T17:08:45.651252416Z     target_node_ref = self._get_node(key)
2025-11-26T17:08:45.651258135Z                       ^^^^^^^^^^^^^^^^^^^
2025-11-26T17:08:45.651260258Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 473, in _get_node
2025-11-26T17:08:45.651262401Z     self._validate_get(key)
2025-11-26T17:08:45.651264604Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 163, in _validate_get
2025-11-26T17:08:45.651499726Z     self._format_and_raise(
2025-11-26T17:08:45.651502130Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:08:45.651504193Z     format_and_raise(
2025-11-26T17:08:45.651506507Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 906, in format_and_raise
2025-11-26T17:08:45.651797692Z     _raise(ex, cause)
2025-11-26T17:08:45.651800677Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:08:45.651803221Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:08:45.652081177Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:08:45.652083551Z omegaconf.errors.ConfigKeyError: Key 'max_new_tokens' not in 'NormConfig'
2025-11-26T17:08:45.652086124Z     full_key: actor.adv_norm.max_new_tokens
2025-11-26T17:08:45.652088167Z     reference_type=Optional[NormConfig]
2025-11-26T17:08:45.652090201Z     object_type=NormConfig
2025-11-26T17:08:48.439623566Z E1126 17:08:48.438000 966 torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 0 (pid: 1032) of binary: /usr/bin/python3
2025-11-26T17:08:48.440203224Z Traceback (most recent call last):
2025-11-26T17:08:48.440227250Z   File "/usr/local/bin/torchrun", line 7, in <module>
2025-11-26T17:08:48.440229844Z     sys.exit(main())
2025-11-26T17:08:48.440232328Z              ^^^^^^
2025-11-26T17:08:48.440234461Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
2025-11-26T17:08:48.440237316Z     return f(*args, **kwargs)
2025-11-26T17:08:48.440240020Z            ^^^^^^^^^^^^^^^^^^
2025-11-26T17:08:48.440242052Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 901, in main
2025-11-26T17:08:48.440540350Z     run(args)
2025-11-26T17:08:48.440547420Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 892, in run
2025-11-26T17:08:48.440557155Z     elastic_launch(
2025-11-26T17:08:48.440559478Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 143, in __call__
2025-11-26T17:08:48.441332536Z     return launch_agent(self._config, self._entrypoint, list(args))
2025-11-26T17:08:48.441339887Z            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:08:48.441342100Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 277, in launch_agent
2025-11-26T17:08:48.441344243Z     raise ChildFailedError(
2025-11-26T17:08:48.441346406Z torch.distributed.elastic.multiprocessing.errors.ChildFailedError:
2025-11-26T17:08:48.441348480Z ============================================================
2025-11-26T17:08:48.441350493Z examples/cloud_gsm8k/gsm8k_grpo_train.py FAILED
2025-11-26T17:08:48.441352526Z ------------------------------------------------------------
2025-11-26T17:08:48.441354569Z Failures:
2025-11-26T17:08:48.441356622Z   <NO_OTHER_FAILURES>
2025-11-26T17:08:48.441358665Z ------------------------------------------------------------
2025-11-26T17:08:48.441360688Z Root Cause (first observed failure):
2025-11-26T17:08:48.441362781Z [0]:
2025-11-26T17:08:48.441364834Z   time      : 2025-11-26_17:08:48
2025-11-26T17:08:48.441366857Z   host      : cef7c503fdea
2025-11-26T17:08:48.441368870Z   rank      : 0 (local_rank: 0)
2025-11-26T17:08:48.441370863Z   exitcode  : 1 (pid: 1032)
2025-11-26T17:08:48.441372866Z   error_file: <N/A>
2025-11-26T17:08:48.441374889Z   traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
2025-11-26T17:08:48.441377063Z ============================================================
2025-11-26T17:08:49.637445610Z [37m20251126-17:08:49.637 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [315][0m
2025-11-26T17:08:49.802199423Z Killed
2025-11-26T17:08:49.812299232Z [37m20251126-17:08:49.812 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [965][0m
2025-11-26T17:08:49.813266832Z Traceback (most recent call last):
2025-11-26T17:08:49.813272891Z   File "<frozen runpy>", line 198, in _run_module_as_main
2025-11-26T17:08:49.813275695Z   File "<frozen runpy>", line 88, in _run_code
2025-11-26T17:08:49.813277769Z   File "/workspace/AReaL/areal/launcher/local.py", line 405, in <module>
2025-11-26T17:08:49.813426791Z     main()
2025-11-26T17:08:49.813429896Z   File "/workspace/AReaL/areal/launcher/local.py", line 260, in main
2025-11-26T17:08:49.813515304Z     local_main(config, run_id=0)
2025-11-26T17:08:49.813518169Z   File "/workspace/AReaL/areal/launcher/local.py", line 399, in local_main
2025-11-26T17:08:49.813619950Z     raise e
2025-11-26T17:08:49.813622664Z   File "/workspace/AReaL/areal/launcher/local.py", line 375, in local_main
2025-11-26T17:08:49.813689325Z     launcher.wait(
2025-11-26T17:08:49.813691828Z   File "/workspace/AReaL/areal/launcher/local.py", line 235, in wait
2025-11-26T17:08:49.813751157Z     raise JobException(
2025-11-26T17:08:49.813754051Z areal.utils.launcher.JobException: Job gsm8k-grpo-cloud-2gpu-2000samples_trial_20251126_170803:trainer JobState.COMPLETED at node local
2025-11-26T17:08:50.094170046Z [37m20251126-17:08:50.093 Local Scheduler INFO: Waiting for 0 local running processes, pids: [0m
2025-11-26T17:09:06.553480300Z ==========
2025-11-26T17:09:06.553485778Z == CUDA ==
2025-11-26T17:09:06.553488261Z ==========
2025-11-26T17:09:06.557730265Z CUDA Version 12.9.1
2025-11-26T17:09:06.559245115Z Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
2025-11-26T17:09:06.560756919Z This container image and its contents are governed by the NVIDIA Deep Learning Container License.
2025-11-26T17:09:06.560759232Z By pulling and using the container, you accept the terms and conditions of this license:
2025-11-26T17:09:06.560761656Z https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license
2025-11-26T17:09:06.560765822Z A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
2025-11-26T17:09:06.724904565Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:09:06.883188898Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:09:07.071714810Z Branch 'feature/reasoning_model' set up to track remote branch 'feature/reasoning_model' from 'origin'.
2025-11-26T17:09:07.071750454Z Your branch is up to date with 'origin/feature/reasoning_model'.
2025-11-26T17:09:07.142393160Z Checking AReaL installation...
2025-11-26T17:09:07.201669801Z AReaL already installed. Skipping installation.
2025-11-26T17:09:07.201698533Z Cleaning up any leftover GPU processes...
2025-11-26T17:09:10.221094336Z Checking for processes holding GPU device files...
2025-11-26T17:09:12.434970464Z Found processes holding GPU devices: 1
2025-11-26T17:09:12.435012066Z 20
2025-11-26T17:09:12.435015211Z 71
2025-11-26T17:09:12.435017334Z 72
2025-11-26T17:09:12.435019567Z Killing process 1...
2025-11-26T17:09:12.435022301Z Killing process 71...
2025-11-26T17:09:12.435083141Z Killing process 72...
2025-11-26T17:09:14.438026844Z Using fuser to kill processes on GPU devices...
2025-11-26T17:09:16.460870845Z Checking GPU...
2025-11-26T17:09:16.496575648Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:09:16.496603089Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:09:16.513293579Z Set PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True for better memory management
2025-11-26T17:09:16.513315392Z Detected 2 GPU(s)
2025-11-26T17:09:16.513319298Z Checking GPU status...
2025-11-26T17:09:16.541445487Z index, name, utilization.gpu [%], memory.used [MiB], compute_mode
2025-11-26T17:09:16.542896952Z 0, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:09:16.543235679Z 1, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:09:16.585959125Z Verifying GPU accessibility...
2025-11-26T17:09:17.109083902Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:09:17.109170932Z   import pynvml  # type: ignore[import]
2025-11-26T17:09:18.211357063Z GPU accessibility verified on attempt 1
2025-11-26T17:09:18.676949282Z Starting training...
2025-11-26T17:09:21.680022234Z Using STANDARD 2000 SAMPLES 2 GPUs configuration
2025-11-26T17:09:21.680067752Z Note: GRPO only (no reasoning XML). Dataset capped at 2000 samples (~6 hours).
2025-11-26T17:09:21.680071578Z GPU count: 2 (required: 2)
2025-11-26T17:09:21.682462760Z ==========================================
2025-11-26T17:09:21.682466986Z Starting GRPO Training (Cloud)
2025-11-26T17:09:21.682469931Z ==========================================
2025-11-26T17:09:21.682472595Z Config: standard_2000samples_2GPUs
2025-11-26T17:09:21.682475279Z Config file: examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml
2025-11-26T17:09:21.682478694Z Training script: examples/cloud_gsm8k/gsm8k_grpo_train.py
2025-11-26T17:09:21.682481929Z Experiment: gsm8k-grpo-cloud-2gpu-2000samples
2025-11-26T17:09:21.682484753Z Trial: trial_20251126_170921
2025-11-26T17:09:21.682487878Z GPU: NVIDIA A100 80GB PCIe NVIDIA A100 80GB PCIe (81920 MB)
2025-11-26T17:09:21.682490652Z WandB API key: e1adc5be02...
2025-11-26T17:09:21.682493556Z ==========================================
2025-11-26T17:09:22.363051942Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:09:22.363091402Z   import pynvml  # type: ignore[import]
2025-11-26T17:09:26.308936750Z [37m20251126-17:09:26.308 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:09:26.308994075Z [37m20251126-17:09:26.308 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:09:26.309236868Z [37m20251126-17:09:26.308 name-resolve INFO: No such name resolve path: ./tmp/areal/name_resolve/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_170921[0m
2025-11-26T17:09:26.414199483Z [37m20251126-17:09:26.413 Local Scheduler INFO: LocalLauncher: experiment_name=gsm8k-grpo-cloud-2gpu-2000samples, trial_name=trial_20251126_170921, fileroot=/workspace/outputs/grpo, run_id=0, is_recover_run=False[0m
2025-11-26T17:09:26.422009611Z [37m20251126-17:09:26.421 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL CUDA_VISIBLE_DEVICES=0 stdbuf -oL python3 -m areal.launcher.sglang_server examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_170921 sglang.random_seed=1 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_170921/llm_server.log[0m
2025-11-26T17:09:27.128353832Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:09:27.128406420Z   import pynvml  # type: ignore[import]
2025-11-26T17:09:28.652686004Z [37m20251126-17:09:28.652 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:09:28.653424659Z [37m20251126-17:09:28.652 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:09:28.807084657Z [37m20251126-17:09:28.806 SGLangServer Wrapper INFO: Launch command: python3 -m sglang.launch_server --host 172.21.0.2 --port 15985 --tokenizer-path Qwen/Qwen2.5-0.5B-Instruct --tokenizer-mode auto --load-format auto --trust-remote-code --device cuda --tp-size 1 --base-gpu-id 0 --nnodes 1 --node-rank 0 --dist-init-addr localhost:23921 --model-path Qwen/Qwen2.5-0.5B-Instruct --random-seed 1 --skip-tokenizer-init --disable-radix-cache --torch-compile-max-bs 32 --triton-attention-num-kv-splits 8 --num-continuous-decode-steps 1 --attention-backend flashinfer --context-length 4096 --mem-fraction-static 0.6 --chunked-prefill-size -1 --max-prefill-tokens 32768 --schedule-policy lpm --schedule-conservativeness 1.0 --cpu-offload-gb 0 --dtype bfloat16 --kv-cache-dtype auto --dp-size 1 --ep-size 1 --max-loaded-loras 1 --max-loras-per-batch 1 --lora-backend triton --log-level warning --log-level-http warning --log-requests-level 0 --enable-metrics --decode-log-interval 1[0m
2025-11-26T17:09:29.895007293Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:09:29.895050578Z   import pynvml  # type: ignore[import]
2025-11-26T17:09:35.407707206Z INFO 11-26 17:09:35 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:09:36.066462123Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:09:37.085095380Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:09:37.085154909Z   import pynvml  # type: ignore[import]
2025-11-26T17:09:37.125779931Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:09:37.125817798Z   import pynvml  # type: ignore[import]
2025-11-26T17:09:42.446010958Z INFO 11-26 17:09:42 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:09:42.583211459Z INFO 11-26 17:09:42 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:09:43.205037300Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:09:43.418832664Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:09:43.422633828Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:09:43.423439234Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:09:43.424305922Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:09:43.458667472Z [2025-11-26 17:09:43] MOE_RUNNER_BACKEND is not initialized, using triton backend
2025-11-26T17:09:43.981227333Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:09:43.981265911Z   warnings.warn(
2025-11-26T17:09:43.981268985Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:09:43.981271308Z   warnings.warn(
2025-11-26T17:09:45.231455286Z Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
2025-11-26T17:09:45.349961322Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  8.45it/s]
2025-11-26T17:09:45.350455442Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  8.43it/s]
2025-11-26T17:09:47.910229430Z   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   4%|â–         | 1/23 [00:00<00:12,  1.77it/s]Capturing batches (bs=152 avail_mem=30.62 GB):   4%|â–         | 1/23 [00:00<00:12,  1.77it/s]Capturing batches (bs=144 avail_mem=30.60 GB):   4%|â–         | 1/23 [00:00<00:12,  1.77it/s]Capturing batches (bs=136 avail_mem=30.59 GB):   4%|â–         | 1/23 [00:00<00:12,  1.77it/s]Capturing batches (bs=136 avail_mem=30.59 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  6.99it/s]Capturing batches (bs=128 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  6.99it/s]Capturing batches (bs=120 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  6.99it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  6.99it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.15it/s]Capturing batches (bs=104 avail_mem=30.54 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.15it/s]Capturing batches (bs=96 avail_mem=30.53 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.15it/s] Capturing batches (bs=88 avail_mem=30.51 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.15it/s]Capturing batches (bs=88 avail_mem=30.51 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.39it/s]Capturing batches (bs=80 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.39it/s]Capturing batches (bs=72 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:01<00:00, 14.39it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:01<00:00, 14.39it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 16.83it/s]Capturing batches (bs=56 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 16.83it/s]Capturing batches (bs=48 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 16.83it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 16.83it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 18.74it/s]Capturing batches (bs=32 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 18.74it/s]Capturing batches (bs=24 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 18.74it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 18.74it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.22it/s]Capturing batches (bs=8 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.22it/s] Capturing batches (bs=4 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.22it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.22it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 18.92it/s]Capturing batches (bs=1 avail_mem=30.35 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 18.92it/s]Capturing batches (bs=1 avail_mem=30.35 GB): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00, 14.44it/s]
2025-11-26T17:09:53.837009044Z [37m20251126-17:09:53.836 SGLangServer Wrapper INFO: SGLang server launched at: http://172.21.0.2:15985[0m
2025-11-26T17:09:54.428939436Z [37m20251126-17:09:54.428 Launcher Utils INFO: Found 1 rollout servers: 172.21.0.2:15985[0m
2025-11-26T17:09:54.428978124Z [37m20251126-17:09:54.428 Local Scheduler INFO: LLM inference server launched at: AREAL_LLM_SERVER_ADDRS=172.21.0.2:15985[0m
2025-11-26T17:09:54.431903776Z [37m20251126-17:09:54.431 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL AREAL_LLM_SERVER_ADDRS=172.21.0.2:15985 AREAL_RECOVER_RUN=0 NCCL_CUMEM_ENABLE=0 NCCL_NVLS_ENABLE=0 CUDA_VISIBLE_DEVICES=1 stdbuf -oL torchrun --nnodes 1 --nproc-per-node 1 --master-addr localhost --master-port 29813 examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_170921 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_170921/trainer.log[0m
2025-11-26T17:09:54.432662092Z [37m20251126-17:09:54.432 Local Scheduler INFO: Waiting for 2 local running processes, pids: 315 965[0m
2025-11-26T17:09:54.943645336Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:09:54.943681921Z   import pynvml  # type: ignore[import]
2025-11-26T17:09:56.117456278Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:09:56.117492291Z   import pynvml  # type: ignore[import]
2025-11-26T17:10:02.810951457Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:10:02.811001642Z   warnings.warn(
2025-11-26T17:10:02.811005016Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:10:02.811007340Z   warnings.warn(
2025-11-26T17:10:03.227939379Z Traceback (most recent call last):
2025-11-26T17:10:03.227983686Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 665, in <module>
2025-11-26T17:10:03.228644945Z     main(sys.argv[1:])
2025-11-26T17:10:03.228686428Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 102, in main
2025-11-26T17:10:03.228690684Z     config, _ = load_expr_config(args_with_overrides, GRPOConfig)
2025-11-26T17:10:03.228694219Z                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:10:03.228696362Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1282, in load_expr_config
2025-11-26T17:10:03.228698345Z     cfg = to_structured_cfg(cfg, config_cls=config_cls)
2025-11-26T17:10:03.229134690Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:10:03.229146898Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1276, in to_structured_cfg
2025-11-26T17:10:03.229150413Z     cfg = OmegaConf.merge(default_cfg, cfg)
2025-11-26T17:10:03.229153517Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:10:03.229157152Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/omegaconf.py", line 274, in merge
2025-11-26T17:10:03.229160077Z     target.merge_with(
2025-11-26T17:10:03.229163522Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 507, in merge_with
2025-11-26T17:10:03.229167518Z     self._format_and_raise(key=None, value=None, cause=e)
2025-11-26T17:10:03.229446906Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:10:03.229452745Z     format_and_raise(
2025-11-26T17:10:03.229455309Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:10:03.229457602Z     _raise(ex, cause)
2025-11-26T17:10:03.229459616Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:10:03.229461989Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:10:03.229974137Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:10:03.229989771Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 502, in merge_with
2025-11-26T17:10:03.229992675Z     self._merge_with(
2025-11-26T17:10:03.229995619Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:10:03.229997823Z     BaseContainer._map_merge(
2025-11-26T17:10:03.230001217Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:10:03.230003381Z     dest_node._merge_with(
2025-11-26T17:10:03.230005364Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:10:03.230007497Z     BaseContainer._map_merge(
2025-11-26T17:10:03.230009750Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:10:03.230386184Z     dest_node._merge_with(
2025-11-26T17:10:03.230395007Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:10:03.230398082Z     BaseContainer._map_merge(
2025-11-26T17:10:03.230407986Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 432, in _map_merge
2025-11-26T17:10:03.230410320Z     dest[key] = src._get_node(key)
2025-11-26T17:10:03.230413204Z     ~~~~^^^^^
2025-11-26T17:10:03.230417120Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 308, in __setitem__
2025-11-26T17:10:03.230419303Z     self._format_and_raise(
2025-11-26T17:10:03.230421326Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:10:03.230423449Z     format_and_raise(
2025-11-26T17:10:03.230426324Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:10:03.231239411Z     _raise(ex, cause)
2025-11-26T17:10:03.231249737Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:10:03.231253793Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:10:03.231256167Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:10:03.231258580Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 306, in __setitem__
2025-11-26T17:10:03.231260964Z     self.__set_impl(key=key, value=value)
2025-11-26T17:10:03.231263367Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 316, in __set_impl
2025-11-26T17:10:03.231265490Z     self._set_item_impl(key, value)
2025-11-26T17:10:03.231267484Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 579, in _set_item_impl
2025-11-26T17:10:03.231269837Z     target_node_ref = self._get_node(key)
2025-11-26T17:10:03.231272351Z                       ^^^^^^^^^^^^^^^^^^^
2025-11-26T17:10:03.231274524Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 473, in _get_node
2025-11-26T17:10:03.231276678Z     self._validate_get(key)
2025-11-26T17:10:03.231279091Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 163, in _validate_get
2025-11-26T17:10:03.231616647Z     self._format_and_raise(
2025-11-26T17:10:03.231623247Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:10:03.231625951Z     format_and_raise(
2025-11-26T17:10:03.231628474Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 906, in format_and_raise
2025-11-26T17:10:03.231630918Z     _raise(ex, cause)
2025-11-26T17:10:03.231633262Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:10:03.231637067Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:10:03.232016296Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:10:03.232021354Z omegaconf.errors.ConfigKeyError: Key 'max_new_tokens' not in 'NormConfig'
2025-11-26T17:10:03.232024909Z     full_key: actor.adv_norm.max_new_tokens
2025-11-26T17:10:03.232027252Z     reference_type=Optional[NormConfig]
2025-11-26T17:10:03.232029386Z     object_type=NormConfig
2025-11-26T17:10:05.535647306Z E1126 17:10:05.534000 966 torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 0 (pid: 1032) of binary: /usr/bin/python3
2025-11-26T17:10:05.536159152Z Traceback (most recent call last):
2025-11-26T17:10:05.536170960Z   File "/usr/local/bin/torchrun", line 7, in <module>
2025-11-26T17:10:05.536173494Z     sys.exit(main())
2025-11-26T17:10:05.536175937Z              ^^^^^^
2025-11-26T17:10:05.536178011Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
2025-11-26T17:10:05.536181496Z     return f(*args, **kwargs)
2025-11-26T17:10:05.536184931Z            ^^^^^^^^^^^^^^^^^^
2025-11-26T17:10:05.536724479Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 901, in main
2025-11-26T17:10:05.536727844Z     run(args)
2025-11-26T17:10:05.536730228Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 892, in run
2025-11-26T17:10:05.536732341Z     elastic_launch(
2025-11-26T17:10:05.536734945Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 143, in __call__
2025-11-26T17:10:05.536760343Z     return launch_agent(self._config, self._entrypoint, list(args))
2025-11-26T17:10:05.536763417Z            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:10:05.536765481Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 277, in launch_agent
2025-11-26T17:10:05.536768485Z     raise ChildFailedError(
2025-11-26T17:10:05.536770789Z torch.distributed.elastic.multiprocessing.errors.ChildFailedError:
2025-11-26T17:10:05.536772762Z ============================================================
2025-11-26T17:10:05.536775075Z examples/cloud_gsm8k/gsm8k_grpo_train.py FAILED
2025-11-26T17:10:05.536777479Z ------------------------------------------------------------
2025-11-26T17:10:05.536779512Z Failures:
2025-11-26T17:10:05.536781515Z   <NO_OTHER_FAILURES>
2025-11-26T17:10:05.536783498Z ------------------------------------------------------------
2025-11-26T17:10:05.536785521Z Root Cause (first observed failure):
2025-11-26T17:10:05.536787504Z [0]:
2025-11-26T17:10:05.536789537Z   time      : 2025-11-26_17:10:05
2025-11-26T17:10:05.536791580Z   host      : cef7c503fdea
2025-11-26T17:10:05.536793543Z   rank      : 0 (local_rank: 0)
2025-11-26T17:10:05.536795496Z   exitcode  : 1 (pid: 1032)
2025-11-26T17:10:05.536797539Z   error_file: <N/A>
2025-11-26T17:10:05.536799522Z   traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
2025-11-26T17:10:05.536801555Z ============================================================
2025-11-26T17:10:06.435657932Z [37m20251126-17:10:06.435 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [315][0m
2025-11-26T17:10:06.555789302Z Killed
2025-11-26T17:10:06.567777860Z [37m20251126-17:10:06.567 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [965][0m
2025-11-26T17:10:06.568760491Z Traceback (most recent call last):
2025-11-26T17:10:06.568775393Z   File "<frozen runpy>", line 198, in _run_module_as_main
2025-11-26T17:10:06.568778237Z   File "<frozen runpy>", line 88, in _run_code
2025-11-26T17:10:06.568780321Z   File "/workspace/AReaL/areal/launcher/local.py", line 405, in <module>
2025-11-26T17:10:06.568915494Z     main()
2025-11-26T17:10:06.568920952Z   File "/workspace/AReaL/areal/launcher/local.py", line 260, in main
2025-11-26T17:10:06.569015123Z     local_main(config, run_id=0)
2025-11-26T17:10:06.569019399Z   File "/workspace/AReaL/areal/launcher/local.py", line 399, in local_main
2025-11-26T17:10:06.569109023Z     raise e
2025-11-26T17:10:06.569111367Z   File "/workspace/AReaL/areal/launcher/local.py", line 375, in local_main
2025-11-26T17:10:06.569208262Z     launcher.wait(
2025-11-26T17:10:06.569216594Z   File "/workspace/AReaL/areal/launcher/local.py", line 235, in wait
2025-11-26T17:10:06.569276685Z     raise JobException(
2025-11-26T17:10:06.569279579Z areal.utils.launcher.JobException: Job gsm8k-grpo-cloud-2gpu-2000samples_trial_20251126_170921:trainer JobState.COMPLETED at node local
2025-11-26T17:10:06.748872045Z [37m20251126-17:10:06.748 Local Scheduler INFO: Waiting for 0 local running processes, pids: [0m
2025-11-26T17:10:09.379377278Z ==========
2025-11-26T17:10:09.379382096Z == CUDA ==
2025-11-26T17:10:09.379416347Z ==========
2025-11-26T17:10:09.383646684Z CUDA Version 12.9.1
2025-11-26T17:10:09.385286420Z Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
2025-11-26T17:10:09.386879767Z This container image and its contents are governed by the NVIDIA Deep Learning Container License.
2025-11-26T17:10:09.386882541Z By pulling and using the container, you accept the terms and conditions of this license:
2025-11-26T17:10:09.386885425Z https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license
2025-11-26T17:10:09.386889902Z A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
2025-11-26T17:10:09.551226946Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:10:09.709005498Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:10:09.896388483Z Branch 'feature/reasoning_model' set up to track remote branch 'feature/reasoning_model' from 'origin'.
2025-11-26T17:10:09.896413770Z Your branch is up to date with 'origin/feature/reasoning_model'.
2025-11-26T17:10:09.966943314Z Checking AReaL installation...
2025-11-26T17:10:10.025436379Z AReaL already installed. Skipping installation.
2025-11-26T17:10:10.025470059Z Cleaning up any leftover GPU processes...
2025-11-26T17:10:13.044071631Z Checking for processes holding GPU device files...
2025-11-26T17:10:15.201784476Z Found processes holding GPU devices: 1
2025-11-26T17:10:15.201827730Z 20
2025-11-26T17:10:15.201831175Z 71
2025-11-26T17:10:15.201834431Z 72
2025-11-26T17:10:15.201836634Z Killing process 1...
2025-11-26T17:10:15.201839418Z Killing process 71...
2025-11-26T17:10:15.201948290Z Killing process 72...
2025-11-26T17:10:17.204546364Z Using fuser to kill processes on GPU devices...
2025-11-26T17:10:19.226603565Z Checking GPU...
2025-11-26T17:10:19.260747338Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:10:19.260776202Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:10:19.276783438Z Set PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True for better memory management
2025-11-26T17:10:19.276802276Z Detected 2 GPU(s)
2025-11-26T17:10:19.276805992Z Checking GPU status...
2025-11-26T17:10:19.304806172Z index, name, utilization.gpu [%], memory.used [MiB], compute_mode
2025-11-26T17:10:19.306222374Z 0, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:10:19.306535883Z 1, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:10:19.349011315Z Verifying GPU accessibility...
2025-11-26T17:10:19.874226317Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:10:19.874284004Z   import pynvml  # type: ignore[import]
2025-11-26T17:10:20.977441356Z GPU accessibility verified on attempt 1
2025-11-26T17:10:21.437863046Z Starting training...
2025-11-26T17:10:24.440214356Z Using STANDARD 2000 SAMPLES 2 GPUs configuration
2025-11-26T17:10:24.440257721Z Note: GRPO only (no reasoning XML). Dataset capped at 2000 samples (~6 hours).
2025-11-26T17:10:24.440264131Z GPU count: 2 (required: 2)
2025-11-26T17:10:24.443192648Z ==========================================
2025-11-26T17:10:24.443196002Z Starting GRPO Training (Cloud)
2025-11-26T17:10:24.443199006Z ==========================================
2025-11-26T17:10:24.443201119Z Config: standard_2000samples_2GPUs
2025-11-26T17:10:24.443203172Z Config file: examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml
2025-11-26T17:10:24.443205976Z Training script: examples/cloud_gsm8k/gsm8k_grpo_train.py
2025-11-26T17:10:24.443208841Z Experiment: gsm8k-grpo-cloud-2gpu-2000samples
2025-11-26T17:10:24.443210834Z Trial: trial_20251126_171024
2025-11-26T17:10:24.443212827Z GPU: NVIDIA A100 80GB PCIe NVIDIA A100 80GB PCIe (81920 MB)
2025-11-26T17:10:24.443221109Z WandB API key: e1adc5be02...
2025-11-26T17:10:24.443223342Z ==========================================
2025-11-26T17:10:25.175832303Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:10:25.175882708Z   import pynvml  # type: ignore[import]
2025-11-26T17:10:29.357993891Z [37m20251126-17:10:29.357 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:10:29.358036435Z [37m20251126-17:10:29.357 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:10:29.358377696Z [37m20251126-17:10:29.357 name-resolve INFO: No such name resolve path: ./tmp/areal/name_resolve/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_171024[0m
2025-11-26T17:10:29.465096687Z [37m20251126-17:10:29.464 Local Scheduler INFO: LocalLauncher: experiment_name=gsm8k-grpo-cloud-2gpu-2000samples, trial_name=trial_20251126_171024, fileroot=/workspace/outputs/grpo, run_id=0, is_recover_run=False[0m
2025-11-26T17:10:29.472764501Z [37m20251126-17:10:29.472 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL CUDA_VISIBLE_DEVICES=0 stdbuf -oL python3 -m areal.launcher.sglang_server examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_171024 sglang.random_seed=1 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_171024/llm_server.log[0m
2025-11-26T17:10:30.205323948Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:10:30.205375064Z   import pynvml  # type: ignore[import]
2025-11-26T17:10:31.686598008Z [37m20251126-17:10:31.685 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:10:31.687177727Z [37m20251126-17:10:31.686 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:10:31.787439435Z [37m20251126-17:10:31.786 SGLangServer Wrapper INFO: Launch command: python3 -m sglang.launch_server --host 172.21.0.2 --port 14478 --tokenizer-path Qwen/Qwen2.5-0.5B-Instruct --tokenizer-mode auto --load-format auto --trust-remote-code --device cuda --tp-size 1 --base-gpu-id 0 --nnodes 1 --node-rank 0 --dist-init-addr localhost:28633 --model-path Qwen/Qwen2.5-0.5B-Instruct --random-seed 1 --skip-tokenizer-init --disable-radix-cache --torch-compile-max-bs 32 --triton-attention-num-kv-splits 8 --num-continuous-decode-steps 1 --attention-backend flashinfer --context-length 4096 --mem-fraction-static 0.6 --chunked-prefill-size -1 --max-prefill-tokens 32768 --schedule-policy lpm --schedule-conservativeness 1.0 --cpu-offload-gb 0 --dtype bfloat16 --kv-cache-dtype auto --dp-size 1 --ep-size 1 --max-loaded-loras 1 --max-loras-per-batch 1 --lora-backend triton --log-level warning --log-level-http warning --log-requests-level 0 --enable-metrics --decode-log-interval 1[0m
2025-11-26T17:10:32.822828109Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:10:32.822873416Z   import pynvml  # type: ignore[import]
2025-11-26T17:10:38.106598469Z INFO 11-26 17:10:38 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:10:38.751227607Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:10:39.752956552Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:10:39.752999988Z   import pynvml  # type: ignore[import]
2025-11-26T17:10:39.786440978Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:10:39.786482650Z   import pynvml  # type: ignore[import]
2025-11-26T17:10:44.945882140Z INFO 11-26 17:10:44 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:10:45.632201013Z INFO 11-26 17:10:45 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:10:46.240844520Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:10:46.457878438Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:10:46.461411199Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:10:46.462204738Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:10:46.463071857Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:10:46.496430324Z [2025-11-26 17:10:46] MOE_RUNNER_BACKEND is not initialized, using triton backend
2025-11-26T17:10:47.000203638Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:10:47.000242907Z   warnings.warn(
2025-11-26T17:10:47.000245992Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:10:47.000248295Z   warnings.warn(
2025-11-26T17:10:48.426633249Z Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
2025-11-26T17:10:48.545382870Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  8.44it/s]
2025-11-26T17:10:48.546024410Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  8.42it/s]
2025-11-26T17:10:51.178097675Z   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   4%|â–         | 1/23 [00:00<00:12,  1.78it/s]Capturing batches (bs=152 avail_mem=30.62 GB):   4%|â–         | 1/23 [00:00<00:12,  1.78it/s]Capturing batches (bs=144 avail_mem=30.60 GB):   4%|â–         | 1/23 [00:00<00:12,  1.78it/s]Capturing batches (bs=136 avail_mem=30.59 GB):   4%|â–         | 1/23 [00:00<00:12,  1.78it/s]Capturing batches (bs=136 avail_mem=30.59 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  6.98it/s]Capturing batches (bs=128 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  6.98it/s]Capturing batches (bs=120 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  6.98it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  6.98it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.05it/s]Capturing batches (bs=104 avail_mem=30.54 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.05it/s]Capturing batches (bs=96 avail_mem=30.53 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.05it/s] Capturing batches (bs=88 avail_mem=30.51 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.05it/s]Capturing batches (bs=88 avail_mem=30.51 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.21it/s]Capturing batches (bs=80 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.21it/s]Capturing batches (bs=72 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:01<00:00, 14.21it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:01<00:00, 14.21it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 16.55it/s]Capturing batches (bs=56 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 16.55it/s]Capturing batches (bs=48 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 16.55it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 16.55it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 18.41it/s]Capturing batches (bs=32 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 18.41it/s]Capturing batches (bs=24 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 18.41it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 18.41it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 16.92it/s]Capturing batches (bs=8 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 16.92it/s] Capturing batches (bs=4 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 16.92it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 16.92it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 18.60it/s]Capturing batches (bs=1 avail_mem=30.35 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 18.60it/s]Capturing batches (bs=1 avail_mem=30.35 GB): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00, 14.26it/s]
2025-11-26T17:10:56.815993346Z [37m20251126-17:10:56.815 SGLangServer Wrapper INFO: SGLang server launched at: http://172.21.0.2:14478[0m
2025-11-26T17:10:57.479642835Z [37m20251126-17:10:57.479 Launcher Utils INFO: Found 1 rollout servers: 172.21.0.2:14478[0m
2025-11-26T17:10:57.479681542Z [37m20251126-17:10:57.479 Local Scheduler INFO: LLM inference server launched at: AREAL_LLM_SERVER_ADDRS=172.21.0.2:14478[0m
2025-11-26T17:10:57.482375918Z [37m20251126-17:10:57.482 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL AREAL_LLM_SERVER_ADDRS=172.21.0.2:14478 AREAL_RECOVER_RUN=0 NCCL_CUMEM_ENABLE=0 NCCL_NVLS_ENABLE=0 CUDA_VISIBLE_DEVICES=1 stdbuf -oL torchrun --nnodes 1 --nproc-per-node 1 --master-addr localhost --master-port 28245 examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_171024 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_171024/trainer.log[0m
2025-11-26T17:10:57.483063699Z [37m20251126-17:10:57.482 Local Scheduler INFO: Waiting for 2 local running processes, pids: 315 965[0m
2025-11-26T17:10:57.994535134Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:10:57.994576616Z   import pynvml  # type: ignore[import]
2025-11-26T17:10:59.163993406Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:10:59.164037463Z   import pynvml  # type: ignore[import]
2025-11-26T17:11:06.048169951Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:11:06.048226385Z   warnings.warn(
2025-11-26T17:11:06.048229620Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:11:06.048231894Z   warnings.warn(
2025-11-26T17:11:06.496443925Z Traceback (most recent call last):
2025-11-26T17:11:06.496483164Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 665, in <module>
2025-11-26T17:11:06.496945757Z     main(sys.argv[1:])
2025-11-26T17:11:06.496954891Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 102, in main
2025-11-26T17:11:06.496958225Z     config, _ = load_expr_config(args_with_overrides, GRPOConfig)
2025-11-26T17:11:06.496960929Z                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:11:06.496962963Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1282, in load_expr_config
2025-11-26T17:11:06.497363363Z     cfg = to_structured_cfg(cfg, config_cls=config_cls)
2025-11-26T17:11:06.497370874Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:11:06.497373277Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1276, in to_structured_cfg
2025-11-26T17:11:06.497377423Z     cfg = OmegaConf.merge(default_cfg, cfg)
2025-11-26T17:11:06.497867317Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:11:06.497870492Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/omegaconf.py", line 274, in merge
2025-11-26T17:11:06.497872705Z     target.merge_with(
2025-11-26T17:11:06.497874708Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 507, in merge_with
2025-11-26T17:11:06.497877312Z     self._format_and_raise(key=None, value=None, cause=e)
2025-11-26T17:11:06.497879756Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:11:06.497881789Z     format_and_raise(
2025-11-26T17:11:06.497883812Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:11:06.497886055Z     _raise(ex, cause)
2025-11-26T17:11:06.497888339Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:11:06.498392974Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:11:06.498431232Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:11:06.498434617Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 502, in merge_with
2025-11-26T17:11:06.498437501Z     self._merge_with(
2025-11-26T17:11:06.498440356Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:11:06.498442619Z     BaseContainer._map_merge(
2025-11-26T17:11:06.498445263Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:11:06.498447346Z     dest_node._merge_with(
2025-11-26T17:11:06.498449409Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:11:06.498909928Z     BaseContainer._map_merge(
2025-11-26T17:11:06.498915036Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:11:06.498917700Z     dest_node._merge_with(
2025-11-26T17:11:06.498920204Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:11:06.498922257Z     BaseContainer._map_merge(
2025-11-26T17:11:06.498924460Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 432, in _map_merge
2025-11-26T17:11:06.498936568Z     dest[key] = src._get_node(key)
2025-11-26T17:11:06.498939022Z     ~~~~^^^^^
2025-11-26T17:11:06.498941436Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 308, in __setitem__
2025-11-26T17:11:06.498943519Z     self._format_and_raise(
2025-11-26T17:11:06.498945512Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:11:06.498947565Z     format_and_raise(
2025-11-26T17:11:06.498949799Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:11:06.499537428Z     _raise(ex, cause)
2025-11-26T17:11:06.499545120Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:11:06.499547443Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:11:06.499549507Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:11:06.499551680Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 306, in __setitem__
2025-11-26T17:11:06.499553833Z     self.__set_impl(key=key, value=value)
2025-11-26T17:11:06.499560914Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 316, in __set_impl
2025-11-26T17:11:06.499563137Z     self._set_item_impl(key, value)
2025-11-26T17:11:06.499565270Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 579, in _set_item_impl
2025-11-26T17:11:06.499567594Z     target_node_ref = self._get_node(key)
2025-11-26T17:11:06.499931189Z                       ^^^^^^^^^^^^^^^^^^^
2025-11-26T17:11:06.499935225Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 473, in _get_node
2025-11-26T17:11:06.499937478Z     self._validate_get(key)
2025-11-26T17:11:06.499939531Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 163, in _validate_get
2025-11-26T17:11:06.499941725Z     self._format_and_raise(
2025-11-26T17:11:06.499943677Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:11:06.499946041Z     format_and_raise(
2025-11-26T17:11:06.499948505Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 906, in format_and_raise
2025-11-26T17:11:06.500277057Z     _raise(ex, cause)
2025-11-26T17:11:06.500282896Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:11:06.500285189Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:11:06.500287432Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:11:06.500289746Z omegaconf.errors.ConfigKeyError: Key 'max_new_tokens' not in 'NormConfig'
2025-11-26T17:11:06.500292630Z     full_key: actor.adv_norm.max_new_tokens
2025-11-26T17:11:06.500294864Z     reference_type=Optional[NormConfig]
2025-11-26T17:11:06.500297227Z     object_type=NormConfig
2025-11-26T17:11:08.986802148Z E1126 17:11:08.985000 966 torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 0 (pid: 1032) of binary: /usr/bin/python3
2025-11-26T17:11:08.987396468Z Traceback (most recent call last):
2025-11-26T17:11:08.987402597Z   File "/usr/local/bin/torchrun", line 7, in <module>
2025-11-26T17:11:08.987405362Z     sys.exit(main())
2025-11-26T17:11:08.987408356Z              ^^^^^^
2025-11-26T17:11:08.987410420Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
2025-11-26T17:11:08.987413894Z     return f(*args, **kwargs)
2025-11-26T17:11:08.987416449Z            ^^^^^^^^^^^^^^^^^^
2025-11-26T17:11:08.987418432Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 901, in main
2025-11-26T17:11:08.987855145Z     run(args)
2025-11-26T17:11:08.987858610Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 892, in run
2025-11-26T17:11:08.987861384Z     elastic_launch(
2025-11-26T17:11:08.987864059Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 143, in __call__
2025-11-26T17:11:08.987866832Z     return launch_agent(self._config, self._entrypoint, list(args))
2025-11-26T17:11:08.988492600Z            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:11:08.988526151Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 277, in launch_agent
2025-11-26T17:11:08.988529616Z     raise ChildFailedError(
2025-11-26T17:11:08.988532400Z torch.distributed.elastic.multiprocessing.errors.ChildFailedError:
2025-11-26T17:11:08.988534483Z ============================================================
2025-11-26T17:11:08.988537197Z examples/cloud_gsm8k/gsm8k_grpo_train.py FAILED
2025-11-26T17:11:08.988539511Z ------------------------------------------------------------
2025-11-26T17:11:08.988541543Z Failures:
2025-11-26T17:11:08.988544107Z   <NO_OTHER_FAILURES>
2025-11-26T17:11:08.988546771Z ------------------------------------------------------------
2025-11-26T17:11:08.988548834Z Root Cause (first observed failure):
2025-11-26T17:11:08.988550928Z [0]:
2025-11-26T17:11:08.988553131Z   time      : 2025-11-26_17:11:08
2025-11-26T17:11:08.988555194Z   host      : cef7c503fdea
2025-11-26T17:11:08.988557207Z   rank      : 0 (local_rank: 0)
2025-11-26T17:11:08.988559210Z   exitcode  : 1 (pid: 1032)
2025-11-26T17:11:08.988561183Z   error_file: <N/A>
2025-11-26T17:11:08.988563166Z   traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
2025-11-26T17:11:08.988565910Z ============================================================
2025-11-26T17:11:09.486454089Z [37m20251126-17:11:09.486 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [315][0m
2025-11-26T17:11:09.607081784Z Killed
2025-11-26T17:11:09.612781020Z [37m20251126-17:11:09.612 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [965][0m
2025-11-26T17:11:09.614147598Z Traceback (most recent call last):
2025-11-26T17:11:09.614154328Z   File "<frozen runpy>", line 198, in _run_module_as_main
2025-11-26T17:11:09.614157042Z   File "<frozen runpy>", line 88, in _run_code
2025-11-26T17:11:09.614159115Z   File "/workspace/AReaL/areal/launcher/local.py", line 405, in <module>
2025-11-26T17:11:09.614378523Z     main()
2025-11-26T17:11:09.614402720Z   File "/workspace/AReaL/areal/launcher/local.py", line 260, in main
2025-11-26T17:11:09.614463901Z     local_main(config, run_id=0)
2025-11-26T17:11:09.614467987Z   File "/workspace/AReaL/areal/launcher/local.py", line 399, in local_main
2025-11-26T17:11:09.614576399Z     raise e
2025-11-26T17:11:09.614579604Z   File "/workspace/AReaL/areal/launcher/local.py", line 375, in local_main
2025-11-26T17:11:09.614672694Z     launcher.wait(
2025-11-26T17:11:09.614675519Z   File "/workspace/AReaL/areal/launcher/local.py", line 235, in wait
2025-11-26T17:11:09.614724712Z     raise JobException(
2025-11-26T17:11:09.614727517Z areal.utils.launcher.JobException: Job gsm8k-grpo-cloud-2gpu-2000samples_trial_20251126_171024:trainer JobState.COMPLETED at node local
2025-11-26T17:11:09.826806992Z [37m20251126-17:11:09.826 Local Scheduler INFO: Waiting for 0 local running processes, pids: [0m
2025-11-26T17:11:12.178712952Z ==========
2025-11-26T17:11:12.178716548Z == CUDA ==
2025-11-26T17:11:12.178719382Z ==========
2025-11-26T17:11:12.182992724Z CUDA Version 12.9.1
2025-11-26T17:11:12.184605549Z Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
2025-11-26T17:11:12.186067889Z This container image and its contents are governed by the NVIDIA Deep Learning Container License.
2025-11-26T17:11:12.186071174Z By pulling and using the container, you accept the terms and conditions of this license:
2025-11-26T17:11:12.186074279Z https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license
2025-11-26T17:11:12.186079086Z A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
2025-11-26T17:11:12.355016663Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:11:12.512090888Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:11:12.696961310Z Branch 'feature/reasoning_model' set up to track remote branch 'feature/reasoning_model' from 'origin'.
2025-11-26T17:11:12.697008871Z Your branch is up to date with 'origin/feature/reasoning_model'.
2025-11-26T17:11:12.767102672Z Checking AReaL installation...
2025-11-26T17:11:12.824726345Z AReaL already installed. Skipping installation.
2025-11-26T17:11:12.824758353Z Cleaning up any leftover GPU processes...
2025-11-26T17:11:15.844004239Z Checking for processes holding GPU device files...
2025-11-26T17:11:17.749807286Z Found processes holding GPU devices: 1
2025-11-26T17:11:17.749877021Z 20
2025-11-26T17:11:17.749880105Z 71
2025-11-26T17:11:17.749882389Z 72
2025-11-26T17:11:17.749884502Z Killing process 1...
2025-11-26T17:11:17.749887196Z Killing process 71...
2025-11-26T17:11:17.749960055Z Killing process 72...
2025-11-26T17:11:19.752381614Z Using fuser to kill processes on GPU devices...
2025-11-26T17:11:21.775548777Z Checking GPU...
2025-11-26T17:11:21.809410318Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:11:21.809435004Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:11:21.825391705Z Set PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True for better memory management
2025-11-26T17:11:21.825411425Z Detected 2 GPU(s)
2025-11-26T17:11:21.825414640Z Checking GPU status...
2025-11-26T17:11:21.852898878Z index, name, utilization.gpu [%], memory.used [MiB], compute_mode
2025-11-26T17:11:21.854410372Z 0, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:11:21.854735609Z 1, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:11:21.897848196Z Verifying GPU accessibility...
2025-11-26T17:11:22.429168863Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:11:22.429225178Z   import pynvml  # type: ignore[import]
2025-11-26T17:11:23.528687185Z GPU accessibility verified on attempt 1
2025-11-26T17:11:24.003481171Z Starting training...
2025-11-26T17:11:27.006448775Z Using STANDARD 2000 SAMPLES 2 GPUs configuration
2025-11-26T17:11:27.006490458Z Note: GRPO only (no reasoning XML). Dataset capped at 2000 samples (~6 hours).
2025-11-26T17:11:27.006496477Z GPU count: 2 (required: 2)
2025-11-26T17:11:27.009257312Z ==========================================
2025-11-26T17:11:27.009260377Z Starting GRPO Training (Cloud)
2025-11-26T17:11:27.009262670Z ==========================================
2025-11-26T17:11:27.009264823Z Config: standard_2000samples_2GPUs
2025-11-26T17:11:27.009266987Z Config file: examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml
2025-11-26T17:11:27.009269110Z Training script: examples/cloud_gsm8k/gsm8k_grpo_train.py
2025-11-26T17:11:27.009271493Z Experiment: gsm8k-grpo-cloud-2gpu-2000samples
2025-11-26T17:11:27.009273496Z Trial: trial_20251126_171127
2025-11-26T17:11:27.009275469Z GPU: NVIDIA A100 80GB PCIe NVIDIA A100 80GB PCIe (81920 MB)
2025-11-26T17:11:27.009277552Z WandB API key: e1adc5be02...
2025-11-26T17:11:27.009279525Z ==========================================
2025-11-26T17:11:27.696999328Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:11:27.697037745Z   import pynvml  # type: ignore[import]
2025-11-26T17:11:31.658376030Z [37m20251126-17:11:31.657 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:11:31.658444431Z [37m20251126-17:11:31.658 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:11:31.658737310Z [37m20251126-17:11:31.658 name-resolve INFO: No such name resolve path: ./tmp/areal/name_resolve/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_171127[0m
2025-11-26T17:11:31.763706961Z [37m20251126-17:11:31.763 Local Scheduler INFO: LocalLauncher: experiment_name=gsm8k-grpo-cloud-2gpu-2000samples, trial_name=trial_20251126_171127, fileroot=/workspace/outputs/grpo, run_id=0, is_recover_run=False[0m
2025-11-26T17:11:31.771439824Z [37m20251126-17:11:31.771 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL CUDA_VISIBLE_DEVICES=0 stdbuf -oL python3 -m areal.launcher.sglang_server examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_171127 sglang.random_seed=1 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_171127/llm_server.log[0m
2025-11-26T17:11:32.501597101Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:11:32.501643151Z   import pynvml  # type: ignore[import]
2025-11-26T17:11:34.022477337Z [37m20251126-17:11:34.021 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:11:34.023193659Z [37m20251126-17:11:34.022 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:11:34.138412982Z [37m20251126-17:11:34.137 SGLangServer Wrapper INFO: Launch command: python3 -m sglang.launch_server --host 172.21.0.2 --port 13584 --tokenizer-path Qwen/Qwen2.5-0.5B-Instruct --tokenizer-mode auto --load-format auto --trust-remote-code --device cuda --tp-size 1 --base-gpu-id 0 --nnodes 1 --node-rank 0 --dist-init-addr localhost:29651 --model-path Qwen/Qwen2.5-0.5B-Instruct --random-seed 1 --skip-tokenizer-init --disable-radix-cache --torch-compile-max-bs 32 --triton-attention-num-kv-splits 8 --num-continuous-decode-steps 1 --attention-backend flashinfer --context-length 4096 --mem-fraction-static 0.6 --chunked-prefill-size -1 --max-prefill-tokens 32768 --schedule-policy lpm --schedule-conservativeness 1.0 --cpu-offload-gb 0 --dtype bfloat16 --kv-cache-dtype auto --dp-size 1 --ep-size 1 --max-loaded-loras 1 --max-loras-per-batch 1 --lora-backend triton --log-level warning --log-level-http warning --log-requests-level 0 --enable-metrics --decode-log-interval 1[0m
2025-11-26T17:11:35.172833405Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:11:35.172875940Z   import pynvml  # type: ignore[import]
2025-11-26T17:11:40.432288656Z INFO 11-26 17:11:40 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:11:41.054319134Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:11:42.068428183Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:11:42.068466771Z   import pynvml  # type: ignore[import]
2025-11-26T17:11:42.069967579Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:11:42.069977474Z   import pynvml  # type: ignore[import]
2025-11-26T17:11:47.532727652Z INFO 11-26 17:11:47 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:11:47.876608990Z INFO 11-26 17:11:47 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:11:48.109456604Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:11:48.332454206Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:11:48.336014288Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:11:48.336869549Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:11:48.337752471Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:11:48.370677849Z [2025-11-26 17:11:48] MOE_RUNNER_BACKEND is not initialized, using triton backend
2025-11-26T17:11:48.852230300Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:11:48.852268197Z   warnings.warn(
2025-11-26T17:11:48.852272212Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:11:48.852274616Z   warnings.warn(
2025-11-26T17:11:49.971373216Z Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
2025-11-26T17:11:50.076197789Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  9.56it/s]
2025-11-26T17:11:50.076775064Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  9.54it/s]
2025-11-26T17:11:52.525490852Z   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   4%|â–         | 1/23 [00:00<00:11,  1.84it/s]Capturing batches (bs=152 avail_mem=30.62 GB):   4%|â–         | 1/23 [00:00<00:11,  1.84it/s]Capturing batches (bs=144 avail_mem=30.60 GB):   4%|â–         | 1/23 [00:00<00:11,  1.84it/s]Capturing batches (bs=136 avail_mem=30.59 GB):   4%|â–         | 1/23 [00:00<00:11,  1.84it/s]Capturing batches (bs=136 avail_mem=30.59 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.27it/s]Capturing batches (bs=128 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.27it/s]Capturing batches (bs=120 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.27it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.27it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.60it/s]Capturing batches (bs=104 avail_mem=30.54 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.60it/s]Capturing batches (bs=96 avail_mem=30.53 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.60it/s] Capturing batches (bs=88 avail_mem=30.51 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.60it/s]Capturing batches (bs=88 avail_mem=30.51 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.94it/s]Capturing batches (bs=80 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.94it/s]Capturing batches (bs=72 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.94it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:01<00:00, 14.94it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.44it/s]Capturing batches (bs=56 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.44it/s]Capturing batches (bs=48 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.44it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.44it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.50it/s]Capturing batches (bs=32 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.50it/s]Capturing batches (bs=24 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.50it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.50it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.96it/s]Capturing batches (bs=8 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.96it/s] Capturing batches (bs=4 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.96it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.96it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.46it/s]Capturing batches (bs=1 avail_mem=30.35 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.46it/s]Capturing batches (bs=1 avail_mem=30.35 GB): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00, 14.95it/s]
2025-11-26T17:11:58.176179207Z [37m20251126-17:11:58.175 SGLangServer Wrapper INFO: SGLang server launched at: http://172.21.0.2:13584[0m
2025-11-26T17:11:58.778031961Z [37m20251126-17:11:58.777 Launcher Utils INFO: Found 1 rollout servers: 172.21.0.2:13584[0m
2025-11-26T17:11:58.778057279Z [37m20251126-17:11:58.777 Local Scheduler INFO: LLM inference server launched at: AREAL_LLM_SERVER_ADDRS=172.21.0.2:13584[0m
2025-11-26T17:11:58.781043482Z [37m20251126-17:11:58.780 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL AREAL_LLM_SERVER_ADDRS=172.21.0.2:13584 AREAL_RECOVER_RUN=0 NCCL_CUMEM_ENABLE=0 NCCL_NVLS_ENABLE=0 CUDA_VISIBLE_DEVICES=1 stdbuf -oL torchrun --nnodes 1 --nproc-per-node 1 --master-addr localhost --master-port 31339 examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_171127 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_171127/trainer.log[0m
2025-11-26T17:11:58.781774727Z [37m20251126-17:11:58.781 Local Scheduler INFO: Waiting for 2 local running processes, pids: 315 965[0m
2025-11-26T17:11:59.287252085Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:11:59.287289161Z   import pynvml  # type: ignore[import]
2025-11-26T17:12:00.461774171Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:12:00.461815443Z   import pynvml  # type: ignore[import]
2025-11-26T17:12:07.544318474Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:12:07.544367137Z   warnings.warn(
2025-11-26T17:12:07.544377072Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:12:07.544379676Z   warnings.warn(
2025-11-26T17:12:07.981742717Z Traceback (most recent call last):
2025-11-26T17:12:07.981785361Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 665, in <module>
2025-11-26T17:12:07.982458029Z     main(sys.argv[1:])
2025-11-26T17:12:07.982497078Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 102, in main
2025-11-26T17:12:07.982500413Z     config, _ = load_expr_config(args_with_overrides, GRPOConfig)
2025-11-26T17:12:07.982503307Z                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:12:07.982505340Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1282, in load_expr_config
2025-11-26T17:12:07.982507543Z     cfg = to_structured_cfg(cfg, config_cls=config_cls)
2025-11-26T17:12:07.982929314Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:12:07.982937657Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1276, in to_structured_cfg
2025-11-26T17:12:07.982940982Z     cfg = OmegaConf.merge(default_cfg, cfg)
2025-11-26T17:12:07.982943266Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:12:07.982945519Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/omegaconf.py", line 274, in merge
2025-11-26T17:12:07.982948303Z     target.merge_with(
2025-11-26T17:12:07.982950977Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 507, in merge_with
2025-11-26T17:12:07.983358648Z     self._format_and_raise(key=None, value=None, cause=e)
2025-11-26T17:12:07.983365719Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:12:07.983368763Z     format_and_raise(
2025-11-26T17:12:07.983371137Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:12:07.983373340Z     _raise(ex, cause)
2025-11-26T17:12:07.983375534Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:12:07.983378518Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:12:07.983890244Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:12:07.983894200Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 502, in merge_with
2025-11-26T17:12:07.983896514Z     self._merge_with(
2025-11-26T17:12:07.983899078Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:12:07.983901702Z     BaseContainer._map_merge(
2025-11-26T17:12:07.983904486Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:12:07.983906549Z     dest_node._merge_with(
2025-11-26T17:12:07.983908782Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:12:07.983910785Z     BaseContainer._map_merge(
2025-11-26T17:12:07.983912808Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:12:07.983914741Z     dest_node._merge_with(
2025-11-26T17:12:07.983916794Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:12:07.984429482Z     BaseContainer._map_merge(
2025-11-26T17:12:07.984435962Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 432, in _map_merge
2025-11-26T17:12:07.984438526Z     dest[key] = src._get_node(key)
2025-11-26T17:12:07.984441059Z     ~~~~^^^^^
2025-11-26T17:12:07.984443823Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 308, in __setitem__
2025-11-26T17:12:07.984453308Z     self._format_and_raise(
2025-11-26T17:12:07.984455481Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:12:07.984457524Z     format_and_raise(
2025-11-26T17:12:07.984459767Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:12:07.984461841Z     _raise(ex, cause)
2025-11-26T17:12:07.984463984Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:12:07.985105124Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:12:07.985109611Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:12:07.985148299Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 306, in __setitem__
2025-11-26T17:12:07.985150762Z     self.__set_impl(key=key, value=value)
2025-11-26T17:12:07.985152756Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 316, in __set_impl
2025-11-26T17:12:07.985154779Z     self._set_item_impl(key, value)
2025-11-26T17:12:07.985156731Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 579, in _set_item_impl
2025-11-26T17:12:07.985158795Z     target_node_ref = self._get_node(key)
2025-11-26T17:12:07.985161078Z                       ^^^^^^^^^^^^^^^^^^^
2025-11-26T17:12:07.985163151Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 473, in _get_node
2025-11-26T17:12:07.985165215Z     self._validate_get(key)
2025-11-26T17:12:07.985167568Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 163, in _validate_get
2025-11-26T17:12:07.985378503Z     self._format_and_raise(
2025-11-26T17:12:07.985382910Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:12:07.985385254Z     format_and_raise(
2025-11-26T17:12:07.985387367Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 906, in format_and_raise
2025-11-26T17:12:07.985389420Z     _raise(ex, cause)
2025-11-26T17:12:07.985391483Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:12:07.986264861Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:12:07.986273224Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:12:07.986275638Z omegaconf.errors.ConfigKeyError: Key 'max_new_tokens' not in 'NormConfig'
2025-11-26T17:12:07.986278402Z     full_key: actor.adv_norm.max_new_tokens
2025-11-26T17:12:07.986280525Z     reference_type=Optional[NormConfig]
2025-11-26T17:12:07.986282678Z     object_type=NormConfig
2025-11-26T17:12:10.779775065Z E1126 17:12:10.778000 966 torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 0 (pid: 1032) of binary: /usr/bin/python3
2025-11-26T17:12:10.780389575Z Traceback (most recent call last):
2025-11-26T17:12:10.780396225Z   File "/usr/local/bin/torchrun", line 7, in <module>
2025-11-26T17:12:10.780398969Z     sys.exit(main())
2025-11-26T17:12:10.780401653Z              ^^^^^^
2025-11-26T17:12:10.780403727Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
2025-11-26T17:12:10.780406311Z     return f(*args, **kwargs)
2025-11-26T17:12:10.780408884Z            ^^^^^^^^^^^^^^^^^^
2025-11-26T17:12:10.780410857Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 901, in main
2025-11-26T17:12:10.781314881Z     run(args)
2025-11-26T17:12:10.781319479Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 892, in run
2025-11-26T17:12:10.781322232Z     elastic_launch(
2025-11-26T17:12:10.781324856Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 143, in __call__
2025-11-26T17:12:10.781327480Z     return launch_agent(self._config, self._entrypoint, list(args))
2025-11-26T17:12:10.781330144Z            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:12:10.781346329Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 277, in launch_agent
2025-11-26T17:12:10.781348542Z     raise ChildFailedError(
2025-11-26T17:12:10.781351116Z torch.distributed.elastic.multiprocessing.errors.ChildFailedError:
2025-11-26T17:12:10.781353169Z ============================================================
2025-11-26T17:12:10.781355582Z examples/cloud_gsm8k/gsm8k_grpo_train.py FAILED
2025-11-26T17:12:10.781358056Z ------------------------------------------------------------
2025-11-26T17:12:10.781360289Z Failures:
2025-11-26T17:12:10.781363104Z   <NO_OTHER_FAILURES>
2025-11-26T17:12:10.781365077Z ------------------------------------------------------------
2025-11-26T17:12:10.781367090Z Root Cause (first observed failure):
2025-11-26T17:12:10.781369083Z [0]:
2025-11-26T17:12:10.781371206Z   time      : 2025-11-26_17:12:10
2025-11-26T17:12:10.781373259Z   host      : cef7c503fdea
2025-11-26T17:12:10.781375282Z   rank      : 0 (local_rank: 0)
2025-11-26T17:12:10.781377275Z   exitcode  : 1 (pid: 1032)
2025-11-26T17:12:10.781379278Z   error_file: <N/A>
2025-11-26T17:12:10.781381271Z   traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
2025-11-26T17:12:10.781383384Z ============================================================
2025-11-26T17:12:12.785963076Z [37m20251126-17:12:12.785 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [315][0m
2025-11-26T17:12:12.957917411Z Killed
2025-11-26T17:12:12.967092023Z [37m20251126-17:12:12.966 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [965][0m
2025-11-26T17:12:12.968143638Z Traceback (most recent call last):
2025-11-26T17:12:12.968154114Z   File "<frozen runpy>", line 198, in _run_module_as_main
2025-11-26T17:12:12.968156878Z   File "<frozen runpy>", line 88, in _run_code
2025-11-26T17:12:12.968159171Z   File "/workspace/AReaL/areal/launcher/local.py", line 405, in <module>
2025-11-26T17:12:12.968309918Z     main()
2025-11-26T17:12:12.968315656Z   File "/workspace/AReaL/areal/launcher/local.py", line 260, in main
2025-11-26T17:12:12.968397678Z     local_main(config, run_id=0)
2025-11-26T17:12:12.968401724Z   File "/workspace/AReaL/areal/launcher/local.py", line 399, in local_main
2025-11-26T17:12:12.968475175Z     raise e
2025-11-26T17:12:12.968477508Z   File "/workspace/AReaL/areal/launcher/local.py", line 375, in local_main
2025-11-26T17:12:12.968559722Z     launcher.wait(
2025-11-26T17:12:12.968562426Z   File "/workspace/AReaL/areal/launcher/local.py", line 235, in wait
2025-11-26T17:12:12.968622215Z     raise JobException(
2025-11-26T17:12:12.968626081Z areal.utils.launcher.JobException: Job gsm8k-grpo-cloud-2gpu-2000samples_trial_20251126_171127:trainer JobState.COMPLETED at node local
2025-11-26T17:12:13.168239786Z [37m20251126-17:12:13.167 Local Scheduler INFO: Waiting for 0 local running processes, pids: [0m
2025-11-26T17:12:15.180925208Z ==========
2025-11-26T17:12:15.180928894Z == CUDA ==
2025-11-26T17:12:15.180937627Z ==========
2025-11-26T17:12:15.185470107Z CUDA Version 12.9.1
2025-11-26T17:12:15.187203092Z Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
2025-11-26T17:12:15.189167154Z This container image and its contents are governed by the NVIDIA Deep Learning Container License.
2025-11-26T17:12:15.189170479Z By pulling and using the container, you accept the terms and conditions of this license:
2025-11-26T17:12:15.189173654Z https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license
2025-11-26T17:12:15.189178701Z A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
2025-11-26T17:12:15.354683806Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:12:15.512134435Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:12:15.698560146Z Branch 'feature/reasoning_model' set up to track remote branch 'feature/reasoning_model' from 'origin'.
2025-11-26T17:12:15.698590442Z Your branch is up to date with 'origin/feature/reasoning_model'.
2025-11-26T17:12:15.768643302Z Checking AReaL installation...
2025-11-26T17:12:15.827362045Z AReaL already installed. Skipping installation.
2025-11-26T17:12:15.827410046Z Cleaning up any leftover GPU processes...
2025-11-26T17:12:18.849537218Z Checking for processes holding GPU device files...
2025-11-26T17:12:20.754891373Z Found processes holding GPU devices: 1
2025-11-26T17:12:20.754921659Z 20
2025-11-26T17:12:20.754924583Z 71
2025-11-26T17:12:20.754927087Z 72
2025-11-26T17:12:20.754929180Z Killing process 1...
2025-11-26T17:12:20.754932284Z Killing process 71...
2025-11-26T17:12:20.754942210Z Killing process 72...
2025-11-26T17:12:22.757610709Z Using fuser to kill processes on GPU devices...
2025-11-26T17:12:24.779952076Z Checking GPU...
2025-11-26T17:12:24.814217951Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:12:24.814243990Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:12:24.831489201Z Set PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True for better memory management
2025-11-26T17:12:24.831511164Z Detected 2 GPU(s)
2025-11-26T17:12:24.831514619Z Checking GPU status...
2025-11-26T17:12:24.857971768Z index, name, utilization.gpu [%], memory.used [MiB], compute_mode
2025-11-26T17:12:24.859447028Z 0, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:12:24.859801449Z 1, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:12:24.904342285Z Verifying GPU accessibility...
2025-11-26T17:12:25.433010118Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:12:25.433067144Z   import pynvml  # type: ignore[import]
2025-11-26T17:12:26.534890298Z GPU accessibility verified on attempt 1
2025-11-26T17:12:26.987096271Z Starting training...
2025-11-26T17:12:29.989888131Z Using STANDARD 2000 SAMPLES 2 GPUs configuration
2025-11-26T17:12:29.989937776Z Note: GRPO only (no reasoning XML). Dataset capped at 2000 samples (~6 hours).
2025-11-26T17:12:29.989940951Z GPU count: 2 (required: 2)
2025-11-26T17:12:29.992559733Z ==========================================
2025-11-26T17:12:29.992563249Z Starting GRPO Training (Cloud)
2025-11-26T17:12:29.992565592Z ==========================================
2025-11-26T17:12:29.992567615Z Config: standard_2000samples_2GPUs
2025-11-26T17:12:29.992569688Z Config file: examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml
2025-11-26T17:12:29.992572383Z Training script: examples/cloud_gsm8k/gsm8k_grpo_train.py
2025-11-26T17:12:29.992574746Z Experiment: gsm8k-grpo-cloud-2gpu-2000samples
2025-11-26T17:12:29.992576769Z Trial: trial_20251126_171229
2025-11-26T17:12:29.992578832Z GPU: NVIDIA A100 80GB PCIe NVIDIA A100 80GB PCIe (81920 MB)
2025-11-26T17:12:29.992580885Z WandB API key: e1adc5be02...
2025-11-26T17:12:29.992582878Z ==========================================
2025-11-26T17:12:30.662837970Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:12:30.662882918Z   import pynvml  # type: ignore[import]
2025-11-26T17:12:34.572424457Z [37m20251126-17:12:34.571 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:12:34.572473541Z [37m20251126-17:12:34.572 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:12:34.572685899Z [37m20251126-17:12:34.572 name-resolve INFO: No such name resolve path: ./tmp/areal/name_resolve/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_171229[0m
2025-11-26T17:12:34.678380526Z [37m20251126-17:12:34.677 Local Scheduler INFO: LocalLauncher: experiment_name=gsm8k-grpo-cloud-2gpu-2000samples, trial_name=trial_20251126_171229, fileroot=/workspace/outputs/grpo, run_id=0, is_recover_run=False[0m
2025-11-26T17:12:34.685685197Z [37m20251126-17:12:34.685 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL CUDA_VISIBLE_DEVICES=0 stdbuf -oL python3 -m areal.launcher.sglang_server examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_171229 sglang.random_seed=1 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_171229/llm_server.log[0m
2025-11-26T17:12:35.389313078Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:12:35.389354340Z   import pynvml  # type: ignore[import]
2025-11-26T17:12:36.851463212Z [37m20251126-17:12:36.850 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:12:36.851505827Z [37m20251126-17:12:36.851 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:12:36.951501527Z [37m20251126-17:12:36.950 SGLangServer Wrapper INFO: Launch command: python3 -m sglang.launch_server --host 172.21.0.2 --port 11243 --tokenizer-path Qwen/Qwen2.5-0.5B-Instruct --tokenizer-mode auto --load-format auto --trust-remote-code --device cuda --tp-size 1 --base-gpu-id 0 --nnodes 1 --node-rank 0 --dist-init-addr localhost:26324 --model-path Qwen/Qwen2.5-0.5B-Instruct --random-seed 1 --skip-tokenizer-init --disable-radix-cache --torch-compile-max-bs 32 --triton-attention-num-kv-splits 8 --num-continuous-decode-steps 1 --attention-backend flashinfer --context-length 4096 --mem-fraction-static 0.6 --chunked-prefill-size -1 --max-prefill-tokens 32768 --schedule-policy lpm --schedule-conservativeness 1.0 --cpu-offload-gb 0 --dtype bfloat16 --kv-cache-dtype auto --dp-size 1 --ep-size 1 --max-loaded-loras 1 --max-loras-per-batch 1 --lora-backend triton --log-level warning --log-level-http warning --log-requests-level 0 --enable-metrics --decode-log-interval 1[0m
2025-11-26T17:12:37.983203438Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:12:37.983242777Z   import pynvml  # type: ignore[import]
2025-11-26T17:12:43.283211389Z INFO 11-26 17:12:43 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:12:44.001131136Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:12:45.059920302Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:12:45.059961403Z   import pynvml  # type: ignore[import]
2025-11-26T17:12:45.076420396Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:12:45.076439335Z   import pynvml  # type: ignore[import]
2025-11-26T17:12:50.596622170Z INFO 11-26 17:12:50 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:12:50.605809581Z INFO 11-26 17:12:50 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:12:51.210367528Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:12:51.431847505Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:12:51.435616892Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:12:51.436489639Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:12:51.437241855Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:12:51.471040972Z [2025-11-26 17:12:51] MOE_RUNNER_BACKEND is not initialized, using triton backend
2025-11-26T17:12:51.972316906Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:12:51.972356785Z   warnings.warn(
2025-11-26T17:12:51.972359760Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:12:51.972362073Z   warnings.warn(
2025-11-26T17:12:53.190319921Z Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
2025-11-26T17:12:53.309845144Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  8.38it/s]
2025-11-26T17:12:53.310390201Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  8.36it/s]
2025-11-26T17:12:55.863616601Z   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   4%|â–         | 1/23 [00:00<00:12,  1.77it/s]Capturing batches (bs=152 avail_mem=30.62 GB):   4%|â–         | 1/23 [00:00<00:12,  1.77it/s]Capturing batches (bs=144 avail_mem=30.60 GB):   4%|â–         | 1/23 [00:00<00:12,  1.77it/s]Capturing batches (bs=136 avail_mem=30.59 GB):   4%|â–         | 1/23 [00:00<00:12,  1.77it/s]Capturing batches (bs=136 avail_mem=30.59 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  6.93it/s]Capturing batches (bs=128 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  6.93it/s]Capturing batches (bs=120 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  6.93it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  6.93it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.05it/s]Capturing batches (bs=104 avail_mem=30.54 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.05it/s]Capturing batches (bs=96 avail_mem=30.53 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.05it/s] Capturing batches (bs=88 avail_mem=30.51 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.05it/s]Capturing batches (bs=88 avail_mem=30.51 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.26it/s]Capturing batches (bs=80 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.26it/s]Capturing batches (bs=72 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:01<00:00, 14.26it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:01<00:00, 14.26it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 16.65it/s]Capturing batches (bs=56 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 16.65it/s]Capturing batches (bs=48 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 16.65it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 16.65it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 18.61it/s]Capturing batches (bs=32 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 18.61it/s]Capturing batches (bs=24 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 18.61it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 18.61it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.13it/s]Capturing batches (bs=8 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.13it/s] Capturing batches (bs=4 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.13it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.13it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 18.65it/s]Capturing batches (bs=1 avail_mem=30.35 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 18.65it/s]Capturing batches (bs=1 avail_mem=30.35 GB): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00, 14.29it/s]
2025-11-26T17:13:01.980924490Z [37m20251126-17:13:01.980 SGLangServer Wrapper INFO: SGLang server launched at: http://172.21.0.2:11243[0m
2025-11-26T17:13:02.692308918Z [37m20251126-17:13:02.691 Launcher Utils INFO: Found 1 rollout servers: 172.21.0.2:11243[0m
2025-11-26T17:13:02.692348508Z [37m20251126-17:13:02.692 Local Scheduler INFO: LLM inference server launched at: AREAL_LLM_SERVER_ADDRS=172.21.0.2:11243[0m
2025-11-26T17:13:02.695014100Z [37m20251126-17:13:02.694 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL AREAL_LLM_SERVER_ADDRS=172.21.0.2:11243 AREAL_RECOVER_RUN=0 NCCL_CUMEM_ENABLE=0 NCCL_NVLS_ENABLE=0 CUDA_VISIBLE_DEVICES=1 stdbuf -oL torchrun --nnodes 1 --nproc-per-node 1 --master-addr localhost --master-port 46023 examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_171229 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_171229/trainer.log[0m
2025-11-26T17:13:02.695643503Z [37m20251126-17:13:02.695 Local Scheduler INFO: Waiting for 2 local running processes, pids: 315 965[0m
2025-11-26T17:13:03.261315874Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:13:03.261379349Z   import pynvml  # type: ignore[import]
2025-11-26T17:13:04.490225106Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:13:04.490270003Z   import pynvml  # type: ignore[import]
2025-11-26T17:13:11.608853217Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:13:11.608911605Z   warnings.warn(
2025-11-26T17:13:11.608915099Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:13:11.608927769Z   warnings.warn(
2025-11-26T17:13:12.049029703Z Traceback (most recent call last):
2025-11-26T17:13:12.049588069Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 665, in <module>
2025-11-26T17:13:12.049600067Z     main(sys.argv[1:])
2025-11-26T17:13:12.049603763Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 102, in main
2025-11-26T17:13:12.049606346Z     config, _ = load_expr_config(args_with_overrides, GRPOConfig)
2025-11-26T17:13:12.049611003Z                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:13:12.049614318Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1282, in load_expr_config
2025-11-26T17:13:12.050065954Z     cfg = to_structured_cfg(cfg, config_cls=config_cls)
2025-11-26T17:13:12.050069670Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:13:12.050072614Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1276, in to_structured_cfg
2025-11-26T17:13:12.050075879Z     cfg = OmegaConf.merge(default_cfg, cfg)
2025-11-26T17:13:12.050476079Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:13:12.050483190Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/omegaconf.py", line 274, in merge
2025-11-26T17:13:12.050486855Z     target.merge_with(
2025-11-26T17:13:12.050490220Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 507, in merge_with
2025-11-26T17:13:12.050493185Z     self._format_and_raise(key=None, value=None, cause=e)
2025-11-26T17:13:12.050495869Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:13:12.050498693Z     format_and_raise(
2025-11-26T17:13:12.050501387Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:13:12.051171371Z     _raise(ex, cause)
2025-11-26T17:13:12.051177060Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:13:12.051179994Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:13:12.051182958Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:13:12.051185733Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 502, in merge_with
2025-11-26T17:13:12.051188437Z     self._merge_with(
2025-11-26T17:13:12.051191261Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:13:12.051194095Z     BaseContainer._map_merge(
2025-11-26T17:13:12.051197811Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:13:12.051200735Z     dest_node._merge_with(
2025-11-26T17:13:12.051203549Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:13:12.051206073Z     BaseContainer._map_merge(
2025-11-26T17:13:12.051208106Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:13:12.051611069Z     dest_node._merge_with(
2025-11-26T17:13:12.051614163Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:13:12.051616767Z     BaseContainer._map_merge(
2025-11-26T17:13:12.051619351Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 432, in _map_merge
2025-11-26T17:13:12.051622266Z     dest[key] = src._get_node(key)
2025-11-26T17:13:12.051625030Z     ~~~~^^^^^
2025-11-26T17:13:12.051628475Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 308, in __setitem__
2025-11-26T17:13:12.051631099Z     self._format_and_raise(
2025-11-26T17:13:12.051633683Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:13:12.051643778Z     format_and_raise(
2025-11-26T17:13:12.051646402Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:13:12.052215424Z     _raise(ex, cause)
2025-11-26T17:13:12.052221593Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:13:12.052225129Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:13:12.052227903Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:13:12.052230507Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 306, in __setitem__
2025-11-26T17:13:12.052233041Z     self.__set_impl(key=key, value=value)
2025-11-26T17:13:12.052235805Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 316, in __set_impl
2025-11-26T17:13:12.052238870Z     self._set_item_impl(key, value)
2025-11-26T17:13:12.052241774Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 579, in _set_item_impl
2025-11-26T17:13:12.052523966Z     target_node_ref = self._get_node(key)
2025-11-26T17:13:12.052527101Z                       ^^^^^^^^^^^^^^^^^^^
2025-11-26T17:13:12.052529995Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 473, in _get_node
2025-11-26T17:13:12.052532980Z     self._validate_get(key)
2025-11-26T17:13:12.052535604Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 163, in _validate_get
2025-11-26T17:13:12.052538268Z     self._format_and_raise(
2025-11-26T17:13:12.052540942Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:13:12.052786620Z     format_and_raise(
2025-11-26T17:13:12.052789624Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 906, in format_and_raise
2025-11-26T17:13:12.052792879Z     _raise(ex, cause)
2025-11-26T17:13:12.052795824Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:13:12.053107811Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:13:12.053161982Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:13:12.053167040Z omegaconf.errors.ConfigKeyError: Key 'max_new_tokens' not in 'NormConfig'
2025-11-26T17:13:12.053169253Z     full_key: actor.adv_norm.max_new_tokens
2025-11-26T17:13:12.053171276Z     reference_type=Optional[NormConfig]
2025-11-26T17:13:12.053173370Z     object_type=NormConfig
2025-11-26T17:13:14.574145468Z E1126 17:13:14.573000 966 torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 0 (pid: 1032) of binary: /usr/bin/python3
2025-11-26T17:13:14.574857384Z Traceback (most recent call last):
2025-11-26T17:13:14.574865647Z   File "/usr/local/bin/torchrun", line 7, in <module>
2025-11-26T17:13:14.574868952Z     sys.exit(main())
2025-11-26T17:13:14.574872477Z              ^^^^^^
2025-11-26T17:13:14.574875282Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
2025-11-26T17:13:14.574880319Z     return f(*args, **kwargs)
2025-11-26T17:13:14.574884214Z            ^^^^^^^^^^^^^^^^^^
2025-11-26T17:13:14.574887178Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 901, in main
2025-11-26T17:13:14.575253427Z     run(args)
2025-11-26T17:13:14.575264974Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 892, in run
2025-11-26T17:13:14.575268219Z     elastic_launch(
2025-11-26T17:13:14.575270923Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 143, in __call__
2025-11-26T17:13:14.575275160Z     return launch_agent(self._config, self._entrypoint, list(args))
2025-11-26T17:13:14.575278785Z            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:13:14.575281790Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 277, in launch_agent
2025-11-26T17:13:14.575284594Z     raise ChildFailedError(
2025-11-26T17:13:14.575298945Z torch.distributed.elastic.multiprocessing.errors.ChildFailedError:
2025-11-26T17:13:14.575301309Z ============================================================
2025-11-26T17:13:14.575303482Z examples/cloud_gsm8k/gsm8k_grpo_train.py FAILED
2025-11-26T17:13:14.575305485Z ------------------------------------------------------------
2025-11-26T17:13:14.575307618Z Failures:
2025-11-26T17:13:14.575309612Z   <NO_OTHER_FAILURES>
2025-11-26T17:13:14.575311684Z ------------------------------------------------------------
2025-11-26T17:13:14.575313898Z Root Cause (first observed failure):
2025-11-26T17:13:14.575315881Z [0]:
2025-11-26T17:13:14.575318345Z   time      : 2025-11-26_17:13:14
2025-11-26T17:13:14.575320768Z   host      : cef7c503fdea
2025-11-26T17:13:14.575322781Z   rank      : 0 (local_rank: 0)
2025-11-26T17:13:14.575324744Z   exitcode  : 1 (pid: 1032)
2025-11-26T17:13:14.575326777Z   error_file: <N/A>
2025-11-26T17:13:14.575328770Z   traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
2025-11-26T17:13:14.575330853Z ============================================================
2025-11-26T17:13:16.699280836Z [37m20251126-17:13:16.698 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [315][0m
2025-11-26T17:13:16.869759931Z Killed
2025-11-26T17:13:16.879228283Z [37m20251126-17:13:16.878 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [965][0m
2025-11-26T17:13:16.880171386Z Traceback (most recent call last):
2025-11-26T17:13:16.880179808Z   File "<frozen runpy>", line 198, in _run_module_as_main
2025-11-26T17:13:16.880182442Z   File "<frozen runpy>", line 88, in _run_code
2025-11-26T17:13:16.880184535Z   File "/workspace/AReaL/areal/launcher/local.py", line 405, in <module>
2025-11-26T17:13:16.880308772Z     main()
2025-11-26T17:13:16.880312267Z   File "/workspace/AReaL/areal/launcher/local.py", line 260, in main
2025-11-26T17:13:16.880412767Z     local_main(config, run_id=0)
2025-11-26T17:13:16.880420769Z   File "/workspace/AReaL/areal/launcher/local.py", line 399, in local_main
2025-11-26T17:13:16.880502011Z     raise e
2025-11-26T17:13:16.880505646Z   File "/workspace/AReaL/areal/launcher/local.py", line 375, in local_main
2025-11-26T17:13:16.880570193Z     launcher.wait(
2025-11-26T17:13:16.880573128Z   File "/workspace/AReaL/areal/launcher/local.py", line 235, in wait
2025-11-26T17:13:16.880631575Z     raise JobException(
2025-11-26T17:13:16.880634510Z areal.utils.launcher.JobException: Job gsm8k-grpo-cloud-2gpu-2000samples_trial_20251126_171229:trainer JobState.COMPLETED at node local
2025-11-26T17:13:17.164626662Z [37m20251126-17:13:17.163 Local Scheduler INFO: Waiting for 0 local running processes, pids: [0m
2025-11-26T17:13:33.622431490Z ==========
2025-11-26T17:13:33.622473271Z == CUDA ==
2025-11-26T17:13:33.622503637Z ==========
2025-11-26T17:13:33.627022847Z CUDA Version 12.9.1
2025-11-26T17:13:33.628766688Z Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
2025-11-26T17:13:33.630571743Z This container image and its contents are governed by the NVIDIA Deep Learning Container License.
2025-11-26T17:13:33.630576470Z By pulling and using the container, you accept the terms and conditions of this license:
2025-11-26T17:13:33.630580175Z https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license
2025-11-26T17:13:33.630586084Z A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
2025-11-26T17:13:33.795854354Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:13:33.956364746Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:13:34.150979373Z Branch 'feature/reasoning_model' set up to track remote branch 'feature/reasoning_model' from 'origin'.
2025-11-26T17:13:34.151018962Z Your branch is up to date with 'origin/feature/reasoning_model'.
2025-11-26T17:13:34.224451644Z Checking AReaL installation...
2025-11-26T17:13:34.282594375Z AReaL already installed. Skipping installation.
2025-11-26T17:13:34.282640634Z Cleaning up any leftover GPU processes...
2025-11-26T17:13:37.303268701Z Checking for processes holding GPU device files...
2025-11-26T17:13:39.875225209Z Found processes holding GPU devices: 1
2025-11-26T17:13:39.875268604Z 21
2025-11-26T17:13:39.875271849Z 72
2025-11-26T17:13:39.875274062Z 73
2025-11-26T17:13:39.875276566Z Killing process 1...
2025-11-26T17:13:39.875279089Z Killing process 72...
2025-11-26T17:13:39.875344999Z Killing process 73...
2025-11-26T17:13:41.878230453Z Using fuser to kill processes on GPU devices...
2025-11-26T17:13:43.901752988Z Checking GPU...
2025-11-26T17:13:43.935892115Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:13:43.935932255Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:13:43.953093630Z Set PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True for better memory management
2025-11-26T17:13:43.953139890Z Detected 2 GPU(s)
2025-11-26T17:13:43.953145427Z Checking GPU status...
2025-11-26T17:13:43.981712096Z index, name, utilization.gpu [%], memory.used [MiB], compute_mode
2025-11-26T17:13:43.983068939Z 0, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:13:43.983408197Z 1, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:13:44.029040988Z Verifying GPU accessibility...
2025-11-26T17:13:44.584265901Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:13:44.584327604Z   import pynvml  # type: ignore[import]
2025-11-26T17:13:45.698160998Z GPU accessibility verified on attempt 1
2025-11-26T17:13:46.234565469Z Starting training...
2025-11-26T17:13:49.237569997Z Using STANDARD 2000 SAMPLES 2 GPUs configuration
2025-11-26T17:13:49.237615005Z Note: GRPO only (no reasoning XML). Dataset capped at 2000 samples (~6 hours).
2025-11-26T17:13:49.237618520Z GPU count: 2 (required: 2)
2025-11-26T17:13:49.240514828Z ==========================================
2025-11-26T17:13:49.240517502Z Starting GRPO Training (Cloud)
2025-11-26T17:13:49.240519676Z ==========================================
2025-11-26T17:13:49.240521869Z Config: standard_2000samples_2GPUs
2025-11-26T17:13:49.240523922Z Config file: examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml
2025-11-26T17:13:49.240526095Z Training script: examples/cloud_gsm8k/gsm8k_grpo_train.py
2025-11-26T17:13:49.240529240Z Experiment: gsm8k-grpo-cloud-2gpu-2000samples
2025-11-26T17:13:49.240532034Z Trial: trial_20251126_171349
2025-11-26T17:13:49.240534828Z GPU: NVIDIA A100 80GB PCIe NVIDIA A100 80GB PCIe (81920 MB)
2025-11-26T17:13:49.240537793Z WandB API key: e1adc5be02...
2025-11-26T17:13:49.240540757Z ==========================================
2025-11-26T17:13:49.944535166Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:13:49.944575077Z   import pynvml  # type: ignore[import]
2025-11-26T17:13:54.095623500Z [37m20251126-17:13:54.095 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:13:54.095664883Z [37m20251126-17:13:54.095 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:13:54.095898983Z [37m20251126-17:13:54.095 name-resolve INFO: No such name resolve path: ./tmp/areal/name_resolve/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_171349[0m
2025-11-26T17:13:54.200760903Z [37m20251126-17:13:54.200 Local Scheduler INFO: LocalLauncher: experiment_name=gsm8k-grpo-cloud-2gpu-2000samples, trial_name=trial_20251126_171349, fileroot=/workspace/outputs/grpo, run_id=0, is_recover_run=False[0m
2025-11-26T17:13:54.208183731Z [37m20251126-17:13:54.207 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL CUDA_VISIBLE_DEVICES=0 stdbuf -oL python3 -m areal.launcher.sglang_server examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_171349 sglang.random_seed=1 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_171349/llm_server.log[0m
2025-11-26T17:13:54.961097185Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:13:54.961149954Z   import pynvml  # type: ignore[import]
2025-11-26T17:13:56.470310033Z [37m20251126-17:13:56.469 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:13:56.470751685Z [37m20251126-17:13:56.470 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:13:56.588636590Z [37m20251126-17:13:56.587 SGLangServer Wrapper INFO: Launch command: python3 -m sglang.launch_server --host 172.21.0.2 --port 10978 --tokenizer-path Qwen/Qwen2.5-0.5B-Instruct --tokenizer-mode auto --load-format auto --trust-remote-code --device cuda --tp-size 1 --base-gpu-id 0 --nnodes 1 --node-rank 0 --dist-init-addr localhost:16255 --model-path Qwen/Qwen2.5-0.5B-Instruct --random-seed 1 --skip-tokenizer-init --disable-radix-cache --torch-compile-max-bs 32 --triton-attention-num-kv-splits 8 --num-continuous-decode-steps 1 --attention-backend flashinfer --context-length 4096 --mem-fraction-static 0.6 --chunked-prefill-size -1 --max-prefill-tokens 32768 --schedule-policy lpm --schedule-conservativeness 1.0 --cpu-offload-gb 0 --dtype bfloat16 --kv-cache-dtype auto --dp-size 1 --ep-size 1 --max-loaded-loras 1 --max-loras-per-batch 1 --lora-backend triton --log-level warning --log-level-http warning --log-requests-level 0 --enable-metrics --decode-log-interval 1[0m
2025-11-26T17:13:57.629077162Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:13:57.629131502Z   import pynvml  # type: ignore[import]
2025-11-26T17:14:03.469078251Z INFO 11-26 17:14:03 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:14:04.162580073Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:14:05.272360927Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:14:05.272402780Z   import pynvml  # type: ignore[import]
2025-11-26T17:14:05.285327689Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:14:05.285343543Z   import pynvml  # type: ignore[import]
2025-11-26T17:14:11.095316084Z INFO 11-26 17:14:11 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:14:11.398064270Z INFO 11-26 17:14:11 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:14:11.994075024Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:14:12.219320963Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:14:12.223170097Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:14:12.224018949Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:14:12.224923254Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:14:12.260178471Z [2025-11-26 17:14:12] MOE_RUNNER_BACKEND is not initialized, using triton backend
2025-11-26T17:14:12.784317862Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:14:12.784367046Z   warnings.warn(
2025-11-26T17:14:12.784370371Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:14:12.784372945Z   warnings.warn(
2025-11-26T17:14:13.948662725Z Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
2025-11-26T17:14:14.066929012Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  8.47it/s]
2025-11-26T17:14:14.067426627Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  8.46it/s]
2025-11-26T17:14:16.623536408Z   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   4%|â–         | 1/23 [00:00<00:12,  1.77it/s]Capturing batches (bs=152 avail_mem=30.62 GB):   4%|â–         | 1/23 [00:00<00:12,  1.77it/s]Capturing batches (bs=144 avail_mem=30.60 GB):   4%|â–         | 1/23 [00:00<00:12,  1.77it/s]Capturing batches (bs=136 avail_mem=30.59 GB):   4%|â–         | 1/23 [00:00<00:12,  1.77it/s]Capturing batches (bs=136 avail_mem=30.59 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  6.98it/s]Capturing batches (bs=128 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  6.98it/s]Capturing batches (bs=120 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  6.98it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  6.98it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.13it/s]Capturing batches (bs=104 avail_mem=30.54 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.13it/s]Capturing batches (bs=96 avail_mem=30.53 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.13it/s] Capturing batches (bs=88 avail_mem=30.51 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.13it/s]Capturing batches (bs=88 avail_mem=30.51 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.40it/s]Capturing batches (bs=80 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.40it/s]Capturing batches (bs=72 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:01<00:00, 14.40it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:01<00:00, 14.40it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 16.88it/s]Capturing batches (bs=56 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 16.88it/s]Capturing batches (bs=48 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 16.88it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 16.88it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 18.87it/s]Capturing batches (bs=32 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 18.87it/s]Capturing batches (bs=24 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 18.87it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 18.87it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.32it/s]Capturing batches (bs=8 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.32it/s] Capturing batches (bs=4 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.32it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.32it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.10it/s]Capturing batches (bs=1 avail_mem=30.35 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.10it/s]Capturing batches (bs=1 avail_mem=30.35 GB): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00, 14.50it/s]
2025-11-26T17:14:22.627172720Z [37m20251126-17:14:22.626 SGLangServer Wrapper INFO: SGLang server launched at: http://172.21.0.2:10978[0m
2025-11-26T17:14:23.215978352Z [37m20251126-17:14:23.215 Launcher Utils INFO: Found 1 rollout servers: 172.21.0.2:10978[0m
2025-11-26T17:14:23.216017201Z [37m20251126-17:14:23.215 Local Scheduler INFO: LLM inference server launched at: AREAL_LLM_SERVER_ADDRS=172.21.0.2:10978[0m
2025-11-26T17:14:23.218334792Z [37m20251126-17:14:23.218 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL AREAL_LLM_SERVER_ADDRS=172.21.0.2:10978 AREAL_RECOVER_RUN=0 NCCL_CUMEM_ENABLE=0 NCCL_NVLS_ENABLE=0 CUDA_VISIBLE_DEVICES=1 stdbuf -oL torchrun --nnodes 1 --nproc-per-node 1 --master-addr localhost --master-port 14612 examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_171349 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_171349/trainer.log[0m
2025-11-26T17:14:23.218960389Z [37m20251126-17:14:23.218 Local Scheduler INFO: Waiting for 2 local running processes, pids: 316 966[0m
2025-11-26T17:14:23.740940465Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:14:23.740982689Z   import pynvml  # type: ignore[import]
2025-11-26T17:14:24.917242588Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:14:24.917300775Z   import pynvml  # type: ignore[import]
2025-11-26T17:14:32.119677171Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:14:32.119735648Z   warnings.warn(
2025-11-26T17:14:32.119738873Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:14:32.119751532Z   warnings.warn(
2025-11-26T17:14:32.669637758Z Traceback (most recent call last):
2025-11-26T17:14:32.669678168Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 665, in <module>
2025-11-26T17:14:32.670374221Z     main(sys.argv[1:])
2025-11-26T17:14:32.670384397Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 102, in main
2025-11-26T17:14:32.670387742Z     config, _ = load_expr_config(args_with_overrides, GRPOConfig)
2025-11-26T17:14:32.670390466Z                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:14:32.670392719Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1282, in load_expr_config
2025-11-26T17:14:32.671261571Z     cfg = to_structured_cfg(cfg, config_cls=config_cls)
2025-11-26T17:14:32.671266928Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:14:32.671268971Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1276, in to_structured_cfg
2025-11-26T17:14:32.671271635Z     cfg = OmegaConf.merge(default_cfg, cfg)
2025-11-26T17:14:32.671273779Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:14:32.671275802Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/omegaconf.py", line 274, in merge
2025-11-26T17:14:32.671277955Z     target.merge_with(
2025-11-26T17:14:32.671280949Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 507, in merge_with
2025-11-26T17:14:32.671767718Z     self._format_and_raise(key=None, value=None, cause=e)
2025-11-26T17:14:32.671770923Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:14:32.671773627Z     format_and_raise(
2025-11-26T17:14:32.671775801Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:14:32.671778114Z     _raise(ex, cause)
2025-11-26T17:14:32.671780107Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:14:32.671782240Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:14:32.672202280Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:14:32.672206856Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 502, in merge_with
2025-11-26T17:14:32.672209070Z     self._merge_with(
2025-11-26T17:14:32.672211664Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:14:32.672214058Z     BaseContainer._map_merge(
2025-11-26T17:14:32.672216591Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:14:32.672798082Z     dest_node._merge_with(
2025-11-26T17:14:32.672801047Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:14:32.672803060Z     BaseContainer._map_merge(
2025-11-26T17:14:32.672805073Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:14:32.672807255Z     dest_node._merge_with(
2025-11-26T17:14:32.672809258Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:14:32.672811361Z     BaseContainer._map_merge(
2025-11-26T17:14:32.672813364Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 432, in _map_merge
2025-11-26T17:14:32.672815658Z     dest[key] = src._get_node(key)
2025-11-26T17:14:32.672818832Z     ~~~~^^^^^
2025-11-26T17:14:32.672821767Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 308, in __setitem__
2025-11-26T17:14:32.673443639Z     self._format_and_raise(
2025-11-26T17:14:32.673486212Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:14:32.673489648Z     format_and_raise(
2025-11-26T17:14:32.673502647Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:14:32.673505211Z     _raise(ex, cause)
2025-11-26T17:14:32.673507284Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:14:32.673509918Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:14:32.673774224Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:14:32.673780684Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 306, in __setitem__
2025-11-26T17:14:32.673783328Z     self.__set_impl(key=key, value=value)
2025-11-26T17:14:32.673785581Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 316, in __set_impl
2025-11-26T17:14:32.673788144Z     self._set_item_impl(key, value)
2025-11-26T17:14:32.673790147Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 579, in _set_item_impl
2025-11-26T17:14:32.674146932Z     target_node_ref = self._get_node(key)
2025-11-26T17:14:32.674155775Z                       ^^^^^^^^^^^^^^^^^^^
2025-11-26T17:14:32.674158310Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 473, in _get_node
2025-11-26T17:14:32.674160543Z     self._validate_get(key)
2025-11-26T17:14:32.674579469Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 163, in _validate_get
2025-11-26T17:14:32.674583686Z     self._format_and_raise(
2025-11-26T17:14:32.674586800Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:14:32.674589024Z     format_and_raise(
2025-11-26T17:14:32.674592008Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 906, in format_and_raise
2025-11-26T17:14:32.674594182Z     _raise(ex, cause)
2025-11-26T17:14:32.674596715Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:14:32.674970616Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:14:32.674975623Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:14:32.674977637Z omegaconf.errors.ConfigKeyError: Key 'max_new_tokens' not in 'NormConfig'
2025-11-26T17:14:32.674979780Z     full_key: actor.adv_norm.max_new_tokens
2025-11-26T17:14:32.674981752Z     reference_type=Optional[NormConfig]
2025-11-26T17:14:32.674983916Z     object_type=NormConfig
2025-11-26T17:14:36.033622397Z E1126 17:14:36.032000 967 torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 0 (pid: 1033) of binary: /usr/bin/python3
2025-11-26T17:14:36.034214564Z Traceback (most recent call last):
2025-11-26T17:14:36.034220703Z   File "/usr/local/bin/torchrun", line 7, in <module>
2025-11-26T17:14:36.034223727Z     sys.exit(main())
2025-11-26T17:14:36.034226281Z              ^^^^^^
2025-11-26T17:14:36.034228365Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
2025-11-26T17:14:36.034231429Z     return f(*args, **kwargs)
2025-11-26T17:14:36.034233993Z            ^^^^^^^^^^^^^^^^^^
2025-11-26T17:14:36.034236046Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 901, in main
2025-11-26T17:14:36.034795915Z     run(args)
2025-11-26T17:14:36.034798909Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 892, in run
2025-11-26T17:14:36.034801483Z     elastic_launch(
2025-11-26T17:14:36.034804187Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 143, in __call__
2025-11-26T17:14:36.034806781Z     return launch_agent(self._config, self._entrypoint, list(args))
2025-11-26T17:14:36.034809395Z            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:14:36.034811678Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 277, in launch_agent
2025-11-26T17:14:36.034813731Z     raise ChildFailedError(
2025-11-26T17:14:36.034816135Z torch.distributed.elastic.multiprocessing.errors.ChildFailedError:
2025-11-26T17:14:36.034818118Z ============================================================
2025-11-26T17:14:36.034828343Z examples/cloud_gsm8k/gsm8k_grpo_train.py FAILED
2025-11-26T17:14:36.034830967Z ------------------------------------------------------------
2025-11-26T17:14:36.034832990Z Failures:
2025-11-26T17:14:36.034834983Z   <NO_OTHER_FAILURES>
2025-11-26T17:14:36.034836976Z ------------------------------------------------------------
2025-11-26T17:14:36.034838999Z Root Cause (first observed failure):
2025-11-26T17:14:36.034840982Z [0]:
2025-11-26T17:14:36.034843085Z   time      : 2025-11-26_17:14:36
2025-11-26T17:14:36.034845138Z   host      : cef7c503fdea
2025-11-26T17:14:36.034847132Z   rank      : 0 (local_rank: 0)
2025-11-26T17:14:36.034849104Z   exitcode  : 1 (pid: 1033)
2025-11-26T17:14:36.034851107Z   error_file: <N/A>
2025-11-26T17:14:36.034853121Z   traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
2025-11-26T17:14:36.034855173Z ============================================================
2025-11-26T17:14:37.222870511Z [37m20251126-17:14:37.222 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [316][0m
2025-11-26T17:14:37.378289298Z Killed
2025-11-26T17:14:37.407982153Z [37m20251126-17:14:37.407 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [966][0m
2025-11-26T17:14:37.409063223Z Traceback (most recent call last):
2025-11-26T17:14:37.409091345Z   File "<frozen runpy>", line 198, in _run_module_as_main
2025-11-26T17:14:37.409095320Z   File "<frozen runpy>", line 88, in _run_code
2025-11-26T17:14:37.409098245Z   File "/workspace/AReaL/areal/launcher/local.py", line 405, in <module>
2025-11-26T17:14:37.409222301Z     main()
2025-11-26T17:14:37.409231936Z   File "/workspace/AReaL/areal/launcher/local.py", line 260, in main
2025-11-26T17:14:37.409352766Z     local_main(config, run_id=0)
2025-11-26T17:14:37.409361179Z   File "/workspace/AReaL/areal/launcher/local.py", line 399, in local_main
2025-11-26T17:14:37.409454729Z     raise e
2025-11-26T17:14:37.409457313Z   File "/workspace/AReaL/areal/launcher/local.py", line 375, in local_main
2025-11-26T17:14:37.409541589Z     launcher.wait(
2025-11-26T17:14:37.409544514Z   File "/workspace/AReaL/areal/launcher/local.py", line 235, in wait
2025-11-26T17:14:37.409625905Z     raise JobException(
2025-11-26T17:14:37.409629400Z areal.utils.launcher.JobException: Job gsm8k-grpo-cloud-2gpu-2000samples_trial_20251126_171349:trainer JobState.COMPLETED at node local
2025-11-26T17:14:37.682001367Z [37m20251126-17:14:37.681 Local Scheduler INFO: Waiting for 0 local running processes, pids: [0m
2025-11-26T17:14:51.930334272Z ==========
2025-11-26T17:14:51.930337216Z == CUDA ==
2025-11-26T17:14:51.930368813Z ==========
2025-11-26T17:14:51.935078668Z CUDA Version 12.9.1
2025-11-26T17:14:51.936787958Z Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
2025-11-26T17:14:51.938485372Z This container image and its contents are governed by the NVIDIA Deep Learning Container License.
2025-11-26T17:14:51.938488686Z By pulling and using the container, you accept the terms and conditions of this license:
2025-11-26T17:14:51.938491280Z https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license
2025-11-26T17:14:51.938496117Z A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
2025-11-26T17:14:52.141220731Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:14:52.307041719Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:14:52.495713654Z Branch 'feature/reasoning_model' set up to track remote branch 'feature/reasoning_model' from 'origin'.
2025-11-26T17:14:52.495751522Z Your branch is up to date with 'origin/feature/reasoning_model'.
2025-11-26T17:14:52.568312518Z Checking AReaL installation...
2025-11-26T17:14:52.627998369Z AReaL already installed. Skipping installation.
2025-11-26T17:14:52.628038569Z Cleaning up any leftover GPU processes...
2025-11-26T17:14:55.648632114Z Checking for processes holding GPU device files...
2025-11-26T17:14:58.177011678Z Found processes holding GPU devices: 1
2025-11-26T17:14:58.177059390Z 20
2025-11-26T17:14:58.177062915Z 71
2025-11-26T17:14:58.177065158Z 72
2025-11-26T17:14:58.177067352Z Killing process 1...
2025-11-26T17:14:58.177070056Z Killing process 71...
2025-11-26T17:14:58.177247150Z Killing process 72...
2025-11-26T17:15:00.180063701Z Using fuser to kill processes on GPU devices...
2025-11-26T17:15:02.208013729Z Checking GPU...
2025-11-26T17:15:02.242776159Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:15:02.242800375Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:15:02.260172256Z Set PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True for better memory management
2025-11-26T17:15:02.260191975Z Detected 2 GPU(s)
2025-11-26T17:15:02.260195500Z Checking GPU status...
2025-11-26T17:15:02.287487900Z index, name, utilization.gpu [%], memory.used [MiB], compute_mode
2025-11-26T17:15:02.288880727Z 0, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:15:02.289165264Z 1, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:15:02.330457834Z Verifying GPU accessibility...
2025-11-26T17:15:02.884922798Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:15:02.884981846Z   import pynvml  # type: ignore[import]
2025-11-26T17:15:03.998686777Z GPU accessibility verified on attempt 1
2025-11-26T17:15:04.510400917Z Starting training...
2025-11-26T17:15:07.513200589Z Using STANDARD 2000 SAMPLES 2 GPUs configuration
2025-11-26T17:15:07.513238305Z Note: GRPO only (no reasoning XML). Dataset capped at 2000 samples (~6 hours).
2025-11-26T17:15:07.513241339Z GPU count: 2 (required: 2)
2025-11-26T17:15:07.515795536Z ==========================================
2025-11-26T17:15:07.515798360Z Starting GRPO Training (Cloud)
2025-11-26T17:15:07.515800573Z ==========================================
2025-11-26T17:15:07.515802676Z Config: standard_2000samples_2GPUs
2025-11-26T17:15:07.515804739Z Config file: examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml
2025-11-26T17:15:07.515807073Z Training script: examples/cloud_gsm8k/gsm8k_grpo_train.py
2025-11-26T17:15:07.515809607Z Experiment: gsm8k-grpo-cloud-2gpu-2000samples
2025-11-26T17:15:07.515811630Z Trial: trial_20251126_171507
2025-11-26T17:15:07.515813623Z GPU: NVIDIA A100 80GB PCIe NVIDIA A100 80GB PCIe (81920 MB)
2025-11-26T17:15:07.515815636Z WandB API key: e1adc5be02...
2025-11-26T17:15:07.515817719Z ==========================================
2025-11-26T17:15:08.221903230Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:15:08.221966946Z   import pynvml  # type: ignore[import]
2025-11-26T17:15:12.382578875Z [37m20251126-17:15:12.382 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:15:12.382617523Z [37m20251126-17:15:12.382 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:15:12.382889080Z [37m20251126-17:15:12.382 name-resolve INFO: No such name resolve path: ./tmp/areal/name_resolve/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_171507[0m
2025-11-26T17:15:12.487106593Z [37m20251126-17:15:12.486 Local Scheduler INFO: LocalLauncher: experiment_name=gsm8k-grpo-cloud-2gpu-2000samples, trial_name=trial_20251126_171507, fileroot=/workspace/outputs/grpo, run_id=0, is_recover_run=False[0m
2025-11-26T17:15:12.494648490Z [37m20251126-17:15:12.494 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL CUDA_VISIBLE_DEVICES=0 stdbuf -oL python3 -m areal.launcher.sglang_server examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_171507 sglang.random_seed=1 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_171507/llm_server.log[0m
2025-11-26T17:15:13.194803388Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:15:13.194849787Z   import pynvml  # type: ignore[import]
2025-11-26T17:15:14.665591201Z [37m20251126-17:15:14.665 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:15:14.666446112Z [37m20251126-17:15:14.665 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:15:14.776246439Z [37m20251126-17:15:14.775 SGLangServer Wrapper INFO: Launch command: python3 -m sglang.launch_server --host 172.21.0.2 --port 19904 --tokenizer-path Qwen/Qwen2.5-0.5B-Instruct --tokenizer-mode auto --load-format auto --trust-remote-code --device cuda --tp-size 1 --base-gpu-id 0 --nnodes 1 --node-rank 0 --dist-init-addr localhost:20706 --model-path Qwen/Qwen2.5-0.5B-Instruct --random-seed 1 --skip-tokenizer-init --disable-radix-cache --torch-compile-max-bs 32 --triton-attention-num-kv-splits 8 --num-continuous-decode-steps 1 --attention-backend flashinfer --context-length 4096 --mem-fraction-static 0.6 --chunked-prefill-size -1 --max-prefill-tokens 32768 --schedule-policy lpm --schedule-conservativeness 1.0 --cpu-offload-gb 0 --dtype bfloat16 --kv-cache-dtype auto --dp-size 1 --ep-size 1 --max-loaded-loras 1 --max-loras-per-batch 1 --lora-backend triton --log-level warning --log-level-http warning --log-requests-level 0 --enable-metrics --decode-log-interval 1[0m
2025-11-26T17:15:15.813785213Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:15:15.813833064Z   import pynvml  # type: ignore[import]
2025-11-26T17:15:22.952398569Z INFO 11-26 17:15:22 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:15:23.804688986Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:15:25.112212732Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:15:25.112259632Z   import pynvml  # type: ignore[import]
2025-11-26T17:15:25.129409630Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:15:25.129427477Z   import pynvml  # type: ignore[import]
2025-11-26T17:15:30.249306960Z INFO 11-26 17:15:30 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:15:32.465411238Z INFO 11-26 17:15:32 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:15:33.252687923Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:15:33.520698738Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:15:33.525283485Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:15:33.526288470Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:15:33.527286705Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:15:33.578620926Z [2025-11-26 17:15:33] MOE_RUNNER_BACKEND is not initialized, using triton backend
2025-11-26T17:15:34.261932796Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:15:34.261990033Z   warnings.warn(
2025-11-26T17:15:34.261993137Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:15:34.261995330Z   warnings.warn(
2025-11-26T17:15:35.707080655Z Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
2025-11-26T17:15:35.833338022Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  7.93it/s]
2025-11-26T17:15:35.833962857Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  7.91it/s]
2025-11-26T17:15:38.596571856Z   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   4%|â–         | 1/23 [00:00<00:13,  1.65it/s]Capturing batches (bs=152 avail_mem=30.62 GB):   4%|â–         | 1/23 [00:00<00:13,  1.65it/s]Capturing batches (bs=144 avail_mem=30.60 GB):   4%|â–         | 1/23 [00:00<00:13,  1.65it/s]Capturing batches (bs=136 avail_mem=30.59 GB):   4%|â–         | 1/23 [00:00<00:13,  1.65it/s]Capturing batches (bs=136 avail_mem=30.59 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  6.62it/s]Capturing batches (bs=128 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  6.62it/s]Capturing batches (bs=120 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  6.62it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  6.62it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 10.76it/s]Capturing batches (bs=104 avail_mem=30.54 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 10.76it/s]Capturing batches (bs=96 avail_mem=30.53 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 10.76it/s] Capturing batches (bs=88 avail_mem=30.51 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 10.76it/s]Capturing batches (bs=88 avail_mem=30.51 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.10it/s]Capturing batches (bs=80 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.10it/s]Capturing batches (bs=72 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:01<00:00, 14.10it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:01<00:00, 14.10it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 16.71it/s]Capturing batches (bs=56 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 16.71it/s]Capturing batches (bs=48 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 16.71it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 16.71it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 18.87it/s]Capturing batches (bs=32 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 18.87it/s]Capturing batches (bs=24 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 18.87it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 18.87it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.44it/s]Capturing batches (bs=8 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.44it/s] Capturing batches (bs=4 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.44it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.44it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.26it/s]Capturing batches (bs=1 avail_mem=30.35 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.26it/s]Capturing batches (bs=1 avail_mem=30.35 GB): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00, 14.28it/s]
2025-11-26T17:15:43.804944610Z [37m20251126-17:15:43.804 SGLangServer Wrapper INFO: SGLang server launched at: http://172.21.0.2:19904[0m
2025-11-26T17:15:44.503309828Z [37m20251126-17:15:44.502 Launcher Utils INFO: Found 1 rollout servers: 172.21.0.2:19904[0m
2025-11-26T17:15:44.503355086Z [37m20251126-17:15:44.503 Local Scheduler INFO: LLM inference server launched at: AREAL_LLM_SERVER_ADDRS=172.21.0.2:19904[0m
2025-11-26T17:15:44.507235988Z [37m20251126-17:15:44.506 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL AREAL_LLM_SERVER_ADDRS=172.21.0.2:19904 AREAL_RECOVER_RUN=0 NCCL_CUMEM_ENABLE=0 NCCL_NVLS_ENABLE=0 CUDA_VISIBLE_DEVICES=1 stdbuf -oL torchrun --nnodes 1 --nproc-per-node 1 --master-addr localhost --master-port 48709 examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_171507 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_171507/trainer.log[0m
2025-11-26T17:15:44.507899102Z [37m20251126-17:15:44.507 Local Scheduler INFO: Waiting for 2 local running processes, pids: 315 965[0m
2025-11-26T17:15:45.005051349Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:15:45.005095686Z   import pynvml  # type: ignore[import]
2025-11-26T17:15:46.184214308Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:15:46.184253727Z   import pynvml  # type: ignore[import]
2025-11-26T17:15:52.812569115Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:15:52.812610647Z   warnings.warn(
2025-11-26T17:15:52.812613952Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:15:52.812622896Z   warnings.warn(
2025-11-26T17:15:53.265972182Z Traceback (most recent call last):
2025-11-26T17:15:53.266012593Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 665, in <module>
2025-11-26T17:15:53.266763888Z     main(sys.argv[1:])
2025-11-26T17:15:53.266775035Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 102, in main
2025-11-26T17:15:53.266778661Z     config, _ = load_expr_config(args_with_overrides, GRPOConfig)
2025-11-26T17:15:53.266781305Z                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:15:53.266783378Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1282, in load_expr_config
2025-11-26T17:15:53.266785581Z     cfg = to_structured_cfg(cfg, config_cls=config_cls)
2025-11-26T17:15:53.267206050Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:15:53.267211188Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1276, in to_structured_cfg
2025-11-26T17:15:53.267213822Z     cfg = OmegaConf.merge(default_cfg, cfg)
2025-11-26T17:15:53.267216096Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:15:53.267218199Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/omegaconf.py", line 274, in merge
2025-11-26T17:15:53.267675694Z     target.merge_with(
2025-11-26T17:15:53.267678188Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 507, in merge_with
2025-11-26T17:15:53.267680692Z     self._format_and_raise(key=None, value=None, cause=e)
2025-11-26T17:15:53.267682745Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:15:53.267685139Z     format_and_raise(
2025-11-26T17:15:53.267687232Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:15:53.267689285Z     _raise(ex, cause)
2025-11-26T17:15:53.267691618Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:15:53.268182684Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:15:53.268195613Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:15:53.268199128Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 502, in merge_with
2025-11-26T17:15:53.268201392Z     self._merge_with(
2025-11-26T17:15:53.268203705Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:15:53.268206008Z     BaseContainer._map_merge(
2025-11-26T17:15:53.268208933Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:15:53.268210986Z     dest_node._merge_with(
2025-11-26T17:15:53.268671756Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:15:53.268674530Z     BaseContainer._map_merge(
2025-11-26T17:15:53.268676613Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:15:53.268678616Z     dest_node._merge_with(
2025-11-26T17:15:53.268680669Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:15:53.268682662Z     BaseContainer._map_merge(
2025-11-26T17:15:53.268684635Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 432, in _map_merge
2025-11-26T17:15:53.268686839Z     dest[key] = src._get_node(key)
2025-11-26T17:15:53.268688962Z     ~~~~^^^^^
2025-11-26T17:15:53.268691486Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 308, in __setitem__
2025-11-26T17:15:53.269313377Z     self._format_and_raise(
2025-11-26T17:15:53.269318074Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:15:53.269334218Z     format_and_raise(
2025-11-26T17:15:53.269336352Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:15:53.269338475Z     _raise(ex, cause)
2025-11-26T17:15:53.269348680Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:15:53.269350803Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:15:53.269352846Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:15:53.269354989Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 306, in __setitem__
2025-11-26T17:15:53.269636662Z     self.__set_impl(key=key, value=value)
2025-11-26T17:15:53.269639346Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 316, in __set_impl
2025-11-26T17:15:53.269641489Z     self._set_item_impl(key, value)
2025-11-26T17:15:53.269643461Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 579, in _set_item_impl
2025-11-26T17:15:53.269645524Z     target_node_ref = self._get_node(key)
2025-11-26T17:15:53.270048127Z                       ^^^^^^^^^^^^^^^^^^^
2025-11-26T17:15:53.270050501Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 473, in _get_node
2025-11-26T17:15:53.270052614Z     self._validate_get(key)
2025-11-26T17:15:53.270055288Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 163, in _validate_get
2025-11-26T17:15:53.270058012Z     self._format_and_raise(
2025-11-26T17:15:53.270059985Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:15:53.270061948Z     format_and_raise(
2025-11-26T17:15:53.270064471Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 906, in format_and_raise
2025-11-26T17:15:53.270436008Z     _raise(ex, cause)
2025-11-26T17:15:53.270440835Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:15:53.270443399Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:15:53.270445513Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:15:53.271176108Z omegaconf.errors.ConfigKeyError: Key 'max_new_tokens' not in 'NormConfig'
2025-11-26T17:15:53.271180764Z     full_key: actor.adv_norm.max_new_tokens
2025-11-26T17:15:53.271182898Z     reference_type=Optional[NormConfig]
2025-11-26T17:15:53.271184951Z     object_type=NormConfig
2025-11-26T17:15:57.294777103Z E1126 17:15:57.293000 966 torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 0 (pid: 1032) of binary: /usr/bin/python3
2025-11-26T17:15:57.295376180Z Traceback (most recent call last):
2025-11-26T17:15:57.295382089Z   File "/usr/local/bin/torchrun", line 7, in <module>
2025-11-26T17:15:57.295385013Z     sys.exit(main())
2025-11-26T17:15:57.295387777Z              ^^^^^^
2025-11-26T17:15:57.295389850Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
2025-11-26T17:15:57.295392545Z     return f(*args, **kwargs)
2025-11-26T17:15:57.295394998Z            ^^^^^^^^^^^^^^^^^^
2025-11-26T17:15:57.295396991Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 901, in main
2025-11-26T17:15:57.296320154Z     run(args)
2025-11-26T17:15:57.296324951Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 892, in run
2025-11-26T17:15:57.296327735Z     elastic_launch(
2025-11-26T17:15:57.296330269Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 143, in __call__
2025-11-26T17:15:57.296332793Z     return launch_agent(self._config, self._entrypoint, list(args))
2025-11-26T17:15:57.296335157Z            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:15:57.296337180Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 277, in launch_agent
2025-11-26T17:15:57.296351021Z     raise ChildFailedError(
2025-11-26T17:15:57.296353734Z torch.distributed.elastic.multiprocessing.errors.ChildFailedError:
2025-11-26T17:15:57.296355757Z ============================================================
2025-11-26T17:15:57.296358301Z examples/cloud_gsm8k/gsm8k_grpo_train.py FAILED
2025-11-26T17:15:57.296374776Z ------------------------------------------------------------
2025-11-26T17:15:57.296377129Z Failures:
2025-11-26T17:15:57.296379183Z   <NO_OTHER_FAILURES>
2025-11-26T17:15:57.296381216Z ------------------------------------------------------------
2025-11-26T17:15:57.296383209Z Root Cause (first observed failure):
2025-11-26T17:15:57.296385422Z [0]:
2025-11-26T17:15:57.296387485Z   time      : 2025-11-26_17:15:57
2025-11-26T17:15:57.296389558Z   host      : cef7c503fdea
2025-11-26T17:15:57.296391580Z   rank      : 0 (local_rank: 0)
2025-11-26T17:15:57.296393553Z   exitcode  : 1 (pid: 1032)
2025-11-26T17:15:57.296395596Z   error_file: <N/A>
2025-11-26T17:15:57.296397609Z   traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
2025-11-26T17:15:57.296399682Z ============================================================
2025-11-26T17:15:58.512030355Z [37m20251126-17:15:58.511 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [315][0m
2025-11-26T17:15:58.672785876Z Killed
2025-11-26T17:15:58.677695249Z [37m20251126-17:15:58.677 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [965][0m
2025-11-26T17:15:58.678903219Z Traceback (most recent call last):
2025-11-26T17:15:58.678908997Z   File "<frozen runpy>", line 198, in _run_module_as_main
2025-11-26T17:15:58.678911661Z   File "<frozen runpy>", line 88, in _run_code
2025-11-26T17:15:58.678913754Z   File "/workspace/AReaL/areal/launcher/local.py", line 405, in <module>
2025-11-26T17:15:58.679155016Z     main()
2025-11-26T17:15:58.679192692Z   File "/workspace/AReaL/areal/launcher/local.py", line 260, in main
2025-11-26T17:15:58.679231079Z     local_main(config, run_id=0)
2025-11-26T17:15:58.679250529Z   File "/workspace/AReaL/areal/launcher/local.py", line 399, in local_main
2025-11-26T17:15:58.679357418Z     raise e
2025-11-26T17:15:58.679361715Z   File "/workspace/AReaL/areal/launcher/local.py", line 375, in local_main
2025-11-26T17:15:58.679442206Z     launcher.wait(
2025-11-26T17:15:58.679445310Z   File "/workspace/AReaL/areal/launcher/local.py", line 235, in wait
2025-11-26T17:15:58.679506923Z     raise JobException(
2025-11-26T17:15:58.679509727Z areal.utils.launcher.JobException: Job gsm8k-grpo-cloud-2gpu-2000samples_trial_20251126_171507:trainer JobState.COMPLETED at node local
2025-11-26T17:15:58.960661785Z [37m20251126-17:15:58.959 Local Scheduler INFO: Waiting for 0 local running processes, pids: [0m
2025-11-26T17:16:10.375706733Z ==========
2025-11-26T17:16:10.375710339Z == CUDA ==
2025-11-26T17:16:10.375783247Z ==========
2025-11-26T17:16:10.380611460Z CUDA Version 12.9.1
2025-11-26T17:16:10.382447980Z Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
2025-11-26T17:16:10.383993095Z This container image and its contents are governed by the NVIDIA Deep Learning Container License.
2025-11-26T17:16:10.383996861Z By pulling and using the container, you accept the terms and conditions of this license:
2025-11-26T17:16:10.384000235Z https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license
2025-11-26T17:16:10.384006735Z A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
2025-11-26T17:16:10.549575805Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:16:10.707001388Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:16:10.958934000Z Branch 'feature/reasoning_model' set up to track remote branch 'feature/reasoning_model' from 'origin'.
2025-11-26T17:16:10.958965377Z Your branch is up to date with 'origin/feature/reasoning_model'.
2025-11-26T17:16:11.031644890Z Checking AReaL installation...
2025-11-26T17:16:11.091747366Z AReaL already installed. Skipping installation.
2025-11-26T17:16:11.091772103Z Cleaning up any leftover GPU processes...
2025-11-26T17:16:14.112044136Z Checking for processes holding GPU device files...
2025-11-26T17:16:16.157281929Z Found processes holding GPU devices: 1
2025-11-26T17:16:16.157328899Z 20
2025-11-26T17:16:16.157332685Z 71
2025-11-26T17:16:16.157335249Z 72
2025-11-26T17:16:16.157337352Z Killing process 1...
2025-11-26T17:16:16.157348147Z Killing process 71...
2025-11-26T17:16:16.157481357Z Killing process 72...
2025-11-26T17:16:18.160244538Z Using fuser to kill processes on GPU devices...
2025-11-26T17:16:20.184222476Z Checking GPU...
2025-11-26T17:16:20.222101233Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:16:20.222166121Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:16:20.240791479Z Set PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True for better memory management
2025-11-26T17:16:20.240831809Z Detected 2 GPU(s)
2025-11-26T17:16:20.240834944Z Checking GPU status...
2025-11-26T17:16:20.268778550Z index, name, utilization.gpu [%], memory.used [MiB], compute_mode
2025-11-26T17:16:20.270246529Z 0, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:16:20.270549933Z 1, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:16:20.320654272Z Verifying GPU accessibility...
2025-11-26T17:16:20.853859793Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:16:20.853955226Z   import pynvml  # type: ignore[import]
2025-11-26T17:16:21.939669500Z GPU accessibility verified on attempt 1
2025-11-26T17:16:22.406524517Z Starting training...
2025-11-26T17:16:25.409284329Z Using STANDARD 2000 SAMPLES 2 GPUs configuration
2025-11-26T17:16:25.409320283Z Note: GRPO only (no reasoning XML). Dataset capped at 2000 samples (~6 hours).
2025-11-26T17:16:25.409323027Z GPU count: 2 (required: 2)
2025-11-26T17:16:25.412419114Z ==========================================
2025-11-26T17:16:25.412422589Z Starting GRPO Training (Cloud)
2025-11-26T17:16:25.412425904Z ==========================================
2025-11-26T17:16:25.412428167Z Config: standard_2000samples_2GPUs
2025-11-26T17:16:25.412430230Z Config file: examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml
2025-11-26T17:16:25.412432965Z Training script: examples/cloud_gsm8k/gsm8k_grpo_train.py
2025-11-26T17:16:25.412436039Z Experiment: gsm8k-grpo-cloud-2gpu-2000samples
2025-11-26T17:16:25.412438142Z Trial: trial_20251126_171625
2025-11-26T17:16:25.412440196Z GPU: NVIDIA A100 80GB PCIe NVIDIA A100 80GB PCIe (81920 MB)
2025-11-26T17:16:25.412442228Z WandB API key: e1adc5be02...
2025-11-26T17:16:25.412444291Z ==========================================
2025-11-26T17:16:26.089941742Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:16:26.089989344Z   import pynvml  # type: ignore[import]
2025-11-26T17:16:30.023109261Z [37m20251126-17:16:30.022 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:16:30.023200777Z [37m20251126-17:16:30.022 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:16:30.023429020Z [37m20251126-17:16:30.023 name-resolve INFO: No such name resolve path: ./tmp/areal/name_resolve/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_171625[0m
2025-11-26T17:16:30.128253382Z [37m20251126-17:16:30.127 Local Scheduler INFO: LocalLauncher: experiment_name=gsm8k-grpo-cloud-2gpu-2000samples, trial_name=trial_20251126_171625, fileroot=/workspace/outputs/grpo, run_id=0, is_recover_run=False[0m
2025-11-26T17:16:30.135358825Z [37m20251126-17:16:30.135 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL CUDA_VISIBLE_DEVICES=0 stdbuf -oL python3 -m areal.launcher.sglang_server examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_171625 sglang.random_seed=1 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_171625/llm_server.log[0m
2025-11-26T17:16:30.847903441Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:16:30.847938794Z   import pynvml  # type: ignore[import]
2025-11-26T17:16:32.329242650Z [37m20251126-17:16:32.328 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:16:32.329827145Z [37m20251126-17:16:32.328 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:16:32.436498665Z [37m20251126-17:16:32.435 SGLangServer Wrapper INFO: Launch command: python3 -m sglang.launch_server --host 172.21.0.2 --port 16124 --tokenizer-path Qwen/Qwen2.5-0.5B-Instruct --tokenizer-mode auto --load-format auto --trust-remote-code --device cuda --tp-size 1 --base-gpu-id 0 --nnodes 1 --node-rank 0 --dist-init-addr localhost:16262 --model-path Qwen/Qwen2.5-0.5B-Instruct --random-seed 1 --skip-tokenizer-init --disable-radix-cache --torch-compile-max-bs 32 --triton-attention-num-kv-splits 8 --num-continuous-decode-steps 1 --attention-backend flashinfer --context-length 4096 --mem-fraction-static 0.6 --chunked-prefill-size -1 --max-prefill-tokens 32768 --schedule-policy lpm --schedule-conservativeness 1.0 --cpu-offload-gb 0 --dtype bfloat16 --kv-cache-dtype auto --dp-size 1 --ep-size 1 --max-loaded-loras 1 --max-loras-per-batch 1 --lora-backend triton --log-level warning --log-level-http warning --log-requests-level 0 --enable-metrics --decode-log-interval 1[0m
2025-11-26T17:16:33.541465247Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:16:33.541516594Z   import pynvml  # type: ignore[import]
2025-11-26T17:16:39.262497596Z INFO 11-26 17:16:39 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:16:39.960348614Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:16:41.258240352Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:16:41.258284779Z   import pynvml  # type: ignore[import]
2025-11-26T17:16:41.270691913Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:16:41.270707346Z   import pynvml  # type: ignore[import]
2025-11-26T17:16:46.412097269Z INFO 11-26 17:16:46 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:16:46.982757342Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:16:47.190745089Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:16:47.194200055Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:16:47.194956468Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:16:47.195856917Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:16:47.228136377Z [2025-11-26 17:16:47] MOE_RUNNER_BACKEND is not initialized, using triton backend
2025-11-26T17:16:47.705248858Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:16:47.705298602Z   warnings.warn(
2025-11-26T17:16:47.705301687Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:16:47.705304371Z   warnings.warn(
2025-11-26T17:16:48.428839429Z INFO 11-26 17:16:48 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:16:48.803858337Z Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
2025-11-26T17:16:48.911752919Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  9.28it/s]
2025-11-26T17:16:48.912327910Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  9.26it/s]
2025-11-26T17:16:51.336284864Z   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   4%|â–         | 1/23 [00:00<00:11,  1.85it/s]Capturing batches (bs=152 avail_mem=30.62 GB):   4%|â–         | 1/23 [00:00<00:11,  1.85it/s]Capturing batches (bs=144 avail_mem=30.60 GB):   4%|â–         | 1/23 [00:00<00:11,  1.85it/s]Capturing batches (bs=136 avail_mem=30.59 GB):   4%|â–         | 1/23 [00:00<00:11,  1.85it/s]Capturing batches (bs=136 avail_mem=30.59 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.30it/s]Capturing batches (bs=128 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.30it/s]Capturing batches (bs=120 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.30it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.30it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.62it/s]Capturing batches (bs=104 avail_mem=30.54 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.62it/s]Capturing batches (bs=96 avail_mem=30.53 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.62it/s] Capturing batches (bs=88 avail_mem=30.51 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.62it/s]Capturing batches (bs=88 avail_mem=30.51 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 15.00it/s]Capturing batches (bs=80 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 15.00it/s]Capturing batches (bs=72 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 15.00it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:01<00:00, 15.00it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.57it/s]Capturing batches (bs=56 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.57it/s]Capturing batches (bs=48 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.57it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.57it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.63it/s]Capturing batches (bs=32 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.63it/s]Capturing batches (bs=24 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.63it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.63it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 18.06it/s]Capturing batches (bs=8 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 18.06it/s] Capturing batches (bs=4 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 18.06it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 18.06it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.89it/s]Capturing batches (bs=1 avail_mem=30.35 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.89it/s]Capturing batches (bs=1 avail_mem=30.35 GB): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00, 15.12it/s]
2025-11-26T17:16:57.464203194Z [37m20251126-17:16:57.463 SGLangServer Wrapper INFO: SGLang server launched at: http://172.21.0.2:16124[0m
2025-11-26T17:16:58.142338610Z [37m20251126-17:16:58.141 Launcher Utils INFO: Found 1 rollout servers: 172.21.0.2:16124[0m
2025-11-26T17:16:58.142378980Z [37m20251126-17:16:58.142 Local Scheduler INFO: LLM inference server launched at: AREAL_LLM_SERVER_ADDRS=172.21.0.2:16124[0m
2025-11-26T17:16:58.145326696Z [37m20251126-17:16:58.145 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL AREAL_LLM_SERVER_ADDRS=172.21.0.2:16124 AREAL_RECOVER_RUN=0 NCCL_CUMEM_ENABLE=0 NCCL_NVLS_ENABLE=0 CUDA_VISIBLE_DEVICES=1 stdbuf -oL torchrun --nnodes 1 --nproc-per-node 1 --master-addr localhost --master-port 14193 examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_171625 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_171625/trainer.log[0m
2025-11-26T17:16:58.146026153Z [37m20251126-17:16:58.145 Local Scheduler INFO: Waiting for 2 local running processes, pids: 315 965[0m
2025-11-26T17:16:58.724923294Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:16:58.724961752Z   import pynvml  # type: ignore[import]
2025-11-26T17:16:59.969926051Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:16:59.969964028Z   import pynvml  # type: ignore[import]
2025-11-26T17:17:08.492444112Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:17:08.492494336Z   warnings.warn(
2025-11-26T17:17:08.492498683Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:17:08.492501758Z   warnings.warn(
2025-11-26T17:17:09.048469373Z Traceback (most recent call last):
2025-11-26T17:17:09.048509103Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 665, in <module>
2025-11-26T17:17:09.049203342Z     main(sys.argv[1:])
2025-11-26T17:17:09.049238235Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 102, in main
2025-11-26T17:17:09.049241600Z     config, _ = load_expr_config(args_with_overrides, GRPOConfig)
2025-11-26T17:17:09.049244304Z                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:17:09.049246337Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1282, in load_expr_config
2025-11-26T17:17:09.049639476Z     cfg = to_structured_cfg(cfg, config_cls=config_cls)
2025-11-26T17:17:09.049647057Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:17:09.049649551Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1276, in to_structured_cfg
2025-11-26T17:17:09.050048299Z     cfg = OmegaConf.merge(default_cfg, cfg)
2025-11-26T17:17:09.050051714Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:17:09.050053797Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/omegaconf.py", line 274, in merge
2025-11-26T17:17:09.050056952Z     target.merge_with(
2025-11-26T17:17:09.050059606Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 507, in merge_with
2025-11-26T17:17:09.050417190Z     self._format_and_raise(key=None, value=None, cause=e)
2025-11-26T17:17:09.050423720Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:17:09.050426084Z     format_and_raise(
2025-11-26T17:17:09.050428618Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:17:09.050430781Z     _raise(ex, cause)
2025-11-26T17:17:09.051229707Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:17:09.051233713Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:17:09.051235836Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:17:09.051238090Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 502, in merge_with
2025-11-26T17:17:09.051240293Z     self._merge_with(
2025-11-26T17:17:09.051242286Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:17:09.051244340Z     BaseContainer._map_merge(
2025-11-26T17:17:09.051247173Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:17:09.051249217Z     dest_node._merge_with(
2025-11-26T17:17:09.051251300Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:17:09.051606803Z     BaseContainer._map_merge(
2025-11-26T17:17:09.051613402Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:17:09.051616827Z     dest_node._merge_with(
2025-11-26T17:17:09.051619071Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:17:09.051626492Z     BaseContainer._map_merge(
2025-11-26T17:17:09.051628635Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 432, in _map_merge
2025-11-26T17:17:09.051630739Z     dest[key] = src._get_node(key)
2025-11-26T17:17:09.052150777Z     ~~~~^^^^^
2025-11-26T17:17:09.052156846Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 308, in __setitem__
2025-11-26T17:17:09.052159851Z     self._format_and_raise(
2025-11-26T17:17:09.052162074Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:17:09.052164218Z     format_and_raise(
2025-11-26T17:17:09.052166221Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:17:09.052168273Z     _raise(ex, cause)
2025-11-26T17:17:09.052170287Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:17:09.052172339Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:17:09.052468593Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:17:09.052477106Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 306, in __setitem__
2025-11-26T17:17:09.052480261Z     self.__set_impl(key=key, value=value)
2025-11-26T17:17:09.052482404Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 316, in __set_impl
2025-11-26T17:17:09.052784046Z     self._set_item_impl(key, value)
2025-11-26T17:17:09.052788813Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 579, in _set_item_impl
2025-11-26T17:17:09.052791046Z     target_node_ref = self._get_node(key)
2025-11-26T17:17:09.053166219Z                       ^^^^^^^^^^^^^^^^^^^
2025-11-26T17:17:09.053171957Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 473, in _get_node
2025-11-26T17:17:09.053174481Z     self._validate_get(key)
2025-11-26T17:17:09.053176995Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 163, in _validate_get
2025-11-26T17:17:09.053179078Z     self._format_and_raise(
2025-11-26T17:17:09.053181121Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:17:09.053183174Z     format_and_raise(
2025-11-26T17:17:09.053185417Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 906, in format_and_raise
2025-11-26T17:17:09.053453589Z     _raise(ex, cause)
2025-11-26T17:17:09.053459839Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:17:09.053747810Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:17:09.053752757Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:17:09.053755691Z omegaconf.errors.ConfigKeyError: Key 'max_new_tokens' not in 'NormConfig'
2025-11-26T17:17:09.053759297Z     full_key: actor.adv_norm.max_new_tokens
2025-11-26T17:17:09.053761911Z     reference_type=Optional[NormConfig]
2025-11-26T17:17:09.053764785Z     object_type=NormConfig
2025-11-26T17:17:11.428707511Z E1126 17:17:11.427000 966 torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 0 (pid: 1032) of binary: /usr/bin/python3
2025-11-26T17:17:11.429414941Z Traceback (most recent call last):
2025-11-26T17:17:11.429423173Z   File "/usr/local/bin/torchrun", line 7, in <module>
2025-11-26T17:17:11.429426919Z     sys.exit(main())
2025-11-26T17:17:11.429429492Z              ^^^^^^
2025-11-26T17:17:11.429431726Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
2025-11-26T17:17:11.429437174Z     return f(*args, **kwargs)
2025-11-26T17:17:11.429439578Z            ^^^^^^^^^^^^^^^^^^
2025-11-26T17:17:11.429441581Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 901, in main
2025-11-26T17:17:11.429813178Z     run(args)
2025-11-26T17:17:11.429817444Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 892, in run
2025-11-26T17:17:11.429820949Z     elastic_launch(
2025-11-26T17:17:11.429823994Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 143, in __call__
2025-11-26T17:17:11.429826598Z     return launch_agent(self._config, self._entrypoint, list(args))
2025-11-26T17:17:11.429829282Z            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:17:11.429831245Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 277, in launch_agent
2025-11-26T17:17:11.429833558Z     raise ChildFailedError(
2025-11-26T17:17:11.429835992Z torch.distributed.elastic.multiprocessing.errors.ChildFailedError:
2025-11-26T17:17:11.429837975Z ============================================================
2025-11-26T17:17:11.429840268Z examples/cloud_gsm8k/gsm8k_grpo_train.py FAILED
2025-11-26T17:17:11.429842822Z ------------------------------------------------------------
2025-11-26T17:17:11.429844805Z Failures:
2025-11-26T17:17:11.429846808Z   <NO_OTHER_FAILURES>
2025-11-26T17:17:11.429872496Z ------------------------------------------------------------
2025-11-26T17:17:11.429875080Z Root Cause (first observed failure):
2025-11-26T17:17:11.429877143Z [0]:
2025-11-26T17:17:11.429879266Z   time      : 2025-11-26_17:17:11
2025-11-26T17:17:11.429881801Z   host      : cef7c503fdea
2025-11-26T17:17:11.429884935Z   rank      : 0 (local_rank: 0)
2025-11-26T17:17:11.429887649Z   exitcode  : 1 (pid: 1032)
2025-11-26T17:17:11.429890463Z   error_file: <N/A>
2025-11-26T17:17:11.429893368Z   traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
2025-11-26T17:17:11.429896312Z ============================================================
2025-11-26T17:17:12.149605540Z [37m20251126-17:17:12.149 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [315][0m
2025-11-26T17:17:12.327224309Z Killed
2025-11-26T17:17:12.336879130Z [37m20251126-17:17:12.336 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [965][0m
2025-11-26T17:17:12.337924367Z Traceback (most recent call last):
2025-11-26T17:17:12.337939329Z   File "<frozen runpy>", line 198, in _run_module_as_main
2025-11-26T17:17:12.337942414Z   File "<frozen runpy>", line 88, in _run_code
2025-11-26T17:17:12.337944957Z   File "/workspace/AReaL/areal/launcher/local.py", line 405, in <module>
2025-11-26T17:17:12.338106388Z     main()
2025-11-26T17:17:12.338111837Z   File "/workspace/AReaL/areal/launcher/local.py", line 260, in main
2025-11-26T17:17:12.338216554Z     local_main(config, run_id=0)
2025-11-26T17:17:12.338220740Z   File "/workspace/AReaL/areal/launcher/local.py", line 399, in local_main
2025-11-26T17:17:12.338318447Z     raise e
2025-11-26T17:17:12.338320821Z   File "/workspace/AReaL/areal/launcher/local.py", line 375, in local_main
2025-11-26T17:17:12.338377615Z     launcher.wait(
2025-11-26T17:17:12.338380670Z   File "/workspace/AReaL/areal/launcher/local.py", line 235, in wait
2025-11-26T17:17:12.338448601Z     raise JobException(
2025-11-26T17:17:12.338451776Z areal.utils.launcher.JobException: Job gsm8k-grpo-cloud-2gpu-2000samples_trial_20251126_171625:trainer JobState.COMPLETED at node local
2025-11-26T17:17:12.543330777Z [37m20251126-17:17:12.542 Local Scheduler INFO: Waiting for 0 local running processes, pids: [0m
2025-11-26T17:17:28.706161373Z ==========
2025-11-26T17:17:28.706169635Z == CUDA ==
2025-11-26T17:17:28.706250146Z ==========
2025-11-26T17:17:28.711160702Z CUDA Version 12.9.1
2025-11-26T17:17:28.712776892Z Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
2025-11-26T17:17:28.714290870Z This container image and its contents are governed by the NVIDIA Deep Learning Container License.
2025-11-26T17:17:28.714293194Z By pulling and using the container, you accept the terms and conditions of this license:
2025-11-26T17:17:28.714295978Z https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license
2025-11-26T17:17:28.714300094Z A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
2025-11-26T17:17:28.878625411Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:17:29.040214630Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:17:29.224407867Z Branch 'feature/reasoning_model' set up to track remote branch 'feature/reasoning_model' from 'origin'.
2025-11-26T17:17:29.224435408Z Your branch is up to date with 'origin/feature/reasoning_model'.
2025-11-26T17:17:29.297922513Z Checking AReaL installation...
2025-11-26T17:17:29.365684250Z AReaL already installed. Skipping installation.
2025-11-26T17:17:29.365721476Z Cleaning up any leftover GPU processes...
2025-11-26T17:17:32.385508823Z Checking for processes holding GPU device files...
2025-11-26T17:17:35.008244970Z Found processes holding GPU devices: 1
2025-11-26T17:17:35.008286973Z 20
2025-11-26T17:17:35.008289527Z 71
2025-11-26T17:17:35.008292091Z 72
2025-11-26T17:17:35.008294264Z Killing process 1...
2025-11-26T17:17:35.008297539Z Killing process 71...
2025-11-26T17:17:35.008497037Z Killing process 72...
2025-11-26T17:17:37.011602131Z Using fuser to kill processes on GPU devices...
2025-11-26T17:17:39.035250065Z Checking GPU...
2025-11-26T17:17:39.071703347Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:17:39.071729566Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:17:39.086563515Z Set PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True for better memory management
2025-11-26T17:17:39.086581202Z Detected 2 GPU(s)
2025-11-26T17:17:39.086584246Z Checking GPU status...
2025-11-26T17:17:39.114361473Z index, name, utilization.gpu [%], memory.used [MiB], compute_mode
2025-11-26T17:17:39.115769642Z 0, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:17:39.116405004Z 1, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:17:39.161267933Z Verifying GPU accessibility...
2025-11-26T17:17:39.734921068Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:17:39.734972565Z   import pynvml  # type: ignore[import]
2025-11-26T17:17:40.859984763Z GPU accessibility verified on attempt 1
2025-11-26T17:17:41.422970710Z Starting training...
2025-11-26T17:17:44.425872856Z Using STANDARD 2000 SAMPLES 2 GPUs configuration
2025-11-26T17:17:44.425924723Z Note: GRPO only (no reasoning XML). Dataset capped at 2000 samples (~6 hours).
2025-11-26T17:17:44.425928088Z GPU count: 2 (required: 2)
2025-11-26T17:17:44.428636665Z ==========================================
2025-11-26T17:17:44.428640401Z Starting GRPO Training (Cloud)
2025-11-26T17:17:44.428643806Z ==========================================
2025-11-26T17:17:44.428646350Z Config: standard_2000samples_2GPUs
2025-11-26T17:17:44.428648874Z Config file: examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml
2025-11-26T17:17:44.428651668Z Training script: examples/cloud_gsm8k/gsm8k_grpo_train.py
2025-11-26T17:17:44.428813110Z Experiment: gsm8k-grpo-cloud-2gpu-2000samples
2025-11-26T17:17:44.428822264Z Trial: trial_20251126_171744
2025-11-26T17:17:44.428826340Z GPU: NVIDIA A100 80GB PCIe NVIDIA A100 80GB PCIe (81920 MB)
2025-11-26T17:17:44.428829114Z WandB API key: e1adc5be02...
2025-11-26T17:17:44.428831718Z ==========================================
2025-11-26T17:17:45.182739851Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:17:45.182778789Z   import pynvml  # type: ignore[import]
2025-11-26T17:17:49.574741280Z [37m20251126-17:17:49.574 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:17:49.574791596Z [37m20251126-17:17:49.574 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:17:49.575254220Z [37m20251126-17:17:49.574 name-resolve INFO: No such name resolve path: ./tmp/areal/name_resolve/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_171744[0m
2025-11-26T17:17:49.762570664Z [37m20251126-17:17:49.762 Local Scheduler INFO: LocalLauncher: experiment_name=gsm8k-grpo-cloud-2gpu-2000samples, trial_name=trial_20251126_171744, fileroot=/workspace/outputs/grpo, run_id=0, is_recover_run=False[0m
2025-11-26T17:17:49.773848357Z [37m20251126-17:17:49.773 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL CUDA_VISIBLE_DEVICES=0 stdbuf -oL python3 -m areal.launcher.sglang_server examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_171744 sglang.random_seed=1 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_171744/llm_server.log[0m
2025-11-26T17:17:50.522986125Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:17:50.523016961Z   import pynvml  # type: ignore[import]
2025-11-26T17:17:52.023955606Z [37m20251126-17:17:52.023 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:17:52.024655594Z [37m20251126-17:17:52.023 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:17:52.141765109Z [37m20251126-17:17:52.141 SGLangServer Wrapper INFO: Launch command: python3 -m sglang.launch_server --host 172.21.0.2 --port 20845 --tokenizer-path Qwen/Qwen2.5-0.5B-Instruct --tokenizer-mode auto --load-format auto --trust-remote-code --device cuda --tp-size 1 --base-gpu-id 0 --nnodes 1 --node-rank 0 --dist-init-addr localhost:28551 --model-path Qwen/Qwen2.5-0.5B-Instruct --random-seed 1 --skip-tokenizer-init --disable-radix-cache --torch-compile-max-bs 32 --triton-attention-num-kv-splits 8 --num-continuous-decode-steps 1 --attention-backend flashinfer --context-length 4096 --mem-fraction-static 0.6 --chunked-prefill-size -1 --max-prefill-tokens 32768 --schedule-policy lpm --schedule-conservativeness 1.0 --cpu-offload-gb 0 --dtype bfloat16 --kv-cache-dtype auto --dp-size 1 --ep-size 1 --max-loaded-loras 1 --max-loras-per-batch 1 --lora-backend triton --log-level warning --log-level-http warning --log-requests-level 0 --enable-metrics --decode-log-interval 1[0m
2025-11-26T17:17:53.227337992Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:17:53.227378141Z   import pynvml  # type: ignore[import]
2025-11-26T17:17:59.166328874Z INFO 11-26 17:17:59 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:18:00.097366635Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:18:01.093830734Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:18:01.093868341Z   import pynvml  # type: ignore[import]
2025-11-26T17:18:01.093871716Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:18:01.093874139Z   import pynvml  # type: ignore[import]
2025-11-26T17:18:07.546431446Z INFO 11-26 17:18:07 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:18:07.556036352Z INFO 11-26 17:18:07 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:18:08.132439417Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:18:08.360875204Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:18:08.364281155Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:18:08.365089867Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:18:08.365966380Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:18:08.398462394Z [2025-11-26 17:18:08] MOE_RUNNER_BACKEND is not initialized, using triton backend
2025-11-26T17:18:08.874466184Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:18:08.874514847Z   warnings.warn(
2025-11-26T17:18:08.874518012Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:18:08.874520325Z   warnings.warn(
2025-11-26T17:18:09.952286334Z Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
2025-11-26T17:18:10.054553296Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  9.79it/s]
2025-11-26T17:18:10.055135428Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  9.77it/s]
2025-11-26T17:18:12.494987511Z   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   4%|â–         | 1/23 [00:00<00:12,  1.81it/s]Capturing batches (bs=152 avail_mem=30.62 GB):   4%|â–         | 1/23 [00:00<00:12,  1.81it/s]Capturing batches (bs=144 avail_mem=30.60 GB):   4%|â–         | 1/23 [00:00<00:12,  1.81it/s]Capturing batches (bs=136 avail_mem=30.59 GB):   4%|â–         | 1/23 [00:00<00:12,  1.81it/s]Capturing batches (bs=136 avail_mem=30.59 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.17it/s]Capturing batches (bs=128 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.17it/s]Capturing batches (bs=120 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.17it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.17it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.49it/s]Capturing batches (bs=104 avail_mem=30.54 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.49it/s]Capturing batches (bs=96 avail_mem=30.53 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.49it/s] Capturing batches (bs=88 avail_mem=30.51 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.49it/s]Capturing batches (bs=88 avail_mem=30.51 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.88it/s]Capturing batches (bs=80 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.88it/s]Capturing batches (bs=72 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.88it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:01<00:00, 14.88it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.46it/s]Capturing batches (bs=56 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.46it/s]Capturing batches (bs=48 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.46it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.46it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.52it/s]Capturing batches (bs=32 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.52it/s]Capturing batches (bs=24 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.52it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.52it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.99it/s]Capturing batches (bs=8 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.99it/s] Capturing batches (bs=4 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.99it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.99it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.83it/s]Capturing batches (bs=1 avail_mem=30.35 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.83it/s]Capturing batches (bs=1 avail_mem=30.35 GB): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00, 14.99it/s]
2025-11-26T17:18:18.173219902Z [37m20251126-17:18:18.172 SGLangServer Wrapper INFO: SGLang server launched at: http://172.21.0.2:20845[0m
2025-11-26T17:18:18.780340827Z [37m20251126-17:18:18.779 Launcher Utils INFO: Found 1 rollout servers: 172.21.0.2:20845[0m
2025-11-26T17:18:18.780380817Z [37m20251126-17:18:18.780 Local Scheduler INFO: LLM inference server launched at: AREAL_LLM_SERVER_ADDRS=172.21.0.2:20845[0m
2025-11-26T17:18:18.783420190Z [37m20251126-17:18:18.783 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL AREAL_LLM_SERVER_ADDRS=172.21.0.2:20845 AREAL_RECOVER_RUN=0 NCCL_CUMEM_ENABLE=0 NCCL_NVLS_ENABLE=0 CUDA_VISIBLE_DEVICES=1 stdbuf -oL torchrun --nnodes 1 --nproc-per-node 1 --master-addr localhost --master-port 22348 examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_171744 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_171744/trainer.log[0m
2025-11-26T17:18:18.783997145Z [37m20251126-17:18:18.783 Local Scheduler INFO: Waiting for 2 local running processes, pids: 315 965[0m
2025-11-26T17:18:19.394775818Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:18:19.394819174Z   import pynvml  # type: ignore[import]
2025-11-26T17:18:20.968344093Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:18:20.968383071Z   import pynvml  # type: ignore[import]
2025-11-26T17:18:29.516983410Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:18:29.517023821Z   warnings.warn(
2025-11-26T17:18:29.517026995Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:18:29.517029679Z   warnings.warn(
2025-11-26T17:18:29.943443800Z Traceback (most recent call last):
2025-11-26T17:18:29.943481667Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 665, in <module>
2025-11-26T17:18:29.944057449Z     main(sys.argv[1:])
2025-11-26T17:18:29.944079994Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 102, in main
2025-11-26T17:18:29.944083238Z     config, _ = load_expr_config(args_with_overrides, GRPOConfig)
2025-11-26T17:18:29.944088236Z                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:18:29.944090659Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1282, in load_expr_config
2025-11-26T17:18:29.944093013Z     cfg = to_structured_cfg(cfg, config_cls=config_cls)
2025-11-26T17:18:29.944479733Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:18:29.944490889Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1276, in to_structured_cfg
2025-11-26T17:18:29.944494284Z     cfg = OmegaConf.merge(default_cfg, cfg)
2025-11-26T17:18:29.944496878Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:18:29.944498971Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/omegaconf.py", line 274, in merge
2025-11-26T17:18:29.944953752Z     target.merge_with(
2025-11-26T17:18:29.944957248Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 507, in merge_with
2025-11-26T17:18:29.944959941Z     self._format_and_raise(key=None, value=None, cause=e)
2025-11-26T17:18:29.944962576Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:18:29.944964789Z     format_and_raise(
2025-11-26T17:18:29.944966812Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:18:29.944968845Z     _raise(ex, cause)
2025-11-26T17:18:29.944970808Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:18:29.944973502Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:18:29.945541483Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:18:29.945546860Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 502, in merge_with
2025-11-26T17:18:29.945549695Z     self._merge_with(
2025-11-26T17:18:29.945552559Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:18:29.945554943Z     BaseContainer._map_merge(
2025-11-26T17:18:29.945559970Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:18:29.945562074Z     dest_node._merge_with(
2025-11-26T17:18:29.945564086Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:18:29.945566160Z     BaseContainer._map_merge(
2025-11-26T17:18:29.945568413Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:18:29.945570516Z     dest_node._merge_with(
2025-11-26T17:18:29.945572479Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:18:29.946152408Z     BaseContainer._map_merge(
2025-11-26T17:18:29.946170665Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 432, in _map_merge
2025-11-26T17:18:29.946173339Z     dest[key] = src._get_node(key)
2025-11-26T17:18:29.946176303Z     ~~~~^^^^^
2025-11-26T17:18:29.946179178Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 308, in __setitem__
2025-11-26T17:18:29.946181311Z     self._format_and_raise(
2025-11-26T17:18:29.946183494Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:18:29.946185528Z     format_and_raise(
2025-11-26T17:18:29.946187851Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:18:29.946189874Z     _raise(ex, cause)
2025-11-26T17:18:29.946191927Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:18:29.946194040Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:18:29.946778025Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:18:29.946786207Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 306, in __setitem__
2025-11-26T17:18:29.946788801Z     self.__set_impl(key=key, value=value)
2025-11-26T17:18:29.946790844Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 316, in __set_impl
2025-11-26T17:18:29.946796102Z     self._set_item_impl(key, value)
2025-11-26T17:18:29.946798115Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 579, in _set_item_impl
2025-11-26T17:18:29.946800509Z     target_node_ref = self._get_node(key)
2025-11-26T17:18:29.946802662Z                       ^^^^^^^^^^^^^^^^^^^
2025-11-26T17:18:29.946804735Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 473, in _get_node
2025-11-26T17:18:29.947084624Z     self._validate_get(key)
2025-11-26T17:18:29.947089071Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 163, in _validate_get
2025-11-26T17:18:29.947091795Z     self._format_and_raise(
2025-11-26T17:18:29.947093788Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:18:29.947095931Z     format_and_raise(
2025-11-26T17:18:29.947098015Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 906, in format_and_raise
2025-11-26T17:18:29.947100178Z     _raise(ex, cause)
2025-11-26T17:18:29.947102431Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:18:29.947512375Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:18:29.947519014Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:18:29.947521148Z omegaconf.errors.ConfigKeyError: Key 'max_new_tokens' not in 'NormConfig'
2025-11-26T17:18:29.947523311Z     full_key: actor.adv_norm.max_new_tokens
2025-11-26T17:18:29.947525524Z     reference_type=Optional[NormConfig]
2025-11-26T17:18:29.947527627Z     object_type=NormConfig
2025-11-26T17:18:33.243349478Z E1126 17:18:33.242000 966 torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 0 (pid: 1032) of binary: /usr/bin/python3
2025-11-26T17:18:33.243919772Z Traceback (most recent call last):
2025-11-26T17:18:33.243929767Z   File "/usr/local/bin/torchrun", line 7, in <module>
2025-11-26T17:18:33.243932481Z     sys.exit(main())
2025-11-26T17:18:33.243935325Z              ^^^^^^
2025-11-26T17:18:33.243937419Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
2025-11-26T17:18:33.244312010Z     return f(*args, **kwargs)
2025-11-26T17:18:33.244319011Z            ^^^^^^^^^^^^^^^^^^
2025-11-26T17:18:33.244321204Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 901, in main
2025-11-26T17:18:33.244323687Z     run(args)
2025-11-26T17:18:33.244326131Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 892, in run
2025-11-26T17:18:33.244328485Z     elastic_launch(
2025-11-26T17:18:33.244331049Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 143, in __call__
2025-11-26T17:18:33.244865579Z     return launch_agent(self._config, self._entrypoint, list(args))
2025-11-26T17:18:33.244888924Z            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:18:33.244891468Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 277, in launch_agent
2025-11-26T17:18:33.244894142Z     raise ChildFailedError(
2025-11-26T17:18:33.244897166Z torch.distributed.elastic.multiprocessing.errors.ChildFailedError:
2025-11-26T17:18:33.244899600Z ============================================================
2025-11-26T17:18:33.244902885Z examples/cloud_gsm8k/gsm8k_grpo_train.py FAILED
2025-11-26T17:18:33.244905729Z ------------------------------------------------------------
2025-11-26T17:18:33.244908163Z Failures:
2025-11-26T17:18:33.244911648Z   <NO_OTHER_FAILURES>
2025-11-26T17:18:33.244914963Z ------------------------------------------------------------
2025-11-26T17:18:33.244917637Z Root Cause (first observed failure):
2025-11-26T17:18:33.244933431Z [0]:
2025-11-26T17:18:33.244936686Z   time      : 2025-11-26_17:18:33
2025-11-26T17:18:33.244939350Z   host      : cef7c503fdea
2025-11-26T17:18:33.244941994Z   rank      : 0 (local_rank: 0)
2025-11-26T17:18:33.244944758Z   exitcode  : 1 (pid: 1032)
2025-11-26T17:18:33.244947662Z   error_file: <N/A>
2025-11-26T17:18:33.244950827Z   traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
2025-11-26T17:18:33.244954172Z ============================================================
2025-11-26T17:18:34.787975071Z [37m20251126-17:18:34.787 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [315][0m
2025-11-26T17:18:34.958402338Z Killed
2025-11-26T17:18:34.968435737Z [37m20251126-17:18:34.968 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [965][0m
2025-11-26T17:18:34.969425489Z Traceback (most recent call last):
2025-11-26T17:18:34.969431828Z   File "<frozen runpy>", line 198, in _run_module_as_main
2025-11-26T17:18:34.969434703Z   File "<frozen runpy>", line 88, in _run_code
2025-11-26T17:18:34.969436916Z   File "/workspace/AReaL/areal/launcher/local.py", line 405, in <module>
2025-11-26T17:18:34.969572910Z     main()
2025-11-26T17:18:34.969575424Z   File "/workspace/AReaL/areal/launcher/local.py", line 260, in main
2025-11-26T17:18:34.969655904Z     local_main(config, run_id=0)
2025-11-26T17:18:34.969658979Z   File "/workspace/AReaL/areal/launcher/local.py", line 399, in local_main
2025-11-26T17:18:34.969749223Z     raise e
2025-11-26T17:18:34.969751928Z   File "/workspace/AReaL/areal/launcher/local.py", line 375, in local_main
2025-11-26T17:18:34.969829114Z     launcher.wait(
2025-11-26T17:18:34.969831838Z   File "/workspace/AReaL/areal/launcher/local.py", line 235, in wait
2025-11-26T17:18:34.969884317Z     raise JobException(
2025-11-26T17:18:34.969887551Z areal.utils.launcher.JobException: Job gsm8k-grpo-cloud-2gpu-2000samples_trial_20251126_171744:trainer JobState.COMPLETED at node local
2025-11-26T17:18:35.269183916Z [37m20251126-17:18:35.268 Local Scheduler INFO: Waiting for 0 local running processes, pids: [0m
2025-11-26T17:18:47.120715364Z ==========
2025-11-26T17:18:47.120742324Z == CUDA ==
2025-11-26T17:18:47.120766961Z ==========
2025-11-26T17:18:47.125699950Z CUDA Version 12.9.1
2025-11-26T17:18:47.127523821Z Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
2025-11-26T17:18:47.129416267Z This container image and its contents are governed by the NVIDIA Deep Learning Container License.
2025-11-26T17:18:47.129418911Z By pulling and using the container, you accept the terms and conditions of this license:
2025-11-26T17:18:47.129421264Z https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license
2025-11-26T17:18:47.129426462Z A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
2025-11-26T17:18:47.297178572Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:18:47.455012576Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:18:48.663306288Z Branch 'feature/reasoning_model' set up to track remote branch 'feature/reasoning_model' from 'origin'.
2025-11-26T17:18:48.663345928Z Your branch is up to date with 'origin/feature/reasoning_model'.
2025-11-26T17:18:48.735494017Z Checking AReaL installation...
2025-11-26T17:18:48.802489446Z AReaL already installed. Skipping installation.
2025-11-26T17:18:48.802528445Z Cleaning up any leftover GPU processes...
2025-11-26T17:18:51.822985815Z Checking for processes holding GPU device files...
2025-11-26T17:18:53.556019718Z Found processes holding GPU devices: 1
2025-11-26T17:18:53.556058496Z 20
2025-11-26T17:18:53.556061630Z 71
2025-11-26T17:18:53.556063724Z 72
2025-11-26T17:18:53.556066127Z Killing process 1...
2025-11-26T17:18:53.556068701Z Killing process 71...
2025-11-26T17:18:53.556218195Z Killing process 72...
2025-11-26T17:18:55.558793625Z Using fuser to kill processes on GPU devices...
2025-11-26T17:18:57.580597666Z Checking GPU...
2025-11-26T17:18:57.615966114Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:18:57.616004281Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:18:57.632858576Z Set PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True for better memory management
2025-11-26T17:18:57.632877465Z Detected 2 GPU(s)
2025-11-26T17:18:57.632880419Z Checking GPU status...
2025-11-26T17:18:57.666420928Z index, name, utilization.gpu [%], memory.used [MiB], compute_mode
2025-11-26T17:18:57.667834055Z 0, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:18:57.668166613Z 1, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:18:57.713076302Z Verifying GPU accessibility...
2025-11-26T17:18:58.296344119Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:18:58.296402056Z   import pynvml  # type: ignore[import]
2025-11-26T17:18:59.635043851Z GPU accessibility verified on attempt 1
2025-11-26T17:19:00.193408057Z Starting training...
2025-11-26T17:19:03.195933117Z Using STANDARD 2000 SAMPLES 2 GPUs configuration
2025-11-26T17:19:03.195980728Z Note: GRPO only (no reasoning XML). Dataset capped at 2000 samples (~6 hours).
2025-11-26T17:19:03.195984033Z GPU count: 2 (required: 2)
2025-11-26T17:19:03.198774173Z ==========================================
2025-11-26T17:19:03.198777398Z Starting GRPO Training (Cloud)
2025-11-26T17:19:03.198780312Z ==========================================
2025-11-26T17:19:03.198782415Z Config: standard_2000samples_2GPUs
2025-11-26T17:19:03.198784548Z Config file: examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml
2025-11-26T17:19:03.198786952Z Training script: examples/cloud_gsm8k/gsm8k_grpo_train.py
2025-11-26T17:19:03.198789376Z Experiment: gsm8k-grpo-cloud-2gpu-2000samples
2025-11-26T17:19:03.198791388Z Trial: trial_20251126_171903
2025-11-26T17:19:03.198793522Z GPU: NVIDIA A100 80GB PCIe NVIDIA A100 80GB PCIe (81920 MB)
2025-11-26T17:19:03.198799170Z WandB API key: e1adc5be02...
2025-11-26T17:19:03.198801544Z ==========================================
2025-11-26T17:19:03.928895005Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:19:03.928941796Z   import pynvml  # type: ignore[import]
2025-11-26T17:19:09.233604449Z [37m20251126-17:19:09.233 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:19:09.233658641Z [37m20251126-17:19:09.233 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:19:09.234066613Z [37m20251126-17:19:09.233 name-resolve INFO: No such name resolve path: ./tmp/areal/name_resolve/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_171903[0m
2025-11-26T17:19:09.391800286Z [37m20251126-17:19:09.391 Local Scheduler INFO: LocalLauncher: experiment_name=gsm8k-grpo-cloud-2gpu-2000samples, trial_name=trial_20251126_171903, fileroot=/workspace/outputs/grpo, run_id=0, is_recover_run=False[0m
2025-11-26T17:19:09.405429150Z [37m20251126-17:19:09.405 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL CUDA_VISIBLE_DEVICES=0 stdbuf -oL python3 -m areal.launcher.sglang_server examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_171903 sglang.random_seed=1 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_171903/llm_server.log[0m
2025-11-26T17:19:10.208181606Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:19:10.208241906Z   import pynvml  # type: ignore[import]
2025-11-26T17:19:12.081856469Z [37m20251126-17:19:12.081 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:19:12.082499893Z [37m20251126-17:19:12.081 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:19:12.243797246Z [37m20251126-17:19:12.243 SGLangServer Wrapper INFO: Launch command: python3 -m sglang.launch_server --host 172.21.0.2 --port 22827 --tokenizer-path Qwen/Qwen2.5-0.5B-Instruct --tokenizer-mode auto --load-format auto --trust-remote-code --device cuda --tp-size 1 --base-gpu-id 0 --nnodes 1 --node-rank 0 --dist-init-addr localhost:26174 --model-path Qwen/Qwen2.5-0.5B-Instruct --random-seed 1 --skip-tokenizer-init --disable-radix-cache --torch-compile-max-bs 32 --triton-attention-num-kv-splits 8 --num-continuous-decode-steps 1 --attention-backend flashinfer --context-length 4096 --mem-fraction-static 0.6 --chunked-prefill-size -1 --max-prefill-tokens 32768 --schedule-policy lpm --schedule-conservativeness 1.0 --cpu-offload-gb 0 --dtype bfloat16 --kv-cache-dtype auto --dp-size 1 --ep-size 1 --max-loaded-loras 1 --max-loras-per-batch 1 --lora-backend triton --log-level warning --log-level-http warning --log-requests-level 0 --enable-metrics --decode-log-interval 1[0m
2025-11-26T17:19:13.276483812Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:19:13.276521929Z   import pynvml  # type: ignore[import]
2025-11-26T17:19:19.186706614Z INFO 11-26 17:19:19 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:19:19.903347215Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:19:20.895007420Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:19:20.895052166Z   import pynvml  # type: ignore[import]
2025-11-26T17:19:20.912312209Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:19:20.912349035Z   import pynvml  # type: ignore[import]
2025-11-26T17:19:26.109817366Z INFO 11-26 17:19:26 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:19:27.951354162Z INFO 11-26 17:19:27 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:19:28.723571941Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:19:28.967533102Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:19:28.972054514Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:19:28.973160040Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:19:28.974239287Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:19:29.022556830Z [2025-11-26 17:19:29] MOE_RUNNER_BACKEND is not initialized, using triton backend
2025-11-26T17:19:29.684444018Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:19:29.684496647Z   warnings.warn(
2025-11-26T17:19:29.684499642Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:19:29.684501875Z   warnings.warn(
2025-11-26T17:19:31.069398775Z Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
2025-11-26T17:19:31.195013939Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  7.98it/s]
2025-11-26T17:19:31.195553498Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  7.96it/s]
2025-11-26T17:19:34.309341696Z   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   4%|â–         | 1/23 [00:00<00:14,  1.56it/s]Capturing batches (bs=152 avail_mem=30.62 GB):   4%|â–         | 1/23 [00:00<00:14,  1.56it/s]Capturing batches (bs=144 avail_mem=30.60 GB):   4%|â–         | 1/23 [00:00<00:14,  1.56it/s]Capturing batches (bs=144 avail_mem=30.60 GB):  13%|â–ˆâ–Ž        | 3/23 [00:00<00:04,  4.76it/s]Capturing batches (bs=136 avail_mem=30.59 GB):  13%|â–ˆâ–Ž        | 3/23 [00:00<00:04,  4.76it/s]Capturing batches (bs=128 avail_mem=30.57 GB):  13%|â–ˆâ–Ž        | 3/23 [00:00<00:04,  4.76it/s]Capturing batches (bs=128 avail_mem=30.57 GB):  22%|â–ˆâ–ˆâ–       | 5/23 [00:00<00:02,  7.69it/s]Capturing batches (bs=120 avail_mem=30.57 GB):  22%|â–ˆâ–ˆâ–       | 5/23 [00:00<00:02,  7.69it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  22%|â–ˆâ–ˆâ–       | 5/23 [00:00<00:02,  7.69it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 10.13it/s]Capturing batches (bs=104 avail_mem=30.54 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 10.13it/s]Capturing batches (bs=96 avail_mem=30.53 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:01<00:01, 10.13it/s] Capturing batches (bs=96 avail_mem=30.53 GB):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 9/23 [00:01<00:01, 12.07it/s]Capturing batches (bs=88 avail_mem=30.51 GB):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 9/23 [00:01<00:01, 12.07it/s]Capturing batches (bs=80 avail_mem=30.50 GB):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 9/23 [00:01<00:01, 12.07it/s]Capturing batches (bs=80 avail_mem=30.50 GB):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 11/23 [00:01<00:00, 13.50it/s]Capturing batches (bs=72 avail_mem=30.50 GB):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 11/23 [00:01<00:00, 13.50it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 11/23 [00:01<00:00, 13.50it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 14.50it/s]Capturing batches (bs=56 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 14.50it/s]Capturing batches (bs=48 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 14.50it/s]Capturing batches (bs=48 avail_mem=30.44 GB):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 15/23 [00:01<00:00, 15.17it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 15/23 [00:01<00:00, 15.17it/s]Capturing batches (bs=32 avail_mem=30.44 GB):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 15/23 [00:01<00:00, 15.17it/s]Capturing batches (bs=32 avail_mem=30.44 GB):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 17/23 [00:01<00:00, 15.03it/s]Capturing batches (bs=24 avail_mem=30.41 GB):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 17/23 [00:01<00:00, 15.03it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 17/23 [00:01<00:00, 15.03it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 13.79it/s]Capturing batches (bs=8 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 13.79it/s] Capturing batches (bs=4 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 13.79it/s]Capturing batches (bs=4 avail_mem=30.38 GB):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 21/23 [00:01<00:00, 14.80it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 21/23 [00:01<00:00, 14.80it/s]Capturing batches (bs=1 avail_mem=30.35 GB):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 21/23 [00:01<00:00, 14.80it/s]Capturing batches (bs=1 avail_mem=30.35 GB): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00, 15.26it/s]Capturing batches (bs=1 avail_mem=30.35 GB): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00, 11.57it/s]
2025-11-26T17:19:40.278281608Z [37m20251126-17:19:40.277 SGLangServer Wrapper INFO: SGLang server launched at: http://172.21.0.2:22827[0m
2025-11-26T17:19:40.413393428Z [37m20251126-17:19:40.412 Launcher Utils INFO: Found 1 rollout servers: 172.21.0.2:22827[0m
2025-11-26T17:19:40.413434389Z [37m20251126-17:19:40.413 Local Scheduler INFO: LLM inference server launched at: AREAL_LLM_SERVER_ADDRS=172.21.0.2:22827[0m
2025-11-26T17:19:40.415910889Z [37m20251126-17:19:40.415 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL AREAL_LLM_SERVER_ADDRS=172.21.0.2:22827 AREAL_RECOVER_RUN=0 NCCL_CUMEM_ENABLE=0 NCCL_NVLS_ENABLE=0 CUDA_VISIBLE_DEVICES=1 stdbuf -oL torchrun --nnodes 1 --nproc-per-node 1 --master-addr localhost --master-port 14516 examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_171903 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_171903/trainer.log[0m
2025-11-26T17:19:40.416756426Z [37m20251126-17:19:40.416 Local Scheduler INFO: Waiting for 2 local running processes, pids: 315 965[0m
2025-11-26T17:19:40.966207719Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:19:40.966243052Z   import pynvml  # type: ignore[import]
2025-11-26T17:19:42.167104912Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:19:42.167179975Z   import pynvml  # type: ignore[import]
2025-11-26T17:19:48.839904542Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:19:48.839944763Z   warnings.warn(
2025-11-26T17:19:48.839947697Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:19:48.839956070Z   warnings.warn(
2025-11-26T17:19:49.284205166Z Traceback (most recent call last):
2025-11-26T17:19:49.284249432Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 665, in <module>
2025-11-26T17:19:49.284907668Z     main(sys.argv[1:])
2025-11-26T17:19:49.284930101Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 102, in main
2025-11-26T17:19:49.284933616Z     config, _ = load_expr_config(args_with_overrides, GRPOConfig)
2025-11-26T17:19:49.284936551Z                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:19:49.284938574Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1282, in load_expr_config
2025-11-26T17:19:49.284940807Z     cfg = to_structured_cfg(cfg, config_cls=config_cls)
2025-11-26T17:19:49.285389279Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:19:49.285401017Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1276, in to_structured_cfg
2025-11-26T17:19:49.285404422Z     cfg = OmegaConf.merge(default_cfg, cfg)
2025-11-26T17:19:49.285406665Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:19:49.285409099Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/omegaconf.py", line 274, in merge
2025-11-26T17:19:49.285412204Z     target.merge_with(
2025-11-26T17:19:49.285415759Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 507, in merge_with
2025-11-26T17:19:49.286372221Z     self._format_and_raise(key=None, value=None, cause=e)
2025-11-26T17:19:49.286391660Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:19:49.286394935Z     format_and_raise(
2025-11-26T17:19:49.286397499Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:19:49.286399792Z     _raise(ex, cause)
2025-11-26T17:19:49.286401906Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:19:49.286404470Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:19:49.286406643Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:19:49.286409667Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 502, in merge_with
2025-11-26T17:19:49.286411931Z     self._merge_with(
2025-11-26T17:19:49.286413914Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:19:49.286416277Z     BaseContainer._map_merge(
2025-11-26T17:19:49.286418781Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:19:49.286420904Z     dest_node._merge_with(
2025-11-26T17:19:49.286422977Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:19:49.286424970Z     BaseContainer._map_merge(
2025-11-26T17:19:49.286429737Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:19:49.286432041Z     dest_node._merge_with(
2025-11-26T17:19:49.286708655Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:19:49.286717108Z     BaseContainer._map_merge(
2025-11-26T17:19:49.286720433Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 432, in _map_merge
2025-11-26T17:19:49.286723017Z     dest[key] = src._get_node(key)
2025-11-26T17:19:49.286726141Z     ~~~~^^^^^
2025-11-26T17:19:49.286729346Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 308, in __setitem__
2025-11-26T17:19:49.286731860Z     self._format_and_raise(
2025-11-26T17:19:49.286733983Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:19:49.286736337Z     format_and_raise(
2025-11-26T17:19:49.286738880Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:19:49.287417908Z     _raise(ex, cause)
2025-11-26T17:19:49.287432660Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:19:49.287435434Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:19:49.287437748Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:19:49.287440081Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 306, in __setitem__
2025-11-26T17:19:49.287443066Z     self.__set_impl(key=key, value=value)
2025-11-26T17:19:49.287445219Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 316, in __set_impl
2025-11-26T17:19:49.287449255Z     self._set_item_impl(key, value)
2025-11-26T17:19:49.287451689Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 579, in _set_item_impl
2025-11-26T17:19:49.287453832Z     target_node_ref = self._get_node(key)
2025-11-26T17:19:49.287779148Z                       ^^^^^^^^^^^^^^^^^^^
2025-11-26T17:19:49.287785948Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 473, in _get_node
2025-11-26T17:19:49.287788643Z     self._validate_get(key)
2025-11-26T17:19:49.287790886Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 163, in _validate_get
2025-11-26T17:19:49.287794000Z     self._format_and_raise(
2025-11-26T17:19:49.287796154Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:19:49.287798297Z     format_and_raise(
2025-11-26T17:19:49.287801262Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 906, in format_and_raise
2025-11-26T17:19:49.288206689Z     _raise(ex, cause)
2025-11-26T17:19:49.288215483Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:19:49.288218176Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:19:49.288220600Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:19:49.288223725Z omegaconf.errors.ConfigKeyError: Key 'max_new_tokens' not in 'NormConfig'
2025-11-26T17:19:49.288226199Z     full_key: actor.adv_norm.max_new_tokens
2025-11-26T17:19:49.288230145Z     reference_type=Optional[NormConfig]
2025-11-26T17:19:49.288232318Z     object_type=NormConfig
2025-11-26T17:19:52.482921574Z E1126 17:19:52.481000 966 torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 0 (pid: 1032) of binary: /usr/bin/python3
2025-11-26T17:19:52.483694191Z Traceback (most recent call last):
2025-11-26T17:19:52.483704947Z   File "/usr/local/bin/torchrun", line 7, in <module>
2025-11-26T17:19:52.483708283Z     sys.exit(main())
2025-11-26T17:19:52.483711197Z              ^^^^^^
2025-11-26T17:19:52.483713390Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
2025-11-26T17:19:52.483716124Z     return f(*args, **kwargs)
2025-11-26T17:19:52.483719079Z            ^^^^^^^^^^^^^^^^^^
2025-11-26T17:19:52.483721062Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 901, in main
2025-11-26T17:19:52.484101962Z     run(args)
2025-11-26T17:19:52.484105107Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 892, in run
2025-11-26T17:19:52.484108242Z     elastic_launch(
2025-11-26T17:19:52.484137406Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 143, in __call__
2025-11-26T17:19:52.484142373Z     return launch_agent(self._config, self._entrypoint, list(args))
2025-11-26T17:19:52.484145157Z            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:19:52.484147181Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 277, in launch_agent
2025-11-26T17:19:52.484152839Z     raise ChildFailedError(
2025-11-26T17:19:52.484155313Z torch.distributed.elastic.multiprocessing.errors.ChildFailedError:
2025-11-26T17:19:52.484157586Z ============================================================
2025-11-26T17:19:52.484160190Z examples/cloud_gsm8k/gsm8k_grpo_train.py FAILED
2025-11-26T17:19:52.484162493Z ------------------------------------------------------------
2025-11-26T17:19:52.484173950Z Failures:
2025-11-26T17:19:52.484176094Z   <NO_OTHER_FAILURES>
2025-11-26T17:19:52.484178127Z ------------------------------------------------------------
2025-11-26T17:19:52.484180200Z Root Cause (first observed failure):
2025-11-26T17:19:52.484182303Z [0]:
2025-11-26T17:19:52.484184416Z   time      : 2025-11-26_17:19:52
2025-11-26T17:19:52.484186480Z   host      : cef7c503fdea
2025-11-26T17:19:52.484188483Z   rank      : 0 (local_rank: 0)
2025-11-26T17:19:52.484190415Z   exitcode  : 1 (pid: 1032)
2025-11-26T17:19:52.484192378Z   error_file: <N/A>
2025-11-26T17:19:52.484194401Z   traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
2025-11-26T17:19:52.484196483Z ============================================================
2025-11-26T17:19:54.420489592Z [37m20251126-17:19:54.420 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [315][0m
2025-11-26T17:19:54.606783645Z Killed
2025-11-26T17:19:54.610216116Z [37m20251126-17:19:54.609 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [965][0m
2025-11-26T17:19:54.611367431Z Traceback (most recent call last):
2025-11-26T17:19:54.611373450Z   File "<frozen runpy>", line 198, in _run_module_as_main
2025-11-26T17:19:54.611376074Z   File "<frozen runpy>", line 88, in _run_code
2025-11-26T17:19:54.611378207Z   File "/workspace/AReaL/areal/launcher/local.py", line 405, in <module>
2025-11-26T17:19:54.611495003Z     main()
2025-11-26T17:19:54.611497587Z   File "/workspace/AReaL/areal/launcher/local.py", line 260, in main
2025-11-26T17:19:54.611581792Z     local_main(config, run_id=0)
2025-11-26T17:19:54.611584365Z   File "/workspace/AReaL/areal/launcher/local.py", line 399, in local_main
2025-11-26T17:19:54.611680109Z     raise e
2025-11-26T17:19:54.611682433Z   File "/workspace/AReaL/areal/launcher/local.py", line 375, in local_main
2025-11-26T17:19:54.611744506Z     launcher.wait(
2025-11-26T17:19:54.611747450Z   File "/workspace/AReaL/areal/launcher/local.py", line 235, in wait
2025-11-26T17:19:54.611799439Z     raise JobException(
2025-11-26T17:19:54.611801902Z areal.utils.launcher.JobException: Job gsm8k-grpo-cloud-2gpu-2000samples_trial_20251126_171903:trainer JobState.COMPLETED at node local
2025-11-26T17:19:54.879147420Z [37m20251126-17:19:54.878 Local Scheduler INFO: Waiting for 0 local running processes, pids: [0m
2025-11-26T17:20:12.139091154Z ==========
2025-11-26T17:20:12.139101309Z == CUDA ==
2025-11-26T17:20:12.139104363Z ==========
2025-11-26T17:20:12.144281318Z CUDA Version 12.9.1
2025-11-26T17:20:12.146350517Z Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
2025-11-26T17:20:12.147969583Z This container image and its contents are governed by the NVIDIA Deep Learning Container License.
2025-11-26T17:20:12.147971826Z By pulling and using the container, you accept the terms and conditions of this license:
2025-11-26T17:20:12.147974450Z https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license
2025-11-26T17:20:12.147978515Z A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
2025-11-26T17:20:12.313498903Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:20:12.470830604Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:20:12.659598794Z Branch 'feature/reasoning_model' set up to track remote branch 'feature/reasoning_model' from 'origin'.
2025-11-26T17:20:12.659642259Z Your branch is up to date with 'origin/feature/reasoning_model'.
2025-11-26T17:20:12.732089014Z Checking AReaL installation...
2025-11-26T17:20:12.796975066Z AReaL already installed. Skipping installation.
2025-11-26T17:20:12.797004520Z Cleaning up any leftover GPU processes...
2025-11-26T17:20:15.818438653Z Checking for processes holding GPU device files...
2025-11-26T17:20:17.912325556Z Found processes holding GPU devices: 1
2025-11-26T17:20:17.912369020Z 20
2025-11-26T17:20:17.912372245Z 71
2025-11-26T17:20:17.912374388Z 72
2025-11-26T17:20:17.912376441Z Killing process 1...
2025-11-26T17:20:17.912390242Z Killing process 71...
2025-11-26T17:20:17.912475259Z Killing process 72...
2025-11-26T17:20:19.915279642Z Using fuser to kill processes on GPU devices...
2025-11-26T17:20:21.940508564Z Checking GPU...
2025-11-26T17:20:21.979262692Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:20:21.979295852Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:20:21.996673442Z Set PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True for better memory management
2025-11-26T17:20:21.996697598Z Detected 2 GPU(s)
2025-11-26T17:20:21.996701033Z Checking GPU status...
2025-11-26T17:20:22.025022525Z index, name, utilization.gpu [%], memory.used [MiB], compute_mode
2025-11-26T17:20:22.026473148Z 0, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:20:22.026786307Z 1, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:20:22.072895942Z Verifying GPU accessibility...
2025-11-26T17:20:22.624001335Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:20:22.624062706Z   import pynvml  # type: ignore[import]
2025-11-26T17:20:23.736311746Z GPU accessibility verified on attempt 1
2025-11-26T17:20:24.271609562Z Starting training...
2025-11-26T17:20:27.274615743Z Using STANDARD 2000 SAMPLES 2 GPUs configuration
2025-11-26T17:20:27.274660139Z Note: GRPO only (no reasoning XML). Dataset capped at 2000 samples (~6 hours).
2025-11-26T17:20:27.274666068Z GPU count: 2 (required: 2)
2025-11-26T17:20:27.277088255Z ==========================================
2025-11-26T17:20:27.277091631Z Starting GRPO Training (Cloud)
2025-11-26T17:20:27.277094224Z ==========================================
2025-11-26T17:20:27.277096327Z Config: standard_2000samples_2GPUs
2025-11-26T17:20:27.277098541Z Config file: examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml
2025-11-26T17:20:27.277101355Z Training script: examples/cloud_gsm8k/gsm8k_grpo_train.py
2025-11-26T17:20:27.277103899Z Experiment: gsm8k-grpo-cloud-2gpu-2000samples
2025-11-26T17:20:27.277105922Z Trial: trial_20251126_172027
2025-11-26T17:20:27.277107915Z GPU: NVIDIA A100 80GB PCIe NVIDIA A100 80GB PCIe (81920 MB)
2025-11-26T17:20:27.277109968Z WandB API key: e1adc5be02...
2025-11-26T17:20:27.277111971Z ==========================================
2025-11-26T17:20:27.974000097Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:20:27.974036522Z   import pynvml  # type: ignore[import]
2025-11-26T17:20:32.014154947Z [37m20251126-17:20:32.013 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:20:32.014203159Z [37m20251126-17:20:32.013 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:20:32.014455958Z [37m20251126-17:20:32.014 name-resolve INFO: No such name resolve path: ./tmp/areal/name_resolve/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_172027[0m
2025-11-26T17:20:32.120177926Z [37m20251126-17:20:32.119 Local Scheduler INFO: LocalLauncher: experiment_name=gsm8k-grpo-cloud-2gpu-2000samples, trial_name=trial_20251126_172027, fileroot=/workspace/outputs/grpo, run_id=0, is_recover_run=False[0m
2025-11-26T17:20:32.127903487Z [37m20251126-17:20:32.127 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL CUDA_VISIBLE_DEVICES=0 stdbuf -oL python3 -m areal.launcher.sglang_server examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_172027 sglang.random_seed=1 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_172027/llm_server.log[0m
2025-11-26T17:20:32.854346882Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:20:32.854391549Z   import pynvml  # type: ignore[import]
2025-11-26T17:20:34.342621889Z [37m20251126-17:20:34.341 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:20:34.343187045Z [37m20251126-17:20:34.342 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:20:34.457848313Z [37m20251126-17:20:34.457 SGLangServer Wrapper INFO: Launch command: python3 -m sglang.launch_server --host 172.21.0.2 --port 16109 --tokenizer-path Qwen/Qwen2.5-0.5B-Instruct --tokenizer-mode auto --load-format auto --trust-remote-code --device cuda --tp-size 1 --base-gpu-id 0 --nnodes 1 --node-rank 0 --dist-init-addr localhost:25549 --model-path Qwen/Qwen2.5-0.5B-Instruct --random-seed 1 --skip-tokenizer-init --disable-radix-cache --torch-compile-max-bs 32 --triton-attention-num-kv-splits 8 --num-continuous-decode-steps 1 --attention-backend flashinfer --context-length 4096 --mem-fraction-static 0.6 --chunked-prefill-size -1 --max-prefill-tokens 32768 --schedule-policy lpm --schedule-conservativeness 1.0 --cpu-offload-gb 0 --dtype bfloat16 --kv-cache-dtype auto --dp-size 1 --ep-size 1 --max-loaded-loras 1 --max-loras-per-batch 1 --lora-backend triton --log-level warning --log-level-http warning --log-requests-level 0 --enable-metrics --decode-log-interval 1[0m
2025-11-26T17:20:35.804322741Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:20:35.804370021Z   import pynvml  # type: ignore[import]
2025-11-26T17:20:41.618626098Z INFO 11-26 17:20:41 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:20:42.300212214Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:20:43.331781576Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:20:43.331819372Z   import pynvml  # type: ignore[import]
2025-11-26T17:20:43.331822156Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:20:43.331824350Z   import pynvml  # type: ignore[import]
2025-11-26T17:20:48.492666190Z INFO 11-26 17:20:48 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:20:48.613565511Z INFO 11-26 17:20:48 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:20:49.184600855Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:20:49.387853771Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:20:49.391291160Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:20:49.392159611Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:20:49.392946089Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:20:49.425178979Z [2025-11-26 17:20:49] MOE_RUNNER_BACKEND is not initialized, using triton backend
2025-11-26T17:20:49.910848677Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:20:49.910897160Z   warnings.warn(
2025-11-26T17:20:49.910900245Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:20:49.910902578Z   warnings.warn(
2025-11-26T17:20:50.998800654Z Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
2025-11-26T17:20:51.103393509Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  9.57it/s]
2025-11-26T17:20:51.105180997Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  9.55it/s]
2025-11-26T17:20:53.545001351Z   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   4%|â–         | 1/23 [00:00<00:11,  1.87it/s]Capturing batches (bs=152 avail_mem=30.62 GB):   4%|â–         | 1/23 [00:00<00:11,  1.87it/s]Capturing batches (bs=144 avail_mem=30.60 GB):   4%|â–         | 1/23 [00:00<00:11,  1.87it/s]Capturing batches (bs=136 avail_mem=30.59 GB):   4%|â–         | 1/23 [00:00<00:11,  1.87it/s]Capturing batches (bs=136 avail_mem=30.59 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.36it/s]Capturing batches (bs=128 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.36it/s]Capturing batches (bs=120 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.36it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.36it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.70it/s]Capturing batches (bs=104 avail_mem=30.54 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.70it/s]Capturing batches (bs=96 avail_mem=30.53 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.70it/s] Capturing batches (bs=88 avail_mem=30.51 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.70it/s]Capturing batches (bs=88 avail_mem=30.51 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.93it/s]Capturing batches (bs=80 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.93it/s]Capturing batches (bs=72 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.93it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:01<00:00, 14.93it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.35it/s]Capturing batches (bs=56 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.35it/s]Capturing batches (bs=48 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.35it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.35it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.42it/s]Capturing batches (bs=32 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.42it/s]Capturing batches (bs=24 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.42it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.42it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.94it/s]Capturing batches (bs=8 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.94it/s] Capturing batches (bs=4 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.94it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.94it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.75it/s]Capturing batches (bs=1 avail_mem=30.35 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.75it/s]Capturing batches (bs=1 avail_mem=30.35 GB): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00, 15.06it/s]
2025-11-26T17:20:59.490962024Z [37m20251126-17:20:59.490 SGLangServer Wrapper INFO: SGLang server launched at: http://172.21.0.2:16109[0m
2025-11-26T17:21:00.135418393Z [37m20251126-17:21:00.134 Launcher Utils INFO: Found 1 rollout servers: 172.21.0.2:16109[0m
2025-11-26T17:21:00.135442349Z [37m20251126-17:21:00.135 Local Scheduler INFO: LLM inference server launched at: AREAL_LLM_SERVER_ADDRS=172.21.0.2:16109[0m
2025-11-26T17:21:00.138062654Z [37m20251126-17:21:00.137 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL AREAL_LLM_SERVER_ADDRS=172.21.0.2:16109 AREAL_RECOVER_RUN=0 NCCL_CUMEM_ENABLE=0 NCCL_NVLS_ENABLE=0 CUDA_VISIBLE_DEVICES=1 stdbuf -oL torchrun --nnodes 1 --nproc-per-node 1 --master-addr localhost --master-port 40976 examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_172027 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_172027/trainer.log[0m
2025-11-26T17:21:00.138765948Z [37m20251126-17:21:00.138 Local Scheduler INFO: Waiting for 2 local running processes, pids: 315 965[0m
2025-11-26T17:21:00.676580101Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:21:00.676624998Z   import pynvml  # type: ignore[import]
2025-11-26T17:21:01.874323740Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:21:01.874361217Z   import pynvml  # type: ignore[import]
2025-11-26T17:21:09.089322813Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:21:09.089370154Z   warnings.warn(
2025-11-26T17:21:09.089373619Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:21:09.089376033Z   warnings.warn(
2025-11-26T17:21:09.520215542Z Traceback (most recent call last):
2025-11-26T17:21:09.520259047Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 665, in <module>
2025-11-26T17:21:09.520828491Z     main(sys.argv[1:])
2025-11-26T17:21:09.520837033Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 102, in main
2025-11-26T17:21:09.520840228Z     config, _ = load_expr_config(args_with_overrides, GRPOConfig)
2025-11-26T17:21:09.520843573Z                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:21:09.520846638Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1282, in load_expr_config
2025-11-26T17:21:09.520849462Z     cfg = to_structured_cfg(cfg, config_cls=config_cls)
2025-11-26T17:21:09.521269752Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:21:09.521277664Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1276, in to_structured_cfg
2025-11-26T17:21:09.521280688Z     cfg = OmegaConf.merge(default_cfg, cfg)
2025-11-26T17:21:09.521283602Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:21:09.521285666Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/omegaconf.py", line 274, in merge
2025-11-26T17:21:09.521748118Z     target.merge_with(
2025-11-26T17:21:09.521755479Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 507, in merge_with
2025-11-26T17:21:09.521758504Z     self._format_and_raise(key=None, value=None, cause=e)
2025-11-26T17:21:09.521760727Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:21:09.521763111Z     format_and_raise(
2025-11-26T17:21:09.521765183Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:21:09.521767257Z     _raise(ex, cause)
2025-11-26T17:21:09.521769410Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:21:09.521771583Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:21:09.522170271Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:21:09.522175458Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 502, in merge_with
2025-11-26T17:21:09.522177602Z     self._merge_with(
2025-11-26T17:21:09.522179725Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:21:09.522186094Z     BaseContainer._map_merge(
2025-11-26T17:21:09.522188829Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:21:09.522190862Z     dest_node._merge_with(
2025-11-26T17:21:09.522193045Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:21:09.522618452Z     BaseContainer._map_merge(
2025-11-26T17:21:09.522621476Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:21:09.522623729Z     dest_node._merge_with(
2025-11-26T17:21:09.522625783Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:21:09.522627956Z     BaseContainer._map_merge(
2025-11-26T17:21:09.522630179Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 432, in _map_merge
2025-11-26T17:21:09.522632242Z     dest[key] = src._get_node(key)
2025-11-26T17:21:09.522634516Z     ~~~~^^^^^
2025-11-26T17:21:09.522637060Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 308, in __setitem__
2025-11-26T17:21:09.522639223Z     self._format_and_raise(
2025-11-26T17:21:09.522641456Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:21:09.523292081Z     format_and_raise(
2025-11-26T17:21:09.523296898Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:21:09.523299132Z     _raise(ex, cause)
2025-11-26T17:21:09.523301184Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:21:09.523303248Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:21:09.523313593Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:21:09.523315887Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 306, in __setitem__
2025-11-26T17:21:09.523318120Z     self.__set_impl(key=key, value=value)
2025-11-26T17:21:09.523320233Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 316, in __set_impl
2025-11-26T17:21:09.523322276Z     self._set_item_impl(key, value)
2025-11-26T17:21:09.523324350Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 579, in _set_item_impl
2025-11-26T17:21:09.523595686Z     target_node_ref = self._get_node(key)
2025-11-26T17:21:09.523598500Z                       ^^^^^^^^^^^^^^^^^^^
2025-11-26T17:21:09.523600523Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 473, in _get_node
2025-11-26T17:21:09.523602696Z     self._validate_get(key)
2025-11-26T17:21:09.523604770Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 163, in _validate_get
2025-11-26T17:21:09.523606882Z     self._format_and_raise(
2025-11-26T17:21:09.523968384Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:21:09.523972110Z     format_and_raise(
2025-11-26T17:21:09.523974473Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 906, in format_and_raise
2025-11-26T17:21:09.523976907Z     _raise(ex, cause)
2025-11-26T17:21:09.523978930Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:21:09.523981063Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:21:09.524322654Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:21:09.524327441Z omegaconf.errors.ConfigKeyError: Key 'max_new_tokens' not in 'NormConfig'
2025-11-26T17:21:09.524330156Z     full_key: actor.adv_norm.max_new_tokens
2025-11-26T17:21:09.524332389Z     reference_type=Optional[NormConfig]
2025-11-26T17:21:09.524334472Z     object_type=NormConfig
2025-11-26T17:21:11.886340872Z E1126 17:21:11.885000 966 torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 0 (pid: 1032) of binary: /usr/bin/python3
2025-11-26T17:21:11.887024505Z Traceback (most recent call last):
2025-11-26T17:21:11.887034130Z   File "/usr/local/bin/torchrun", line 7, in <module>
2025-11-26T17:21:11.887037404Z     sys.exit(main())
2025-11-26T17:21:11.887040068Z              ^^^^^^
2025-11-26T17:21:11.887042131Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
2025-11-26T17:21:11.887046729Z     return f(*args, **kwargs)
2025-11-26T17:21:11.887052146Z            ^^^^^^^^^^^^^^^^^^
2025-11-26T17:21:11.887497845Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 901, in main
2025-11-26T17:21:11.887505036Z     run(args)
2025-11-26T17:21:11.887508010Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 892, in run
2025-11-26T17:21:11.887510203Z     elastic_launch(
2025-11-26T17:21:11.887513859Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 143, in __call__
2025-11-26T17:21:11.887516753Z     return launch_agent(self._config, self._entrypoint, list(args))
2025-11-26T17:21:11.888009461Z            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:21:11.888012636Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 277, in launch_agent
2025-11-26T17:21:11.888015009Z     raise ChildFailedError(
2025-11-26T17:21:11.888017123Z torch.distributed.elastic.multiprocessing.errors.ChildFailedError:
2025-11-26T17:21:11.888019186Z ============================================================
2025-11-26T17:21:11.888022791Z examples/cloud_gsm8k/gsm8k_grpo_train.py FAILED
2025-11-26T17:21:11.888024924Z ------------------------------------------------------------
2025-11-26T17:21:11.888030142Z Failures:
2025-11-26T17:21:11.888032305Z   <NO_OTHER_FAILURES>
2025-11-26T17:21:11.888060838Z ------------------------------------------------------------
2025-11-26T17:21:11.888063822Z Root Cause (first observed failure):
2025-11-26T17:21:11.888068740Z [0]:
2025-11-26T17:21:11.888071694Z   time      : 2025-11-26_17:21:11
2025-11-26T17:21:11.888074518Z   host      : cef7c503fdea
2025-11-26T17:21:11.888077193Z   rank      : 0 (local_rank: 0)
2025-11-26T17:21:11.888079917Z   exitcode  : 1 (pid: 1032)
2025-11-26T17:21:11.888084303Z   error_file: <N/A>
2025-11-26T17:21:11.888088780Z   traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
2025-11-26T17:21:11.888091644Z ============================================================
2025-11-26T17:21:14.142477151Z [37m20251126-17:21:14.142 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [315][0m
2025-11-26T17:21:14.309315453Z Killed
2025-11-26T17:21:14.321670229Z [37m20251126-17:21:14.321 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [965][0m
2025-11-26T17:21:14.322995254Z Traceback (most recent call last):
2025-11-26T17:21:14.323003496Z   File "<frozen runpy>", line 198, in _run_module_as_main
2025-11-26T17:21:14.323007151Z   File "<frozen runpy>", line 88, in _run_code
2025-11-26T17:21:14.323010186Z   File "/workspace/AReaL/areal/launcher/local.py", line 405, in <module>
2025-11-26T17:21:14.323194141Z     main()
2025-11-26T17:21:14.323206450Z   File "/workspace/AReaL/areal/launcher/local.py", line 260, in main
2025-11-26T17:21:14.323331367Z     local_main(config, run_id=0)
2025-11-26T17:21:14.323336104Z   File "/workspace/AReaL/areal/launcher/local.py", line 399, in local_main
2025-11-26T17:21:14.323447270Z     raise e
2025-11-26T17:21:14.323451216Z   File "/workspace/AReaL/areal/launcher/local.py", line 375, in local_main
2025-11-26T17:21:14.323545207Z     launcher.wait(
2025-11-26T17:21:14.323548402Z   File "/workspace/AReaL/areal/launcher/local.py", line 235, in wait
2025-11-26T17:21:14.323605778Z     raise JobException(
2025-11-26T17:21:14.323609884Z areal.utils.launcher.JobException: Job gsm8k-grpo-cloud-2gpu-2000samples_trial_20251126_172027:trainer JobState.COMPLETED at node local
2025-11-26T17:21:14.612787253Z [37m20251126-17:21:14.612 Local Scheduler INFO: Waiting for 0 local running processes, pids: [0m
2025-11-26T17:21:30.629790399Z ==========
2025-11-26T17:21:30.629795457Z == CUDA ==
2025-11-26T17:21:30.629849346Z ==========
2025-11-26T17:21:30.634997138Z CUDA Version 12.9.1
2025-11-26T17:21:30.636540989Z Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
2025-11-26T17:21:30.638574435Z This container image and its contents are governed by the NVIDIA Deep Learning Container License.
2025-11-26T17:21:30.638577059Z By pulling and using the container, you accept the terms and conditions of this license:
2025-11-26T17:21:30.638580164Z https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license
2025-11-26T17:21:30.638584841Z A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
2025-11-26T17:21:30.803939040Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:21:30.963006462Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:21:31.147482832Z Branch 'feature/reasoning_model' set up to track remote branch 'feature/reasoning_model' from 'origin'.
2025-11-26T17:21:31.147497193Z Your branch is up to date with 'origin/feature/reasoning_model'.
2025-11-26T17:21:31.218720336Z Checking AReaL installation...
2025-11-26T17:21:31.277694262Z AReaL already installed. Skipping installation.
2025-11-26T17:21:31.277724628Z Cleaning up any leftover GPU processes...
2025-11-26T17:21:34.297174809Z Checking for processes holding GPU device files...
2025-11-26T17:21:36.431873001Z Found processes holding GPU devices: 1
2025-11-26T17:21:36.431911899Z 20
2025-11-26T17:21:36.431914854Z 71
2025-11-26T17:21:36.431917467Z 72
2025-11-26T17:21:36.431919530Z Killing process 1...
2025-11-26T17:21:36.431922125Z Killing process 71...
2025-11-26T17:21:36.432014453Z Killing process 72...
2025-11-26T17:21:38.434501911Z Using fuser to kill processes on GPU devices...
2025-11-26T17:21:40.459049733Z Checking GPU...
2025-11-26T17:21:40.492285235Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:21:40.492325134Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:21:40.510505646Z Set PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True for better memory management
2025-11-26T17:21:40.510524595Z Detected 2 GPU(s)
2025-11-26T17:21:40.510528040Z Checking GPU status...
2025-11-26T17:21:40.539409811Z index, name, utilization.gpu [%], memory.used [MiB], compute_mode
2025-11-26T17:21:40.540792382Z 0, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:21:40.541121755Z 1, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:21:40.591385504Z Verifying GPU accessibility...
2025-11-26T17:21:41.151164618Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:21:41.151215194Z   import pynvml  # type: ignore[import]
2025-11-26T17:21:42.305186138Z GPU accessibility verified on attempt 1
2025-11-26T17:21:42.896419906Z Starting training...
2025-11-26T17:21:45.899023575Z Using STANDARD 2000 SAMPLES 2 GPUs configuration
2025-11-26T17:21:45.899053420Z Note: GRPO only (no reasoning XML). Dataset capped at 2000 samples (~6 hours).
2025-11-26T17:21:45.899056003Z GPU count: 2 (required: 2)
2025-11-26T17:21:45.902006002Z ==========================================
2025-11-26T17:21:45.902009067Z Starting GRPO Training (Cloud)
2025-11-26T17:21:45.902011591Z ==========================================
2025-11-26T17:21:45.902013634Z Config: standard_2000samples_2GPUs
2025-11-26T17:21:45.902015686Z Config file: examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml
2025-11-26T17:21:45.902018631Z Training script: examples/cloud_gsm8k/gsm8k_grpo_train.py
2025-11-26T17:21:45.902021535Z Experiment: gsm8k-grpo-cloud-2gpu-2000samples
2025-11-26T17:21:45.902023598Z Trial: trial_20251126_172145
2025-11-26T17:21:45.902025621Z GPU: NVIDIA A100 80GB PCIe NVIDIA A100 80GB PCIe (81920 MB)
2025-11-26T17:21:45.902031390Z WandB API key: e1adc5be02...
2025-11-26T17:21:45.902033844Z ==========================================
2025-11-26T17:21:46.622481187Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:21:46.622518002Z   import pynvml  # type: ignore[import]
2025-11-26T17:21:50.803683238Z [37m20251126-17:21:50.803 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:21:50.803726873Z [37m20251126-17:21:50.803 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:21:50.804001455Z [37m20251126-17:21:50.803 name-resolve INFO: No such name resolve path: ./tmp/areal/name_resolve/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_172145[0m
2025-11-26T17:21:50.908773199Z [37m20251126-17:21:50.908 Local Scheduler INFO: LocalLauncher: experiment_name=gsm8k-grpo-cloud-2gpu-2000samples, trial_name=trial_20251126_172145, fileroot=/workspace/outputs/grpo, run_id=0, is_recover_run=False[0m
2025-11-26T17:21:50.916587523Z [37m20251126-17:21:50.916 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL CUDA_VISIBLE_DEVICES=0 stdbuf -oL python3 -m areal.launcher.sglang_server examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_172145 sglang.random_seed=1 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_172145/llm_server.log[0m
2025-11-26T17:21:51.618527365Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:21:51.618574376Z   import pynvml  # type: ignore[import]
2025-11-26T17:21:53.121182131Z [37m20251126-17:21:53.120 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:21:53.121692515Z [37m20251126-17:21:53.120 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:21:53.239663160Z [37m20251126-17:21:53.239 SGLangServer Wrapper INFO: Launch command: python3 -m sglang.launch_server --host 172.21.0.2 --port 12202 --tokenizer-path Qwen/Qwen2.5-0.5B-Instruct --tokenizer-mode auto --load-format auto --trust-remote-code --device cuda --tp-size 1 --base-gpu-id 0 --nnodes 1 --node-rank 0 --dist-init-addr localhost:16050 --model-path Qwen/Qwen2.5-0.5B-Instruct --random-seed 1 --skip-tokenizer-init --disable-radix-cache --torch-compile-max-bs 32 --triton-attention-num-kv-splits 8 --num-continuous-decode-steps 1 --attention-backend flashinfer --context-length 4096 --mem-fraction-static 0.6 --chunked-prefill-size -1 --max-prefill-tokens 32768 --schedule-policy lpm --schedule-conservativeness 1.0 --cpu-offload-gb 0 --dtype bfloat16 --kv-cache-dtype auto --dp-size 1 --ep-size 1 --max-loaded-loras 1 --max-loras-per-batch 1 --lora-backend triton --log-level warning --log-level-http warning --log-requests-level 0 --enable-metrics --decode-log-interval 1[0m
2025-11-26T17:21:54.280598621Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:21:54.280641686Z   import pynvml  # type: ignore[import]
2025-11-26T17:21:59.865533657Z INFO 11-26 17:21:59 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:22:00.619872996Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:22:01.602208973Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:22:01.602249894Z   import pynvml  # type: ignore[import]
2025-11-26T17:22:01.605315847Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:22:01.605351310Z   import pynvml  # type: ignore[import]
2025-11-26T17:22:06.877230649Z INFO 11-26 17:22:06 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:22:06.916478597Z INFO 11-26 17:22:06 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:22:07.541762219Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:22:07.778373219Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:22:07.781822787Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:22:07.782677768Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:22:07.783505137Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:22:07.815977637Z [2025-11-26 17:22:07] MOE_RUNNER_BACKEND is not initialized, using triton backend
2025-11-26T17:22:08.296308277Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:22:08.296363730Z   warnings.warn(
2025-11-26T17:22:08.296366935Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:22:08.296369248Z   warnings.warn(
2025-11-26T17:22:09.385806570Z Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
2025-11-26T17:22:09.489300029Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  9.69it/s]
2025-11-26T17:22:09.489759007Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  9.67it/s]
2025-11-26T17:22:11.966742587Z   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   4%|â–         | 1/23 [00:00<00:12,  1.79it/s]Capturing batches (bs=152 avail_mem=30.62 GB):   4%|â–         | 1/23 [00:00<00:12,  1.79it/s]Capturing batches (bs=144 avail_mem=30.60 GB):   4%|â–         | 1/23 [00:00<00:12,  1.79it/s]Capturing batches (bs=136 avail_mem=30.59 GB):   4%|â–         | 1/23 [00:00<00:12,  1.79it/s]Capturing batches (bs=136 avail_mem=30.59 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.10it/s]Capturing batches (bs=128 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.10it/s]Capturing batches (bs=120 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.10it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.10it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.38it/s]Capturing batches (bs=104 avail_mem=30.54 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.38it/s]Capturing batches (bs=96 avail_mem=30.53 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.38it/s] Capturing batches (bs=88 avail_mem=30.51 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.38it/s]Capturing batches (bs=88 avail_mem=30.51 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.65it/s]Capturing batches (bs=80 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.65it/s]Capturing batches (bs=72 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.65it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:01<00:00, 14.65it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.22it/s]Capturing batches (bs=56 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.22it/s]Capturing batches (bs=48 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.22it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.22it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.31it/s]Capturing batches (bs=32 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.31it/s]Capturing batches (bs=24 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.31it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.31it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.82it/s]Capturing batches (bs=8 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.82it/s] Capturing batches (bs=4 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.82it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.82it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.68it/s]Capturing batches (bs=1 avail_mem=30.35 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.68it/s]Capturing batches (bs=1 avail_mem=30.35 GB): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00, 14.84it/s]
2025-11-26T17:22:17.265199435Z [37m20251126-17:22:17.264 SGLangServer Wrapper INFO: SGLang server launched at: http://172.21.0.2:12202[0m
2025-11-26T17:22:17.923300162Z [37m20251126-17:22:17.922 Launcher Utils INFO: Found 1 rollout servers: 172.21.0.2:12202[0m
2025-11-26T17:22:17.923345750Z [37m20251126-17:22:17.923 Local Scheduler INFO: LLM inference server launched at: AREAL_LLM_SERVER_ADDRS=172.21.0.2:12202[0m
2025-11-26T17:22:17.926572463Z [37m20251126-17:22:17.926 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL AREAL_LLM_SERVER_ADDRS=172.21.0.2:12202 AREAL_RECOVER_RUN=0 NCCL_CUMEM_ENABLE=0 NCCL_NVLS_ENABLE=0 CUDA_VISIBLE_DEVICES=1 stdbuf -oL torchrun --nnodes 1 --nproc-per-node 1 --master-addr localhost --master-port 20654 examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_172145 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_172145/trainer.log[0m
2025-11-26T17:22:17.927158111Z [37m20251126-17:22:17.926 Local Scheduler INFO: Waiting for 2 local running processes, pids: 315 965[0m
2025-11-26T17:22:18.465166886Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:22:18.465213676Z   import pynvml  # type: ignore[import]
2025-11-26T17:22:19.704198219Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:22:19.704239180Z   import pynvml  # type: ignore[import]
2025-11-26T17:22:26.743382675Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:22:26.743425428Z   warnings.warn(
2025-11-26T17:22:26.743428612Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:22:26.743430866Z   warnings.warn(
2025-11-26T17:22:27.197863776Z Traceback (most recent call last):
2025-11-26T17:22:27.197917507Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 665, in <module>
2025-11-26T17:22:27.198490535Z     main(sys.argv[1:])
2025-11-26T17:22:27.198499739Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 102, in main
2025-11-26T17:22:27.198502383Z     config, _ = load_expr_config(args_with_overrides, GRPOConfig)
2025-11-26T17:22:27.198504886Z                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:22:27.198511967Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1282, in load_expr_config
2025-11-26T17:22:27.198915801Z     cfg = to_structured_cfg(cfg, config_cls=config_cls)
2025-11-26T17:22:27.198918856Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:22:27.198921009Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1276, in to_structured_cfg
2025-11-26T17:22:27.198923813Z     cfg = OmegaConf.merge(default_cfg, cfg)
2025-11-26T17:22:27.199429341Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:22:27.199434148Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/omegaconf.py", line 274, in merge
2025-11-26T17:22:27.199436352Z     target.merge_with(
2025-11-26T17:22:27.199438415Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 507, in merge_with
2025-11-26T17:22:27.199440969Z     self._format_and_raise(key=None, value=None, cause=e)
2025-11-26T17:22:27.199443683Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:22:27.199445696Z     format_and_raise(
2025-11-26T17:22:27.199447729Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:22:27.199910091Z     _raise(ex, cause)
2025-11-26T17:22:27.199934588Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:22:27.199937833Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:22:27.199940026Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:22:27.199942630Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 502, in merge_with
2025-11-26T17:22:27.199945624Z     self._merge_with(
2025-11-26T17:22:27.199947728Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:22:27.200371862Z     BaseContainer._map_merge(
2025-11-26T17:22:27.200377981Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:22:27.200380916Z     dest_node._merge_with(
2025-11-26T17:22:27.200382969Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:22:27.200385092Z     BaseContainer._map_merge(
2025-11-26T17:22:27.200387175Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:22:27.200389228Z     dest_node._merge_with(
2025-11-26T17:22:27.200391481Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:22:27.204872293Z     BaseContainer._map_merge(
2025-11-26T17:22:27.204894577Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 432, in _map_merge
2025-11-26T17:22:27.204897431Z     dest[key] = src._get_node(key)
2025-11-26T17:22:27.204899905Z     ~~~~^^^^^
2025-11-26T17:22:27.204903190Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 308, in __setitem__
2025-11-26T17:22:27.204905263Z     self._format_and_raise(
2025-11-26T17:22:27.204907336Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:22:27.204909469Z     format_and_raise(
2025-11-26T17:22:27.204911592Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:22:27.204913896Z     _raise(ex, cause)
2025-11-26T17:22:27.204916130Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:22:27.204918383Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:22:27.204920616Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:22:27.204932054Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 306, in __setitem__
2025-11-26T17:22:27.204934186Z     self.__set_impl(key=key, value=value)
2025-11-26T17:22:27.204936290Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 316, in __set_impl
2025-11-26T17:22:27.204938253Z     self._set_item_impl(key, value)
2025-11-26T17:22:27.204940215Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 579, in _set_item_impl
2025-11-26T17:22:27.204942359Z     target_node_ref = self._get_node(key)
2025-11-26T17:22:27.204944362Z                       ^^^^^^^^^^^^^^^^^^^
2025-11-26T17:22:27.204946395Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 473, in _get_node
2025-11-26T17:22:27.204948508Z     self._validate_get(key)
2025-11-26T17:22:27.204950511Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 163, in _validate_get
2025-11-26T17:22:27.204952694Z     self._format_and_raise(
2025-11-26T17:22:27.204954647Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:22:27.204956791Z     format_and_raise(
2025-11-26T17:22:27.204958774Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 906, in format_and_raise
2025-11-26T17:22:27.204960817Z     _raise(ex, cause)
2025-11-26T17:22:27.204962780Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:22:27.204964812Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:22:27.204966826Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:22:27.204968849Z omegaconf.errors.ConfigKeyError: Key 'max_new_tokens' not in 'NormConfig'
2025-11-26T17:22:27.204971793Z     full_key: actor.adv_norm.max_new_tokens
2025-11-26T17:22:27.204973826Z     reference_type=Optional[NormConfig]
2025-11-26T17:22:27.204975929Z     object_type=NormConfig
2025-11-26T17:22:30.790057531Z E1126 17:22:30.789000 966 torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 0 (pid: 1032) of binary: /usr/bin/python3
2025-11-26T17:22:30.791294825Z Traceback (most recent call last):
2025-11-26T17:22:30.791305110Z   File "/usr/local/bin/torchrun", line 7, in <module>
2025-11-26T17:22:30.791307834Z     sys.exit(main())
2025-11-26T17:22:30.791310618Z              ^^^^^^
2025-11-26T17:22:30.791312712Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
2025-11-26T17:22:30.791315425Z     return f(*args, **kwargs)
2025-11-26T17:22:30.791317889Z            ^^^^^^^^^^^^^^^^^^
2025-11-26T17:22:30.791319852Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 901, in main
2025-11-26T17:22:30.791322707Z     run(args)
2025-11-26T17:22:30.791324790Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 892, in run
2025-11-26T17:22:30.791326883Z     elastic_launch(
2025-11-26T17:22:30.791328876Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 143, in __call__
2025-11-26T17:22:30.791331819Z     return launch_agent(self._config, self._entrypoint, list(args))
2025-11-26T17:22:30.791334503Z            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:22:30.791336496Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 277, in launch_agent
2025-11-26T17:22:30.791338699Z     raise ChildFailedError(
2025-11-26T17:22:30.791340873Z torch.distributed.elastic.multiprocessing.errors.ChildFailedError:
2025-11-26T17:22:30.791342866Z ============================================================
2025-11-26T17:22:30.791344899Z examples/cloud_gsm8k/gsm8k_grpo_train.py FAILED
2025-11-26T17:22:30.791346862Z ------------------------------------------------------------
2025-11-26T17:22:30.791348835Z Failures:
2025-11-26T17:22:30.791350808Z   <NO_OTHER_FAILURES>
2025-11-26T17:22:30.791352760Z ------------------------------------------------------------
2025-11-26T17:22:30.791355134Z Root Cause (first observed failure):
2025-11-26T17:22:30.791367082Z [0]:
2025-11-26T17:22:30.791369396Z   time      : 2025-11-26_17:22:30
2025-11-26T17:22:30.791371408Z   host      : cef7c503fdea
2025-11-26T17:22:30.791373422Z   rank      : 0 (local_rank: 0)
2025-11-26T17:22:30.791375425Z   exitcode  : 1 (pid: 1032)
2025-11-26T17:22:30.791377377Z   error_file: <N/A>
2025-11-26T17:22:30.791379351Z   traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
2025-11-26T17:22:30.791381594Z ============================================================
2025-11-26T17:22:31.931111567Z [37m20251126-17:22:31.930 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [315][0m
2025-11-26T17:22:32.110928919Z Killed
2025-11-26T17:22:32.120605133Z [37m20251126-17:22:32.120 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [965][0m
2025-11-26T17:22:32.121624851Z Traceback (most recent call last):
2025-11-26T17:22:32.121630970Z   File "<frozen runpy>", line 198, in _run_module_as_main
2025-11-26T17:22:32.121633634Z   File "<frozen runpy>", line 88, in _run_code
2025-11-26T17:22:32.121635767Z   File "/workspace/AReaL/areal/launcher/local.py", line 405, in <module>
2025-11-26T17:22:32.121776357Z     main()
2025-11-26T17:22:32.121779632Z   File "/workspace/AReaL/areal/launcher/local.py", line 260, in main
2025-11-26T17:22:32.121878701Z     local_main(config, run_id=0)
2025-11-26T17:22:32.121881595Z   File "/workspace/AReaL/areal/launcher/local.py", line 399, in local_main
2025-11-26T17:22:32.121985361Z     raise e
2025-11-26T17:22:32.121987915Z   File "/workspace/AReaL/areal/launcher/local.py", line 375, in local_main
2025-11-26T17:22:32.122062376Z     launcher.wait(
2025-11-26T17:22:32.122065240Z   File "/workspace/AReaL/areal/launcher/local.py", line 235, in wait
2025-11-26T17:22:32.122108445Z     raise JobException(
2025-11-26T17:22:32.122111710Z areal.utils.launcher.JobException: Job gsm8k-grpo-cloud-2gpu-2000samples_trial_20251126_172145:trainer JobState.COMPLETED at node local
2025-11-26T17:22:32.325099078Z [37m20251126-17:22:32.324 Local Scheduler INFO: Waiting for 0 local running processes, pids: [0m
2025-11-26T17:22:49.035642363Z ==========
2025-11-26T17:22:49.035648503Z == CUDA ==
2025-11-26T17:22:49.035684096Z ==========
2025-11-26T17:22:49.040694121Z CUDA Version 12.9.1
2025-11-26T17:22:49.042752264Z Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
2025-11-26T17:22:49.044965839Z This container image and its contents are governed by the NVIDIA Deep Learning Container License.
2025-11-26T17:22:49.044968202Z By pulling and using the container, you accept the terms and conditions of this license:
2025-11-26T17:22:49.044970455Z https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license
2025-11-26T17:22:49.044974512Z A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
2025-11-26T17:22:49.208939550Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:22:49.364049693Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:22:49.561889481Z Branch 'feature/reasoning_model' set up to track remote branch 'feature/reasoning_model' from 'origin'.
2025-11-26T17:22:49.561930282Z Your branch is up to date with 'origin/feature/reasoning_model'.
2025-11-26T17:22:49.635190967Z Checking AReaL installation...
2025-11-26T17:22:49.693645595Z AReaL already installed. Skipping installation.
2025-11-26T17:22:49.693676581Z Cleaning up any leftover GPU processes...
2025-11-26T17:22:52.711657952Z Checking for processes holding GPU device files...
2025-11-26T17:22:54.890819725Z Found processes holding GPU devices: 1
2025-11-26T17:22:54.890862459Z 20
2025-11-26T17:22:54.890865153Z 71
2025-11-26T17:22:54.890868007Z 72
2025-11-26T17:22:54.890870111Z Killing process 1...
2025-11-26T17:22:54.890877212Z Killing process 71...
2025-11-26T17:22:54.890934917Z Killing process 72...
2025-11-26T17:22:56.893625019Z Using fuser to kill processes on GPU devices...
2025-11-26T17:22:58.917678600Z Checking GPU...
2025-11-26T17:22:58.952514761Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:22:58.952547278Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:22:58.970738587Z Set PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True for better memory management
2025-11-26T17:22:58.970762843Z Detected 2 GPU(s)
2025-11-26T17:22:58.970767080Z Checking GPU status...
2025-11-26T17:22:58.999007490Z index, name, utilization.gpu [%], memory.used [MiB], compute_mode
2025-11-26T17:22:59.000636100Z 0, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:22:59.000938923Z 1, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:22:59.043970869Z Verifying GPU accessibility...
2025-11-26T17:22:59.579411387Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:22:59.579474352Z   import pynvml  # type: ignore[import]
2025-11-26T17:23:00.709867168Z GPU accessibility verified on attempt 1
2025-11-26T17:23:01.197309432Z Starting training...
2025-11-26T17:23:04.199829845Z Using STANDARD 2000 SAMPLES 2 GPUs configuration
2025-11-26T17:23:04.199871748Z Note: GRPO only (no reasoning XML). Dataset capped at 2000 samples (~6 hours).
2025-11-26T17:23:04.199874793Z GPU count: 2 (required: 2)
2025-11-26T17:23:04.202395148Z ==========================================
2025-11-26T17:23:04.202397842Z Starting GRPO Training (Cloud)
2025-11-26T17:23:04.202400636Z ==========================================
2025-11-26T17:23:04.202402709Z Config: standard_2000samples_2GPUs
2025-11-26T17:23:04.202404712Z Config file: examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml
2025-11-26T17:23:04.202407236Z Training script: examples/cloud_gsm8k/gsm8k_grpo_train.py
2025-11-26T17:23:04.202409890Z Experiment: gsm8k-grpo-cloud-2gpu-2000samples
2025-11-26T17:23:04.202411963Z Trial: trial_20251126_172304
2025-11-26T17:23:04.202413976Z GPU: NVIDIA A100 80GB PCIe NVIDIA A100 80GB PCIe (81920 MB)
2025-11-26T17:23:04.202416009Z WandB API key: e1adc5be02...
2025-11-26T17:23:04.202417992Z ==========================================
2025-11-26T17:23:04.879840790Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:23:04.879876114Z   import pynvml  # type: ignore[import]
2025-11-26T17:23:09.218985157Z [37m20251126-17:23:09.218 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:23:09.219020580Z [37m20251126-17:23:09.218 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:23:09.219492358Z [37m20251126-17:23:09.219 name-resolve INFO: No such name resolve path: ./tmp/areal/name_resolve/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_172304[0m
2025-11-26T17:23:09.326195044Z [37m20251126-17:23:09.325 Local Scheduler INFO: LocalLauncher: experiment_name=gsm8k-grpo-cloud-2gpu-2000samples, trial_name=trial_20251126_172304, fileroot=/workspace/outputs/grpo, run_id=0, is_recover_run=False[0m
2025-11-26T17:23:09.333177993Z [37m20251126-17:23:09.332 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL CUDA_VISIBLE_DEVICES=0 stdbuf -oL python3 -m areal.launcher.sglang_server examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_172304 sglang.random_seed=1 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_172304/llm_server.log[0m
2025-11-26T17:23:10.062508763Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:23:10.062555343Z   import pynvml  # type: ignore[import]
2025-11-26T17:23:11.631206652Z [37m20251126-17:23:11.630 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:23:11.631500953Z [37m20251126-17:23:11.630 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:23:11.759396273Z [37m20251126-17:23:11.758 SGLangServer Wrapper INFO: Launch command: python3 -m sglang.launch_server --host 172.21.0.2 --port 18099 --tokenizer-path Qwen/Qwen2.5-0.5B-Instruct --tokenizer-mode auto --load-format auto --trust-remote-code --device cuda --tp-size 1 --base-gpu-id 0 --nnodes 1 --node-rank 0 --dist-init-addr localhost:24112 --model-path Qwen/Qwen2.5-0.5B-Instruct --random-seed 1 --skip-tokenizer-init --disable-radix-cache --torch-compile-max-bs 32 --triton-attention-num-kv-splits 8 --num-continuous-decode-steps 1 --attention-backend flashinfer --context-length 4096 --mem-fraction-static 0.6 --chunked-prefill-size -1 --max-prefill-tokens 32768 --schedule-policy lpm --schedule-conservativeness 1.0 --cpu-offload-gb 0 --dtype bfloat16 --kv-cache-dtype auto --dp-size 1 --ep-size 1 --max-loaded-loras 1 --max-loras-per-batch 1 --lora-backend triton --log-level warning --log-level-http warning --log-requests-level 0 --enable-metrics --decode-log-interval 1[0m
2025-11-26T17:23:12.836384117Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:23:12.836448113Z   import pynvml  # type: ignore[import]
2025-11-26T17:23:18.818644863Z INFO 11-26 17:23:18 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:23:19.504492841Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:23:20.767942769Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:23:20.767991071Z   import pynvml  # type: ignore[import]
2025-11-26T17:23:20.798018809Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:23:20.798057827Z   import pynvml  # type: ignore[import]
2025-11-26T17:23:26.265722778Z INFO 11-26 17:23:26 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:23:28.022975086Z INFO 11-26 17:23:28 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:23:28.784482813Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:23:29.049265152Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:23:29.053635498Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:23:29.054600995Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:23:29.055740561Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:23:29.100171093Z [2025-11-26 17:23:29] MOE_RUNNER_BACKEND is not initialized, using triton backend
2025-11-26T17:23:29.799241526Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:23:29.799293874Z   warnings.warn(
2025-11-26T17:23:29.799297390Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:23:29.799299693Z   warnings.warn(
2025-11-26T17:23:31.306749421Z Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
2025-11-26T17:23:31.451340790Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  6.93it/s]
2025-11-26T17:23:31.452011314Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  6.92it/s]
2025-11-26T17:23:34.585065550Z   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   4%|â–         | 1/23 [00:00<00:14,  1.54it/s]Capturing batches (bs=152 avail_mem=30.62 GB):   4%|â–         | 1/23 [00:00<00:14,  1.54it/s]Capturing batches (bs=144 avail_mem=30.60 GB):   4%|â–         | 1/23 [00:00<00:14,  1.54it/s]Capturing batches (bs=144 avail_mem=30.60 GB):  13%|â–ˆâ–Ž        | 3/23 [00:00<00:04,  4.74it/s]Capturing batches (bs=136 avail_mem=30.59 GB):  13%|â–ˆâ–Ž        | 3/23 [00:00<00:04,  4.74it/s]Capturing batches (bs=128 avail_mem=30.57 GB):  13%|â–ˆâ–Ž        | 3/23 [00:00<00:04,  4.74it/s]Capturing batches (bs=128 avail_mem=30.57 GB):  22%|â–ˆâ–ˆâ–       | 5/23 [00:00<00:02,  7.54it/s]Capturing batches (bs=120 avail_mem=30.57 GB):  22%|â–ˆâ–ˆâ–       | 5/23 [00:00<00:02,  7.54it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  22%|â–ˆâ–ˆâ–       | 5/23 [00:00<00:02,  7.54it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01,  9.91it/s]Capturing batches (bs=104 avail_mem=30.54 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01,  9.91it/s]Capturing batches (bs=96 avail_mem=30.53 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:01<00:01,  9.91it/s] Capturing batches (bs=96 avail_mem=30.53 GB):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 9/23 [00:01<00:01, 11.82it/s]Capturing batches (bs=88 avail_mem=30.51 GB):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 9/23 [00:01<00:01, 11.82it/s]Capturing batches (bs=80 avail_mem=30.50 GB):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 9/23 [00:01<00:01, 11.82it/s]Capturing batches (bs=80 avail_mem=30.50 GB):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 11/23 [00:01<00:00, 13.30it/s]Capturing batches (bs=72 avail_mem=30.50 GB):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 11/23 [00:01<00:00, 13.30it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 11/23 [00:01<00:00, 13.30it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 14.27it/s]Capturing batches (bs=56 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 14.27it/s]Capturing batches (bs=48 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 14.27it/s]Capturing batches (bs=48 avail_mem=30.44 GB):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 15/23 [00:01<00:00, 15.02it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 15/23 [00:01<00:00, 15.02it/s]Capturing batches (bs=32 avail_mem=30.44 GB):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 15/23 [00:01<00:00, 15.02it/s]Capturing batches (bs=32 avail_mem=30.44 GB):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 17/23 [00:01<00:00, 14.86it/s]Capturing batches (bs=24 avail_mem=30.41 GB):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 17/23 [00:01<00:00, 14.86it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 17/23 [00:01<00:00, 14.86it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 13.73it/s]Capturing batches (bs=8 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 13.73it/s] Capturing batches (bs=4 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 13.73it/s]Capturing batches (bs=4 avail_mem=30.38 GB):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 21/23 [00:01<00:00, 14.79it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 21/23 [00:01<00:00, 14.79it/s]Capturing batches (bs=1 avail_mem=30.35 GB):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 21/23 [00:01<00:00, 14.79it/s]Capturing batches (bs=1 avail_mem=30.35 GB): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:02<00:00, 15.33it/s]Capturing batches (bs=1 avail_mem=30.35 GB): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:02<00:00, 11.47it/s]
2025-11-26T17:23:39.790022718Z [37m20251126-17:23:39.789 SGLangServer Wrapper INFO: SGLang server launched at: http://172.21.0.2:18099[0m
2025-11-26T17:23:40.347208097Z [37m20251126-17:23:40.343 Launcher Utils INFO: Found 1 rollout servers: 172.21.0.2:18099[0m
2025-11-26T17:23:40.347259184Z [37m20251126-17:23:40.343 Local Scheduler INFO: LLM inference server launched at: AREAL_LLM_SERVER_ADDRS=172.21.0.2:18099[0m
2025-11-26T17:23:40.347439223Z [37m20251126-17:23:40.347 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL AREAL_LLM_SERVER_ADDRS=172.21.0.2:18099 AREAL_RECOVER_RUN=0 NCCL_CUMEM_ENABLE=0 NCCL_NVLS_ENABLE=0 CUDA_VISIBLE_DEVICES=1 stdbuf -oL torchrun --nnodes 1 --nproc-per-node 1 --master-addr localhost --master-port 30586 examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_172304 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_172304/trainer.log[0m
2025-11-26T17:23:40.348009477Z [37m20251126-17:23:40.347 Local Scheduler INFO: Waiting for 2 local running processes, pids: 315 965[0m
2025-11-26T17:23:40.890393126Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:23:40.890438544Z   import pynvml  # type: ignore[import]
2025-11-26T17:23:42.097743064Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:23:42.097788833Z   import pynvml  # type: ignore[import]
2025-11-26T17:23:49.310216173Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:23:49.310257304Z   warnings.warn(
2025-11-26T17:23:49.310260489Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:23:49.310270664Z   warnings.warn(
2025-11-26T17:23:49.735944166Z Traceback (most recent call last):
2025-11-26T17:23:49.735979479Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 665, in <module>
2025-11-26T17:23:49.736735712Z     main(sys.argv[1:])
2025-11-26T17:23:49.736747750Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 102, in main
2025-11-26T17:23:49.736751356Z     config, _ = load_expr_config(args_with_overrides, GRPOConfig)
2025-11-26T17:23:49.736754130Z                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:23:49.736756153Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1282, in load_expr_config
2025-11-26T17:23:49.736758236Z     cfg = to_structured_cfg(cfg, config_cls=config_cls)
2025-11-26T17:23:49.736760610Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:23:49.736762603Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1276, in to_structured_cfg
2025-11-26T17:23:49.737372646Z     cfg = OmegaConf.merge(default_cfg, cfg)
2025-11-26T17:23:49.737411194Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:23:49.737414438Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/omegaconf.py", line 274, in merge
2025-11-26T17:23:49.737417463Z     target.merge_with(
2025-11-26T17:23:49.737420457Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 507, in merge_with
2025-11-26T17:23:49.737422891Z     self._format_and_raise(key=None, value=None, cause=e)
2025-11-26T17:23:49.737425725Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:23:49.737427808Z     format_and_raise(
2025-11-26T17:23:49.737429902Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:23:49.737942590Z     _raise(ex, cause)
2025-11-26T17:23:49.737946967Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:23:49.737949611Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:23:49.737951844Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:23:49.737954217Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 502, in merge_with
2025-11-26T17:23:49.737956761Z     self._merge_with(
2025-11-26T17:23:49.737958815Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:23:49.737961368Z     BaseContainer._map_merge(
2025-11-26T17:23:49.737964223Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:23:49.737966366Z     dest_node._merge_with(
2025-11-26T17:23:49.737968409Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:23:49.738536240Z     BaseContainer._map_merge(
2025-11-26T17:23:49.738542189Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:23:49.738544642Z     dest_node._merge_with(
2025-11-26T17:23:49.738546925Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:23:49.738549089Z     BaseContainer._map_merge(
2025-11-26T17:23:49.738551162Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 432, in _map_merge
2025-11-26T17:23:49.738553174Z     dest[key] = src._get_node(key)
2025-11-26T17:23:49.738555657Z     ~~~~^^^^^
2025-11-26T17:23:49.738558522Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 308, in __setitem__
2025-11-26T17:23:49.738560815Z     self._format_and_raise(
2025-11-26T17:23:49.738562818Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:23:49.738565022Z     format_and_raise(
2025-11-26T17:23:49.738567365Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:23:49.738569468Z     _raise(ex, cause)
2025-11-26T17:23:49.738571441Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:23:49.739198851Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:23:49.739207985Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:23:49.739210268Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 306, in __setitem__
2025-11-26T17:23:49.739212932Z     self.__set_impl(key=key, value=value)
2025-11-26T17:23:49.739214965Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 316, in __set_impl
2025-11-26T17:23:49.739217139Z     self._set_item_impl(key, value)
2025-11-26T17:23:49.739219392Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 579, in _set_item_impl
2025-11-26T17:23:49.739221485Z     target_node_ref = self._get_node(key)
2025-11-26T17:23:49.739223518Z                       ^^^^^^^^^^^^^^^^^^^
2025-11-26T17:23:49.739225601Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 473, in _get_node
2025-11-26T17:23:49.739498810Z     self._validate_get(key)
2025-11-26T17:23:49.739503287Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 163, in _validate_get
2025-11-26T17:23:49.739505661Z     self._format_and_raise(
2025-11-26T17:23:49.739507724Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:23:49.739509927Z     format_and_raise(
2025-11-26T17:23:49.739512061Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 906, in format_and_raise
2025-11-26T17:23:49.739519472Z     _raise(ex, cause)
2025-11-26T17:23:49.739521575Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:23:49.739814784Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:23:49.739818910Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:23:49.739821003Z omegaconf.errors.ConfigKeyError: Key 'max_new_tokens' not in 'NormConfig'
2025-11-26T17:23:49.739823056Z     full_key: actor.adv_norm.max_new_tokens
2025-11-26T17:23:49.739825029Z     reference_type=Optional[NormConfig]
2025-11-26T17:23:49.739827122Z     object_type=NormConfig
2025-11-26T17:23:52.311923418Z E1126 17:23:52.310000 966 torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 0 (pid: 1032) of binary: /usr/bin/python3
2025-11-26T17:23:52.312540673Z Traceback (most recent call last):
2025-11-26T17:23:52.312550408Z   File "/usr/local/bin/torchrun", line 7, in <module>
2025-11-26T17:23:52.312552972Z     sys.exit(main())
2025-11-26T17:23:52.312555656Z              ^^^^^^
2025-11-26T17:23:52.312557739Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
2025-11-26T17:23:52.312560593Z     return f(*args, **kwargs)
2025-11-26T17:23:52.312562826Z            ^^^^^^^^^^^^^^^^^^
2025-11-26T17:23:52.312565030Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 901, in main
2025-11-26T17:23:52.313163226Z     run(args)
2025-11-26T17:23:52.313205699Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 892, in run
2025-11-26T17:23:52.313209836Z     elastic_launch(
2025-11-26T17:23:52.313213842Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 143, in __call__
2025-11-26T17:23:52.313217797Z     return launch_agent(self._config, self._entrypoint, list(args))
2025-11-26T17:23:52.313221493Z            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:23:52.313224398Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 277, in launch_agent
2025-11-26T17:23:52.313230617Z     raise ChildFailedError(
2025-11-26T17:23:52.313234102Z torch.distributed.elastic.multiprocessing.errors.ChildFailedError:
2025-11-26T17:23:52.313236956Z ============================================================
2025-11-26T17:23:52.313240361Z examples/cloud_gsm8k/gsm8k_grpo_train.py FAILED
2025-11-26T17:23:52.313243876Z ------------------------------------------------------------
2025-11-26T17:23:52.313254822Z Failures:
2025-11-26T17:23:52.313257756Z   <NO_OTHER_FAILURES>
2025-11-26T17:23:52.313260601Z ------------------------------------------------------------
2025-11-26T17:23:52.313263435Z Root Cause (first observed failure):
2025-11-26T17:23:52.313266340Z [0]:
2025-11-26T17:23:52.313269694Z   time      : 2025-11-26_17:23:52
2025-11-26T17:23:52.313272609Z   host      : cef7c503fdea
2025-11-26T17:23:52.313275503Z   rank      : 0 (local_rank: 0)
2025-11-26T17:23:52.313278347Z   exitcode  : 1 (pid: 1032)
2025-11-26T17:23:52.313281182Z   error_file: <N/A>
2025-11-26T17:23:52.313284016Z   traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
2025-11-26T17:23:52.313286920Z ============================================================
2025-11-26T17:23:54.351683085Z [37m20251126-17:23:54.351 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [315][0m
2025-11-26T17:23:54.519856386Z Killed
2025-11-26T17:23:54.529355374Z [37m20251126-17:23:54.529 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [965][0m
2025-11-26T17:23:54.530361121Z Traceback (most recent call last):
2025-11-26T17:23:54.530367691Z   File "<frozen runpy>", line 198, in _run_module_as_main
2025-11-26T17:23:54.530369954Z   File "<frozen runpy>", line 88, in _run_code
2025-11-26T17:23:54.530372077Z   File "/workspace/AReaL/areal/launcher/local.py", line 405, in <module>
2025-11-26T17:23:54.530504786Z     main()
2025-11-26T17:23:54.530508131Z   File "/workspace/AReaL/areal/launcher/local.py", line 260, in main
2025-11-26T17:23:54.530608932Z     local_main(config, run_id=0)
2025-11-26T17:23:54.530612097Z   File "/workspace/AReaL/areal/launcher/local.py", line 399, in local_main
2025-11-26T17:23:54.530692668Z     raise e
2025-11-26T17:23:54.530694981Z   File "/workspace/AReaL/areal/launcher/local.py", line 375, in local_main
2025-11-26T17:23:54.530771215Z     launcher.wait(
2025-11-26T17:23:54.530773919Z   File "/workspace/AReaL/areal/launcher/local.py", line 235, in wait
2025-11-26T17:23:54.530817354Z     raise JobException(
2025-11-26T17:23:54.530820208Z areal.utils.launcher.JobException: Job gsm8k-grpo-cloud-2gpu-2000samples_trial_20251126_172304:trainer JobState.COMPLETED at node local
2025-11-26T17:23:54.771107196Z [37m20251126-17:23:54.770 Local Scheduler INFO: Waiting for 0 local running processes, pids: [0m
2025-11-26T17:24:07.972312293Z ==========
2025-11-26T17:24:07.972318052Z == CUDA ==
2025-11-26T17:24:07.972320395Z ==========
2025-11-26T17:24:07.977097331Z CUDA Version 12.9.1
2025-11-26T17:24:07.979056765Z Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
2025-11-26T17:24:07.980597694Z This container image and its contents are governed by the NVIDIA Deep Learning Container License.
2025-11-26T17:24:07.980601049Z By pulling and using the container, you accept the terms and conditions of this license:
2025-11-26T17:24:07.980603843Z https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license
2025-11-26T17:24:07.980609081Z A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
2025-11-26T17:24:08.145691533Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:24:08.303292387Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:24:08.485179941Z Branch 'feature/reasoning_model' set up to track remote branch 'feature/reasoning_model' from 'origin'.
2025-11-26T17:24:08.485219870Z Your branch is up to date with 'origin/feature/reasoning_model'.
2025-11-26T17:24:08.556879357Z Checking AReaL installation...
2025-11-26T17:24:08.615949716Z AReaL already installed. Skipping installation.
2025-11-26T17:24:08.616004107Z Cleaning up any leftover GPU processes...
2025-11-26T17:24:11.637216670Z Checking for processes holding GPU device files...
2025-11-26T17:24:14.379952409Z Found processes holding GPU devices: 1
2025-11-26T17:24:14.379996836Z 20
2025-11-26T17:24:14.380000212Z 71
2025-11-26T17:24:14.380002344Z 72
2025-11-26T17:24:14.380004418Z Killing process 1...
2025-11-26T17:24:14.380016656Z Killing process 71...
2025-11-26T17:24:14.380073031Z Killing process 72...
2025-11-26T17:24:16.382731796Z Using fuser to kill processes on GPU devices...
2025-11-26T17:24:18.408634256Z Checking GPU...
2025-11-26T17:24:18.443745698Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:24:18.443772528Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:24:18.461532540Z Set PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True for better memory management
2025-11-26T17:24:18.461552039Z Detected 2 GPU(s)
2025-11-26T17:24:18.461555034Z Checking GPU status...
2025-11-26T17:24:18.496914278Z index, name, utilization.gpu [%], memory.used [MiB], compute_mode
2025-11-26T17:24:18.498347084Z 0, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:24:18.498678000Z 1, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:24:18.543264915Z Verifying GPU accessibility...
2025-11-26T17:24:19.244007753Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:24:19.244057559Z   import pynvml  # type: ignore[import]
2025-11-26T17:24:20.363670989Z GPU accessibility verified on attempt 1
2025-11-26T17:24:20.915308028Z Starting training...
2025-11-26T17:24:23.918274839Z Using STANDARD 2000 SAMPLES 2 GPUs configuration
2025-11-26T17:24:23.918313057Z Note: GRPO only (no reasoning XML). Dataset capped at 2000 samples (~6 hours).
2025-11-26T17:24:23.918316252Z GPU count: 2 (required: 2)
2025-11-26T17:24:23.920718480Z ==========================================
2025-11-26T17:24:23.920721555Z Starting GRPO Training (Cloud)
2025-11-26T17:24:23.920724119Z ==========================================
2025-11-26T17:24:23.920726151Z Config: standard_2000samples_2GPUs
2025-11-26T17:24:23.920728405Z Config file: examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml
2025-11-26T17:24:23.920731029Z Training script: examples/cloud_gsm8k/gsm8k_grpo_train.py
2025-11-26T17:24:23.920733573Z Experiment: gsm8k-grpo-cloud-2gpu-2000samples
2025-11-26T17:24:23.920735546Z Trial: trial_20251126_172423
2025-11-26T17:24:23.920737609Z GPU: NVIDIA A100 80GB PCIe NVIDIA A100 80GB PCIe (81920 MB)
2025-11-26T17:24:23.920739652Z WandB API key: e1adc5be02...
2025-11-26T17:24:23.920741665Z ==========================================
2025-11-26T17:24:24.630776792Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:24:24.630822170Z   import pynvml  # type: ignore[import]
2025-11-26T17:24:28.818090747Z [37m20251126-17:24:28.817 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:24:28.818155384Z [37m20251126-17:24:28.817 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:24:28.818336486Z [37m20251126-17:24:28.818 name-resolve INFO: No such name resolve path: ./tmp/areal/name_resolve/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_172423[0m
2025-11-26T17:24:28.923789780Z [37m20251126-17:24:28.923 Local Scheduler INFO: LocalLauncher: experiment_name=gsm8k-grpo-cloud-2gpu-2000samples, trial_name=trial_20251126_172423, fileroot=/workspace/outputs/grpo, run_id=0, is_recover_run=False[0m
2025-11-26T17:24:28.931637765Z [37m20251126-17:24:28.931 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL CUDA_VISIBLE_DEVICES=0 stdbuf -oL python3 -m areal.launcher.sglang_server examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_172423 sglang.random_seed=1 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_172423/llm_server.log[0m
2025-11-26T17:24:29.659213938Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:24:29.659250812Z   import pynvml  # type: ignore[import]
2025-11-26T17:24:31.121721938Z [37m20251126-17:24:31.121 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:24:31.122150110Z [37m20251126-17:24:31.121 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:24:31.225068958Z [37m20251126-17:24:31.224 SGLangServer Wrapper INFO: Launch command: python3 -m sglang.launch_server --host 172.21.0.2 --port 25418 --tokenizer-path Qwen/Qwen2.5-0.5B-Instruct --tokenizer-mode auto --load-format auto --trust-remote-code --device cuda --tp-size 1 --base-gpu-id 0 --nnodes 1 --node-rank 0 --dist-init-addr localhost:26801 --model-path Qwen/Qwen2.5-0.5B-Instruct --random-seed 1 --skip-tokenizer-init --disable-radix-cache --torch-compile-max-bs 32 --triton-attention-num-kv-splits 8 --num-continuous-decode-steps 1 --attention-backend flashinfer --context-length 4096 --mem-fraction-static 0.6 --chunked-prefill-size -1 --max-prefill-tokens 32768 --schedule-policy lpm --schedule-conservativeness 1.0 --cpu-offload-gb 0 --dtype bfloat16 --kv-cache-dtype auto --dp-size 1 --ep-size 1 --max-loaded-loras 1 --max-loras-per-batch 1 --lora-backend triton --log-level warning --log-level-http warning --log-requests-level 0 --enable-metrics --decode-log-interval 1[0m
2025-11-26T17:24:32.353450784Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:24:32.353486486Z   import pynvml  # type: ignore[import]
2025-11-26T17:24:37.860371864Z INFO 11-26 17:24:37 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:24:38.503589558Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:24:39.516300312Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:24:39.516340924Z   import pynvml  # type: ignore[import]
2025-11-26T17:24:39.524933595Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:24:39.524953153Z   import pynvml  # type: ignore[import]
2025-11-26T17:24:44.964577422Z INFO 11-26 17:24:44 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:24:45.126144137Z INFO 11-26 17:24:45 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:24:45.564757411Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:24:45.789502159Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:24:45.793170704Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:24:45.793983241Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:24:45.794831792Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:24:45.827789638Z [2025-11-26 17:24:45] MOE_RUNNER_BACKEND is not initialized, using triton backend
2025-11-26T17:24:46.332485455Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:24:46.332534869Z   warnings.warn(
2025-11-26T17:24:46.332538414Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:24:46.332540878Z   warnings.warn(
2025-11-26T17:24:47.488633270Z Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
2025-11-26T17:24:47.592490183Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  9.65it/s]
2025-11-26T17:24:47.593083162Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  9.63it/s]
2025-11-26T17:24:50.094529534Z   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   4%|â–         | 1/23 [00:00<00:12,  1.77it/s]Capturing batches (bs=152 avail_mem=30.62 GB):   4%|â–         | 1/23 [00:00<00:12,  1.77it/s]Capturing batches (bs=144 avail_mem=30.60 GB):   4%|â–         | 1/23 [00:00<00:12,  1.77it/s]Capturing batches (bs=136 avail_mem=30.59 GB):   4%|â–         | 1/23 [00:00<00:12,  1.77it/s]Capturing batches (bs=136 avail_mem=30.59 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.01it/s]Capturing batches (bs=128 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.01it/s]Capturing batches (bs=120 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.01it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.01it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.25it/s]Capturing batches (bs=104 avail_mem=30.54 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.25it/s]Capturing batches (bs=96 avail_mem=30.53 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.25it/s] Capturing batches (bs=88 avail_mem=30.51 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.25it/s]Capturing batches (bs=88 avail_mem=30.51 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.65it/s]Capturing batches (bs=80 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.65it/s]Capturing batches (bs=72 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.65it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:01<00:00, 14.65it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.24it/s]Capturing batches (bs=56 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.24it/s]Capturing batches (bs=48 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.24it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.24it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.36it/s]Capturing batches (bs=32 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.36it/s]Capturing batches (bs=24 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.36it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.36it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.75it/s]Capturing batches (bs=8 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.75it/s] Capturing batches (bs=4 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.75it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.75it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.65it/s]Capturing batches (bs=1 avail_mem=30.35 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.65it/s]Capturing batches (bs=1 avail_mem=30.35 GB): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00, 14.78it/s]
2025-11-26T17:24:56.252103194Z [37m20251126-17:24:56.251 SGLangServer Wrapper INFO: SGLang server launched at: http://172.21.0.2:25418[0m
2025-11-26T17:24:56.938670970Z [37m20251126-17:24:56.938 Launcher Utils INFO: Found 1 rollout servers: 172.21.0.2:25418[0m
2025-11-26T17:24:56.938708627Z [37m20251126-17:24:56.938 Local Scheduler INFO: LLM inference server launched at: AREAL_LLM_SERVER_ADDRS=172.21.0.2:25418[0m
2025-11-26T17:24:56.942213516Z [37m20251126-17:24:56.941 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL AREAL_LLM_SERVER_ADDRS=172.21.0.2:25418 AREAL_RECOVER_RUN=0 NCCL_CUMEM_ENABLE=0 NCCL_NVLS_ENABLE=0 CUDA_VISIBLE_DEVICES=1 stdbuf -oL torchrun --nnodes 1 --nproc-per-node 1 --master-addr localhost --master-port 19781 examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_172423 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_172423/trainer.log[0m
2025-11-26T17:24:56.942850120Z [37m20251126-17:24:56.942 Local Scheduler INFO: Waiting for 2 local running processes, pids: 315 965[0m
2025-11-26T17:24:57.473702727Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:24:57.473739381Z   import pynvml  # type: ignore[import]
2025-11-26T17:24:58.662850761Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:24:58.662888257Z   import pynvml  # type: ignore[import]
2025-11-26T17:25:05.418921830Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:25:05.418966648Z   warnings.warn(
2025-11-26T17:25:05.418969632Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:25:05.418971965Z   warnings.warn(
2025-11-26T17:25:05.866835255Z Traceback (most recent call last):
2025-11-26T17:25:05.866884638Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 665, in <module>
2025-11-26T17:25:05.867476095Z     main(sys.argv[1:])
2025-11-26T17:25:05.867516195Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 102, in main
2025-11-26T17:25:05.867519510Z     config, _ = load_expr_config(args_with_overrides, GRPOConfig)
2025-11-26T17:25:05.867524127Z                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:25:05.867526220Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1282, in load_expr_config
2025-11-26T17:25:05.867936464Z     cfg = to_structured_cfg(cfg, config_cls=config_cls)
2025-11-26T17:25:05.867942052Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:25:05.867944316Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1276, in to_structured_cfg
2025-11-26T17:25:05.867947290Z     cfg = OmegaConf.merge(default_cfg, cfg)
2025-11-26T17:25:05.867949353Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:25:05.867951346Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/omegaconf.py", line 274, in merge
2025-11-26T17:25:05.868296513Z     target.merge_with(
2025-11-26T17:25:05.868304215Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 507, in merge_with
2025-11-26T17:25:05.868308251Z     self._format_and_raise(key=None, value=None, cause=e)
2025-11-26T17:25:05.868311085Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:25:05.868313198Z     format_and_raise(
2025-11-26T17:25:05.868315301Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:25:05.868317535Z     _raise(ex, cause)
2025-11-26T17:25:05.868803193Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:25:05.868809291Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:25:05.868811935Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:25:05.868814709Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 502, in merge_with
2025-11-26T17:25:05.868817504Z     self._merge_with(
2025-11-26T17:25:05.868820398Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:25:05.868822812Z     BaseContainer._map_merge(
2025-11-26T17:25:05.868826477Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:25:05.869195490Z     dest_node._merge_with(
2025-11-26T17:25:05.869201699Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:25:05.869204343Z     BaseContainer._map_merge(
2025-11-26T17:25:05.869206396Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:25:05.869208490Z     dest_node._merge_with(
2025-11-26T17:25:05.869210562Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:25:05.869212636Z     BaseContainer._map_merge(
2025-11-26T17:25:05.869214989Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 432, in _map_merge
2025-11-26T17:25:05.869217052Z     dest[key] = src._get_node(key)
2025-11-26T17:25:05.869797973Z     ~~~~^^^^^
2025-11-26T17:25:05.869801948Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 308, in __setitem__
2025-11-26T17:25:05.869804672Z     self._format_and_raise(
2025-11-26T17:25:05.869806946Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:25:05.869809079Z     format_and_raise(
2025-11-26T17:25:05.869811092Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:25:05.869813145Z     _raise(ex, cause)
2025-11-26T17:25:05.869815319Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:25:05.869817532Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:25:05.869827938Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:25:05.869830281Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 306, in __setitem__
2025-11-26T17:25:05.870052103Z     self.__set_impl(key=key, value=value)
2025-11-26T17:25:05.870056329Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 316, in __set_impl
2025-11-26T17:25:05.870058793Z     self._set_item_impl(key, value)
2025-11-26T17:25:05.870061006Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 579, in _set_item_impl
2025-11-26T17:25:05.870063110Z     target_node_ref = self._get_node(key)
2025-11-26T17:25:05.871048355Z                       ^^^^^^^^^^^^^^^^^^^
2025-11-26T17:25:05.871084089Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 473, in _get_node
2025-11-26T17:25:05.871087625Z     self._validate_get(key)
2025-11-26T17:25:05.871093614Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 163, in _validate_get
2025-11-26T17:25:05.871097489Z     self._format_and_raise(
2025-11-26T17:25:05.871099963Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:25:05.871102136Z     format_and_raise(
2025-11-26T17:25:05.871104920Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 906, in format_and_raise
2025-11-26T17:25:05.871106943Z     _raise(ex, cause)
2025-11-26T17:25:05.871108937Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:25:05.871149967Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:25:05.871154594Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:25:05.871156767Z omegaconf.errors.ConfigKeyError: Key 'max_new_tokens' not in 'NormConfig'
2025-11-26T17:25:05.871159772Z     full_key: actor.adv_norm.max_new_tokens
2025-11-26T17:25:05.871161885Z     reference_type=Optional[NormConfig]
2025-11-26T17:25:05.871163918Z     object_type=NormConfig
2025-11-26T17:25:08.264947146Z E1126 17:25:08.263000 966 torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 0 (pid: 1032) of binary: /usr/bin/python3
2025-11-26T17:25:08.265582117Z Traceback (most recent call last):
2025-11-26T17:25:08.265592721Z   File "/usr/local/bin/torchrun", line 7, in <module>
2025-11-26T17:25:08.265595776Z     sys.exit(main())
2025-11-26T17:25:08.265598460Z              ^^^^^^
2025-11-26T17:25:08.265600733Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
2025-11-26T17:25:08.265604920Z     return f(*args, **kwargs)
2025-11-26T17:25:08.265607584Z            ^^^^^^^^^^^^^^^^^^
2025-11-26T17:25:08.265609547Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 901, in main
2025-11-26T17:25:08.266249356Z     run(args)
2025-11-26T17:25:08.266254212Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 892, in run
2025-11-26T17:25:08.266256987Z     elastic_launch(
2025-11-26T17:25:08.266259711Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 143, in __call__
2025-11-26T17:25:08.266262195Z     return launch_agent(self._config, self._entrypoint, list(args))
2025-11-26T17:25:08.266266130Z            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:25:08.266268314Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 277, in launch_agent
2025-11-26T17:25:08.266270347Z     raise ChildFailedError(
2025-11-26T17:25:08.266272771Z torch.distributed.elastic.multiprocessing.errors.ChildFailedError:
2025-11-26T17:25:08.266275014Z ============================================================
2025-11-26T17:25:08.266277578Z examples/cloud_gsm8k/gsm8k_grpo_train.py FAILED
2025-11-26T17:25:08.266280212Z ------------------------------------------------------------
2025-11-26T17:25:08.266282245Z Failures:
2025-11-26T17:25:08.266284248Z   <NO_OTHER_FAILURES>
2025-11-26T17:25:08.266286261Z ------------------------------------------------------------
2025-11-26T17:25:08.266297468Z Root Cause (first observed failure):
2025-11-26T17:25:08.266299621Z [0]:
2025-11-26T17:25:08.266301734Z   time      : 2025-11-26_17:25:08
2025-11-26T17:25:08.266303787Z   host      : cef7c503fdea
2025-11-26T17:25:08.266305820Z   rank      : 0 (local_rank: 0)
2025-11-26T17:25:08.266307883Z   exitcode  : 1 (pid: 1032)
2025-11-26T17:25:08.266309886Z   error_file: <N/A>
2025-11-26T17:25:08.266311899Z   traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
2025-11-26T17:25:08.266313982Z ============================================================
2025-11-26T17:25:08.946533960Z [37m20251126-17:25:08.946 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [315][0m
2025-11-26T17:25:09.096693590Z Killed
2025-11-26T17:25:09.107016201Z [37m20251126-17:25:09.106 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [965][0m
2025-11-26T17:25:09.108299114Z Traceback (most recent call last):
2025-11-26T17:25:09.108307006Z   File "<frozen runpy>", line 198, in _run_module_as_main
2025-11-26T17:25:09.108310651Z   File "<frozen runpy>", line 88, in _run_code
2025-11-26T17:25:09.108313485Z   File "/workspace/AReaL/areal/launcher/local.py", line 405, in <module>
2025-11-26T17:25:09.108453915Z     main()
2025-11-26T17:25:09.108462758Z   File "/workspace/AReaL/areal/launcher/local.py", line 260, in main
2025-11-26T17:25:09.108556860Z     local_main(config, run_id=0)
2025-11-26T17:25:09.108561937Z   File "/workspace/AReaL/areal/launcher/local.py", line 399, in local_main
2025-11-26T17:25:09.108629719Z     raise e
2025-11-26T17:25:09.108633054Z   File "/workspace/AReaL/areal/launcher/local.py", line 375, in local_main
2025-11-26T17:25:09.108703769Z     launcher.wait(
2025-11-26T17:25:09.108707865Z   File "/workspace/AReaL/areal/launcher/local.py", line 235, in wait
2025-11-26T17:25:09.108761646Z     raise JobException(
2025-11-26T17:25:09.108764671Z areal.utils.launcher.JobException: Job gsm8k-grpo-cloud-2gpu-2000samples_trial_20251126_172423:trainer JobState.COMPLETED at node local
2025-11-26T17:25:09.311031260Z [37m20251126-17:25:09.310 Local Scheduler INFO: Waiting for 0 local running processes, pids: [0m
2025-11-26T17:25:12.253610939Z ==========
2025-11-26T17:25:12.253613863Z == CUDA ==
2025-11-26T17:25:12.253618801Z ==========
2025-11-26T17:25:12.258238831Z CUDA Version 12.9.1
2025-11-26T17:25:12.259985467Z Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
2025-11-26T17:25:12.261646895Z This container image and its contents are governed by the NVIDIA Deep Learning Container License.
2025-11-26T17:25:12.261649840Z By pulling and using the container, you accept the terms and conditions of this license:
2025-11-26T17:25:12.261652584Z https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license
2025-11-26T17:25:12.261657411Z A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
2025-11-26T17:25:12.427053933Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:25:12.585542408Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:25:12.772451853Z Branch 'feature/reasoning_model' set up to track remote branch 'feature/reasoning_model' from 'origin'.
2025-11-26T17:25:12.772482670Z Your branch is up to date with 'origin/feature/reasoning_model'.
2025-11-26T17:25:12.842412245Z Checking AReaL installation...
2025-11-26T17:25:12.901210877Z AReaL already installed. Skipping installation.
2025-11-26T17:25:12.901240241Z Cleaning up any leftover GPU processes...
2025-11-26T17:25:15.920356403Z Checking for processes holding GPU device files...
2025-11-26T17:25:17.840782674Z Found processes holding GPU devices: 1
2025-11-26T17:25:17.840828543Z 20
2025-11-26T17:25:17.840832059Z 71
2025-11-26T17:25:17.840834202Z 72
2025-11-26T17:25:17.840836235Z Killing process 1...
2025-11-26T17:25:17.840838979Z Killing process 71...
2025-11-26T17:25:17.840913790Z Killing process 72...
2025-11-26T17:25:19.843577483Z Using fuser to kill processes on GPU devices...
2025-11-26T17:25:21.865296557Z Checking GPU...
2025-11-26T17:25:21.908645287Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:25:21.908675863Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:25:21.926187393Z Set PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True for better memory management
2025-11-26T17:25:21.926202896Z Detected 2 GPU(s)
2025-11-26T17:25:21.926206071Z Checking GPU status...
2025-11-26T17:25:21.953812302Z index, name, utilization.gpu [%], memory.used [MiB], compute_mode
2025-11-26T17:25:21.955288363Z 0, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:25:21.955599829Z 1, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:25:21.999013878Z Verifying GPU accessibility...
2025-11-26T17:25:22.516769426Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:25:22.516829096Z   import pynvml  # type: ignore[import]
2025-11-26T17:25:23.623951165Z GPU accessibility verified on attempt 1
2025-11-26T17:25:24.073301343Z Starting training...
2025-11-26T17:25:27.076215846Z Using STANDARD 2000 SAMPLES 2 GPUs configuration
2025-11-26T17:25:27.076259521Z Note: GRPO only (no reasoning XML). Dataset capped at 2000 samples (~6 hours).
2025-11-26T17:25:27.076263157Z GPU count: 2 (required: 2)
2025-11-26T17:25:27.078827968Z ==========================================
2025-11-26T17:25:27.078831213Z Starting GRPO Training (Cloud)
2025-11-26T17:25:27.078833788Z ==========================================
2025-11-26T17:25:27.078835931Z Config: standard_2000samples_2GPUs
2025-11-26T17:25:27.078837934Z Config file: examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml
2025-11-26T17:25:27.078840698Z Training script: examples/cloud_gsm8k/gsm8k_grpo_train.py
2025-11-26T17:25:27.078842971Z Experiment: gsm8k-grpo-cloud-2gpu-2000samples
2025-11-26T17:25:27.078844994Z Trial: trial_20251126_172527
2025-11-26T17:25:27.078846997Z GPU: NVIDIA A100 80GB PCIe NVIDIA A100 80GB PCIe (81920 MB)
2025-11-26T17:25:27.078849010Z WandB API key: e1adc5be02...
2025-11-26T17:25:27.078850983Z ==========================================
2025-11-26T17:25:27.834944420Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:25:27.834983298Z   import pynvml  # type: ignore[import]
2025-11-26T17:25:33.445886109Z [37m20251126-17:25:33.445 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:25:33.445939038Z [37m20251126-17:25:33.445 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:25:33.446439008Z [37m20251126-17:25:33.446 name-resolve INFO: No such name resolve path: ./tmp/areal/name_resolve/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_172527[0m
2025-11-26T17:25:33.641310018Z [37m20251126-17:25:33.640 Local Scheduler INFO: LocalLauncher: experiment_name=gsm8k-grpo-cloud-2gpu-2000samples, trial_name=trial_20251126_172527, fileroot=/workspace/outputs/grpo, run_id=0, is_recover_run=False[0m
2025-11-26T17:25:33.654772332Z [37m20251126-17:25:33.654 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL CUDA_VISIBLE_DEVICES=0 stdbuf -oL python3 -m areal.launcher.sglang_server examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_172527 sglang.random_seed=1 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_172527/llm_server.log[0m
2025-11-26T17:25:34.397409214Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:25:34.397455873Z   import pynvml  # type: ignore[import]
2025-11-26T17:25:36.528421524Z [37m20251126-17:25:36.527 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:25:36.529021563Z [37m20251126-17:25:36.528 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:25:36.663971840Z [37m20251126-17:25:36.663 SGLangServer Wrapper INFO: Launch command: python3 -m sglang.launch_server --host 172.21.0.2 --port 17587 --tokenizer-path Qwen/Qwen2.5-0.5B-Instruct --tokenizer-mode auto --load-format auto --trust-remote-code --device cuda --tp-size 1 --base-gpu-id 0 --nnodes 1 --node-rank 0 --dist-init-addr localhost:22659 --model-path Qwen/Qwen2.5-0.5B-Instruct --random-seed 1 --skip-tokenizer-init --disable-radix-cache --torch-compile-max-bs 32 --triton-attention-num-kv-splits 8 --num-continuous-decode-steps 1 --attention-backend flashinfer --context-length 4096 --mem-fraction-static 0.6 --chunked-prefill-size -1 --max-prefill-tokens 32768 --schedule-policy lpm --schedule-conservativeness 1.0 --cpu-offload-gb 0 --dtype bfloat16 --kv-cache-dtype auto --dp-size 1 --ep-size 1 --max-loaded-loras 1 --max-loras-per-batch 1 --lora-backend triton --log-level warning --log-level-http warning --log-requests-level 0 --enable-metrics --decode-log-interval 1[0m
2025-11-26T17:25:37.719974671Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:25:37.720014080Z   import pynvml  # type: ignore[import]
2025-11-26T17:25:44.274149357Z INFO 11-26 17:25:44 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:25:44.907650747Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:25:46.278579625Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:25:46.278619705Z   import pynvml  # type: ignore[import]
2025-11-26T17:25:46.303798811Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:25:46.303819772Z   import pynvml  # type: ignore[import]
2025-11-26T17:25:51.789318604Z INFO 11-26 17:25:51 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:25:51.964655415Z INFO 11-26 17:25:51 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:25:52.564321515Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:25:52.836224148Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:25:52.840077681Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:25:52.841039672Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:25:52.841942965Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:25:52.875059869Z [2025-11-26 17:25:52] MOE_RUNNER_BACKEND is not initialized, using triton backend
2025-11-26T17:25:53.368939424Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:25:53.368987737Z   warnings.warn(
2025-11-26T17:25:53.368990871Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:25:53.368993014Z   warnings.warn(
2025-11-26T17:25:54.534854749Z Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
2025-11-26T17:25:54.642440318Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  9.31it/s]
2025-11-26T17:25:54.642883833Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  9.29it/s]
2025-11-26T17:25:57.125078347Z   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   4%|â–         | 1/23 [00:00<00:11,  1.88it/s]Capturing batches (bs=152 avail_mem=30.62 GB):   4%|â–         | 1/23 [00:00<00:11,  1.88it/s]Capturing batches (bs=144 avail_mem=30.60 GB):   4%|â–         | 1/23 [00:00<00:11,  1.88it/s]Capturing batches (bs=136 avail_mem=30.59 GB):   4%|â–         | 1/23 [00:00<00:11,  1.88it/s]Capturing batches (bs=136 avail_mem=30.59 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.39it/s]Capturing batches (bs=128 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.39it/s]Capturing batches (bs=120 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.39it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.39it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.73it/s]Capturing batches (bs=104 avail_mem=30.54 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.73it/s]Capturing batches (bs=96 avail_mem=30.53 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.73it/s] Capturing batches (bs=88 avail_mem=30.51 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.73it/s]Capturing batches (bs=88 avail_mem=30.51 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 15.10it/s]Capturing batches (bs=80 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 15.10it/s]Capturing batches (bs=72 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 15.10it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 15.10it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.63it/s]Capturing batches (bs=56 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.63it/s]Capturing batches (bs=48 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.63it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.63it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.67it/s]Capturing batches (bs=32 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.67it/s]Capturing batches (bs=24 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.67it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.67it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 18.09it/s]Capturing batches (bs=8 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 18.09it/s] Capturing batches (bs=4 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 18.09it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 18.09it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.93it/s]Capturing batches (bs=1 avail_mem=30.35 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.93it/s]Capturing batches (bs=1 avail_mem=30.35 GB): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00, 15.21it/s]
2025-11-26T17:26:02.694096891Z [37m20251126-17:26:02.693 SGLangServer Wrapper INFO: SGLang server launched at: http://172.21.0.2:17587[0m
2025-11-26T17:26:03.662703906Z [37m20251126-17:26:03.662 Launcher Utils INFO: Found 1 rollout servers: 172.21.0.2:17587[0m
2025-11-26T17:26:03.662758376Z [37m20251126-17:26:03.662 Local Scheduler INFO: LLM inference server launched at: AREAL_LLM_SERVER_ADDRS=172.21.0.2:17587[0m
2025-11-26T17:26:03.665228166Z [37m20251126-17:26:03.664 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL AREAL_LLM_SERVER_ADDRS=172.21.0.2:17587 AREAL_RECOVER_RUN=0 NCCL_CUMEM_ENABLE=0 NCCL_NVLS_ENABLE=0 CUDA_VISIBLE_DEVICES=1 stdbuf -oL torchrun --nnodes 1 --nproc-per-node 1 --master-addr localhost --master-port 27446 examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_172527 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_172527/trainer.log[0m
2025-11-26T17:26:03.665821255Z [37m20251126-17:26:03.665 Local Scheduler INFO: Waiting for 2 local running processes, pids: 315 965[0m
2025-11-26T17:26:04.186884958Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:26:04.186938579Z   import pynvml  # type: ignore[import]
2025-11-26T17:26:05.382599699Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:26:05.382641241Z   import pynvml  # type: ignore[import]
2025-11-26T17:26:12.049230368Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:26:12.049282547Z   warnings.warn(
2025-11-26T17:26:12.049286844Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:26:12.049289117Z   warnings.warn(
2025-11-26T17:26:12.513549387Z Traceback (most recent call last):
2025-11-26T17:26:12.513586953Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 665, in <module>
2025-11-26T17:26:12.514449364Z     main(sys.argv[1:])
2025-11-26T17:26:12.514495132Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 102, in main
2025-11-26T17:26:12.514498948Z     config, _ = load_expr_config(args_with_overrides, GRPOConfig)
2025-11-26T17:26:12.514501802Z                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:26:12.514504266Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1282, in load_expr_config
2025-11-26T17:26:12.514796454Z     cfg = to_structured_cfg(cfg, config_cls=config_cls)
2025-11-26T17:26:12.514802673Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:26:12.514804866Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1276, in to_structured_cfg
2025-11-26T17:26:12.515258286Z     cfg = OmegaConf.merge(default_cfg, cfg)
2025-11-26T17:26:12.515264836Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:26:12.515267069Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/omegaconf.py", line 274, in merge
2025-11-26T17:26:12.515269503Z     target.merge_with(
2025-11-26T17:26:12.515272107Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 507, in merge_with
2025-11-26T17:26:12.515971834Z     self._format_and_raise(key=None, value=None, cause=e)
2025-11-26T17:26:12.515974478Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:26:12.515977573Z     format_and_raise(
2025-11-26T17:26:12.515980427Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:26:12.515982611Z     _raise(ex, cause)
2025-11-26T17:26:12.515984764Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:26:12.515987117Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:26:12.515989230Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:26:12.515991434Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 502, in merge_with
2025-11-26T17:26:12.516377793Z     self._merge_with(
2025-11-26T17:26:12.516387307Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:26:12.516391133Z     BaseContainer._map_merge(
2025-11-26T17:26:12.516393767Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:26:12.516396110Z     dest_node._merge_with(
2025-11-26T17:26:12.516398754Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:26:12.516660937Z     BaseContainer._map_merge(
2025-11-26T17:26:12.516665684Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:26:12.516668178Z     dest_node._merge_with(
2025-11-26T17:26:12.516670461Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:26:12.516672714Z     BaseContainer._map_merge(
2025-11-26T17:26:12.516674808Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 432, in _map_merge
2025-11-26T17:26:12.516927015Z     dest[key] = src._get_node(key)
2025-11-26T17:26:12.516929389Z     ~~~~^^^^^
2025-11-26T17:26:12.516932704Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 308, in __setitem__
2025-11-26T17:26:12.516934847Z     self._format_and_raise(
2025-11-26T17:26:12.516937481Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:26:12.517477710Z     format_and_raise(
2025-11-26T17:26:12.517485943Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:26:12.517488166Z     _raise(ex, cause)
2025-11-26T17:26:12.517490139Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:26:12.517492142Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:26:12.517494285Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:26:12.517738010Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 306, in __setitem__
2025-11-26T17:26:12.517744199Z     self.__set_impl(key=key, value=value)
2025-11-26T17:26:12.517746292Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 316, in __set_impl
2025-11-26T17:26:12.517748445Z     self._set_item_impl(key, value)
2025-11-26T17:26:12.517750579Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 579, in _set_item_impl
2025-11-26T17:26:12.518023528Z     target_node_ref = self._get_node(key)
2025-11-26T17:26:12.518026101Z                       ^^^^^^^^^^^^^^^^^^^
2025-11-26T17:26:12.518028095Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 473, in _get_node
2025-11-26T17:26:12.518310427Z     self._validate_get(key)
2025-11-26T17:26:12.518314524Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 163, in _validate_get
2025-11-26T17:26:12.518316716Z     self._format_and_raise(
2025-11-26T17:26:12.518319050Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:26:12.518621052Z     format_and_raise(
2025-11-26T17:26:12.518624478Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 906, in format_and_raise
2025-11-26T17:26:12.518626481Z     _raise(ex, cause)
2025-11-26T17:26:12.518628464Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:26:12.518889194Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:26:12.518891918Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:26:12.518893921Z omegaconf.errors.ConfigKeyError: Key 'max_new_tokens' not in 'NormConfig'
2025-11-26T17:26:12.518897006Z     full_key: actor.adv_norm.max_new_tokens
2025-11-26T17:26:12.518898989Z     reference_type=Optional[NormConfig]
2025-11-26T17:26:12.518901142Z     object_type=NormConfig
2025-11-26T17:26:15.477179668Z E1126 17:26:15.476000 966 torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 0 (pid: 1032) of binary: /usr/bin/python3
2025-11-26T17:26:15.477719466Z Traceback (most recent call last):
2025-11-26T17:26:15.477726276Z   File "/usr/local/bin/torchrun", line 7, in <module>
2025-11-26T17:26:15.478230702Z     sys.exit(main())
2025-11-26T17:26:15.478238834Z              ^^^^^^
2025-11-26T17:26:15.478241237Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
2025-11-26T17:26:15.478245364Z     return f(*args, **kwargs)
2025-11-26T17:26:15.478247897Z            ^^^^^^^^^^^^^^^^^^
2025-11-26T17:26:15.478249900Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 901, in main
2025-11-26T17:26:15.478253756Z     run(args)
2025-11-26T17:26:15.478617742Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 892, in run
2025-11-26T17:26:15.478624752Z     elastic_launch(
2025-11-26T17:26:15.478627346Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 143, in __call__
2025-11-26T17:26:15.478630300Z     return launch_agent(self._config, self._entrypoint, list(args))
2025-11-26T17:26:15.479077800Z            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:26:15.479081015Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 277, in launch_agent
2025-11-26T17:26:15.479083328Z     raise ChildFailedError(
2025-11-26T17:26:15.479085482Z torch.distributed.elastic.multiprocessing.errors.ChildFailedError:
2025-11-26T17:26:15.479087935Z ============================================================
2025-11-26T17:26:15.479090369Z examples/cloud_gsm8k/gsm8k_grpo_train.py FAILED
2025-11-26T17:26:15.479092893Z ------------------------------------------------------------
2025-11-26T17:26:15.479094966Z Failures:
2025-11-26T17:26:15.479096949Z   <NO_OTHER_FAILURES>
2025-11-26T17:26:15.479098982Z ------------------------------------------------------------
2025-11-26T17:26:15.479101095Z Root Cause (first observed failure):
2025-11-26T17:26:15.479103118Z [0]:
2025-11-26T17:26:15.479128075Z   time      : 2025-11-26_17:26:15
2025-11-26T17:26:15.479132372Z   host      : cef7c503fdea
2025-11-26T17:26:15.479134425Z   rank      : 0 (local_rank: 0)
2025-11-26T17:26:15.479136388Z   exitcode  : 1 (pid: 1032)
2025-11-26T17:26:15.479138521Z   error_file: <N/A>
2025-11-26T17:26:15.479140524Z   traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
2025-11-26T17:26:15.479142657Z ============================================================
2025-11-26T17:26:17.669856243Z [37m20251126-17:26:17.669 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [315][0m
2025-11-26T17:26:17.790501223Z Killed
2025-11-26T17:26:17.802567247Z [37m20251126-17:26:17.802 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [965][0m
2025-11-26T17:26:17.804104939Z Traceback (most recent call last):
2025-11-26T17:26:17.804137548Z   File "<frozen runpy>", line 198, in _run_module_as_main
2025-11-26T17:26:17.804140392Z   File "<frozen runpy>", line 88, in _run_code
2025-11-26T17:26:17.804142566Z   File "/workspace/AReaL/areal/launcher/local.py", line 405, in <module>
2025-11-26T17:26:17.804291038Z     main()
2025-11-26T17:26:17.804317929Z   File "/workspace/AReaL/areal/launcher/local.py", line 260, in main
2025-11-26T17:26:17.804422355Z     local_main(config, run_id=0)
2025-11-26T17:26:17.804426832Z   File "/workspace/AReaL/areal/launcher/local.py", line 399, in local_main
2025-11-26T17:26:17.804545499Z     raise e
2025-11-26T17:26:17.804549185Z   File "/workspace/AReaL/areal/launcher/local.py", line 375, in local_main
2025-11-26T17:26:17.804642565Z     launcher.wait(
2025-11-26T17:26:17.804645530Z   File "/workspace/AReaL/areal/launcher/local.py", line 235, in wait
2025-11-26T17:26:17.804711979Z     raise JobException(
2025-11-26T17:26:17.804714743Z areal.utils.launcher.JobException: Job gsm8k-grpo-cloud-2gpu-2000samples_trial_20251126_172527:trainer JobState.COMPLETED at node local
2025-11-26T17:26:18.024312090Z [37m20251126-17:26:18.023 Local Scheduler INFO: Waiting for 0 local running processes, pids: [0m
2025-11-26T17:26:30.625819962Z ==========
2025-11-26T17:26:30.625843197Z == CUDA ==
2025-11-26T17:26:30.625870547Z ==========
2025-11-26T17:26:30.630638288Z CUDA Version 12.9.1
2025-11-26T17:26:30.632435540Z Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
2025-11-26T17:26:30.633911271Z This container image and its contents are governed by the NVIDIA Deep Learning Container License.
2025-11-26T17:26:30.633914045Z By pulling and using the container, you accept the terms and conditions of this license:
2025-11-26T17:26:30.633916449Z https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license
2025-11-26T17:26:30.633921166Z A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
2025-11-26T17:26:30.800580680Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:26:30.957734586Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:26:31.149194667Z Branch 'feature/reasoning_model' set up to track remote branch 'feature/reasoning_model' from 'origin'.
2025-11-26T17:26:31.149233054Z Your branch is up to date with 'origin/feature/reasoning_model'.
2025-11-26T17:26:31.219770009Z Checking AReaL installation...
2025-11-26T17:26:31.278449313Z AReaL already installed. Skipping installation.
2025-11-26T17:26:31.278489173Z Cleaning up any leftover GPU processes...
2025-11-26T17:26:34.298851942Z Checking for processes holding GPU device files...
2025-11-26T17:26:36.540904175Z Found processes holding GPU devices: 1
2025-11-26T17:26:36.540941531Z 20
2025-11-26T17:26:36.540944636Z 71
2025-11-26T17:26:36.540946749Z 72
2025-11-26T17:26:36.540948922Z Killing process 1...
2025-11-26T17:26:36.540951877Z Killing process 71...
2025-11-26T17:26:36.540962202Z Killing process 72...
2025-11-26T17:26:38.543810160Z Using fuser to kill processes on GPU devices...
2025-11-26T17:26:40.565097558Z Checking GPU...
2025-11-26T17:26:40.602566692Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:26:40.602593813Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:26:40.621178490Z Set PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True for better memory management
2025-11-26T17:26:40.621198830Z Detected 2 GPU(s)
2025-11-26T17:26:40.621202305Z Checking GPU status...
2025-11-26T17:26:40.649422726Z index, name, utilization.gpu [%], memory.used [MiB], compute_mode
2025-11-26T17:26:40.650872057Z 0, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:26:40.651243423Z 1, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:26:40.697622172Z Verifying GPU accessibility...
2025-11-26T17:26:41.239779431Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:26:41.239842947Z   import pynvml  # type: ignore[import]
2025-11-26T17:26:42.342499118Z GPU accessibility verified on attempt 1
2025-11-26T17:26:42.799681235Z Starting training...
2025-11-26T17:26:45.802458343Z Using STANDARD 2000 SAMPLES 2 GPUs configuration
2025-11-26T17:26:45.802494918Z Note: GRPO only (no reasoning XML). Dataset capped at 2000 samples (~6 hours).
2025-11-26T17:26:45.802498694Z GPU count: 2 (required: 2)
2025-11-26T17:26:45.805374321Z ==========================================
2025-11-26T17:26:45.805377145Z Starting GRPO Training (Cloud)
2025-11-26T17:26:45.805379389Z ==========================================
2025-11-26T17:26:45.805381552Z Config: standard_2000samples_2GPUs
2025-11-26T17:26:45.805383655Z Config file: examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml
2025-11-26T17:26:45.805385778Z Training script: examples/cloud_gsm8k/gsm8k_grpo_train.py
2025-11-26T17:26:45.805388212Z Experiment: gsm8k-grpo-cloud-2gpu-2000samples
2025-11-26T17:26:45.805390315Z Trial: trial_20251126_172645
2025-11-26T17:26:45.805392338Z GPU: NVIDIA A100 80GB PCIe NVIDIA A100 80GB PCIe (81920 MB)
2025-11-26T17:26:45.805394351Z WandB API key: e1adc5be02...
2025-11-26T17:26:45.805396344Z ==========================================
2025-11-26T17:26:46.510637471Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:26:46.510680465Z   import pynvml  # type: ignore[import]
2025-11-26T17:26:50.708221479Z [37m20251126-17:26:50.707 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:26:50.708261198Z [37m20251126-17:26:50.708 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:26:50.708562160Z [37m20251126-17:26:50.708 name-resolve INFO: No such name resolve path: ./tmp/areal/name_resolve/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_172645[0m
2025-11-26T17:26:50.814481242Z [37m20251126-17:26:50.814 Local Scheduler INFO: LocalLauncher: experiment_name=gsm8k-grpo-cloud-2gpu-2000samples, trial_name=trial_20251126_172645, fileroot=/workspace/outputs/grpo, run_id=0, is_recover_run=False[0m
2025-11-26T17:26:50.822350079Z [37m20251126-17:26:50.822 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL CUDA_VISIBLE_DEVICES=0 stdbuf -oL python3 -m areal.launcher.sglang_server examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_172645 sglang.random_seed=1 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_172645/llm_server.log[0m
2025-11-26T17:26:51.551365776Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:26:51.551419327Z   import pynvml  # type: ignore[import]
2025-11-26T17:26:53.043454726Z [37m20251126-17:26:53.041 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:26:53.043504159Z [37m20251126-17:26:53.042 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:26:53.147701373Z [37m20251126-17:26:53.147 SGLangServer Wrapper INFO: Launch command: python3 -m sglang.launch_server --host 172.21.0.2 --port 15371 --tokenizer-path Qwen/Qwen2.5-0.5B-Instruct --tokenizer-mode auto --load-format auto --trust-remote-code --device cuda --tp-size 1 --base-gpu-id 0 --nnodes 1 --node-rank 0 --dist-init-addr localhost:19362 --model-path Qwen/Qwen2.5-0.5B-Instruct --random-seed 1 --skip-tokenizer-init --disable-radix-cache --torch-compile-max-bs 32 --triton-attention-num-kv-splits 8 --num-continuous-decode-steps 1 --attention-backend flashinfer --context-length 4096 --mem-fraction-static 0.6 --chunked-prefill-size -1 --max-prefill-tokens 32768 --schedule-policy lpm --schedule-conservativeness 1.0 --cpu-offload-gb 0 --dtype bfloat16 --kv-cache-dtype auto --dp-size 1 --ep-size 1 --max-loaded-loras 1 --max-loras-per-batch 1 --lora-backend triton --log-level warning --log-level-http warning --log-requests-level 0 --enable-metrics --decode-log-interval 1[0m
2025-11-26T17:26:54.194351635Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:26:54.194398135Z   import pynvml  # type: ignore[import]
2025-11-26T17:26:59.562011701Z INFO 11-26 17:26:59 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:27:00.219812168Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:27:01.226673822Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:27:01.226710437Z   import pynvml  # type: ignore[import]
2025-11-26T17:27:01.236228063Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:27:01.236244578Z   import pynvml  # type: ignore[import]
2025-11-26T17:27:06.461679021Z INFO 11-26 17:27:06 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:27:06.734875406Z INFO 11-26 17:27:06 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:27:07.337501267Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:27:07.568582469Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:27:07.572534308Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:27:07.573474907Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:27:07.574411670Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:27:07.611267987Z [2025-11-26 17:27:07] MOE_RUNNER_BACKEND is not initialized, using triton backend
2025-11-26T17:27:08.155329265Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:27:08.155372961Z   warnings.warn(
2025-11-26T17:27:08.155376186Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:27:08.155378459Z   warnings.warn(
2025-11-26T17:27:09.339219701Z Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
2025-11-26T17:27:09.446549127Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  9.33it/s]
2025-11-26T17:27:09.447080374Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  9.31it/s]
2025-11-26T17:27:11.969370923Z   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   4%|â–         | 1/23 [00:00<00:11,  1.87it/s]Capturing batches (bs=152 avail_mem=30.62 GB):   4%|â–         | 1/23 [00:00<00:11,  1.87it/s]Capturing batches (bs=144 avail_mem=30.60 GB):   4%|â–         | 1/23 [00:00<00:11,  1.87it/s]Capturing batches (bs=136 avail_mem=30.59 GB):   4%|â–         | 1/23 [00:00<00:11,  1.87it/s]Capturing batches (bs=136 avail_mem=30.59 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.31it/s]Capturing batches (bs=128 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.31it/s]Capturing batches (bs=120 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.31it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.31it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.59it/s]Capturing batches (bs=104 avail_mem=30.54 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.59it/s]Capturing batches (bs=96 avail_mem=30.53 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.59it/s] Capturing batches (bs=88 avail_mem=30.51 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.59it/s]Capturing batches (bs=88 avail_mem=30.51 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.83it/s]Capturing batches (bs=80 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.83it/s]Capturing batches (bs=72 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.83it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:01<00:00, 14.83it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.22it/s]Capturing batches (bs=56 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.22it/s]Capturing batches (bs=48 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.22it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.22it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.15it/s]Capturing batches (bs=32 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.15it/s]Capturing batches (bs=24 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.15it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.15it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.56it/s]Capturing batches (bs=8 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.56it/s] Capturing batches (bs=4 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.56it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.56it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.01it/s]Capturing batches (bs=1 avail_mem=30.35 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.01it/s]Capturing batches (bs=1 avail_mem=30.35 GB): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00, 14.80it/s]
2025-11-26T17:27:17.173554637Z [37m20251126-17:27:17.172 SGLangServer Wrapper INFO: SGLang server launched at: http://172.21.0.2:15371[0m
2025-11-26T17:27:17.829719483Z [37m20251126-17:27:17.829 Launcher Utils INFO: Found 1 rollout servers: 172.21.0.2:15371[0m
2025-11-26T17:27:17.829761696Z [37m20251126-17:27:17.829 Local Scheduler INFO: LLM inference server launched at: AREAL_LLM_SERVER_ADDRS=172.21.0.2:15371[0m
2025-11-26T17:27:17.833306797Z [37m20251126-17:27:17.832 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL AREAL_LLM_SERVER_ADDRS=172.21.0.2:15371 AREAL_RECOVER_RUN=0 NCCL_CUMEM_ENABLE=0 NCCL_NVLS_ENABLE=0 CUDA_VISIBLE_DEVICES=1 stdbuf -oL torchrun --nnodes 1 --nproc-per-node 1 --master-addr localhost --master-port 49702 examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_172645 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_172645/trainer.log[0m
2025-11-26T17:27:17.842325365Z [37m20251126-17:27:17.842 Local Scheduler INFO: Waiting for 2 local running processes, pids: 315 965[0m
2025-11-26T17:27:18.388903153Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:27:18.388951966Z   import pynvml  # type: ignore[import]
2025-11-26T17:27:19.576901642Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:27:19.576942363Z   import pynvml  # type: ignore[import]
2025-11-26T17:27:26.691863393Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:27:26.691905836Z   warnings.warn(
2025-11-26T17:27:26.691909391Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:27:26.691911834Z   warnings.warn(
2025-11-26T17:27:27.195693650Z Traceback (most recent call last):
2025-11-26T17:27:27.195734832Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 665, in <module>
2025-11-26T17:27:27.196348361Z     main(sys.argv[1:])
2025-11-26T17:27:27.196353659Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 102, in main
2025-11-26T17:27:27.196368751Z     config, _ = load_expr_config(args_with_overrides, GRPOConfig)
2025-11-26T17:27:27.196372938Z                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:27:27.196375081Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1282, in load_expr_config
2025-11-26T17:27:27.196377104Z     cfg = to_structured_cfg(cfg, config_cls=config_cls)
2025-11-26T17:27:27.196747368Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:27:27.196750482Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1276, in to_structured_cfg
2025-11-26T17:27:27.196752776Z     cfg = OmegaConf.merge(default_cfg, cfg)
2025-11-26T17:27:27.196755060Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:27:27.196757192Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/omegaconf.py", line 274, in merge
2025-11-26T17:27:27.197199426Z     target.merge_with(
2025-11-26T17:27:27.197203562Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 507, in merge_with
2025-11-26T17:27:27.197207187Z     self._format_and_raise(key=None, value=None, cause=e)
2025-11-26T17:27:27.197209310Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:27:27.197211384Z     format_and_raise(
2025-11-26T17:27:27.197213467Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:27:27.197215640Z     _raise(ex, cause)
2025-11-26T17:27:27.197217643Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:27:27.197582089Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:27:27.197604872Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:27:27.197607846Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 502, in merge_with
2025-11-26T17:27:27.197611192Z     self._merge_with(
2025-11-26T17:27:27.197614557Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:27:27.197617040Z     BaseContainer._map_merge(
2025-11-26T17:27:27.197623089Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:27:27.197967356Z     dest_node._merge_with(
2025-11-26T17:27:27.197973565Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:27:27.197975948Z     BaseContainer._map_merge(
2025-11-26T17:27:27.197978012Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:27:27.197980064Z     dest_node._merge_with(
2025-11-26T17:27:27.197982178Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:27:27.197984211Z     BaseContainer._map_merge(
2025-11-26T17:27:27.197986464Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 432, in _map_merge
2025-11-26T17:27:27.197988757Z     dest[key] = src._get_node(key)
2025-11-26T17:27:27.198597029Z     ~~~~^^^^^
2025-11-26T17:27:27.198617119Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 308, in __setitem__
2025-11-26T17:27:27.198619893Z     self._format_and_raise(
2025-11-26T17:27:27.198622377Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:27:27.198624580Z     format_and_raise(
2025-11-26T17:27:27.198626613Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:27:27.198629187Z     _raise(ex, cause)
2025-11-26T17:27:27.198631180Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:27:27.198633213Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:27:27.198635306Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:27:27.198637629Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 306, in __setitem__
2025-11-26T17:27:27.198887584Z     self.__set_impl(key=key, value=value)
2025-11-26T17:27:27.198897229Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 316, in __set_impl
2025-11-26T17:27:27.198901825Z     self._set_item_impl(key, value)
2025-11-26T17:27:27.198903899Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 579, in _set_item_impl
2025-11-26T17:27:27.198906272Z     target_node_ref = self._get_node(key)
2025-11-26T17:27:27.199234163Z                       ^^^^^^^^^^^^^^^^^^^
2025-11-26T17:27:27.199240052Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 473, in _get_node
2025-11-26T17:27:27.199242225Z     self._validate_get(key)
2025-11-26T17:27:27.199244539Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 163, in _validate_get
2025-11-26T17:27:27.199247102Z     self._format_and_raise(
2025-11-26T17:27:27.199249156Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:27:27.199251169Z     format_and_raise(
2025-11-26T17:27:27.199253252Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 906, in format_and_raise
2025-11-26T17:27:27.199540943Z     _raise(ex, cause)
2025-11-26T17:27:27.199544828Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:27:27.199547092Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:27:27.199549225Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:27:27.199899600Z omegaconf.errors.ConfigKeyError: Key 'max_new_tokens' not in 'NormConfig'
2025-11-26T17:27:27.199902424Z     full_key: actor.adv_norm.max_new_tokens
2025-11-26T17:27:27.199904478Z     reference_type=Optional[NormConfig]
2025-11-26T17:27:27.199906591Z     object_type=NormConfig
2025-11-26T17:27:29.896694105Z E1126 17:27:29.895000 966 torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 0 (pid: 1032) of binary: /usr/bin/python3
2025-11-26T17:27:29.897365371Z Traceback (most recent call last):
2025-11-26T17:27:29.897375516Z   File "/usr/local/bin/torchrun", line 7, in <module>
2025-11-26T17:27:29.897378671Z     sys.exit(main())
2025-11-26T17:27:29.897381094Z              ^^^^^^
2025-11-26T17:27:29.897383528Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
2025-11-26T17:27:29.897386532Z     return f(*args, **kwargs)
2025-11-26T17:27:29.897389036Z            ^^^^^^^^^^^^^^^^^^
2025-11-26T17:27:29.897391259Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 901, in main
2025-11-26T17:27:29.897783256Z     run(args)
2025-11-26T17:27:29.897811288Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 892, in run
2025-11-26T17:27:29.897815334Z     elastic_launch(
2025-11-26T17:27:29.897819150Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 143, in __call__
2025-11-26T17:27:29.897821844Z     return launch_agent(self._config, self._entrypoint, list(args))
2025-11-26T17:27:29.897824348Z            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:27:29.897826491Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 277, in launch_agent
2025-11-26T17:27:29.898207462Z     raise ChildFailedError(
2025-11-26T17:27:29.898213321Z torch.distributed.elastic.multiprocessing.errors.ChildFailedError:
2025-11-26T17:27:29.898215905Z ============================================================
2025-11-26T17:27:29.898218098Z examples/cloud_gsm8k/gsm8k_grpo_train.py FAILED
2025-11-26T17:27:29.898220211Z ------------------------------------------------------------
2025-11-26T17:27:29.898222244Z Failures:
2025-11-26T17:27:29.898224858Z   <NO_OTHER_FAILURES>
2025-11-26T17:27:29.898227011Z ------------------------------------------------------------
2025-11-26T17:27:29.898229234Z Root Cause (first observed failure):
2025-11-26T17:27:29.898231418Z [0]:
2025-11-26T17:27:29.898233541Z   time      : 2025-11-26_17:27:29
2025-11-26T17:27:29.898235784Z   host      : cef7c503fdea
2025-11-26T17:27:29.898237818Z   rank      : 0 (local_rank: 0)
2025-11-26T17:27:29.898249705Z   exitcode  : 1 (pid: 1032)
2025-11-26T17:27:29.898252420Z   error_file: <N/A>
2025-11-26T17:27:29.898254492Z   traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
2025-11-26T17:27:29.898256746Z ============================================================
2025-11-26T17:27:31.846234883Z [37m20251126-17:27:31.845 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [315][0m
2025-11-26T17:27:31.973047824Z Killed
2025-11-26T17:27:31.985577282Z [37m20251126-17:27:31.985 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [965][0m
2025-11-26T17:27:31.987462145Z Traceback (most recent call last):
2025-11-26T17:27:31.987485730Z   File "<frozen runpy>", line 198, in _run_module_as_main
2025-11-26T17:27:31.987489396Z   File "<frozen runpy>", line 88, in _run_code
2025-11-26T17:27:31.987492170Z   File "/workspace/AReaL/areal/launcher/local.py", line 405, in <module>
2025-11-26T17:27:31.987612561Z     main()
2025-11-26T17:27:31.987627102Z   File "/workspace/AReaL/areal/launcher/local.py", line 260, in main
2025-11-26T17:27:31.987672159Z     local_main(config, run_id=0)
2025-11-26T17:27:31.987676816Z   File "/workspace/AReaL/areal/launcher/local.py", line 399, in local_main
2025-11-26T17:27:31.987763226Z     raise e
2025-11-26T17:27:31.987766751Z   File "/workspace/AReaL/areal/launcher/local.py", line 375, in local_main
2025-11-26T17:27:31.987835625Z     launcher.wait(
2025-11-26T17:27:31.987838209Z   File "/workspace/AReaL/areal/launcher/local.py", line 235, in wait
2025-11-26T17:27:31.987896556Z     raise JobException(
2025-11-26T17:27:31.987899000Z areal.utils.launcher.JobException: Job gsm8k-grpo-cloud-2gpu-2000samples_trial_20251126_172645:trainer JobState.COMPLETED at node local
2025-11-26T17:27:32.188756180Z [37m20251126-17:27:32.188 Local Scheduler INFO: Waiting for 0 local running processes, pids: [0m
2025-11-26T17:27:48.930380687Z ==========
2025-11-26T17:27:48.930383902Z == CUDA ==
2025-11-26T17:27:48.930408098Z ==========
2025-11-26T17:27:48.935795428Z CUDA Version 12.9.1
2025-11-26T17:27:48.937875604Z Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
2025-11-26T17:27:48.939829040Z This container image and its contents are governed by the NVIDIA Deep Learning Container License.
2025-11-26T17:27:48.939831644Z By pulling and using the container, you accept the terms and conditions of this license:
2025-11-26T17:27:48.939834117Z https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license
2025-11-26T17:27:48.939838374Z A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
2025-11-26T17:27:49.106886411Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:27:49.266769887Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:27:49.462123474Z Branch 'feature/reasoning_model' set up to track remote branch 'feature/reasoning_model' from 'origin'.
2025-11-26T17:27:49.462147831Z Your branch is up to date with 'origin/feature/reasoning_model'.
2025-11-26T17:27:49.534727456Z Checking AReaL installation...
2025-11-26T17:27:49.593539319Z AReaL already installed. Skipping installation.
2025-11-26T17:27:49.593572048Z Cleaning up any leftover GPU processes...
2025-11-26T17:27:52.613334060Z Checking for processes holding GPU device files...
2025-11-26T17:27:55.253843196Z Found processes holding GPU devices: 1
2025-11-26T17:27:55.253883566Z 20
2025-11-26T17:27:55.253886641Z 71
2025-11-26T17:27:55.253889235Z 72
2025-11-26T17:27:55.253891378Z Killing process 1...
2025-11-26T17:27:55.253894022Z Killing process 71...
2025-11-26T17:27:55.254066741Z Killing process 72...
2025-11-26T17:27:57.256901708Z Using fuser to kill processes on GPU devices...
2025-11-26T17:27:59.281945230Z Checking GPU...
2025-11-26T17:27:59.322806817Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:27:59.322832415Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:27:59.340930844Z Set PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True for better memory management
2025-11-26T17:27:59.340950503Z Detected 2 GPU(s)
2025-11-26T17:27:59.340966197Z Checking GPU status...
2025-11-26T17:27:59.369507749Z index, name, utilization.gpu [%], memory.used [MiB], compute_mode
2025-11-26T17:27:59.370918162Z 0, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:27:59.371227695Z 1, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:27:59.416261140Z Verifying GPU accessibility...
2025-11-26T17:27:59.999251680Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:27:59.999317990Z   import pynvml  # type: ignore[import]
2025-11-26T17:28:01.170435863Z GPU accessibility verified on attempt 1
2025-11-26T17:28:01.740184749Z Starting training...
2025-11-26T17:28:04.743169811Z Using STANDARD 2000 SAMPLES 2 GPUs configuration
2025-11-26T17:28:04.743212564Z Note: GRPO only (no reasoning XML). Dataset capped at 2000 samples (~6 hours).
2025-11-26T17:28:04.743216210Z GPU count: 2 (required: 2)
2025-11-26T17:28:04.745790766Z ==========================================
2025-11-26T17:28:04.745794512Z Starting GRPO Training (Cloud)
2025-11-26T17:28:04.745797757Z ==========================================
2025-11-26T17:28:04.745799750Z Config: standard_2000samples_2GPUs
2025-11-26T17:28:04.745801833Z Config file: examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml
2025-11-26T17:28:04.745804827Z Training script: examples/cloud_gsm8k/gsm8k_grpo_train.py
2025-11-26T17:28:04.745807401Z Experiment: gsm8k-grpo-cloud-2gpu-2000samples
2025-11-26T17:28:04.745809404Z Trial: trial_20251126_172804
2025-11-26T17:28:04.745811417Z GPU: NVIDIA A100 80GB PCIe NVIDIA A100 80GB PCIe (81920 MB)
2025-11-26T17:28:04.745813430Z WandB API key: e1adc5be02...
2025-11-26T17:28:04.745815453Z ==========================================
2025-11-26T17:28:05.453772418Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:28:05.453815693Z   import pynvml  # type: ignore[import]
2025-11-26T17:28:09.504009127Z [37m20251126-17:28:09.503 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:28:09.504050830Z [37m20251126-17:28:09.503 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:28:09.504322387Z [37m20251126-17:28:09.503 name-resolve INFO: No such name resolve path: ./tmp/areal/name_resolve/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_172804[0m
2025-11-26T17:28:09.610403774Z [37m20251126-17:28:09.609 Local Scheduler INFO: LocalLauncher: experiment_name=gsm8k-grpo-cloud-2gpu-2000samples, trial_name=trial_20251126_172804, fileroot=/workspace/outputs/grpo, run_id=0, is_recover_run=False[0m
2025-11-26T17:28:09.618043468Z [37m20251126-17:28:09.617 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL CUDA_VISIBLE_DEVICES=0 stdbuf -oL python3 -m areal.launcher.sglang_server examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_172804 sglang.random_seed=1 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_172804/llm_server.log[0m
2025-11-26T17:28:10.370027250Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:28:10.370068861Z   import pynvml  # type: ignore[import]
2025-11-26T17:28:11.865371005Z [37m20251126-17:28:11.864 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:28:11.866010633Z [37m20251126-17:28:11.865 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:28:11.984426345Z [37m20251126-17:28:11.983 SGLangServer Wrapper INFO: Launch command: python3 -m sglang.launch_server --host 172.21.0.2 --port 26471 --tokenizer-path Qwen/Qwen2.5-0.5B-Instruct --tokenizer-mode auto --load-format auto --trust-remote-code --device cuda --tp-size 1 --base-gpu-id 0 --nnodes 1 --node-rank 0 --dist-init-addr localhost:29831 --model-path Qwen/Qwen2.5-0.5B-Instruct --random-seed 1 --skip-tokenizer-init --disable-radix-cache --torch-compile-max-bs 32 --triton-attention-num-kv-splits 8 --num-continuous-decode-steps 1 --attention-backend flashinfer --context-length 4096 --mem-fraction-static 0.6 --chunked-prefill-size -1 --max-prefill-tokens 32768 --schedule-policy lpm --schedule-conservativeness 1.0 --cpu-offload-gb 0 --dtype bfloat16 --kv-cache-dtype auto --dp-size 1 --ep-size 1 --max-loaded-loras 1 --max-loras-per-batch 1 --lora-backend triton --log-level warning --log-level-http warning --log-requests-level 0 --enable-metrics --decode-log-interval 1[0m
2025-11-26T17:28:13.018282288Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:28:13.018322288Z   import pynvml  # type: ignore[import]
2025-11-26T17:28:18.750692931Z INFO 11-26 17:28:18 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:28:19.443915266Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:28:20.824135151Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:28:20.824177894Z   import pynvml  # type: ignore[import]
2025-11-26T17:28:20.824871313Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:28:20.824875068Z   import pynvml  # type: ignore[import]
2025-11-26T17:28:26.692618665Z INFO 11-26 17:28:26 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:28:26.760658571Z INFO 11-26 17:28:26 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:28:27.272747428Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:28:27.491307104Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:28:27.494849430Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:28:27.495952322Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:28:27.496508245Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:28:27.530715183Z [2025-11-26 17:28:27] MOE_RUNNER_BACKEND is not initialized, using triton backend
2025-11-26T17:28:28.046682330Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:28:28.046720677Z   warnings.warn(
2025-11-26T17:28:28.046724212Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:28:28.046738374Z   warnings.warn(
2025-11-26T17:28:29.181411849Z Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
2025-11-26T17:28:29.298056378Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  8.58it/s]
2025-11-26T17:28:29.298599271Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  8.57it/s]
2025-11-26T17:28:31.794825961Z   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   4%|â–         | 1/23 [00:00<00:12,  1.80it/s]Capturing batches (bs=152 avail_mem=30.62 GB):   4%|â–         | 1/23 [00:00<00:12,  1.80it/s]Capturing batches (bs=144 avail_mem=30.60 GB):   4%|â–         | 1/23 [00:00<00:12,  1.80it/s]Capturing batches (bs=136 avail_mem=30.59 GB):   4%|â–         | 1/23 [00:00<00:12,  1.80it/s]Capturing batches (bs=136 avail_mem=30.59 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.07it/s]Capturing batches (bs=128 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.07it/s]Capturing batches (bs=120 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.07it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.07it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.26it/s]Capturing batches (bs=104 avail_mem=30.54 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.26it/s]Capturing batches (bs=96 avail_mem=30.53 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.26it/s] Capturing batches (bs=88 avail_mem=30.51 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.26it/s]Capturing batches (bs=88 avail_mem=30.51 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.54it/s]Capturing batches (bs=80 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.54it/s]Capturing batches (bs=72 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.54it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:01<00:00, 14.54it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.02it/s]Capturing batches (bs=56 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.02it/s]Capturing batches (bs=48 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.02it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.02it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.04it/s]Capturing batches (bs=32 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.04it/s]Capturing batches (bs=24 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.04it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.04it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.53it/s]Capturing batches (bs=8 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.53it/s] Capturing batches (bs=4 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.53it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.53it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.36it/s]Capturing batches (bs=1 avail_mem=30.35 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.36it/s]Capturing batches (bs=1 avail_mem=30.35 GB): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00, 14.68it/s]
2025-11-26T17:28:37.015633924Z [37m20251126-17:28:37.015 SGLangServer Wrapper INFO: SGLang server launched at: http://172.21.0.2:26471[0m
2025-11-26T17:28:37.625973861Z [37m20251126-17:28:37.625 Launcher Utils INFO: Found 1 rollout servers: 172.21.0.2:26471[0m
2025-11-26T17:28:37.626024557Z [37m20251126-17:28:37.625 Local Scheduler INFO: LLM inference server launched at: AREAL_LLM_SERVER_ADDRS=172.21.0.2:26471[0m
2025-11-26T17:28:37.628460506Z [37m20251126-17:28:37.628 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL AREAL_LLM_SERVER_ADDRS=172.21.0.2:26471 AREAL_RECOVER_RUN=0 NCCL_CUMEM_ENABLE=0 NCCL_NVLS_ENABLE=0 CUDA_VISIBLE_DEVICES=1 stdbuf -oL torchrun --nnodes 1 --nproc-per-node 1 --master-addr localhost --master-port 45713 examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_172804 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_172804/trainer.log[0m
2025-11-26T17:28:37.628957891Z [37m20251126-17:28:37.628 Local Scheduler INFO: Waiting for 2 local running processes, pids: 315 965[0m
2025-11-26T17:28:38.143397259Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:28:38.143439683Z   import pynvml  # type: ignore[import]
2025-11-26T17:28:39.366222224Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:28:39.366266762Z   import pynvml  # type: ignore[import]
2025-11-26T17:28:46.527701693Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:28:46.527746841Z   warnings.warn(
2025-11-26T17:28:46.527750045Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:28:46.527752599Z   warnings.warn(
2025-11-26T17:28:46.957570936Z Traceback (most recent call last):
2025-11-26T17:28:46.957611747Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 665, in <module>
2025-11-26T17:28:46.958182262Z     main(sys.argv[1:])
2025-11-26T17:28:46.958193178Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 102, in main
2025-11-26T17:28:46.958195882Z     config, _ = load_expr_config(args_with_overrides, GRPOConfig)
2025-11-26T17:28:46.958198666Z                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:28:46.958210643Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1282, in load_expr_config
2025-11-26T17:28:46.958212867Z     cfg = to_structured_cfg(cfg, config_cls=config_cls)
2025-11-26T17:28:46.958639857Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:28:46.958643172Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1276, in to_structured_cfg
2025-11-26T17:28:46.958645785Z     cfg = OmegaConf.merge(default_cfg, cfg)
2025-11-26T17:28:46.958648389Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:28:46.958650423Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/omegaconf.py", line 274, in merge
2025-11-26T17:28:46.958652996Z     target.merge_with(
2025-11-26T17:28:46.959144212Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 507, in merge_with
2025-11-26T17:28:46.959149410Z     self._format_and_raise(key=None, value=None, cause=e)
2025-11-26T17:28:46.959151513Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:28:46.959153556Z     format_and_raise(
2025-11-26T17:28:46.959155759Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:28:46.959157832Z     _raise(ex, cause)
2025-11-26T17:28:46.959159895Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:28:46.959161958Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:28:46.959551843Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:28:46.959559384Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 502, in merge_with
2025-11-26T17:28:46.959561888Z     self._merge_with(
2025-11-26T17:28:46.959564121Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:28:46.959566204Z     BaseContainer._map_merge(
2025-11-26T17:28:46.959568948Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:28:46.959571011Z     dest_node._merge_with(
2025-11-26T17:28:46.959573115Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:28:46.959932593Z     BaseContainer._map_merge(
2025-11-26T17:28:46.959935317Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:28:46.959937331Z     dest_node._merge_with(
2025-11-26T17:28:46.959939394Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:28:46.959941467Z     BaseContainer._map_merge(
2025-11-26T17:28:46.959943430Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 432, in _map_merge
2025-11-26T17:28:46.959945423Z     dest[key] = src._get_node(key)
2025-11-26T17:28:46.959947516Z     ~~~~^^^^^
2025-11-26T17:28:46.959950100Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 308, in __setitem__
2025-11-26T17:28:46.959952123Z     self._format_and_raise(
2025-11-26T17:28:46.959954116Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:28:46.960824800Z     format_and_raise(
2025-11-26T17:28:46.960831170Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:28:46.960833483Z     _raise(ex, cause)
2025-11-26T17:28:46.960835476Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:28:46.960837579Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:28:46.960839562Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:28:46.960841525Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 306, in __setitem__
2025-11-26T17:28:46.960843617Z     self.__set_impl(key=key, value=value)
2025-11-26T17:28:46.960845730Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 316, in __set_impl
2025-11-26T17:28:46.960853823Z     self._set_item_impl(key, value)
2025-11-26T17:28:46.960856066Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 579, in _set_item_impl
2025-11-26T17:28:46.960858129Z     target_node_ref = self._get_node(key)
2025-11-26T17:28:46.960860112Z                       ^^^^^^^^^^^^^^^^^^^
2025-11-26T17:28:46.960862065Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 473, in _get_node
2025-11-26T17:28:46.961230216Z     self._validate_get(key)
2025-11-26T17:28:46.961235004Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 163, in _validate_get
2025-11-26T17:28:46.961239791Z     self._format_and_raise(
2025-11-26T17:28:46.961241824Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:28:46.961243837Z     format_and_raise(
2025-11-26T17:28:46.961245780Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 906, in format_and_raise
2025-11-26T17:28:46.961247833Z     _raise(ex, cause)
2025-11-26T17:28:46.961249776Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:28:46.961251799Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:28:46.961522334Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:28:46.961524908Z omegaconf.errors.ConfigKeyError: Key 'max_new_tokens' not in 'NormConfig'
2025-11-26T17:28:46.961527292Z     full_key: actor.adv_norm.max_new_tokens
2025-11-26T17:28:46.961529315Z     reference_type=Optional[NormConfig]
2025-11-26T17:28:46.961531568Z     object_type=NormConfig
2025-11-26T17:28:49.643655829Z E1126 17:28:49.642000 966 torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 0 (pid: 1032) of binary: /usr/bin/python3
2025-11-26T17:28:49.644423950Z Traceback (most recent call last):
2025-11-26T17:28:49.644433974Z   File "/usr/local/bin/torchrun", line 7, in <module>
2025-11-26T17:28:49.644436578Z     sys.exit(main())
2025-11-26T17:28:49.644440054Z              ^^^^^^
2025-11-26T17:28:49.644442177Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
2025-11-26T17:28:49.644444781Z     return f(*args, **kwargs)
2025-11-26T17:28:49.644447966Z            ^^^^^^^^^^^^^^^^^^
2025-11-26T17:28:49.644450269Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 901, in main
2025-11-26T17:28:49.644842317Z     run(args)
2025-11-26T17:28:49.644845471Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 892, in run
2025-11-26T17:28:49.644848255Z     elastic_launch(
2025-11-26T17:28:49.644850589Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 143, in __call__
2025-11-26T17:28:49.644853213Z     return launch_agent(self._config, self._entrypoint, list(args))
2025-11-26T17:28:49.644855646Z            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:28:49.644857940Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 277, in launch_agent
2025-11-26T17:28:49.644860043Z     raise ChildFailedError(
2025-11-26T17:28:49.644862427Z torch.distributed.elastic.multiprocessing.errors.ChildFailedError:
2025-11-26T17:28:49.644864790Z ============================================================
2025-11-26T17:28:49.644867734Z examples/cloud_gsm8k/gsm8k_grpo_train.py FAILED
2025-11-26T17:28:49.644869917Z ------------------------------------------------------------
2025-11-26T17:28:49.644872050Z Failures:
2025-11-26T17:28:49.644874033Z   <NO_OTHER_FAILURES>
2025-11-26T17:28:49.644876006Z ------------------------------------------------------------
2025-11-26T17:28:49.644878139Z Root Cause (first observed failure):
2025-11-26T17:28:49.644880182Z [0]:
2025-11-26T17:28:49.644882245Z   time      : 2025-11-26_17:28:49
2025-11-26T17:28:49.644884259Z   host      : cef7c503fdea
2025-11-26T17:28:49.644886282Z   rank      : 0 (local_rank: 0)
2025-11-26T17:28:49.644888265Z   exitcode  : 1 (pid: 1032)
2025-11-26T17:28:49.644890277Z   error_file: <N/A>
2025-11-26T17:28:49.644892351Z   traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
2025-11-26T17:28:49.644903047Z ============================================================
2025-11-26T17:28:51.632929793Z [37m20251126-17:28:51.632 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [315][0m
2025-11-26T17:28:51.757933173Z Killed
2025-11-26T17:28:51.769278748Z [37m20251126-17:28:51.768 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [965][0m
2025-11-26T17:28:51.770492525Z Traceback (most recent call last):
2025-11-26T17:28:51.770498664Z   File "<frozen runpy>", line 198, in _run_module_as_main
2025-11-26T17:28:51.770502009Z   File "<frozen runpy>", line 88, in _run_code
2025-11-26T17:28:51.770504092Z   File "/workspace/AReaL/areal/launcher/local.py", line 405, in <module>
2025-11-26T17:28:51.770681909Z     main()
2025-11-26T17:28:51.770684914Z   File "/workspace/AReaL/areal/launcher/local.py", line 260, in main
2025-11-26T17:28:51.770798303Z     local_main(config, run_id=0)
2025-11-26T17:28:51.770801658Z   File "/workspace/AReaL/areal/launcher/local.py", line 399, in local_main
2025-11-26T17:28:51.770912064Z     raise e
2025-11-26T17:28:51.770914337Z   File "/workspace/AReaL/areal/launcher/local.py", line 375, in local_main
2025-11-26T17:28:51.770991122Z     launcher.wait(
2025-11-26T17:28:51.770993957Z   File "/workspace/AReaL/areal/launcher/local.py", line 235, in wait
2025-11-26T17:28:51.771053647Z     raise JobException(
2025-11-26T17:28:51.771057001Z areal.utils.launcher.JobException: Job gsm8k-grpo-cloud-2gpu-2000samples_trial_20251126_172804:trainer JobState.COMPLETED at node local
2025-11-26T17:28:51.980226051Z [37m20251126-17:28:51.979 Local Scheduler INFO: Waiting for 0 local running processes, pids: [0m
2025-11-26T17:29:07.220740336Z ==========
2025-11-26T17:29:07.220744292Z == CUDA ==
2025-11-26T17:29:07.220746635Z ==========
2025-11-26T17:29:07.224962329Z CUDA Version 12.9.1
2025-11-26T17:29:07.226838841Z Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
2025-11-26T17:29:07.228726678Z This container image and its contents are governed by the NVIDIA Deep Learning Container License.
2025-11-26T17:29:07.228729022Z By pulling and using the container, you accept the terms and conditions of this license:
2025-11-26T17:29:07.228732868Z https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license
2025-11-26T17:29:07.228737054Z A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
2025-11-26T17:29:07.393067601Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:29:07.550750291Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:29:07.741305920Z Branch 'feature/reasoning_model' set up to track remote branch 'feature/reasoning_model' from 'origin'.
2025-11-26T17:29:07.741345279Z Your branch is up to date with 'origin/feature/reasoning_model'.
2025-11-26T17:29:07.821934613Z Checking AReaL installation...
2025-11-26T17:29:07.880277734Z AReaL already installed. Skipping installation.
2025-11-26T17:29:07.880305725Z Cleaning up any leftover GPU processes...
2025-11-26T17:29:10.901347355Z Checking for processes holding GPU device files...
2025-11-26T17:29:13.594040576Z Found processes holding GPU devices: 1
2025-11-26T17:29:13.594081237Z 20
2025-11-26T17:29:13.594084682Z 71
2025-11-26T17:29:13.594089059Z 72
2025-11-26T17:29:13.594091562Z Killing process 1...
2025-11-26T17:29:13.594094387Z Killing process 71...
2025-11-26T17:29:13.594411231Z Killing process 72...
2025-11-26T17:29:15.597326709Z Using fuser to kill processes on GPU devices...
2025-11-26T17:29:17.625511617Z Checking GPU...
2025-11-26T17:29:17.661383098Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:29:17.661428286Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:29:17.678468911Z Set PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True for better memory management
2025-11-26T17:29:17.678495591Z Detected 2 GPU(s)
2025-11-26T17:29:17.678498425Z Checking GPU status...
2025-11-26T17:29:17.706706426Z index, name, utilization.gpu [%], memory.used [MiB], compute_mode
2025-11-26T17:29:17.708067636Z 0, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:29:17.708394876Z 1, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:29:17.756385470Z Verifying GPU accessibility...
2025-11-26T17:29:18.311285984Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:29:18.311343560Z   import pynvml  # type: ignore[import]
2025-11-26T17:29:19.451281812Z GPU accessibility verified on attempt 1
2025-11-26T17:29:20.029478701Z Starting training...
2025-11-26T17:29:23.032087249Z Using STANDARD 2000 SAMPLES 2 GPUs configuration
2025-11-26T17:29:23.032135892Z Note: GRPO only (no reasoning XML). Dataset capped at 2000 samples (~6 hours).
2025-11-26T17:29:23.032140679Z GPU count: 2 (required: 2)
2025-11-26T17:29:23.034470088Z ==========================================
2025-11-26T17:29:23.034473613Z Starting GRPO Training (Cloud)
2025-11-26T17:29:23.034476618Z ==========================================
2025-11-26T17:29:23.034478721Z Config: standard_2000samples_2GPUs
2025-11-26T17:29:23.034480824Z Config file: examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml
2025-11-26T17:29:23.034483498Z Training script: examples/cloud_gsm8k/gsm8k_grpo_train.py
2025-11-26T17:29:23.034486042Z Experiment: gsm8k-grpo-cloud-2gpu-2000samples
2025-11-26T17:29:23.034488055Z Trial: trial_20251126_172923
2025-11-26T17:29:23.034490048Z GPU: NVIDIA A100 80GB PCIe NVIDIA A100 80GB PCIe (81920 MB)
2025-11-26T17:29:23.034492412Z WandB API key: e1adc5be02...
2025-11-26T17:29:23.034494515Z ==========================================
2025-11-26T17:29:23.941219240Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:29:23.941266180Z   import pynvml  # type: ignore[import]
2025-11-26T17:29:27.980638466Z [37m20251126-17:29:27.980 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:29:27.980698586Z [37m20251126-17:29:27.980 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:29:27.980926838Z [37m20251126-17:29:27.980 name-resolve INFO: No such name resolve path: ./tmp/areal/name_resolve/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_172923[0m
2025-11-26T17:29:28.087192611Z [37m20251126-17:29:28.086 Local Scheduler INFO: LocalLauncher: experiment_name=gsm8k-grpo-cloud-2gpu-2000samples, trial_name=trial_20251126_172923, fileroot=/workspace/outputs/grpo, run_id=0, is_recover_run=False[0m
2025-11-26T17:29:28.094772485Z [37m20251126-17:29:28.094 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL CUDA_VISIBLE_DEVICES=0 stdbuf -oL python3 -m areal.launcher.sglang_server examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_172923 sglang.random_seed=1 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_172923/llm_server.log[0m
2025-11-26T17:29:28.824016395Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:29:28.824062103Z   import pynvml  # type: ignore[import]
2025-11-26T17:29:30.287171205Z [37m20251126-17:29:30.286 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:29:30.287783253Z [37m20251126-17:29:30.286 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:29:30.389230958Z [37m20251126-17:29:30.388 SGLangServer Wrapper INFO: Launch command: python3 -m sglang.launch_server --host 172.21.0.2 --port 15339 --tokenizer-path Qwen/Qwen2.5-0.5B-Instruct --tokenizer-mode auto --load-format auto --trust-remote-code --device cuda --tp-size 1 --base-gpu-id 0 --nnodes 1 --node-rank 0 --dist-init-addr localhost:22451 --model-path Qwen/Qwen2.5-0.5B-Instruct --random-seed 1 --skip-tokenizer-init --disable-radix-cache --torch-compile-max-bs 32 --triton-attention-num-kv-splits 8 --num-continuous-decode-steps 1 --attention-backend flashinfer --context-length 4096 --mem-fraction-static 0.6 --chunked-prefill-size -1 --max-prefill-tokens 32768 --schedule-policy lpm --schedule-conservativeness 1.0 --cpu-offload-gb 0 --dtype bfloat16 --kv-cache-dtype auto --dp-size 1 --ep-size 1 --max-loaded-loras 1 --max-loras-per-batch 1 --lora-backend triton --log-level warning --log-level-http warning --log-requests-level 0 --enable-metrics --decode-log-interval 1[0m
2025-11-26T17:29:31.445947704Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:29:31.445989607Z   import pynvml  # type: ignore[import]
2025-11-26T17:29:37.366353963Z INFO 11-26 17:29:37 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:29:38.069684799Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:29:39.135011770Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:29:39.135049667Z   import pynvml  # type: ignore[import]
2025-11-26T17:29:39.146312228Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:29:39.146333329Z   import pynvml  # type: ignore[import]
2025-11-26T17:29:46.405305349Z INFO 11-26 17:29:46 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:29:46.405347001Z INFO 11-26 17:29:46 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:29:47.165658978Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:29:47.396238117Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:29:47.399893764Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:29:47.404982345Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:29:47.404995735Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:29:47.435150844Z [2025-11-26 17:29:47] MOE_RUNNER_BACKEND is not initialized, using triton backend
2025-11-26T17:29:47.937756908Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:29:47.937802527Z   warnings.warn(
2025-11-26T17:29:47.937806112Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:29:47.937816077Z   warnings.warn(
2025-11-26T17:29:49.046138121Z Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
2025-11-26T17:29:49.161926728Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  8.65it/s]
2025-11-26T17:29:49.162516141Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  8.63it/s]
2025-11-26T17:29:51.622863847Z   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   4%|â–         | 1/23 [00:00<00:12,  1.80it/s]Capturing batches (bs=152 avail_mem=30.62 GB):   4%|â–         | 1/23 [00:00<00:12,  1.80it/s]Capturing batches (bs=144 avail_mem=30.60 GB):   4%|â–         | 1/23 [00:00<00:12,  1.80it/s]Capturing batches (bs=136 avail_mem=30.59 GB):   4%|â–         | 1/23 [00:00<00:12,  1.80it/s]Capturing batches (bs=136 avail_mem=30.59 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.15it/s]Capturing batches (bs=128 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.15it/s]Capturing batches (bs=120 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.15it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.15it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.49it/s]Capturing batches (bs=104 avail_mem=30.54 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.49it/s]Capturing batches (bs=96 avail_mem=30.53 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.49it/s] Capturing batches (bs=88 avail_mem=30.51 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.49it/s]Capturing batches (bs=88 avail_mem=30.51 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.93it/s]Capturing batches (bs=80 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.93it/s]Capturing batches (bs=72 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.93it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:01<00:00, 14.93it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.54it/s]Capturing batches (bs=56 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.54it/s]Capturing batches (bs=48 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.54it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.54it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.65it/s]Capturing batches (bs=32 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.65it/s]Capturing batches (bs=24 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.65it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.65it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 18.05it/s]Capturing batches (bs=8 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 18.05it/s] Capturing batches (bs=4 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 18.05it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 18.05it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.79it/s]Capturing batches (bs=1 avail_mem=30.35 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.79it/s]Capturing batches (bs=1 avail_mem=30.35 GB): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00, 15.00it/s]
2025-11-26T17:29:57.420422195Z [37m20251126-17:29:57.419 SGLangServer Wrapper INFO: SGLang server launched at: http://172.21.0.2:15339[0m
2025-11-26T17:29:58.103012704Z [37m20251126-17:29:58.102 Launcher Utils INFO: Found 1 rollout servers: 172.21.0.2:15339[0m
2025-11-26T17:29:58.103039043Z [37m20251126-17:29:58.102 Local Scheduler INFO: LLM inference server launched at: AREAL_LLM_SERVER_ADDRS=172.21.0.2:15339[0m
2025-11-26T17:29:58.107269269Z [37m20251126-17:29:58.106 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL AREAL_LLM_SERVER_ADDRS=172.21.0.2:15339 AREAL_RECOVER_RUN=0 NCCL_CUMEM_ENABLE=0 NCCL_NVLS_ENABLE=0 CUDA_VISIBLE_DEVICES=1 stdbuf -oL torchrun --nnodes 1 --nproc-per-node 1 --master-addr localhost --master-port 28183 examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_172923 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_172923/trainer.log[0m
2025-11-26T17:29:58.107955267Z [37m20251126-17:29:58.107 Local Scheduler INFO: Waiting for 2 local running processes, pids: 315 965[0m
2025-11-26T17:29:58.629226279Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:29:58.629266358Z   import pynvml  # type: ignore[import]
2025-11-26T17:29:59.812453972Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:29:59.812492309Z   import pynvml  # type: ignore[import]
2025-11-26T17:30:06.440164328Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:30:06.440204428Z   warnings.warn(
2025-11-26T17:30:06.440207753Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:30:06.440210306Z   warnings.warn(
2025-11-26T17:30:06.857185015Z Traceback (most recent call last):
2025-11-26T17:30:06.857225095Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 665, in <module>
2025-11-26T17:30:06.857807467Z     main(sys.argv[1:])
2025-11-26T17:30:06.857814888Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 102, in main
2025-11-26T17:30:06.857817973Z     config, _ = load_expr_config(args_with_overrides, GRPOConfig)
2025-11-26T17:30:06.857821188Z                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:30:06.857823231Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1282, in load_expr_config
2025-11-26T17:30:06.857838784Z     cfg = to_structured_cfg(cfg, config_cls=config_cls)
2025-11-26T17:30:06.858485703Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:30:06.858492333Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1276, in to_structured_cfg
2025-11-26T17:30:06.858494957Z     cfg = OmegaConf.merge(default_cfg, cfg)
2025-11-26T17:30:06.858497090Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:30:06.858499273Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/omegaconf.py", line 274, in merge
2025-11-26T17:30:06.858796679Z     target.merge_with(
2025-11-26T17:30:06.858799213Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 507, in merge_with
2025-11-26T17:30:06.858801586Z     self._format_and_raise(key=None, value=None, cause=e)
2025-11-26T17:30:06.858803589Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:30:06.858805733Z     format_and_raise(
2025-11-26T17:30:06.858807786Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:30:06.858809869Z     _raise(ex, cause)
2025-11-26T17:30:06.858811872Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:30:06.858813955Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:30:06.859300353Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:30:06.859311870Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 502, in merge_with
2025-11-26T17:30:06.859314745Z     self._merge_with(
2025-11-26T17:30:06.859317299Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:30:06.859319632Z     BaseContainer._map_merge(
2025-11-26T17:30:06.859322066Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:30:06.859324129Z     dest_node._merge_with(
2025-11-26T17:30:06.859326172Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:30:06.859662746Z     BaseContainer._map_merge(
2025-11-26T17:30:06.859665370Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:30:06.859667443Z     dest_node._merge_with(
2025-11-26T17:30:06.859669606Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:30:06.859671620Z     BaseContainer._map_merge(
2025-11-26T17:30:06.859673583Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 432, in _map_merge
2025-11-26T17:30:06.859675575Z     dest[key] = src._get_node(key)
2025-11-26T17:30:06.860739138Z     ~~~~^^^^^
2025-11-26T17:30:06.860745257Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 308, in __setitem__
2025-11-26T17:30:06.860747351Z     self._format_and_raise(
2025-11-26T17:30:06.860749504Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:30:06.860751507Z     format_and_raise(
2025-11-26T17:30:06.860753570Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:30:06.860755553Z     _raise(ex, cause)
2025-11-26T17:30:06.860757827Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:30:06.860760170Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:30:06.860762213Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:30:06.860764266Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 306, in __setitem__
2025-11-26T17:30:06.860766359Z     self.__set_impl(key=key, value=value)
2025-11-26T17:30:06.860768352Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 316, in __set_impl
2025-11-26T17:30:06.860770365Z     self._set_item_impl(key, value)
2025-11-26T17:30:06.860772348Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 579, in _set_item_impl
2025-11-26T17:30:06.860780430Z     target_node_ref = self._get_node(key)
2025-11-26T17:30:06.860782624Z                       ^^^^^^^^^^^^^^^^^^^
2025-11-26T17:30:06.860784656Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 473, in _get_node
2025-11-26T17:30:06.860786770Z     self._validate_get(key)
2025-11-26T17:30:06.861105157Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 163, in _validate_get
2025-11-26T17:30:06.861107861Z     self._format_and_raise(
2025-11-26T17:30:06.861109874Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:30:06.861123354Z     format_and_raise(
2025-11-26T17:30:06.861127630Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 906, in format_and_raise
2025-11-26T17:30:06.861129754Z     _raise(ex, cause)
2025-11-26T17:30:06.861131707Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:30:06.861506928Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:30:06.861509702Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:30:06.861511785Z omegaconf.errors.ConfigKeyError: Key 'max_new_tokens' not in 'NormConfig'
2025-11-26T17:30:06.861513839Z     full_key: actor.adv_norm.max_new_tokens
2025-11-26T17:30:06.861515871Z     reference_type=Optional[NormConfig]
2025-11-26T17:30:06.861517885Z     object_type=NormConfig
2025-11-26T17:30:09.218618930Z E1126 17:30:09.217000 966 torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 0 (pid: 1032) of binary: /usr/bin/python3
2025-11-26T17:30:09.219226570Z Traceback (most recent call last):
2025-11-26T17:30:09.219233040Z   File "/usr/local/bin/torchrun", line 7, in <module>
2025-11-26T17:30:09.219236125Z     sys.exit(main())
2025-11-26T17:30:09.219238618Z              ^^^^^^
2025-11-26T17:30:09.219240721Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
2025-11-26T17:30:09.219243536Z     return f(*args, **kwargs)
2025-11-26T17:30:09.219246149Z            ^^^^^^^^^^^^^^^^^^
2025-11-26T17:30:09.219248183Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 901, in main
2025-11-26T17:30:09.219647290Z     run(args)
2025-11-26T17:30:09.219650054Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 892, in run
2025-11-26T17:30:09.219652838Z     elastic_launch(
2025-11-26T17:30:09.219655172Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 143, in __call__
2025-11-26T17:30:09.219662142Z     return launch_agent(self._config, self._entrypoint, list(args))
2025-11-26T17:30:09.219664966Z            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:30:09.219667230Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 277, in launch_agent
2025-11-26T17:30:09.220220188Z     raise ChildFailedError(
2025-11-26T17:30:09.220232657Z torch.distributed.elastic.multiprocessing.errors.ChildFailedError:
2025-11-26T17:30:09.220235190Z ============================================================
2025-11-26T17:30:09.220237905Z examples/cloud_gsm8k/gsm8k_grpo_train.py FAILED
2025-11-26T17:30:09.220240398Z ------------------------------------------------------------
2025-11-26T17:30:09.220242521Z Failures:
2025-11-26T17:30:09.220244684Z   <NO_OTHER_FAILURES>
2025-11-26T17:30:09.220246738Z ------------------------------------------------------------
2025-11-26T17:30:09.220248741Z Root Cause (first observed failure):
2025-11-26T17:30:09.220250814Z [0]:
2025-11-26T17:30:09.220252847Z   time      : 2025-11-26_17:30:09
2025-11-26T17:30:09.220254870Z   host      : cef7c503fdea
2025-11-26T17:30:09.220256863Z   rank      : 0 (local_rank: 0)
2025-11-26T17:30:09.220258946Z   exitcode  : 1 (pid: 1032)
2025-11-26T17:30:09.220260949Z   error_file: <N/A>
2025-11-26T17:30:09.220262952Z   traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
2025-11-26T17:30:09.220265146Z ============================================================
2025-11-26T17:30:10.111331696Z [37m20251126-17:30:10.110 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [315][0m
2025-11-26T17:30:10.225406878Z Killed
2025-11-26T17:30:10.238236104Z [37m20251126-17:30:10.237 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [965][0m
2025-11-26T17:30:10.239450924Z Traceback (most recent call last):
2025-11-26T17:30:10.239462061Z   File "<frozen runpy>", line 198, in _run_module_as_main
2025-11-26T17:30:10.239464925Z   File "<frozen runpy>", line 88, in _run_code
2025-11-26T17:30:10.239470984Z   File "/workspace/AReaL/areal/launcher/local.py", line 405, in <module>
2025-11-26T17:30:10.239651524Z     main()
2025-11-26T17:30:10.239682811Z   File "/workspace/AReaL/areal/launcher/local.py", line 260, in main
2025-11-26T17:30:10.239779767Z     local_main(config, run_id=0)
2025-11-26T17:30:10.239783202Z   File "/workspace/AReaL/areal/launcher/local.py", line 399, in local_main
2025-11-26T17:30:10.239908329Z     raise e
2025-11-26T17:30:10.239911323Z   File "/workspace/AReaL/areal/launcher/local.py", line 375, in local_main
2025-11-26T17:30:10.240007117Z     launcher.wait(
2025-11-26T17:30:10.240010212Z   File "/workspace/AReaL/areal/launcher/local.py", line 235, in wait
2025-11-26T17:30:10.240072325Z     raise JobException(
2025-11-26T17:30:10.240075389Z areal.utils.launcher.JobException: Job gsm8k-grpo-cloud-2gpu-2000samples_trial_20251126_172923:trainer JobState.COMPLETED at node local
2025-11-26T17:30:10.446038397Z [37m20251126-17:30:10.445 Local Scheduler INFO: Waiting for 0 local running processes, pids: [0m
2025-11-26T17:30:25.510299886Z ==========
2025-11-26T17:30:25.510304583Z == CUDA ==
2025-11-26T17:30:25.510306897Z ==========
2025-11-26T17:30:25.515158794Z CUDA Version 12.9.1
2025-11-26T17:30:25.517172881Z Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
2025-11-26T17:30:25.518699537Z This container image and its contents are governed by the NVIDIA Deep Learning Container License.
2025-11-26T17:30:25.518702161Z By pulling and using the container, you accept the terms and conditions of this license:
2025-11-26T17:30:25.518704545Z https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license
2025-11-26T17:30:25.518709152Z A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
2025-11-26T17:30:25.686309107Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:30:25.846402838Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:30:26.036686860Z Branch 'feature/reasoning_model' set up to track remote branch 'feature/reasoning_model' from 'origin'.
2025-11-26T17:30:26.036710315Z Your branch is up to date with 'origin/feature/reasoning_model'.
2025-11-26T17:30:26.109332946Z Checking AReaL installation...
2025-11-26T17:30:26.168268024Z AReaL already installed. Skipping installation.
2025-11-26T17:30:26.168300993Z Cleaning up any leftover GPU processes...
2025-11-26T17:30:29.187306471Z Checking for processes holding GPU device files...
2025-11-26T17:30:31.170192396Z Found processes holding GPU devices: 1
2025-11-26T17:30:31.170239578Z 20
2025-11-26T17:30:31.170242402Z 71
2025-11-26T17:30:31.170244615Z 72
2025-11-26T17:30:31.170246648Z Killing process 1...
2025-11-26T17:30:31.170249412Z Killing process 71...
2025-11-26T17:30:31.170304164Z Killing process 72...
2025-11-26T17:30:33.172617770Z Using fuser to kill processes on GPU devices...
2025-11-26T17:30:35.195332184Z Checking GPU...
2025-11-26T17:30:35.235617847Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:30:35.235644016Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:30:35.254255264Z Set PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True for better memory management
2025-11-26T17:30:35.254276746Z Detected 2 GPU(s)
2025-11-26T17:30:35.254279850Z Checking GPU status...
2025-11-26T17:30:35.283888601Z index, name, utilization.gpu [%], memory.used [MiB], compute_mode
2025-11-26T17:30:35.285313074Z 0, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:30:35.285666995Z 1, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:30:35.336338685Z Verifying GPU accessibility...
2025-11-26T17:30:35.863476544Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:30:35.863532818Z   import pynvml  # type: ignore[import]
2025-11-26T17:30:36.965966832Z GPU accessibility verified on attempt 1
2025-11-26T17:30:37.428784188Z Starting training...
2025-11-26T17:30:40.431900706Z Using STANDARD 2000 SAMPLES 2 GPUs configuration
2025-11-26T17:30:40.431939524Z Note: GRPO only (no reasoning XML). Dataset capped at 2000 samples (~6 hours).
2025-11-26T17:30:40.431943420Z GPU count: 2 (required: 2)
2025-11-26T17:30:40.434410175Z ==========================================
2025-11-26T17:30:40.434412519Z Starting GRPO Training (Cloud)
2025-11-26T17:30:40.434415193Z ==========================================
2025-11-26T17:30:40.434417236Z Config: standard_2000samples_2GPUs
2025-11-26T17:30:40.434419229Z Config file: examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml
2025-11-26T17:30:40.434421833Z Training script: examples/cloud_gsm8k/gsm8k_grpo_train.py
2025-11-26T17:30:40.434424386Z Experiment: gsm8k-grpo-cloud-2gpu-2000samples
2025-11-26T17:30:40.434426389Z Trial: trial_20251126_173040
2025-11-26T17:30:40.434428533Z GPU: NVIDIA A100 80GB PCIe NVIDIA A100 80GB PCIe (81920 MB)
2025-11-26T17:30:40.434430516Z WandB API key: e1adc5be02...
2025-11-26T17:30:40.434432509Z ==========================================
2025-11-26T17:30:41.155177278Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:30:41.155233752Z   import pynvml  # type: ignore[import]
2025-11-26T17:30:45.181974327Z [37m20251126-17:30:45.181 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:30:45.182023211Z [37m20251126-17:30:45.181 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:30:45.182342618Z [37m20251126-17:30:45.181 name-resolve INFO: No such name resolve path: ./tmp/areal/name_resolve/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_173040[0m
2025-11-26T17:30:45.290727436Z [37m20251126-17:30:45.290 Local Scheduler INFO: LocalLauncher: experiment_name=gsm8k-grpo-cloud-2gpu-2000samples, trial_name=trial_20251126_173040, fileroot=/workspace/outputs/grpo, run_id=0, is_recover_run=False[0m
2025-11-26T17:30:45.297982264Z [37m20251126-17:30:45.297 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL CUDA_VISIBLE_DEVICES=0 stdbuf -oL python3 -m areal.launcher.sglang_server examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_173040 sglang.random_seed=1 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_173040/llm_server.log[0m
2025-11-26T17:30:46.054827837Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:30:46.054873746Z   import pynvml  # type: ignore[import]
2025-11-26T17:30:47.566170618Z [37m20251126-17:30:47.565 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:30:47.566207934Z [37m20251126-17:30:47.565 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:30:47.683254295Z [37m20251126-17:30:47.682 SGLangServer Wrapper INFO: Launch command: python3 -m sglang.launch_server --host 172.21.0.2 --port 11279 --tokenizer-path Qwen/Qwen2.5-0.5B-Instruct --tokenizer-mode auto --load-format auto --trust-remote-code --device cuda --tp-size 1 --base-gpu-id 0 --nnodes 1 --node-rank 0 --dist-init-addr localhost:22794 --model-path Qwen/Qwen2.5-0.5B-Instruct --random-seed 1 --skip-tokenizer-init --disable-radix-cache --torch-compile-max-bs 32 --triton-attention-num-kv-splits 8 --num-continuous-decode-steps 1 --attention-backend flashinfer --context-length 4096 --mem-fraction-static 0.6 --chunked-prefill-size -1 --max-prefill-tokens 32768 --schedule-policy lpm --schedule-conservativeness 1.0 --cpu-offload-gb 0 --dtype bfloat16 --kv-cache-dtype auto --dp-size 1 --ep-size 1 --max-loaded-loras 1 --max-loras-per-batch 1 --lora-backend triton --log-level warning --log-level-http warning --log-requests-level 0 --enable-metrics --decode-log-interval 1[0m
2025-11-26T17:30:48.732453079Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:30:48.732496535Z   import pynvml  # type: ignore[import]
2025-11-26T17:30:54.220785723Z INFO 11-26 17:30:54 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:30:54.930992789Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:30:55.926411037Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:30:55.926448933Z   import pynvml  # type: ignore[import]
2025-11-26T17:30:55.933290581Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:30:55.933305483Z   import pynvml  # type: ignore[import]
2025-11-26T17:31:01.521577535Z INFO 11-26 17:31:01 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:31:01.642176738Z INFO 11-26 17:31:01 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:31:02.272190274Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:31:02.494859805Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:31:02.498603402Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:31:02.499406786Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:31:02.500280746Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:31:02.533638091Z [2025-11-26 17:31:02] MOE_RUNNER_BACKEND is not initialized, using triton backend
2025-11-26T17:31:03.030883485Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:31:03.030922223Z   warnings.warn(
2025-11-26T17:31:03.030926729Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:31:03.030946408Z   warnings.warn(
2025-11-26T17:31:04.172977725Z Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
2025-11-26T17:31:04.277226507Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  9.62it/s]
2025-11-26T17:31:04.277704694Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  9.59it/s]
2025-11-26T17:31:06.734192668Z   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   4%|â–         | 1/23 [00:00<00:11,  1.91it/s]Capturing batches (bs=152 avail_mem=30.62 GB):   4%|â–         | 1/23 [00:00<00:11,  1.91it/s]Capturing batches (bs=144 avail_mem=30.60 GB):   4%|â–         | 1/23 [00:00<00:11,  1.91it/s]Capturing batches (bs=136 avail_mem=30.59 GB):   4%|â–         | 1/23 [00:00<00:11,  1.91it/s]Capturing batches (bs=136 avail_mem=30.59 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.46it/s]Capturing batches (bs=128 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.46it/s]Capturing batches (bs=120 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.46it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.46it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.83it/s]Capturing batches (bs=104 avail_mem=30.54 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.83it/s]Capturing batches (bs=96 avail_mem=30.53 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.83it/s] Capturing batches (bs=88 avail_mem=30.51 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.83it/s]Capturing batches (bs=88 avail_mem=30.51 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 15.19it/s]Capturing batches (bs=80 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 15.19it/s]Capturing batches (bs=72 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 15.19it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 15.19it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.66it/s]Capturing batches (bs=56 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.66it/s]Capturing batches (bs=48 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.66it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.66it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.68it/s]Capturing batches (bs=32 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.68it/s]Capturing batches (bs=24 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.68it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.68it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 18.25it/s]Capturing batches (bs=8 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 18.25it/s] Capturing batches (bs=4 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 18.25it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 18.25it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 20.04it/s]Capturing batches (bs=1 avail_mem=30.35 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 20.04it/s]Capturing batches (bs=1 avail_mem=30.35 GB): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00, 15.32it/s]
2025-11-26T17:31:12.713522087Z [37m20251126-17:31:12.712 SGLangServer Wrapper INFO: SGLang server launched at: http://172.21.0.2:11279[0m
2025-11-26T17:31:13.304945499Z [37m20251126-17:31:13.304 Launcher Utils INFO: Found 1 rollout servers: 172.21.0.2:11279[0m
2025-11-26T17:31:13.304970957Z [37m20251126-17:31:13.304 Local Scheduler INFO: LLM inference server launched at: AREAL_LLM_SERVER_ADDRS=172.21.0.2:11279[0m
2025-11-26T17:31:13.307882208Z [37m20251126-17:31:13.307 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL AREAL_LLM_SERVER_ADDRS=172.21.0.2:11279 AREAL_RECOVER_RUN=0 NCCL_CUMEM_ENABLE=0 NCCL_NVLS_ENABLE=0 CUDA_VISIBLE_DEVICES=1 stdbuf -oL torchrun --nnodes 1 --nproc-per-node 1 --master-addr localhost --master-port 30473 examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_173040 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_173040/trainer.log[0m
2025-11-26T17:31:13.308448346Z [37m20251126-17:31:13.308 Local Scheduler INFO: Waiting for 2 local running processes, pids: 315 965[0m
2025-11-26T17:31:13.821800125Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:31:13.821847175Z   import pynvml  # type: ignore[import]
2025-11-26T17:31:15.004078516Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:31:15.004143955Z   import pynvml  # type: ignore[import]
2025-11-26T17:31:21.920597903Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:31:21.920629911Z   warnings.warn(
2025-11-26T17:31:21.920632916Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:31:21.920635190Z   warnings.warn(
2025-11-26T17:31:22.337225581Z Traceback (most recent call last):
2025-11-26T17:31:22.337268746Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 665, in <module>
2025-11-26T17:31:22.337918299Z     main(sys.argv[1:])
2025-11-26T17:31:22.337925570Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 102, in main
2025-11-26T17:31:22.337928525Z     config, _ = load_expr_config(args_with_overrides, GRPOConfig)
2025-11-26T17:31:22.337930989Z                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:31:22.337933102Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1282, in load_expr_config
2025-11-26T17:31:22.337935095Z     cfg = to_structured_cfg(cfg, config_cls=config_cls)
2025-11-26T17:31:22.338403997Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:31:22.338419500Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1276, in to_structured_cfg
2025-11-26T17:31:22.338421864Z     cfg = OmegaConf.merge(default_cfg, cfg)
2025-11-26T17:31:22.338423947Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:31:22.338426070Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/omegaconf.py", line 274, in merge
2025-11-26T17:31:22.338428143Z     target.merge_with(
2025-11-26T17:31:22.338430256Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 507, in merge_with
2025-11-26T17:31:22.338822614Z     self._format_and_raise(key=None, value=None, cause=e)
2025-11-26T17:31:22.338825849Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:31:22.338828082Z     format_and_raise(
2025-11-26T17:31:22.338830205Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:31:22.338832259Z     _raise(ex, cause)
2025-11-26T17:31:22.338834322Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:31:22.338836375Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:31:22.339314721Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:31:22.339319869Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 502, in merge_with
2025-11-26T17:31:22.339322142Z     self._merge_with(
2025-11-26T17:31:22.339324155Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:31:22.339326228Z     BaseContainer._map_merge(
2025-11-26T17:31:22.339328992Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:31:22.339331015Z     dest_node._merge_with(
2025-11-26T17:31:22.339333249Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:31:22.339335542Z     BaseContainer._map_merge(
2025-11-26T17:31:22.339337756Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:31:22.339339789Z     dest_node._merge_with(
2025-11-26T17:31:22.339341802Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:31:22.339771836Z     BaseContainer._map_merge(
2025-11-26T17:31:22.339774841Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 432, in _map_merge
2025-11-26T17:31:22.339776934Z     dest[key] = src._get_node(key)
2025-11-26T17:31:22.339778967Z     ~~~~^^^^^
2025-11-26T17:31:22.339781370Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 308, in __setitem__
2025-11-26T17:31:22.339783444Z     self._format_and_raise(
2025-11-26T17:31:22.339785477Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:31:22.339787480Z     format_and_raise(
2025-11-26T17:31:22.339789463Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:31:22.339791566Z     _raise(ex, cause)
2025-11-26T17:31:22.339793549Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:31:22.340608109Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:31:22.340612686Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:31:22.340614739Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 306, in __setitem__
2025-11-26T17:31:22.340616982Z     self.__set_impl(key=key, value=value)
2025-11-26T17:31:22.340619075Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 316, in __set_impl
2025-11-26T17:31:22.340621108Z     self._set_item_impl(key, value)
2025-11-26T17:31:22.340623211Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 579, in _set_item_impl
2025-11-26T17:31:22.340625225Z     target_node_ref = self._get_node(key)
2025-11-26T17:31:22.340627518Z                       ^^^^^^^^^^^^^^^^^^^
2025-11-26T17:31:22.340633266Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 473, in _get_node
2025-11-26T17:31:22.340635580Z     self._validate_get(key)
2025-11-26T17:31:22.340637623Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 163, in _validate_get
2025-11-26T17:31:22.340639676Z     self._format_and_raise(
2025-11-26T17:31:22.340641709Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:31:22.340923752Z     format_and_raise(
2025-11-26T17:31:22.340926756Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 906, in format_and_raise
2025-11-26T17:31:22.340928839Z     _raise(ex, cause)
2025-11-26T17:31:22.340930932Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:31:22.340932955Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:31:22.341323851Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:31:22.341331502Z omegaconf.errors.ConfigKeyError: Key 'max_new_tokens' not in 'NormConfig'
2025-11-26T17:31:22.341334186Z     full_key: actor.adv_norm.max_new_tokens
2025-11-26T17:31:22.341336530Z     reference_type=Optional[NormConfig]
2025-11-26T17:31:22.341338613Z     object_type=NormConfig
2025-11-26T17:31:25.011297200Z E1126 17:31:25.010000 966 torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 0 (pid: 1032) of binary: /usr/bin/python3
2025-11-26T17:31:25.011950950Z Traceback (most recent call last):
2025-11-26T17:31:25.011954696Z   File "/usr/local/bin/torchrun", line 7, in <module>
2025-11-26T17:31:25.011957289Z     sys.exit(main())
2025-11-26T17:31:25.011960013Z              ^^^^^^
2025-11-26T17:31:25.011962167Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
2025-11-26T17:31:25.011965031Z     return f(*args, **kwargs)
2025-11-26T17:31:25.011967635Z            ^^^^^^^^^^^^^^^^^^
2025-11-26T17:31:25.011969648Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 901, in main
2025-11-26T17:31:25.012547644Z     run(args)
2025-11-26T17:31:25.012552120Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 892, in run
2025-11-26T17:31:25.012555185Z     elastic_launch(
2025-11-26T17:31:25.012557749Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 143, in __call__
2025-11-26T17:31:25.012560513Z     return launch_agent(self._config, self._entrypoint, list(args))
2025-11-26T17:31:25.012563558Z            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:31:25.012565581Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 277, in launch_agent
2025-11-26T17:31:25.012567664Z     raise ChildFailedError(
2025-11-26T17:31:25.012570178Z torch.distributed.elastic.multiprocessing.errors.ChildFailedError:
2025-11-26T17:31:25.012572341Z ============================================================
2025-11-26T17:31:25.012575025Z examples/cloud_gsm8k/gsm8k_grpo_train.py FAILED
2025-11-26T17:31:25.012577338Z ------------------------------------------------------------
2025-11-26T17:31:25.012579332Z Failures:
2025-11-26T17:31:25.012581335Z   <NO_OTHER_FAILURES>
2025-11-26T17:31:25.012583327Z ------------------------------------------------------------
2025-11-26T17:31:25.012585361Z Root Cause (first observed failure):
2025-11-26T17:31:25.012587404Z [0]:
2025-11-26T17:31:25.012589476Z   time      : 2025-11-26_17:31:25
2025-11-26T17:31:25.012591580Z   host      : cef7c503fdea
2025-11-26T17:31:25.012593613Z   rank      : 0 (local_rank: 0)
2025-11-26T17:31:25.012595626Z   exitcode  : 1 (pid: 1032)
2025-11-26T17:31:25.012597659Z   error_file: <N/A>
2025-11-26T17:31:25.012599692Z   traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
2025-11-26T17:31:25.012601775Z ============================================================
2025-11-26T17:31:25.311602122Z [37m20251126-17:31:25.311 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [315][0m
2025-11-26T17:31:25.432659351Z Killed
2025-11-26T17:31:25.441027866Z [37m20251126-17:31:25.440 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [965][0m
2025-11-26T17:31:25.442413552Z Traceback (most recent call last):
2025-11-26T17:31:25.442427853Z   File "<frozen runpy>", line 198, in _run_module_as_main
2025-11-26T17:31:25.442430517Z   File "<frozen runpy>", line 88, in _run_code
2025-11-26T17:31:25.442432620Z   File "/workspace/AReaL/areal/launcher/local.py", line 405, in <module>
2025-11-26T17:31:25.442538659Z     main()
2025-11-26T17:31:25.442545930Z   File "/workspace/AReaL/areal/launcher/local.py", line 260, in main
2025-11-26T17:31:25.442626031Z     local_main(config, run_id=0)
2025-11-26T17:31:25.442660371Z   File "/workspace/AReaL/areal/launcher/local.py", line 399, in local_main
2025-11-26T17:31:25.442727021Z     raise e
2025-11-26T17:31:25.442729445Z   File "/workspace/AReaL/areal/launcher/local.py", line 375, in local_main
2025-11-26T17:31:25.442794783Z     launcher.wait(
2025-11-26T17:31:25.442797988Z   File "/workspace/AReaL/areal/launcher/local.py", line 235, in wait
2025-11-26T17:31:25.442861232Z     raise JobException(
2025-11-26T17:31:25.442864497Z areal.utils.launcher.JobException: Job gsm8k-grpo-cloud-2gpu-2000samples_trial_20251126_173040:trainer JobState.COMPLETED at node local
2025-11-26T17:31:25.693220291Z [37m20251126-17:31:25.692 Local Scheduler INFO: Waiting for 0 local running processes, pids: [0m
2025-11-26T17:31:28.294911622Z ==========
2025-11-26T17:31:28.294914306Z == CUDA ==
2025-11-26T17:31:28.294918492Z ==========
2025-11-26T17:31:28.299058113Z CUDA Version 12.9.1
2025-11-26T17:31:28.300788255Z Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
2025-11-26T17:31:28.302469022Z This container image and its contents are governed by the NVIDIA Deep Learning Container License.
2025-11-26T17:31:28.302472017Z By pulling and using the container, you accept the terms and conditions of this license:
2025-11-26T17:31:28.302475302Z https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license
2025-11-26T17:31:28.302479768Z A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
2025-11-26T17:31:28.465979862Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:31:28.621619040Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:31:28.807960017Z Branch 'feature/reasoning_model' set up to track remote branch 'feature/reasoning_model' from 'origin'.
2025-11-26T17:31:28.807998184Z Your branch is up to date with 'origin/feature/reasoning_model'.
2025-11-26T17:31:28.878015052Z Checking AReaL installation...
2025-11-26T17:31:28.935599215Z AReaL already installed. Skipping installation.
2025-11-26T17:31:28.935630442Z Cleaning up any leftover GPU processes...
2025-11-26T17:31:31.954298776Z Checking for processes holding GPU device files...
2025-11-26T17:31:33.978780007Z Found processes holding GPU devices: 1
2025-11-26T17:31:33.978815839Z 21
2025-11-26T17:31:33.978818573Z 72
2025-11-26T17:31:33.978821177Z 73
2025-11-26T17:31:33.978823551Z Killing process 1...
2025-11-26T17:31:33.978826425Z Killing process 72...
2025-11-26T17:31:33.978836210Z Killing process 73...
2025-11-26T17:31:35.981401643Z Using fuser to kill processes on GPU devices...
2025-11-26T17:31:38.002436672Z Checking GPU...
2025-11-26T17:31:38.046968976Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:31:38.046993823Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:31:38.064477752Z Set PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True for better memory management
2025-11-26T17:31:38.064497021Z Detected 2 GPU(s)
2025-11-26T17:31:38.064500235Z Checking GPU status...
2025-11-26T17:31:38.092521678Z index, name, utilization.gpu [%], memory.used [MiB], compute_mode
2025-11-26T17:31:38.093918079Z 0, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:31:38.094274734Z 1, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:31:38.144357702Z Verifying GPU accessibility...
2025-11-26T17:31:38.661483194Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:31:38.661532678Z   import pynvml  # type: ignore[import]
2025-11-26T17:31:39.763076389Z GPU accessibility verified on attempt 1
2025-11-26T17:31:40.207755155Z Starting training...
2025-11-26T17:31:43.210856200Z Using STANDARD 2000 SAMPLES 2 GPUs configuration
2025-11-26T17:31:43.210893736Z Note: GRPO only (no reasoning XML). Dataset capped at 2000 samples (~6 hours).
2025-11-26T17:31:43.210901358Z GPU count: 2 (required: 2)
2025-11-26T17:31:43.213544898Z ==========================================
2025-11-26T17:31:43.213548553Z Starting GRPO Training (Cloud)
2025-11-26T17:31:43.213552850Z ==========================================
2025-11-26T17:31:43.213555113Z Config: standard_2000samples_2GPUs
2025-11-26T17:31:43.213557156Z Config file: examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml
2025-11-26T17:31:43.213560141Z Training script: examples/cloud_gsm8k/gsm8k_grpo_train.py
2025-11-26T17:31:43.213562684Z Experiment: gsm8k-grpo-cloud-2gpu-2000samples
2025-11-26T17:31:43.213564877Z Trial: trial_20251126_173143
2025-11-26T17:31:43.213566911Z GPU: NVIDIA A100 80GB PCIe NVIDIA A100 80GB PCIe (81920 MB)
2025-11-26T17:31:43.213568923Z WandB API key: e1adc5be02...
2025-11-26T17:31:43.213570906Z ==========================================
2025-11-26T17:31:43.885460987Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:31:43.885496610Z   import pynvml  # type: ignore[import]
2025-11-26T17:31:47.804623343Z [37m20251126-17:31:47.804 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:31:47.804661510Z [37m20251126-17:31:47.804 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:31:47.805005625Z [37m20251126-17:31:47.804 name-resolve INFO: No such name resolve path: ./tmp/areal/name_resolve/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_173143[0m
2025-11-26T17:31:47.910288717Z [37m20251126-17:31:47.909 Local Scheduler INFO: LocalLauncher: experiment_name=gsm8k-grpo-cloud-2gpu-2000samples, trial_name=trial_20251126_173143, fileroot=/workspace/outputs/grpo, run_id=0, is_recover_run=False[0m
2025-11-26T17:31:47.918066968Z [37m20251126-17:31:47.917 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL CUDA_VISIBLE_DEVICES=0 stdbuf -oL python3 -m areal.launcher.sglang_server examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_173143 sglang.random_seed=1 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_173143/llm_server.log[0m
2025-11-26T17:31:48.679995826Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:31:48.680038540Z   import pynvml  # type: ignore[import]
2025-11-26T17:31:50.177840067Z [37m20251126-17:31:50.177 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:31:50.178437843Z [37m20251126-17:31:50.177 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:31:50.292870058Z [37m20251126-17:31:50.292 SGLangServer Wrapper INFO: Launch command: python3 -m sglang.launch_server --host 172.21.0.2 --port 15102 --tokenizer-path Qwen/Qwen2.5-0.5B-Instruct --tokenizer-mode auto --load-format auto --trust-remote-code --device cuda --tp-size 1 --base-gpu-id 0 --nnodes 1 --node-rank 0 --dist-init-addr localhost:25061 --model-path Qwen/Qwen2.5-0.5B-Instruct --random-seed 1 --skip-tokenizer-init --disable-radix-cache --torch-compile-max-bs 32 --triton-attention-num-kv-splits 8 --num-continuous-decode-steps 1 --attention-backend flashinfer --context-length 4096 --mem-fraction-static 0.6 --chunked-prefill-size -1 --max-prefill-tokens 32768 --schedule-policy lpm --schedule-conservativeness 1.0 --cpu-offload-gb 0 --dtype bfloat16 --kv-cache-dtype auto --dp-size 1 --ep-size 1 --max-loaded-loras 1 --max-loras-per-batch 1 --lora-backend triton --log-level warning --log-level-http warning --log-requests-level 0 --enable-metrics --decode-log-interval 1[0m
2025-11-26T17:31:51.332338107Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:31:51.332383795Z   import pynvml  # type: ignore[import]
2025-11-26T17:31:56.737254564Z INFO 11-26 17:31:56 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:31:57.379962082Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:31:58.398581683Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:31:58.398620071Z   import pynvml  # type: ignore[import]
2025-11-26T17:31:58.400667227Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:31:58.400678765Z   import pynvml  # type: ignore[import]
2025-11-26T17:32:03.903593671Z INFO 11-26 17:32:03 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:32:03.986321258Z INFO 11-26 17:32:03 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:32:04.587728003Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:32:04.809916364Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:32:04.813736586Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:32:04.814633080Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:32:04.815530473Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:32:04.849031553Z [2025-11-26 17:32:04] MOE_RUNNER_BACKEND is not initialized, using triton backend
2025-11-26T17:32:05.346055977Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:32:05.346093994Z   warnings.warn(
2025-11-26T17:32:05.346097059Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:32:05.346136027Z   warnings.warn(
2025-11-26T17:32:06.604977481Z Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
2025-11-26T17:32:06.721099427Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  8.62it/s]
2025-11-26T17:32:06.721682961Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  8.60it/s]
2025-11-26T17:32:09.202102503Z   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   4%|â–         | 1/23 [00:00<00:11,  1.87it/s]Capturing batches (bs=152 avail_mem=30.62 GB):   4%|â–         | 1/23 [00:00<00:11,  1.87it/s]Capturing batches (bs=144 avail_mem=30.60 GB):   4%|â–         | 1/23 [00:00<00:11,  1.87it/s]Capturing batches (bs=136 avail_mem=30.59 GB):   4%|â–         | 1/23 [00:00<00:11,  1.87it/s]Capturing batches (bs=136 avail_mem=30.59 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.31it/s]Capturing batches (bs=128 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.31it/s]Capturing batches (bs=120 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.31it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.31it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.56it/s]Capturing batches (bs=104 avail_mem=30.54 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.56it/s]Capturing batches (bs=96 avail_mem=30.53 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.56it/s] Capturing batches (bs=88 avail_mem=30.51 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.56it/s]Capturing batches (bs=88 avail_mem=30.51 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.78it/s]Capturing batches (bs=80 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.78it/s]Capturing batches (bs=72 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.78it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:01<00:00, 14.78it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.18it/s]Capturing batches (bs=56 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.18it/s]Capturing batches (bs=48 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.18it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.18it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.17it/s]Capturing batches (bs=32 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.17it/s]Capturing batches (bs=24 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.17it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.17it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.58it/s]Capturing batches (bs=8 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.58it/s] Capturing batches (bs=4 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.58it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.58it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.38it/s]Capturing batches (bs=1 avail_mem=30.35 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.38it/s]Capturing batches (bs=1 avail_mem=30.35 GB): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00, 14.88it/s]
2025-11-26T17:32:15.323872681Z [37m20251126-17:32:15.323 SGLangServer Wrapper INFO: SGLang server launched at: http://172.21.0.2:15102[0m
2025-11-26T17:32:15.924918055Z [37m20251126-17:32:15.924 Launcher Utils INFO: Found 1 rollout servers: 172.21.0.2:15102[0m
2025-11-26T17:32:15.924973198Z [37m20251126-17:32:15.924 Local Scheduler INFO: LLM inference server launched at: AREAL_LLM_SERVER_ADDRS=172.21.0.2:15102[0m
2025-11-26T17:32:15.927662045Z [37m20251126-17:32:15.927 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL AREAL_LLM_SERVER_ADDRS=172.21.0.2:15102 AREAL_RECOVER_RUN=0 NCCL_CUMEM_ENABLE=0 NCCL_NVLS_ENABLE=0 CUDA_VISIBLE_DEVICES=1 stdbuf -oL torchrun --nnodes 1 --nproc-per-node 1 --master-addr localhost --master-port 10786 examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_173143 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_173143/trainer.log[0m
2025-11-26T17:32:15.928290336Z [37m20251126-17:32:15.928 Local Scheduler INFO: Waiting for 2 local running processes, pids: 316 966[0m
2025-11-26T17:32:16.460249457Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:32:16.460288716Z   import pynvml  # type: ignore[import]
2025-11-26T17:32:17.644239563Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:32:17.644285231Z   import pynvml  # type: ignore[import]
2025-11-26T17:32:24.308088961Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:32:24.308149220Z   warnings.warn(
2025-11-26T17:32:24.308153887Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:32:24.308156331Z   warnings.warn(
2025-11-26T17:32:24.730089908Z Traceback (most recent call last):
2025-11-26T17:32:24.730138229Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 665, in <module>
2025-11-26T17:32:24.731234743Z     main(sys.argv[1:])
2025-11-26T17:32:24.731251818Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 102, in main
2025-11-26T17:32:24.731254843Z     config, _ = load_expr_config(args_with_overrides, GRPOConfig)
2025-11-26T17:32:24.731257507Z                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:32:24.731259540Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1282, in load_expr_config
2025-11-26T17:32:24.731261523Z     cfg = to_structured_cfg(cfg, config_cls=config_cls)
2025-11-26T17:32:24.731263686Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:32:24.731265729Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1276, in to_structured_cfg
2025-11-26T17:32:24.731267921Z     cfg = OmegaConf.merge(default_cfg, cfg)
2025-11-26T17:32:24.731281392Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:32:24.731283685Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/omegaconf.py", line 274, in merge
2025-11-26T17:32:24.731285848Z     target.merge_with(
2025-11-26T17:32:24.731287891Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 507, in merge_with
2025-11-26T17:32:24.731713830Z     self._format_and_raise(key=None, value=None, cause=e)
2025-11-26T17:32:24.731737846Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:32:24.731741161Z     format_and_raise(
2025-11-26T17:32:24.731748221Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:32:24.731750425Z     _raise(ex, cause)
2025-11-26T17:32:24.731752488Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:32:24.731755222Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:32:24.731995732Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:32:24.732003093Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 502, in merge_with
2025-11-26T17:32:24.732007550Z     self._merge_with(
2025-11-26T17:32:24.732010084Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:32:24.732012387Z     BaseContainer._map_merge(
2025-11-26T17:32:24.732015662Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:32:24.732017745Z     dest_node._merge_with(
2025-11-26T17:32:24.732019839Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:32:24.732485666Z     BaseContainer._map_merge(
2025-11-26T17:32:24.732505966Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:32:24.732509151Z     dest_node._merge_with(
2025-11-26T17:32:24.732511244Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:32:24.732513427Z     BaseContainer._map_merge(
2025-11-26T17:32:24.732515490Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 432, in _map_merge
2025-11-26T17:32:24.732517544Z     dest[key] = src._get_node(key)
2025-11-26T17:32:24.732520428Z     ~~~~^^^^^
2025-11-26T17:32:24.732522901Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 308, in __setitem__
2025-11-26T17:32:24.732524955Z     self._format_and_raise(
2025-11-26T17:32:24.732526978Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:32:24.733194568Z     format_and_raise(
2025-11-26T17:32:24.733204513Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:32:24.733207207Z     _raise(ex, cause)
2025-11-26T17:32:24.733209461Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:32:24.733211984Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:32:24.733214398Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:32:24.733216992Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 306, in __setitem__
2025-11-26T17:32:24.733219225Z     self.__set_impl(key=key, value=value)
2025-11-26T17:32:24.733221258Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 316, in __set_impl
2025-11-26T17:32:24.733223331Z     self._set_item_impl(key, value)
2025-11-26T17:32:24.733225474Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 579, in _set_item_impl
2025-11-26T17:32:24.733227888Z     target_node_ref = self._get_node(key)
2025-11-26T17:32:24.733503591Z                       ^^^^^^^^^^^^^^^^^^^
2025-11-26T17:32:24.733508148Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 473, in _get_node
2025-11-26T17:32:24.733521107Z     self._validate_get(key)
2025-11-26T17:32:24.733523501Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 163, in _validate_get
2025-11-26T17:32:24.733525684Z     self._format_and_raise(
2025-11-26T17:32:24.733527657Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:32:24.733806715Z     format_and_raise(
2025-11-26T17:32:24.733811002Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 906, in format_and_raise
2025-11-26T17:32:24.733813335Z     _raise(ex, cause)
2025-11-26T17:32:24.733815308Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:32:24.733817632Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:32:24.734071932Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:32:24.734074456Z omegaconf.errors.ConfigKeyError: Key 'max_new_tokens' not in 'NormConfig'
2025-11-26T17:32:24.734076960Z     full_key: actor.adv_norm.max_new_tokens
2025-11-26T17:32:24.734078963Z     reference_type=Optional[NormConfig]
2025-11-26T17:32:24.734081126Z     object_type=NormConfig
2025-11-26T17:32:27.060392292Z E1126 17:32:27.059000 967 torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 0 (pid: 1033) of binary: /usr/bin/python3
2025-11-26T17:32:27.060963658Z Traceback (most recent call last):
2025-11-26T17:32:27.060971269Z   File "/usr/local/bin/torchrun", line 7, in <module>
2025-11-26T17:32:27.061472540Z     sys.exit(main())
2025-11-26T17:32:27.061479049Z              ^^^^^^
2025-11-26T17:32:27.061481213Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
2025-11-26T17:32:27.061483826Z     return f(*args, **kwargs)
2025-11-26T17:32:27.061486320Z            ^^^^^^^^^^^^^^^^^^
2025-11-26T17:32:27.061488303Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 901, in main
2025-11-26T17:32:27.061490967Z     run(args)
2025-11-26T17:32:27.061493321Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 892, in run
2025-11-26T17:32:27.061956394Z     elastic_launch(
2025-11-26T17:32:27.061981562Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 143, in __call__
2025-11-26T17:32:27.061984596Z     return launch_agent(self._config, self._entrypoint, list(args))
2025-11-26T17:32:27.061987591Z            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:32:27.061989904Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 277, in launch_agent
2025-11-26T17:32:27.061992708Z     raise ChildFailedError(
2025-11-26T17:32:27.061995773Z torch.distributed.elastic.multiprocessing.errors.ChildFailedError:
2025-11-26T17:32:27.061997906Z ============================================================
2025-11-26T17:32:27.062000330Z examples/cloud_gsm8k/gsm8k_grpo_train.py FAILED
2025-11-26T17:32:27.062002823Z ------------------------------------------------------------
2025-11-26T17:32:27.062004857Z Failures:
2025-11-26T17:32:27.062007591Z   <NO_OTHER_FAILURES>
2025-11-26T17:32:27.062009914Z ------------------------------------------------------------
2025-11-26T17:32:27.062012037Z Root Cause (first observed failure):
2025-11-26T17:32:27.062014080Z [0]:
2025-11-26T17:32:27.062016114Z   time      : 2025-11-26_17:32:27
2025-11-26T17:32:27.062018167Z   host      : cef7c503fdea
2025-11-26T17:32:27.062020170Z   rank      : 0 (local_rank: 0)
2025-11-26T17:32:27.062022132Z   exitcode  : 1 (pid: 1033)
2025-11-26T17:32:27.062024155Z   error_file: <N/A>
2025-11-26T17:32:27.062026159Z   traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
2025-11-26T17:32:27.062028793Z ============================================================
2025-11-26T17:32:27.931343081Z [37m20251126-17:32:27.930 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [316][0m
2025-11-26T17:32:28.088012994Z Killed
2025-11-26T17:32:28.093410609Z [37m20251126-17:32:28.093 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [966][0m
2025-11-26T17:32:28.094342205Z Traceback (most recent call last):
2025-11-26T17:32:28.094353702Z   File "<frozen runpy>", line 198, in _run_module_as_main
2025-11-26T17:32:28.094356867Z   File "<frozen runpy>", line 88, in _run_code
2025-11-26T17:32:28.094358950Z   File "/workspace/AReaL/areal/launcher/local.py", line 405, in <module>
2025-11-26T17:32:28.094487802Z     main()
2025-11-26T17:32:28.094490957Z   File "/workspace/AReaL/areal/launcher/local.py", line 260, in main
2025-11-26T17:32:28.094582985Z     local_main(config, run_id=0)
2025-11-26T17:32:28.094586931Z   File "/workspace/AReaL/areal/launcher/local.py", line 399, in local_main
2025-11-26T17:32:28.094690526Z     raise e
2025-11-26T17:32:28.094693180Z   File "/workspace/AReaL/areal/launcher/local.py", line 375, in local_main
2025-11-26T17:32:28.094755453Z     launcher.wait(
2025-11-26T17:32:28.094758057Z   File "/workspace/AReaL/areal/launcher/local.py", line 235, in wait
2025-11-26T17:32:28.094808914Z     raise JobException(
2025-11-26T17:32:28.094811788Z areal.utils.launcher.JobException: Job gsm8k-grpo-cloud-2gpu-2000samples_trial_20251126_173143:trainer JobState.COMPLETED at node local
2025-11-26T17:32:28.407287309Z [37m20251126-17:32:28.406 Local Scheduler INFO: Waiting for 0 local running processes, pids: [0m
2025-11-26T17:32:31.065725019Z ==========
2025-11-26T17:32:31.065728044Z == CUDA ==
2025-11-26T17:32:31.065733632Z ==========
2025-11-26T17:32:31.070415044Z CUDA Version 12.9.1
2025-11-26T17:32:31.072407900Z Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
2025-11-26T17:32:31.074203880Z This container image and its contents are governed by the NVIDIA Deep Learning Container License.
2025-11-26T17:32:31.074206964Z By pulling and using the container, you accept the terms and conditions of this license:
2025-11-26T17:32:31.074210169Z https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license
2025-11-26T17:32:31.074215597Z A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
2025-11-26T17:32:31.237067200Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:32:31.392763944Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:32:31.585979810Z Branch 'feature/reasoning_model' set up to track remote branch 'feature/reasoning_model' from 'origin'.
2025-11-26T17:32:31.586017716Z Your branch is up to date with 'origin/feature/reasoning_model'.
2025-11-26T17:32:31.658754898Z Checking AReaL installation...
2025-11-26T17:32:31.717996835Z AReaL already installed. Skipping installation.
2025-11-26T17:32:31.718029234Z Cleaning up any leftover GPU processes...
2025-11-26T17:32:34.738181169Z Checking for processes holding GPU device files...
2025-11-26T17:32:37.545964181Z Found processes holding GPU devices: 1
2025-11-26T17:32:37.546008037Z 20
2025-11-26T17:32:37.546011182Z 71
2025-11-26T17:32:37.546013555Z 72
2025-11-26T17:32:37.546015699Z Killing process 1...
2025-11-26T17:32:37.546020005Z Killing process 71...
2025-11-26T17:32:37.546205563Z Killing process 72...
2025-11-26T17:32:39.549045768Z Using fuser to kill processes on GPU devices...
2025-11-26T17:32:41.573182162Z Checking GPU...
2025-11-26T17:32:41.608216279Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:32:41.608255638Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:32:41.625285206Z Set PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True for better memory management
2025-11-26T17:32:41.625316803Z Detected 2 GPU(s)
2025-11-26T17:32:41.625319978Z Checking GPU status...
2025-11-26T17:32:41.653640840Z index, name, utilization.gpu [%], memory.used [MiB], compute_mode
2025-11-26T17:32:41.655152804Z 0, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:32:41.655431711Z 1, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:32:41.698380474Z Verifying GPU accessibility...
2025-11-26T17:32:42.246142195Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:32:42.246226712Z   import pynvml  # type: ignore[import]
2025-11-26T17:32:43.363755807Z GPU accessibility verified on attempt 1
2025-11-26T17:32:43.891026545Z Starting training...
2025-11-26T17:32:46.893757867Z Using STANDARD 2000 SAMPLES 2 GPUs configuration
2025-11-26T17:32:46.893796504Z Note: GRPO only (no reasoning XML). Dataset capped at 2000 samples (~6 hours).
2025-11-26T17:32:46.893799699Z GPU count: 2 (required: 2)
2025-11-26T17:32:46.896081157Z ==========================================
2025-11-26T17:32:46.896084492Z Starting GRPO Training (Cloud)
2025-11-26T17:32:46.896087136Z ==========================================
2025-11-26T17:32:46.896089219Z Config: standard_2000samples_2GPUs
2025-11-26T17:32:46.896091372Z Config file: examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml
2025-11-26T17:32:46.896094387Z Training script: examples/cloud_gsm8k/gsm8k_grpo_train.py
2025-11-26T17:32:46.896096951Z Experiment: gsm8k-grpo-cloud-2gpu-2000samples
2025-11-26T17:32:46.896099014Z Trial: trial_20251126_173246
2025-11-26T17:32:46.896101007Z GPU: NVIDIA A100 80GB PCIe NVIDIA A100 80GB PCIe (81920 MB)
2025-11-26T17:32:46.896103030Z WandB API key: e1adc5be02...
2025-11-26T17:32:46.896105033Z ==========================================
2025-11-26T17:32:47.573600640Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:32:47.573647069Z   import pynvml  # type: ignore[import]
2025-11-26T17:32:51.507984846Z [37m20251126-17:32:51.507 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:32:51.508029683Z [37m20251126-17:32:51.507 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:32:51.508257494Z [37m20251126-17:32:51.507 name-resolve INFO: No such name resolve path: ./tmp/areal/name_resolve/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_173246[0m
2025-11-26T17:32:51.613995928Z [37m20251126-17:32:51.613 Local Scheduler INFO: LocalLauncher: experiment_name=gsm8k-grpo-cloud-2gpu-2000samples, trial_name=trial_20251126_173246, fileroot=/workspace/outputs/grpo, run_id=0, is_recover_run=False[0m
2025-11-26T17:32:51.621776192Z [37m20251126-17:32:51.621 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL CUDA_VISIBLE_DEVICES=0 stdbuf -oL python3 -m areal.launcher.sglang_server examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_173246 sglang.random_seed=1 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_173246/llm_server.log[0m
2025-11-26T17:32:52.360074965Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:32:52.360135475Z   import pynvml  # type: ignore[import]
2025-11-26T17:32:53.855569276Z [37m20251126-17:32:53.854 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:32:53.856172319Z [37m20251126-17:32:53.855 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:32:53.970189293Z [37m20251126-17:32:53.969 SGLangServer Wrapper INFO: Launch command: python3 -m sglang.launch_server --host 172.21.0.2 --port 13881 --tokenizer-path Qwen/Qwen2.5-0.5B-Instruct --tokenizer-mode auto --load-format auto --trust-remote-code --device cuda --tp-size 1 --base-gpu-id 0 --nnodes 1 --node-rank 0 --dist-init-addr localhost:20164 --model-path Qwen/Qwen2.5-0.5B-Instruct --random-seed 1 --skip-tokenizer-init --disable-radix-cache --torch-compile-max-bs 32 --triton-attention-num-kv-splits 8 --num-continuous-decode-steps 1 --attention-backend flashinfer --context-length 4096 --mem-fraction-static 0.6 --chunked-prefill-size -1 --max-prefill-tokens 32768 --schedule-policy lpm --schedule-conservativeness 1.0 --cpu-offload-gb 0 --dtype bfloat16 --kv-cache-dtype auto --dp-size 1 --ep-size 1 --max-loaded-loras 1 --max-loras-per-batch 1 --lora-backend triton --log-level warning --log-level-http warning --log-requests-level 0 --enable-metrics --decode-log-interval 1[0m
2025-11-26T17:32:55.095971089Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:32:55.096013203Z   import pynvml  # type: ignore[import]
2025-11-26T17:33:00.904193421Z INFO 11-26 17:33:00 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:33:01.570524935Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:33:02.963884601Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:33:02.963926054Z   import pynvml  # type: ignore[import]
2025-11-26T17:33:02.971329503Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:33:02.971348882Z   import pynvml  # type: ignore[import]
2025-11-26T17:33:08.104002745Z INFO 11-26 17:33:08 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:33:08.221524237Z INFO 11-26 17:33:08 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:33:08.789206007Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:33:09.011682260Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:33:09.015234831Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:33:09.016095821Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:33:09.016938643Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:33:09.049282641Z [2025-11-26 17:33:09] MOE_RUNNER_BACKEND is not initialized, using triton backend
2025-11-26T17:33:09.525465946Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:33:09.525506206Z   warnings.warn(
2025-11-26T17:33:09.525509521Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:33:09.525511745Z   warnings.warn(
2025-11-26T17:33:10.613300562Z Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
2025-11-26T17:33:10.726480272Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  8.85it/s]
2025-11-26T17:33:10.727002123Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  8.83it/s]
2025-11-26T17:33:13.162126548Z   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   4%|â–         | 1/23 [00:00<00:11,  1.87it/s]Capturing batches (bs=152 avail_mem=30.62 GB):   4%|â–         | 1/23 [00:00<00:11,  1.87it/s]Capturing batches (bs=144 avail_mem=30.60 GB):   4%|â–         | 1/23 [00:00<00:11,  1.87it/s]Capturing batches (bs=136 avail_mem=30.59 GB):   4%|â–         | 1/23 [00:00<00:11,  1.87it/s]Capturing batches (bs=136 avail_mem=30.59 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.36it/s]Capturing batches (bs=128 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.36it/s]Capturing batches (bs=120 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.36it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.36it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.68it/s]Capturing batches (bs=104 avail_mem=30.54 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.68it/s]Capturing batches (bs=96 avail_mem=30.53 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.68it/s] Capturing batches (bs=88 avail_mem=30.51 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.68it/s]Capturing batches (bs=88 avail_mem=30.51 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 15.01it/s]Capturing batches (bs=80 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 15.01it/s]Capturing batches (bs=72 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 15.01it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 15.01it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.52it/s]Capturing batches (bs=56 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.52it/s]Capturing batches (bs=48 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.52it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.52it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.55it/s]Capturing batches (bs=32 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.55it/s]Capturing batches (bs=24 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.55it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.55it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.98it/s]Capturing batches (bs=8 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.98it/s] Capturing batches (bs=4 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.98it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.98it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.79it/s]Capturing batches (bs=1 avail_mem=30.35 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.79it/s]Capturing batches (bs=1 avail_mem=30.35 GB): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00, 15.12it/s]
2025-11-26T17:33:19.000358019Z [37m20251126-17:33:18.999 SGLangServer Wrapper INFO: SGLang server launched at: http://172.21.0.2:13881[0m
2025-11-26T17:33:19.628595994Z [37m20251126-17:33:19.628 Launcher Utils INFO: Found 1 rollout servers: 172.21.0.2:13881[0m
2025-11-26T17:33:19.628637086Z [37m20251126-17:33:19.628 Local Scheduler INFO: LLM inference server launched at: AREAL_LLM_SERVER_ADDRS=172.21.0.2:13881[0m
2025-11-26T17:33:19.631553264Z [37m20251126-17:33:19.631 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL AREAL_LLM_SERVER_ADDRS=172.21.0.2:13881 AREAL_RECOVER_RUN=0 NCCL_CUMEM_ENABLE=0 NCCL_NVLS_ENABLE=0 CUDA_VISIBLE_DEVICES=1 stdbuf -oL torchrun --nnodes 1 --nproc-per-node 1 --master-addr localhost --master-port 31210 examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_173246 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_173246/trainer.log[0m
2025-11-26T17:33:19.632199212Z [37m20251126-17:33:19.632 Local Scheduler INFO: Waiting for 2 local running processes, pids: 315 965[0m
2025-11-26T17:33:20.140381437Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:33:20.140427506Z   import pynvml  # type: ignore[import]
2025-11-26T17:33:21.325937719Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:33:21.325982537Z   import pynvml  # type: ignore[import]
2025-11-26T17:33:27.943432373Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:33:27.943474627Z   warnings.warn(
2025-11-26T17:33:27.943478242Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:33:27.943482078Z   warnings.warn(
2025-11-26T17:33:28.370784907Z Traceback (most recent call last):
2025-11-26T17:33:28.370824365Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 665, in <module>
2025-11-26T17:33:28.371183212Z     main(sys.argv[1:])
2025-11-26T17:33:28.371188230Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 102, in main
2025-11-26T17:33:28.371190974Z     config, _ = load_expr_config(args_with_overrides, GRPOConfig)
2025-11-26T17:33:28.371193758Z                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:33:28.371195802Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1282, in load_expr_config
2025-11-26T17:33:28.371491745Z     cfg = to_structured_cfg(cfg, config_cls=config_cls)
2025-11-26T17:33:28.371494659Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:33:28.371496722Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1276, in to_structured_cfg
2025-11-26T17:33:28.371796421Z     cfg = OmegaConf.merge(default_cfg, cfg)
2025-11-26T17:33:28.371799566Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:33:28.371801789Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/omegaconf.py", line 274, in merge
2025-11-26T17:33:28.372214317Z     target.merge_with(
2025-11-26T17:33:28.372219305Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 507, in merge_with
2025-11-26T17:33:28.372222220Z     self._format_and_raise(key=None, value=None, cause=e)
2025-11-26T17:33:28.372224332Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:33:28.372226395Z     format_and_raise(
2025-11-26T17:33:28.372228559Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:33:28.372230632Z     _raise(ex, cause)
2025-11-26T17:33:28.372232665Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:33:28.372532885Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:33:28.372558543Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:33:28.372561507Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 502, in merge_with
2025-11-26T17:33:28.372731993Z     self._merge_with(
2025-11-26T17:33:28.372735758Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:33:28.372752623Z     BaseContainer._map_merge(
2025-11-26T17:33:28.372755548Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:33:28.372758192Z     dest_node._merge_with(
2025-11-26T17:33:28.372760205Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:33:28.373010580Z     BaseContainer._map_merge(
2025-11-26T17:33:28.373016349Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:33:28.373020475Z     dest_node._merge_with(
2025-11-26T17:33:28.373023269Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:33:28.373026193Z     BaseContainer._map_merge(
2025-11-26T17:33:28.373029148Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 432, in _map_merge
2025-11-26T17:33:28.373281375Z     dest[key] = src._get_node(key)
2025-11-26T17:33:28.373290449Z     ~~~~^^^^^
2025-11-26T17:33:28.373293384Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 308, in __setitem__
2025-11-26T17:33:28.373295737Z     self._format_and_raise(
2025-11-26T17:33:28.373297971Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:33:28.373299963Z     format_and_raise(
2025-11-26T17:33:28.373302017Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:33:28.373756437Z     _raise(ex, cause)
2025-11-26T17:33:28.373764188Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:33:28.373767203Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:33:28.373769767Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:33:28.373772180Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 306, in __setitem__
2025-11-26T17:33:28.373774424Z     self.__set_impl(key=key, value=value)
2025-11-26T17:33:28.373776447Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 316, in __set_impl
2025-11-26T17:33:28.374019952Z     self._set_item_impl(key, value)
2025-11-26T17:33:28.374023858Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 579, in _set_item_impl
2025-11-26T17:33:28.374026231Z     target_node_ref = self._get_node(key)
2025-11-26T17:33:28.374028294Z                       ^^^^^^^^^^^^^^^^^^^
2025-11-26T17:33:28.374030637Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 473, in _get_node
2025-11-26T17:33:28.374341583Z     self._validate_get(key)
2025-11-26T17:33:28.374346200Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 163, in _validate_get
2025-11-26T17:33:28.374351878Z     self._format_and_raise(
2025-11-26T17:33:28.374354132Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:33:28.374359710Z     format_and_raise(
2025-11-26T17:33:28.374361884Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 906, in format_and_raise
2025-11-26T17:33:28.374668793Z     _raise(ex, cause)
2025-11-26T17:33:28.374671457Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:33:28.374673711Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:33:28.374675754Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:33:28.374677927Z omegaconf.errors.ConfigKeyError: Key 'max_new_tokens' not in 'NormConfig'
2025-11-26T17:33:28.374680110Z     full_key: actor.adv_norm.max_new_tokens
2025-11-26T17:33:28.374682113Z     reference_type=Optional[NormConfig]
2025-11-26T17:33:28.374687021Z     object_type=NormConfig
2025-11-26T17:33:31.633102637Z E1126 17:33:31.632000 966 torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 0 (pid: 1032) of binary: /usr/bin/python3
2025-11-26T17:33:31.633888334Z Traceback (most recent call last):
2025-11-26T17:33:31.633922986Z   File "/usr/local/bin/torchrun", line 7, in <module>
2025-11-26T17:33:31.633926371Z     sys.exit(main())
2025-11-26T17:33:31.633928955Z              ^^^^^^
2025-11-26T17:33:31.633931298Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
2025-11-26T17:33:31.633934103Z     return f(*args, **kwargs)
2025-11-26T17:33:31.633936566Z            ^^^^^^^^^^^^^^^^^^
2025-11-26T17:33:31.633938569Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 901, in main
2025-11-26T17:33:31.634478328Z     run(args)
2025-11-26T17:33:31.634490406Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 892, in run
2025-11-26T17:33:31.634493540Z     elastic_launch(
2025-11-26T17:33:31.634496375Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 143, in __call__
2025-11-26T17:33:31.634499259Z     return launch_agent(self._config, self._entrypoint, list(args))
2025-11-26T17:33:31.634501733Z            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:33:31.634503966Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 277, in launch_agent
2025-11-26T17:33:31.634516595Z     raise ChildFailedError(
2025-11-26T17:33:31.634519370Z torch.distributed.elastic.multiprocessing.errors.ChildFailedError:
2025-11-26T17:33:31.634523586Z ============================================================
2025-11-26T17:33:31.634526040Z examples/cloud_gsm8k/gsm8k_grpo_train.py FAILED
2025-11-26T17:33:31.634528904Z ------------------------------------------------------------
2025-11-26T17:33:31.634530927Z Failures:
2025-11-26T17:33:31.634533000Z   <NO_OTHER_FAILURES>
2025-11-26T17:33:31.634535053Z ------------------------------------------------------------
2025-11-26T17:33:31.634537417Z Root Cause (first observed failure):
2025-11-26T17:33:31.634539420Z [0]:
2025-11-26T17:33:31.634541553Z   time      : 2025-11-26_17:33:31
2025-11-26T17:33:31.634543606Z   host      : cef7c503fdea
2025-11-26T17:33:31.634545669Z   rank      : 0 (local_rank: 0)
2025-11-26T17:33:31.634547642Z   exitcode  : 1 (pid: 1032)
2025-11-26T17:33:31.634549645Z   error_file: <N/A>
2025-11-26T17:33:31.634551638Z   traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
2025-11-26T17:33:31.634553741Z ============================================================
2025-11-26T17:33:33.635705536Z [37m20251126-17:33:33.635 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [315][0m
2025-11-26T17:33:33.810105807Z Killed
2025-11-26T17:33:33.819937905Z [37m20251126-17:33:33.819 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [965][0m
2025-11-26T17:33:33.820945784Z Traceback (most recent call last):
2025-11-26T17:33:33.820960486Z   File "<frozen runpy>", line 198, in _run_module_as_main
2025-11-26T17:33:33.820973716Z   File "<frozen runpy>", line 88, in _run_code
2025-11-26T17:33:33.820976310Z   File "/workspace/AReaL/areal/launcher/local.py", line 405, in <module>
2025-11-26T17:33:33.821047587Z     main()
2025-11-26T17:33:33.821055849Z   File "/workspace/AReaL/areal/launcher/local.py", line 260, in main
2025-11-26T17:33:33.821126956Z     local_main(config, run_id=0)
2025-11-26T17:33:33.821155338Z   File "/workspace/AReaL/areal/launcher/local.py", line 399, in local_main
2025-11-26T17:33:33.821251762Z     raise e
2025-11-26T17:33:33.821256560Z   File "/workspace/AReaL/areal/launcher/local.py", line 375, in local_main
2025-11-26T17:33:33.821338723Z     launcher.wait(
2025-11-26T17:33:33.821343210Z   File "/workspace/AReaL/areal/launcher/local.py", line 235, in wait
2025-11-26T17:33:33.821362909Z     raise JobException(
2025-11-26T17:33:33.821365252Z areal.utils.launcher.JobException: Job gsm8k-grpo-cloud-2gpu-2000samples_trial_20251126_173246:trainer JobState.COMPLETED at node local
2025-11-26T17:33:34.148666030Z [37m20251126-17:33:34.147 Local Scheduler INFO: Waiting for 0 local running processes, pids: [0m
2025-11-26T17:33:49.386729223Z ==========
2025-11-26T17:33:49.386732878Z == CUDA ==
2025-11-26T17:33:49.386752247Z ==========
2025-11-26T17:33:49.391004306Z CUDA Version 12.9.1
2025-11-26T17:33:49.392751533Z Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
2025-11-26T17:33:49.394525410Z This container image and its contents are governed by the NVIDIA Deep Learning Container License.
2025-11-26T17:33:49.394528565Z By pulling and using the container, you accept the terms and conditions of this license:
2025-11-26T17:33:49.394530858Z https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license
2025-11-26T17:33:49.394535265Z A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
2025-11-26T17:33:49.560869113Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:33:49.718850060Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:33:49.901010305Z Branch 'feature/reasoning_model' set up to track remote branch 'feature/reasoning_model' from 'origin'.
2025-11-26T17:33:49.901030114Z Your branch is up to date with 'origin/feature/reasoning_model'.
2025-11-26T17:33:49.971559979Z Checking AReaL installation...
2025-11-26T17:33:50.031622636Z AReaL already installed. Skipping installation.
2025-11-26T17:33:50.031650747Z Cleaning up any leftover GPU processes...
2025-11-26T17:33:53.051064518Z Checking for processes holding GPU device files...
2025-11-26T17:33:54.727735700Z Found processes holding GPU devices: 1
2025-11-26T17:33:54.727770773Z 20
2025-11-26T17:33:54.727773366Z 71
2025-11-26T17:33:54.727775961Z 72
2025-11-26T17:33:54.727777984Z Killing process 1...
2025-11-26T17:33:54.727780648Z Killing process 71...
2025-11-26T17:33:54.727927758Z Killing process 72...
2025-11-26T17:33:56.730503336Z Using fuser to kill processes on GPU devices...
2025-11-26T17:33:58.752433175Z Checking GPU...
2025-11-26T17:33:58.787364659Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:33:58.787387102Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:33:58.804382179Z Set PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True for better memory management
2025-11-26T17:33:58.804402790Z Detected 2 GPU(s)
2025-11-26T17:33:58.804406595Z Checking GPU status...
2025-11-26T17:33:58.832036932Z index, name, utilization.gpu [%], memory.used [MiB], compute_mode
2025-11-26T17:33:58.833441816Z 0, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:33:58.833754314Z 1, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:33:58.879704742Z Verifying GPU accessibility...
2025-11-26T17:33:59.533305428Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:33:59.533364437Z   import pynvml  # type: ignore[import]
2025-11-26T17:34:00.655368714Z GPU accessibility verified on attempt 1
2025-11-26T17:34:01.122426300Z Starting training...
2025-11-26T17:34:04.125468448Z Using STANDARD 2000 SAMPLES 2 GPUs configuration
2025-11-26T17:34:04.125503210Z Note: GRPO only (no reasoning XML). Dataset capped at 2000 samples (~6 hours).
2025-11-26T17:34:04.125506656Z GPU count: 2 (required: 2)
2025-11-26T17:34:04.128568481Z ==========================================
2025-11-26T17:34:04.128571486Z Starting GRPO Training (Cloud)
2025-11-26T17:34:04.128574210Z ==========================================
2025-11-26T17:34:04.128576413Z Config: standard_2000samples_2GPUs
2025-11-26T17:34:04.128578867Z Config file: examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml
2025-11-26T17:34:04.128581711Z Training script: examples/cloud_gsm8k/gsm8k_grpo_train.py
2025-11-26T17:34:04.128584215Z Experiment: gsm8k-grpo-cloud-2gpu-2000samples
2025-11-26T17:34:04.128586208Z Trial: trial_20251126_173404
2025-11-26T17:34:04.128588181Z GPU: NVIDIA A100 80GB PCIe NVIDIA A100 80GB PCIe (81920 MB)
2025-11-26T17:34:04.128590214Z WandB API key: e1adc5be02...
2025-11-26T17:34:04.128592237Z ==========================================
2025-11-26T17:34:04.851867627Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:34:04.851915198Z   import pynvml  # type: ignore[import]
2025-11-26T17:34:08.909109680Z [37m20251126-17:34:08.908 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:34:08.909176319Z [37m20251126-17:34:08.908 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:34:08.909455588Z [37m20251126-17:34:08.909 name-resolve INFO: No such name resolve path: ./tmp/areal/name_resolve/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_173404[0m
2025-11-26T17:34:09.013805491Z [37m20251126-17:34:09.013 Local Scheduler INFO: LocalLauncher: experiment_name=gsm8k-grpo-cloud-2gpu-2000samples, trial_name=trial_20251126_173404, fileroot=/workspace/outputs/grpo, run_id=0, is_recover_run=False[0m
2025-11-26T17:34:09.021658854Z [37m20251126-17:34:09.021 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL CUDA_VISIBLE_DEVICES=0 stdbuf -oL python3 -m areal.launcher.sglang_server examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_173404 sglang.random_seed=1 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_173404/llm_server.log[0m
2025-11-26T17:34:09.737683924Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:34:09.737730885Z   import pynvml  # type: ignore[import]
2025-11-26T17:34:11.210798693Z [37m20251126-17:34:11.210 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:34:11.211366184Z [37m20251126-17:34:11.210 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:34:11.314961848Z [37m20251126-17:34:11.314 SGLangServer Wrapper INFO: Launch command: python3 -m sglang.launch_server --host 172.21.0.2 --port 24756 --tokenizer-path Qwen/Qwen2.5-0.5B-Instruct --tokenizer-mode auto --load-format auto --trust-remote-code --device cuda --tp-size 1 --base-gpu-id 0 --nnodes 1 --node-rank 0 --dist-init-addr localhost:28120 --model-path Qwen/Qwen2.5-0.5B-Instruct --random-seed 1 --skip-tokenizer-init --disable-radix-cache --torch-compile-max-bs 32 --triton-attention-num-kv-splits 8 --num-continuous-decode-steps 1 --attention-backend flashinfer --context-length 4096 --mem-fraction-static 0.6 --chunked-prefill-size -1 --max-prefill-tokens 32768 --schedule-policy lpm --schedule-conservativeness 1.0 --cpu-offload-gb 0 --dtype bfloat16 --kv-cache-dtype auto --dp-size 1 --ep-size 1 --max-loaded-loras 1 --max-loras-per-batch 1 --lora-backend triton --log-level warning --log-level-http warning --log-requests-level 0 --enable-metrics --decode-log-interval 1[0m
2025-11-26T17:34:12.405884048Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:34:12.405957839Z   import pynvml  # type: ignore[import]
2025-11-26T17:34:17.738328922Z INFO 11-26 17:34:17 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:34:18.372209429Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:34:19.426290767Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:34:19.426335944Z   import pynvml  # type: ignore[import]
2025-11-26T17:34:19.446332096Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:34:19.446370574Z   import pynvml  # type: ignore[import]
2025-11-26T17:34:24.606822903Z INFO 11-26 17:34:24 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:34:25.024926102Z INFO 11-26 17:34:25 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:34:25.190339040Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:34:25.411720293Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:34:25.415278022Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:34:25.416099141Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:34:25.416951629Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:34:25.449545250Z [2025-11-26 17:34:25] MOE_RUNNER_BACKEND is not initialized, using triton backend
2025-11-26T17:34:25.933156903Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:34:25.933195360Z   warnings.warn(
2025-11-26T17:34:25.933198985Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:34:25.933201289Z   warnings.warn(
2025-11-26T17:34:27.033835758Z Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
2025-11-26T17:34:27.137996277Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  9.61it/s]
2025-11-26T17:34:27.138514424Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  9.59it/s]
2025-11-26T17:34:29.554068274Z   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   4%|â–         | 1/23 [00:00<00:11,  1.89it/s]Capturing batches (bs=152 avail_mem=30.62 GB):   4%|â–         | 1/23 [00:00<00:11,  1.89it/s]Capturing batches (bs=144 avail_mem=30.60 GB):   4%|â–         | 1/23 [00:00<00:11,  1.89it/s]Capturing batches (bs=136 avail_mem=30.59 GB):   4%|â–         | 1/23 [00:00<00:11,  1.89it/s]Capturing batches (bs=136 avail_mem=30.59 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.38it/s]Capturing batches (bs=128 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.38it/s]Capturing batches (bs=120 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.38it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.38it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.72it/s]Capturing batches (bs=104 avail_mem=30.54 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.72it/s]Capturing batches (bs=96 avail_mem=30.53 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.72it/s] Capturing batches (bs=88 avail_mem=30.51 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.72it/s]Capturing batches (bs=88 avail_mem=30.51 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 15.05it/s]Capturing batches (bs=80 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 15.05it/s]Capturing batches (bs=72 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 15.05it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 15.05it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.51it/s]Capturing batches (bs=56 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.51it/s]Capturing batches (bs=48 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.51it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.51it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.56it/s]Capturing batches (bs=32 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.56it/s]Capturing batches (bs=24 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.56it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.56it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.91it/s]Capturing batches (bs=8 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.91it/s] Capturing batches (bs=4 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.91it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.91it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.72it/s]Capturing batches (bs=1 avail_mem=30.35 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.72it/s]Capturing batches (bs=1 avail_mem=30.35 GB): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00, 15.12it/s]
2025-11-26T17:34:35.340400286Z [37m20251126-17:34:35.339 SGLangServer Wrapper INFO: SGLang server launched at: http://172.21.0.2:24756[0m
2025-11-26T17:34:36.028588179Z [37m20251126-17:34:36.028 Launcher Utils INFO: Found 1 rollout servers: 172.21.0.2:24756[0m
2025-11-26T17:34:36.028620258Z [37m20251126-17:34:36.028 Local Scheduler INFO: LLM inference server launched at: AREAL_LLM_SERVER_ADDRS=172.21.0.2:24756[0m
2025-11-26T17:34:36.031195735Z [37m20251126-17:34:36.030 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL AREAL_LLM_SERVER_ADDRS=172.21.0.2:24756 AREAL_RECOVER_RUN=0 NCCL_CUMEM_ENABLE=0 NCCL_NVLS_ENABLE=0 CUDA_VISIBLE_DEVICES=1 stdbuf -oL torchrun --nnodes 1 --nproc-per-node 1 --master-addr localhost --master-port 27137 examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_173404 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_173404/trainer.log[0m
2025-11-26T17:34:36.031843806Z [37m20251126-17:34:36.031 Local Scheduler INFO: Waiting for 2 local running processes, pids: 315 965[0m
2025-11-26T17:34:36.596186793Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:34:36.596225502Z   import pynvml  # type: ignore[import]
2025-11-26T17:34:37.817899363Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:34:37.817950279Z   import pynvml  # type: ignore[import]
2025-11-26T17:34:44.888522069Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:34:44.888558744Z   warnings.warn(
2025-11-26T17:34:44.888561918Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:34:44.888564202Z   warnings.warn(
2025-11-26T17:34:45.329405889Z Traceback (most recent call last):
2025-11-26T17:34:45.329452339Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 665, in <module>
2025-11-26T17:34:45.329933149Z     main(sys.argv[1:])
2025-11-26T17:34:45.329936984Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 102, in main
2025-11-26T17:34:45.329939739Z     config, _ = load_expr_config(args_with_overrides, GRPOConfig)
2025-11-26T17:34:45.329942393Z                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:34:45.329944376Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1282, in load_expr_config
2025-11-26T17:34:45.329946409Z     cfg = to_structured_cfg(cfg, config_cls=config_cls)
2025-11-26T17:34:45.330811124Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:34:45.330818285Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1276, in to_structured_cfg
2025-11-26T17:34:45.330821079Z     cfg = OmegaConf.merge(default_cfg, cfg)
2025-11-26T17:34:45.330824674Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:34:45.330826938Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/omegaconf.py", line 274, in merge
2025-11-26T17:34:45.330829031Z     target.merge_with(
2025-11-26T17:34:45.330831404Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 507, in merge_with
2025-11-26T17:34:45.330844264Z     self._format_and_raise(key=None, value=None, cause=e)
2025-11-26T17:34:45.330846687Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:34:45.330849181Z     format_and_raise(
2025-11-26T17:34:45.330851494Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:34:45.330853568Z     _raise(ex, cause)
2025-11-26T17:34:45.330855601Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:34:45.331292736Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:34:45.331325015Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:34:45.331328049Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 502, in merge_with
2025-11-26T17:34:45.331331004Z     self._merge_with(
2025-11-26T17:34:45.331333908Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:34:45.331336121Z     BaseContainer._map_merge(
2025-11-26T17:34:45.331338845Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:34:45.331724742Z     dest_node._merge_with(
2025-11-26T17:34:45.331729049Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:34:45.331731312Z     BaseContainer._map_merge(
2025-11-26T17:34:45.331733355Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:34:45.331737482Z     dest_node._merge_with(
2025-11-26T17:34:45.331739485Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:34:45.331741548Z     BaseContainer._map_merge(
2025-11-26T17:34:45.331743781Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 432, in _map_merge
2025-11-26T17:34:45.331745954Z     dest[key] = src._get_node(key)
2025-11-26T17:34:45.331748108Z     ~~~~^^^^^
2025-11-26T17:34:45.331751052Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 308, in __setitem__
2025-11-26T17:34:45.332413034Z     self._format_and_raise(
2025-11-26T17:34:45.332418502Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:34:45.332421517Z     format_and_raise(
2025-11-26T17:34:45.332423580Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:34:45.332425763Z     _raise(ex, cause)
2025-11-26T17:34:45.332427826Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:34:45.332430130Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:34:45.332432553Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:34:45.332434897Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 306, in __setitem__
2025-11-26T17:34:45.332437020Z     self.__set_impl(key=key, value=value)
2025-11-26T17:34:45.332439063Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 316, in __set_impl
2025-11-26T17:34:45.332737991Z     self._set_item_impl(key, value)
2025-11-26T17:34:45.332741737Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 579, in _set_item_impl
2025-11-26T17:34:45.332744210Z     target_node_ref = self._get_node(key)
2025-11-26T17:34:45.332746464Z                       ^^^^^^^^^^^^^^^^^^^
2025-11-26T17:34:45.332748607Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 473, in _get_node
2025-11-26T17:34:45.333095687Z     self._validate_get(key)
2025-11-26T17:34:45.333098641Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 163, in _validate_get
2025-11-26T17:34:45.333101205Z     self._format_and_raise(
2025-11-26T17:34:45.333103268Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:34:45.333108336Z     format_and_raise(
2025-11-26T17:34:45.333140794Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 906, in format_and_raise
2025-11-26T17:34:45.333146031Z     _raise(ex, cause)
2025-11-26T17:34:45.333148125Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:34:45.333439431Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:34:45.333444549Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:34:45.333447202Z omegaconf.errors.ConfigKeyError: Key 'max_new_tokens' not in 'NormConfig'
2025-11-26T17:34:45.333449967Z     full_key: actor.adv_norm.max_new_tokens
2025-11-26T17:34:45.333451929Z     reference_type=Optional[NormConfig]
2025-11-26T17:34:45.333454293Z     object_type=NormConfig
2025-11-26T17:34:47.824677297Z E1126 17:34:47.823000 966 torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 0 (pid: 1032) of binary: /usr/bin/python3
2025-11-26T17:34:47.825764115Z Traceback (most recent call last):
2025-11-26T17:34:47.825802823Z   File "/usr/local/bin/torchrun", line 7, in <module>
2025-11-26T17:34:47.825805748Z     sys.exit(main())
2025-11-26T17:34:47.825808481Z              ^^^^^^
2025-11-26T17:34:47.825810915Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
2025-11-26T17:34:47.825813609Z     return f(*args, **kwargs)
2025-11-26T17:34:47.825816513Z            ^^^^^^^^^^^^^^^^^^
2025-11-26T17:34:47.825818496Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 901, in main
2025-11-26T17:34:47.825821381Z     run(args)
2025-11-26T17:34:47.825823695Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 892, in run
2025-11-26T17:34:47.826221391Z     elastic_launch(
2025-11-26T17:34:47.826231005Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 143, in __call__
2025-11-26T17:34:47.826234981Z     return launch_agent(self._config, self._entrypoint, list(args))
2025-11-26T17:34:47.826238686Z            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:34:47.826241971Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 277, in launch_agent
2025-11-26T17:34:47.826245507Z     raise ChildFailedError(
2025-11-26T17:34:47.826249112Z torch.distributed.elastic.multiprocessing.errors.ChildFailedError:
2025-11-26T17:34:47.826252187Z ============================================================
2025-11-26T17:34:47.826255210Z examples/cloud_gsm8k/gsm8k_grpo_train.py FAILED
2025-11-26T17:34:47.826258755Z ------------------------------------------------------------
2025-11-26T17:34:47.826261560Z Failures:
2025-11-26T17:34:47.826264925Z   <NO_OTHER_FAILURES>
2025-11-26T17:34:47.826267779Z ------------------------------------------------------------
2025-11-26T17:34:47.826270673Z Root Cause (first observed failure):
2025-11-26T17:34:47.826274018Z [0]:
2025-11-26T17:34:47.826276963Z   time      : 2025-11-26_17:34:47
2025-11-26T17:34:47.826279837Z   host      : cef7c503fdea
2025-11-26T17:34:47.826282711Z   rank      : 0 (local_rank: 0)
2025-11-26T17:34:47.826285566Z   exitcode  : 1 (pid: 1032)
2025-11-26T17:34:47.826288440Z   error_file: <N/A>
2025-11-26T17:34:47.826291264Z   traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
2025-11-26T17:34:47.826295260Z ============================================================
2025-11-26T17:34:50.035699143Z [37m20251126-17:34:50.035 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [315][0m
2025-11-26T17:34:50.160241983Z Killed
2025-11-26T17:34:50.170029845Z [37m20251126-17:34:50.169 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [965][0m
2025-11-26T17:34:50.171082521Z Traceback (most recent call last):
2025-11-26T17:34:50.171089051Z   File "<frozen runpy>", line 198, in _run_module_as_main
2025-11-26T17:34:50.171091885Z   File "<frozen runpy>", line 88, in _run_code
2025-11-26T17:34:50.171093998Z   File "/workspace/AReaL/areal/launcher/local.py", line 405, in <module>
2025-11-26T17:34:50.171279626Z     main()
2025-11-26T17:34:50.171284914Z   File "/workspace/AReaL/areal/launcher/local.py", line 260, in main
2025-11-26T17:34:50.171372676Z     local_main(config, run_id=0)
2025-11-26T17:34:50.171376662Z   File "/workspace/AReaL/areal/launcher/local.py", line 399, in local_main
2025-11-26T17:34:50.171472215Z     raise e
2025-11-26T17:34:50.171474799Z   File "/workspace/AReaL/areal/launcher/local.py", line 375, in local_main
2025-11-26T17:34:50.171535840Z     launcher.wait(
2025-11-26T17:34:50.171538584Z   File "/workspace/AReaL/areal/launcher/local.py", line 235, in wait
2025-11-26T17:34:50.171609009Z     raise JobException(
2025-11-26T17:34:50.171612205Z areal.utils.launcher.JobException: Job gsm8k-grpo-cloud-2gpu-2000samples_trial_20251126_173404:trainer JobState.COMPLETED at node local
2025-11-26T17:34:50.398449429Z [37m20251126-17:34:50.397 Local Scheduler INFO: Waiting for 0 local running processes, pids: [0m
2025-11-26T17:35:07.746785398Z ==========
2025-11-26T17:35:07.746791197Z == CUDA ==
2025-11-26T17:35:07.746821583Z ==========
2025-11-26T17:35:07.751850965Z CUDA Version 12.9.1
2025-11-26T17:35:07.753649750Z Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
2025-11-26T17:35:07.755519140Z This container image and its contents are governed by the NVIDIA Deep Learning Container License.
2025-11-26T17:35:07.755522605Z By pulling and using the container, you accept the terms and conditions of this license:
2025-11-26T17:35:07.755525289Z https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license
2025-11-26T17:35:07.755529716Z A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
2025-11-26T17:35:07.920333022Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:35:08.076880131Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:35:08.259350990Z Branch 'feature/reasoning_model' set up to track remote branch 'feature/reasoning_model' from 'origin'.
2025-11-26T17:35:08.259386813Z Your branch is up to date with 'origin/feature/reasoning_model'.
2025-11-26T17:35:08.329700054Z Checking AReaL installation...
2025-11-26T17:35:08.388911316Z AReaL already installed. Skipping installation.
2025-11-26T17:35:08.388945407Z Cleaning up any leftover GPU processes...
2025-11-26T17:35:11.409531424Z Checking for processes holding GPU device files...
2025-11-26T17:35:14.102975729Z Found processes holding GPU devices: 1
2025-11-26T17:35:14.103015720Z 21
2025-11-26T17:35:14.103018263Z 72
2025-11-26T17:35:14.103020837Z 73
2025-11-26T17:35:14.103022910Z Killing process 1...
2025-11-26T17:35:14.103025755Z Killing process 72...
2025-11-26T17:35:14.103087527Z Killing process 73...
2025-11-26T17:35:16.105689615Z Using fuser to kill processes on GPU devices...
2025-11-26T17:35:18.129179311Z Checking GPU...
2025-11-26T17:35:18.166520312Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:35:18.166557538Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:35:18.182940558Z Set PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True for better memory management
2025-11-26T17:35:18.182969001Z Detected 2 GPU(s)
2025-11-26T17:35:18.182972516Z Checking GPU status...
2025-11-26T17:35:18.211291093Z index, name, utilization.gpu [%], memory.used [MiB], compute_mode
2025-11-26T17:35:18.212642388Z 0, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:35:18.212928006Z 1, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:35:18.261508273Z Verifying GPU accessibility...
2025-11-26T17:35:18.812137190Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:35:18.812173974Z   import pynvml  # type: ignore[import]
2025-11-26T17:35:19.939595567Z GPU accessibility verified on attempt 1
2025-11-26T17:35:20.475299507Z Starting training...
2025-11-26T17:35:23.477960354Z Using STANDARD 2000 SAMPLES 2 GPUs configuration
2025-11-26T17:35:23.478016268Z Note: GRPO only (no reasoning XML). Dataset capped at 2000 samples (~6 hours).
2025-11-26T17:35:23.478019102Z GPU count: 2 (required: 2)
2025-11-26T17:35:23.480318466Z ==========================================
2025-11-26T17:35:23.480323073Z Starting GRPO Training (Cloud)
2025-11-26T17:35:23.480325977Z ==========================================
2025-11-26T17:35:23.480328031Z Config: standard_2000samples_2GPUs
2025-11-26T17:35:23.480330163Z Config file: examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml
2025-11-26T17:35:23.480332647Z Training script: examples/cloud_gsm8k/gsm8k_grpo_train.py
2025-11-26T17:35:23.480335031Z Experiment: gsm8k-grpo-cloud-2gpu-2000samples
2025-11-26T17:35:23.480337264Z Trial: trial_20251126_173523
2025-11-26T17:35:23.480339267Z GPU: NVIDIA A100 80GB PCIe NVIDIA A100 80GB PCIe (81920 MB)
2025-11-26T17:35:23.480341270Z WandB API key: e1adc5be02...
2025-11-26T17:35:23.480343323Z ==========================================
2025-11-26T17:35:24.189606834Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:35:24.189645462Z   import pynvml  # type: ignore[import]
2025-11-26T17:35:28.266220874Z [37m20251126-17:35:28.265 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:35:28.266267244Z [37m20251126-17:35:28.265 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:35:28.266508655Z [37m20251126-17:35:28.266 name-resolve INFO: No such name resolve path: ./tmp/areal/name_resolve/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_173523[0m
2025-11-26T17:35:28.372802861Z [37m20251126-17:35:28.372 Local Scheduler INFO: LocalLauncher: experiment_name=gsm8k-grpo-cloud-2gpu-2000samples, trial_name=trial_20251126_173523, fileroot=/workspace/outputs/grpo, run_id=0, is_recover_run=False[0m
2025-11-26T17:35:28.380945658Z [37m20251126-17:35:28.380 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL CUDA_VISIBLE_DEVICES=0 stdbuf -oL python3 -m areal.launcher.sglang_server examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_173523 sglang.random_seed=1 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_173523/llm_server.log[0m
2025-11-26T17:35:29.089188972Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:35:29.089238286Z   import pynvml  # type: ignore[import]
2025-11-26T17:35:30.542414660Z [37m20251126-17:35:30.541 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:35:30.543039796Z [37m20251126-17:35:30.542 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:35:30.642927095Z [37m20251126-17:35:30.642 SGLangServer Wrapper INFO: Launch command: python3 -m sglang.launch_server --host 172.21.0.2 --port 16511 --tokenizer-path Qwen/Qwen2.5-0.5B-Instruct --tokenizer-mode auto --load-format auto --trust-remote-code --device cuda --tp-size 1 --base-gpu-id 0 --nnodes 1 --node-rank 0 --dist-init-addr localhost:22499 --model-path Qwen/Qwen2.5-0.5B-Instruct --random-seed 1 --skip-tokenizer-init --disable-radix-cache --torch-compile-max-bs 32 --triton-attention-num-kv-splits 8 --num-continuous-decode-steps 1 --attention-backend flashinfer --context-length 4096 --mem-fraction-static 0.6 --chunked-prefill-size -1 --max-prefill-tokens 32768 --schedule-policy lpm --schedule-conservativeness 1.0 --cpu-offload-gb 0 --dtype bfloat16 --kv-cache-dtype auto --dp-size 1 --ep-size 1 --max-loaded-loras 1 --max-loras-per-batch 1 --lora-backend triton --log-level warning --log-level-http warning --log-requests-level 0 --enable-metrics --decode-log-interval 1[0m
2025-11-26T17:35:31.710460252Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:35:31.710504809Z   import pynvml  # type: ignore[import]
2025-11-26T17:35:36.969653023Z INFO 11-26 17:35:36 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:35:37.663303308Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:35:38.723748217Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:35:38.723791201Z   import pynvml  # type: ignore[import]
2025-11-26T17:35:39.085002393Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:35:39.085039058Z   import pynvml  # type: ignore[import]
2025-11-26T17:35:44.399396959Z INFO 11-26 17:35:44 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:35:44.605631584Z INFO 11-26 17:35:44 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:35:45.187639031Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:35:45.410745317Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:35:45.414601373Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:35:45.415528513Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:35:45.416351165Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:35:45.450324122Z [2025-11-26 17:35:45] MOE_RUNNER_BACKEND is not initialized, using triton backend
2025-11-26T17:35:45.965348146Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:35:45.965386654Z   warnings.warn(
2025-11-26T17:35:45.965390580Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:35:45.965393144Z   warnings.warn(
2025-11-26T17:35:47.116220786Z Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
2025-11-26T17:35:47.224722759Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  9.23it/s]
2025-11-26T17:35:47.225760012Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  9.21it/s]
2025-11-26T17:35:49.726591178Z   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   4%|â–         | 1/23 [00:00<00:11,  1.87it/s]Capturing batches (bs=152 avail_mem=30.62 GB):   4%|â–         | 1/23 [00:00<00:11,  1.87it/s]Capturing batches (bs=144 avail_mem=30.60 GB):   4%|â–         | 1/23 [00:00<00:11,  1.87it/s]Capturing batches (bs=136 avail_mem=30.59 GB):   4%|â–         | 1/23 [00:00<00:11,  1.87it/s]Capturing batches (bs=136 avail_mem=30.59 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.33it/s]Capturing batches (bs=128 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.33it/s]Capturing batches (bs=120 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.33it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.33it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.63it/s]Capturing batches (bs=104 avail_mem=30.54 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.63it/s]Capturing batches (bs=96 avail_mem=30.53 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.63it/s] Capturing batches (bs=88 avail_mem=30.51 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.63it/s]Capturing batches (bs=88 avail_mem=30.51 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.85it/s]Capturing batches (bs=80 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.85it/s]Capturing batches (bs=72 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.85it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:01<00:00, 14.85it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.30it/s]Capturing batches (bs=56 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.30it/s]Capturing batches (bs=48 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.30it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.30it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.21it/s]Capturing batches (bs=32 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.21it/s]Capturing batches (bs=24 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.21it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.21it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.71it/s]Capturing batches (bs=8 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.71it/s] Capturing batches (bs=4 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.71it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.71it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.52it/s]Capturing batches (bs=1 avail_mem=30.35 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.52it/s]Capturing batches (bs=1 avail_mem=30.35 GB): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00, 14.96it/s]
2025-11-26T17:35:55.671029033Z [37m20251126-17:35:55.670 SGLangServer Wrapper INFO: SGLang server launched at: http://172.21.0.2:16511[0m
2025-11-26T17:35:56.388096134Z [37m20251126-17:35:56.387 Launcher Utils INFO: Found 1 rollout servers: 172.21.0.2:16511[0m
2025-11-26T17:35:56.388170525Z [37m20251126-17:35:56.387 Local Scheduler INFO: LLM inference server launched at: AREAL_LLM_SERVER_ADDRS=172.21.0.2:16511[0m
2025-11-26T17:35:56.390822428Z [37m20251126-17:35:56.390 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL AREAL_LLM_SERVER_ADDRS=172.21.0.2:16511 AREAL_RECOVER_RUN=0 NCCL_CUMEM_ENABLE=0 NCCL_NVLS_ENABLE=0 CUDA_VISIBLE_DEVICES=1 stdbuf -oL torchrun --nnodes 1 --nproc-per-node 1 --master-addr localhost --master-port 40257 examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_173523 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_173523/trainer.log[0m
2025-11-26T17:35:56.391347163Z [37m20251126-17:35:56.391 Local Scheduler INFO: Waiting for 2 local running processes, pids: 316 966[0m
2025-11-26T17:35:56.902031647Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:35:56.902072198Z   import pynvml  # type: ignore[import]
2025-11-26T17:35:58.087927669Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:35:58.087967247Z   import pynvml  # type: ignore[import]
2025-11-26T17:36:04.777880155Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:36:04.777935037Z   warnings.warn(
2025-11-26T17:36:04.777938282Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:36:04.777940575Z   warnings.warn(
2025-11-26T17:36:05.218593711Z Traceback (most recent call last):
2025-11-26T17:36:05.218631167Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 665, in <module>
2025-11-26T17:36:05.219106169Z     main(sys.argv[1:])
2025-11-26T17:36:05.219143965Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 102, in main
2025-11-26T17:36:05.219150705Z     config, _ = load_expr_config(args_with_overrides, GRPOConfig)
2025-11-26T17:36:05.219153530Z                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:36:05.219155573Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1282, in load_expr_config
2025-11-26T17:36:05.219573729Z     cfg = to_structured_cfg(cfg, config_cls=config_cls)
2025-11-26T17:36:05.219593930Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:36:05.219596434Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1276, in to_structured_cfg
2025-11-26T17:36:05.219599368Z     cfg = OmegaConf.merge(default_cfg, cfg)
2025-11-26T17:36:05.219927530Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:36:05.219931556Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/omegaconf.py", line 274, in merge
2025-11-26T17:36:05.219934249Z     target.merge_with(
2025-11-26T17:36:05.219936593Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 507, in merge_with
2025-11-26T17:36:05.219939247Z     self._format_and_raise(key=None, value=None, cause=e)
2025-11-26T17:36:05.219948601Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:36:05.219951025Z     format_and_raise(
2025-11-26T17:36:05.219953138Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:36:05.220763852Z     _raise(ex, cause)
2025-11-26T17:36:05.220783372Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:36:05.220786276Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:36:05.220788569Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:36:05.220791133Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 502, in merge_with
2025-11-26T17:36:05.220793737Z     self._merge_with(
2025-11-26T17:36:05.220795830Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:36:05.220797993Z     BaseContainer._map_merge(
2025-11-26T17:36:05.220800657Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:36:05.220802630Z     dest_node._merge_with(
2025-11-26T17:36:05.220804653Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:36:05.220806616Z     BaseContainer._map_merge(
2025-11-26T17:36:05.220808589Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:36:05.220810522Z     dest_node._merge_with(
2025-11-26T17:36:05.220812505Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:36:05.220814468Z     BaseContainer._map_merge(
2025-11-26T17:36:05.220816501Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 432, in _map_merge
2025-11-26T17:36:05.221084232Z     dest[key] = src._get_node(key)
2025-11-26T17:36:05.221088408Z     ~~~~^^^^^
2025-11-26T17:36:05.221091673Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 308, in __setitem__
2025-11-26T17:36:05.221094187Z     self._format_and_raise(
2025-11-26T17:36:05.221096741Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:36:05.221098824Z     format_and_raise(
2025-11-26T17:36:05.221101027Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:36:05.221725192Z     _raise(ex, cause)
2025-11-26T17:36:05.221730571Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:36:05.221732814Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:36:05.221744141Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:36:05.221746384Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 306, in __setitem__
2025-11-26T17:36:05.221748667Z     self.__set_impl(key=key, value=value)
2025-11-26T17:36:05.221750670Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 316, in __set_impl
2025-11-26T17:36:05.221752764Z     self._set_item_impl(key, value)
2025-11-26T17:36:05.221755057Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 579, in _set_item_impl
2025-11-26T17:36:05.221757170Z     target_node_ref = self._get_node(key)
2025-11-26T17:36:05.222056428Z                       ^^^^^^^^^^^^^^^^^^^
2025-11-26T17:36:05.222060204Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 473, in _get_node
2025-11-26T17:36:05.222063118Z     self._validate_get(key)
2025-11-26T17:36:05.222065301Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 163, in _validate_get
2025-11-26T17:36:05.222067514Z     self._format_and_raise(
2025-11-26T17:36:05.222069707Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:36:05.222071770Z     format_and_raise(
2025-11-26T17:36:05.222074014Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 906, in format_and_raise
2025-11-26T17:36:05.222458450Z     _raise(ex, cause)
2025-11-26T17:36:05.222465110Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:36:05.222467464Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:36:05.222469527Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:36:05.222471890Z omegaconf.errors.ConfigKeyError: Key 'max_new_tokens' not in 'NormConfig'
2025-11-26T17:36:05.222475987Z     full_key: actor.adv_norm.max_new_tokens
2025-11-26T17:36:05.222478220Z     reference_type=Optional[NormConfig]
2025-11-26T17:36:05.222480383Z     object_type=NormConfig
2025-11-26T17:36:07.696323043Z E1126 17:36:07.695000 967 torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 0 (pid: 1033) of binary: /usr/bin/python3
2025-11-26T17:36:07.696886106Z Traceback (most recent call last):
2025-11-26T17:36:07.696890223Z   File "/usr/local/bin/torchrun", line 7, in <module>
2025-11-26T17:36:07.696892747Z     sys.exit(main())
2025-11-26T17:36:07.696895300Z              ^^^^^^
2025-11-26T17:36:07.696897554Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
2025-11-26T17:36:07.696900428Z     return f(*args, **kwargs)
2025-11-26T17:36:07.696903112Z            ^^^^^^^^^^^^^^^^^^
2025-11-26T17:36:07.696905165Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 901, in main
2025-11-26T17:36:07.697393056Z     run(args)
2025-11-26T17:36:07.697398754Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 892, in run
2025-11-26T17:36:07.697402039Z     elastic_launch(
2025-11-26T17:36:07.697404733Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 143, in __call__
2025-11-26T17:36:07.697407327Z     return launch_agent(self._config, self._entrypoint, list(args))
2025-11-26T17:36:07.697410342Z            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:36:07.697412374Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 277, in launch_agent
2025-11-26T17:36:07.697962739Z     raise ChildFailedError(
2025-11-26T17:36:07.697984672Z torch.distributed.elastic.multiprocessing.errors.ChildFailedError:
2025-11-26T17:36:07.697987997Z ============================================================
2025-11-26T17:36:07.697990420Z examples/cloud_gsm8k/gsm8k_grpo_train.py FAILED
2025-11-26T17:36:07.697993155Z ------------------------------------------------------------
2025-11-26T17:36:07.697995167Z Failures:
2025-11-26T17:36:07.697997851Z   <NO_OTHER_FAILURES>
2025-11-26T17:36:07.698000946Z ------------------------------------------------------------
2025-11-26T17:36:07.698003119Z Root Cause (first observed failure):
2025-11-26T17:36:07.698005173Z [0]:
2025-11-26T17:36:07.698007286Z   time      : 2025-11-26_17:36:07
2025-11-26T17:36:07.698009349Z   host      : cef7c503fdea
2025-11-26T17:36:07.698011342Z   rank      : 0 (local_rank: 0)
2025-11-26T17:36:07.698013555Z   exitcode  : 1 (pid: 1033)
2025-11-26T17:36:07.698015548Z   error_file: <N/A>
2025-11-26T17:36:07.698017551Z   traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
2025-11-26T17:36:07.698020175Z ============================================================
2025-11-26T17:36:08.394857934Z [37m20251126-17:36:08.394 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [316][0m
2025-11-26T17:36:08.512942311Z Killed
2025-11-26T17:36:08.523106575Z [37m20251126-17:36:08.522 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [966][0m
2025-11-26T17:36:08.524278812Z Traceback (most recent call last):
2025-11-26T17:36:08.524290218Z   File "<frozen runpy>", line 198, in _run_module_as_main
2025-11-26T17:36:08.524293062Z   File "<frozen runpy>", line 88, in _run_code
2025-11-26T17:36:08.524295256Z   File "/workspace/AReaL/areal/launcher/local.py", line 405, in <module>
2025-11-26T17:36:08.524438131Z     main()
2025-11-26T17:36:08.524443128Z   File "/workspace/AReaL/areal/launcher/local.py", line 260, in main
2025-11-26T17:36:08.524537740Z     local_main(config, run_id=0)
2025-11-26T17:36:08.524542427Z   File "/workspace/AReaL/areal/launcher/local.py", line 399, in local_main
2025-11-26T17:36:08.524618830Z     raise e
2025-11-26T17:36:08.524622907Z   File "/workspace/AReaL/areal/launcher/local.py", line 375, in local_main
2025-11-26T17:36:08.524684209Z     launcher.wait(
2025-11-26T17:36:08.524687073Z   File "/workspace/AReaL/areal/launcher/local.py", line 235, in wait
2025-11-26T17:36:08.524744079Z     raise JobException(
2025-11-26T17:36:08.524746863Z areal.utils.launcher.JobException: Job gsm8k-grpo-cloud-2gpu-2000samples_trial_20251126_173523:trainer JobState.COMPLETED at node local
2025-11-26T17:36:08.813326740Z [37m20251126-17:36:08.812 Local Scheduler INFO: Waiting for 0 local running processes, pids: [0m
2025-11-26T17:36:26.069832709Z ==========
2025-11-26T17:36:26.069859319Z == CUDA ==
2025-11-26T17:36:26.069939038Z ==========
2025-11-26T17:36:26.074838036Z CUDA Version 12.9.1
2025-11-26T17:36:26.076544022Z Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
2025-11-26T17:36:26.078161104Z This container image and its contents are governed by the NVIDIA Deep Learning Container License.
2025-11-26T17:36:26.078163989Z By pulling and using the container, you accept the terms and conditions of this license:
2025-11-26T17:36:26.078166482Z https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license
2025-11-26T17:36:26.078172161Z A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
2025-11-26T17:36:26.241979304Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:36:26.401322992Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:36:26.586550981Z Branch 'feature/reasoning_model' set up to track remote branch 'feature/reasoning_model' from 'origin'.
2025-11-26T17:36:26.586595018Z Your branch is up to date with 'origin/feature/reasoning_model'.
2025-11-26T17:36:26.655485637Z Checking AReaL installation...
2025-11-26T17:36:26.715912119Z AReaL already installed. Skipping installation.
2025-11-26T17:36:26.715944698Z Cleaning up any leftover GPU processes...
2025-11-26T17:36:29.734664428Z Checking for processes holding GPU device files...
2025-11-26T17:36:31.791692179Z Found processes holding GPU devices: 1
2025-11-26T17:36:31.791735534Z 20
2025-11-26T17:36:31.791738068Z 71
2025-11-26T17:36:31.791740241Z 72
2025-11-26T17:36:31.791742324Z Killing process 1...
2025-11-26T17:36:31.791744988Z Killing process 71...
2025-11-26T17:36:31.791804528Z Killing process 72...
2025-11-26T17:36:33.794367677Z Using fuser to kill processes on GPU devices...
2025-11-26T17:36:35.819865931Z Checking GPU...
2025-11-26T17:36:35.853532449Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:36:35.853574443Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:36:35.869297754Z Set PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True for better memory management
2025-11-26T17:36:35.869321720Z Detected 2 GPU(s)
2025-11-26T17:36:35.869326066Z Checking GPU status...
2025-11-26T17:36:35.896934691Z index, name, utilization.gpu [%], memory.used [MiB], compute_mode
2025-11-26T17:36:35.898422970Z 0, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:36:35.898717311Z 1, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:36:35.940311634Z Verifying GPU accessibility...
2025-11-26T17:36:36.459381148Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:36:36.459430803Z   import pynvml  # type: ignore[import]
2025-11-26T17:36:37.576522973Z GPU accessibility verified on attempt 1
2025-11-26T17:36:38.033206479Z Starting training...
2025-11-26T17:36:41.035998342Z Using STANDARD 2000 SAMPLES 2 GPUs configuration
2025-11-26T17:36:41.036038934Z Note: GRPO only (no reasoning XML). Dataset capped at 2000 samples (~6 hours).
2025-11-26T17:36:41.036044422Z GPU count: 2 (required: 2)
2025-11-26T17:36:41.038737315Z ==========================================
2025-11-26T17:36:41.038741210Z Starting GRPO Training (Cloud)
2025-11-26T17:36:41.038744325Z ==========================================
2025-11-26T17:36:41.038746378Z Config: standard_2000samples_2GPUs
2025-11-26T17:36:41.038748511Z Config file: examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml
2025-11-26T17:36:41.038751175Z Training script: examples/cloud_gsm8k/gsm8k_grpo_train.py
2025-11-26T17:36:41.038753629Z Experiment: gsm8k-grpo-cloud-2gpu-2000samples
2025-11-26T17:36:41.038755652Z Trial: trial_20251126_173641
2025-11-26T17:36:41.038757695Z GPU: NVIDIA A100 80GB PCIe NVIDIA A100 80GB PCIe (81920 MB)
2025-11-26T17:36:41.038759748Z WandB API key: e1adc5be02...
2025-11-26T17:36:41.038762012Z ==========================================
2025-11-26T17:36:41.707080543Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:36:41.707147494Z   import pynvml  # type: ignore[import]
2025-11-26T17:36:45.636002798Z [37m20251126-17:36:45.635 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:36:45.636046483Z [37m20251126-17:36:45.635 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:36:45.636333814Z [37m20251126-17:36:45.635 name-resolve INFO: No such name resolve path: ./tmp/areal/name_resolve/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_173641[0m
2025-11-26T17:36:45.740380152Z [37m20251126-17:36:45.740 Local Scheduler INFO: LocalLauncher: experiment_name=gsm8k-grpo-cloud-2gpu-2000samples, trial_name=trial_20251126_173641, fileroot=/workspace/outputs/grpo, run_id=0, is_recover_run=False[0m
2025-11-26T17:36:45.747864444Z [37m20251126-17:36:45.747 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL CUDA_VISIBLE_DEVICES=0 stdbuf -oL python3 -m areal.launcher.sglang_server examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_173641 sglang.random_seed=1 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_173641/llm_server.log[0m
2025-11-26T17:36:46.444466430Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:36:46.444505508Z   import pynvml  # type: ignore[import]
2025-11-26T17:36:47.909507886Z [37m20251126-17:36:47.908 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:36:47.910161725Z [37m20251126-17:36:47.909 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:36:48.011847999Z [37m20251126-17:36:48.011 SGLangServer Wrapper INFO: Launch command: python3 -m sglang.launch_server --host 172.21.0.2 --port 10807 --tokenizer-path Qwen/Qwen2.5-0.5B-Instruct --tokenizer-mode auto --load-format auto --trust-remote-code --device cuda --tp-size 1 --base-gpu-id 0 --nnodes 1 --node-rank 0 --dist-init-addr localhost:27195 --model-path Qwen/Qwen2.5-0.5B-Instruct --random-seed 1 --skip-tokenizer-init --disable-radix-cache --torch-compile-max-bs 32 --triton-attention-num-kv-splits 8 --num-continuous-decode-steps 1 --attention-backend flashinfer --context-length 4096 --mem-fraction-static 0.6 --chunked-prefill-size -1 --max-prefill-tokens 32768 --schedule-policy lpm --schedule-conservativeness 1.0 --cpu-offload-gb 0 --dtype bfloat16 --kv-cache-dtype auto --dp-size 1 --ep-size 1 --max-loaded-loras 1 --max-loras-per-batch 1 --lora-backend triton --log-level warning --log-level-http warning --log-requests-level 0 --enable-metrics --decode-log-interval 1[0m
2025-11-26T17:36:49.041440405Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:36:49.041483750Z   import pynvml  # type: ignore[import]
2025-11-26T17:36:54.390099536Z INFO 11-26 17:36:54 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:36:55.113517990Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:36:56.144632827Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:36:56.144671715Z   import pynvml  # type: ignore[import]
2025-11-26T17:36:56.181181993Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:36:56.181207321Z   import pynvml  # type: ignore[import]
2025-11-26T17:37:01.829588149Z INFO 11-26 17:37:01 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:37:02.708272042Z INFO 11-26 17:37:02 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:37:03.352826958Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:37:03.578853529Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:37:03.583417645Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:37:03.584240708Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:37:03.585103291Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:37:03.619479041Z [2025-11-26 17:37:03] MOE_RUNNER_BACKEND is not initialized, using triton backend
2025-11-26T17:37:04.205350495Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:37:04.205392739Z   warnings.warn(
2025-11-26T17:37:04.205396024Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:37:04.205398217Z   warnings.warn(
2025-11-26T17:37:05.787036071Z Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
2025-11-26T17:37:05.916067525Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  7.76it/s]
2025-11-26T17:37:05.916698270Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  7.74it/s]
2025-11-26T17:37:08.688346547Z   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   4%|â–         | 1/23 [00:00<00:12,  1.81it/s]Capturing batches (bs=152 avail_mem=30.62 GB):   4%|â–         | 1/23 [00:00<00:12,  1.81it/s]Capturing batches (bs=144 avail_mem=30.60 GB):   4%|â–         | 1/23 [00:00<00:12,  1.81it/s]Capturing batches (bs=136 avail_mem=30.59 GB):   4%|â–         | 1/23 [00:00<00:12,  1.81it/s]Capturing batches (bs=136 avail_mem=30.59 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.16it/s]Capturing batches (bs=128 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.16it/s]Capturing batches (bs=120 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.16it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.16it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.45it/s]Capturing batches (bs=104 avail_mem=30.54 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.45it/s]Capturing batches (bs=96 avail_mem=30.53 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.45it/s] Capturing batches (bs=88 avail_mem=30.51 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.45it/s]Capturing batches (bs=88 avail_mem=30.51 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.78it/s]Capturing batches (bs=80 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.78it/s]Capturing batches (bs=72 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.78it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:01<00:00, 14.78it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.27it/s]Capturing batches (bs=56 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.27it/s]Capturing batches (bs=48 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.27it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.27it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.28it/s]Capturing batches (bs=32 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.28it/s]Capturing batches (bs=24 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.28it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.28it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.69it/s]Capturing batches (bs=8 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.69it/s] Capturing batches (bs=4 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.69it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.69it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.55it/s]Capturing batches (bs=1 avail_mem=30.35 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.55it/s]Capturing batches (bs=1 avail_mem=30.35 GB): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00, 14.86it/s]
2025-11-26T17:37:14.039203520Z [37m20251126-17:37:14.038 SGLangServer Wrapper INFO: SGLang server launched at: http://172.21.0.2:10807[0m
2025-11-26T17:37:14.755073527Z [37m20251126-17:37:14.754 Launcher Utils INFO: Found 1 rollout servers: 172.21.0.2:10807[0m
2025-11-26T17:37:14.755160578Z [37m20251126-17:37:14.754 Local Scheduler INFO: LLM inference server launched at: AREAL_LLM_SERVER_ADDRS=172.21.0.2:10807[0m
2025-11-26T17:37:14.757928533Z [37m20251126-17:37:14.757 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL AREAL_LLM_SERVER_ADDRS=172.21.0.2:10807 AREAL_RECOVER_RUN=0 NCCL_CUMEM_ENABLE=0 NCCL_NVLS_ENABLE=0 CUDA_VISIBLE_DEVICES=1 stdbuf -oL torchrun --nnodes 1 --nproc-per-node 1 --master-addr localhost --master-port 26420 examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_173641 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_173641/trainer.log[0m
2025-11-26T17:37:14.758565698Z [37m20251126-17:37:14.758 Local Scheduler INFO: Waiting for 2 local running processes, pids: 315 965[0m
2025-11-26T17:37:15.335219326Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:37:15.335281299Z   import pynvml  # type: ignore[import]
2025-11-26T17:37:16.569615193Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:37:16.569679138Z   import pynvml  # type: ignore[import]
2025-11-26T17:37:23.733330149Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:37:23.733374015Z   warnings.warn(
2025-11-26T17:37:23.733377260Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:37:23.733379564Z   warnings.warn(
2025-11-26T17:37:24.165835831Z Traceback (most recent call last):
2025-11-26T17:37:24.165874469Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 665, in <module>
2025-11-26T17:37:24.166505004Z     main(sys.argv[1:])
2025-11-26T17:37:24.166515189Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 102, in main
2025-11-26T17:37:24.166518534Z     config, _ = load_expr_config(args_with_overrides, GRPOConfig)
2025-11-26T17:37:24.166521699Z                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:37:24.166523772Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1282, in load_expr_config
2025-11-26T17:37:24.166967177Z     cfg = to_structured_cfg(cfg, config_cls=config_cls)
2025-11-26T17:37:24.166990300Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:37:24.166992764Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1276, in to_structured_cfg
2025-11-26T17:37:24.166995969Z     cfg = OmegaConf.merge(default_cfg, cfg)
2025-11-26T17:37:24.166998763Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:37:24.167000796Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/omegaconf.py", line 274, in merge
2025-11-26T17:37:24.167295247Z     target.merge_with(
2025-11-26T17:37:24.167301116Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 507, in merge_with
2025-11-26T17:37:24.167303770Z     self._format_and_raise(key=None, value=None, cause=e)
2025-11-26T17:37:24.167306113Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:37:24.167317140Z     format_and_raise(
2025-11-26T17:37:24.167319384Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:37:24.167680635Z     _raise(ex, cause)
2025-11-26T17:37:24.167685542Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:37:24.167687736Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:37:24.167689949Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:37:24.167692232Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 502, in merge_with
2025-11-26T17:37:24.167695016Z     self._merge_with(
2025-11-26T17:37:24.168203538Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:37:24.168209326Z     BaseContainer._map_merge(
2025-11-26T17:37:24.168212141Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:37:24.168214244Z     dest_node._merge_with(
2025-11-26T17:37:24.168216227Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:37:24.168218320Z     BaseContainer._map_merge(
2025-11-26T17:37:24.168220623Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:37:24.168223307Z     dest_node._merge_with(
2025-11-26T17:37:24.168225461Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:37:24.168227544Z     BaseContainer._map_merge(
2025-11-26T17:37:24.168229577Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 432, in _map_merge
2025-11-26T17:37:24.168485380Z     dest[key] = src._get_node(key)
2025-11-26T17:37:24.168489196Z     ~~~~^^^^^
2025-11-26T17:37:24.168491809Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 308, in __setitem__
2025-11-26T17:37:24.168494113Z     self._format_and_raise(
2025-11-26T17:37:24.168496827Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:37:24.168512351Z     format_and_raise(
2025-11-26T17:37:24.168514534Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:37:24.169167782Z     _raise(ex, cause)
2025-11-26T17:37:24.169174272Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:37:24.169176926Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:37:24.169179090Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:37:24.169181693Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 306, in __setitem__
2025-11-26T17:37:24.169184558Z     self.__set_impl(key=key, value=value)
2025-11-26T17:37:24.169186771Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 316, in __set_impl
2025-11-26T17:37:24.169188994Z     self._set_item_impl(key, value)
2025-11-26T17:37:24.169191037Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 579, in _set_item_impl
2025-11-26T17:37:24.169193140Z     target_node_ref = self._get_node(key)
2025-11-26T17:37:24.169512309Z                       ^^^^^^^^^^^^^^^^^^^
2025-11-26T17:37:24.169516315Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 473, in _get_node
2025-11-26T17:37:24.169519069Z     self._validate_get(key)
2025-11-26T17:37:24.169521142Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 163, in _validate_get
2025-11-26T17:37:24.169850405Z     self._format_and_raise(
2025-11-26T17:37:24.169854061Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:37:24.169856745Z     format_and_raise(
2025-11-26T17:37:24.169859098Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 906, in format_and_raise
2025-11-26T17:37:24.169861192Z     _raise(ex, cause)
2025-11-26T17:37:24.169863144Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:37:24.170503874Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:37:24.170510694Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:37:24.170512907Z omegaconf.errors.ConfigKeyError: Key 'max_new_tokens' not in 'NormConfig'
2025-11-26T17:37:24.170515471Z     full_key: actor.adv_norm.max_new_tokens
2025-11-26T17:37:24.170517423Z     reference_type=Optional[NormConfig]
2025-11-26T17:37:24.170519467Z     object_type=NormConfig
2025-11-26T17:37:26.950202249Z E1126 17:37:26.949000 966 torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 0 (pid: 1032) of binary: /usr/bin/python3
2025-11-26T17:37:26.950937861Z Traceback (most recent call last):
2025-11-26T17:37:26.950942838Z   File "/usr/local/bin/torchrun", line 7, in <module>
2025-11-26T17:37:26.950945502Z     sys.exit(main())
2025-11-26T17:37:26.950948406Z              ^^^^^^
2025-11-26T17:37:26.950950510Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
2025-11-26T17:37:26.950953283Z     return f(*args, **kwargs)
2025-11-26T17:37:26.950955858Z            ^^^^^^^^^^^^^^^^^^
2025-11-26T17:37:26.950957841Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 901, in main
2025-11-26T17:37:26.951388606Z     run(args)
2025-11-26T17:37:26.951394315Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 892, in run
2025-11-26T17:37:26.951396759Z     elastic_launch(
2025-11-26T17:37:26.951399252Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 143, in __call__
2025-11-26T17:37:26.951401756Z     return launch_agent(self._config, self._entrypoint, list(args))
2025-11-26T17:37:26.951404280Z            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:37:26.951406333Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 277, in launch_agent
2025-11-26T17:37:26.951408426Z     raise ChildFailedError(
2025-11-26T17:37:26.951411490Z torch.distributed.elastic.multiprocessing.errors.ChildFailedError:
2025-11-26T17:37:26.951413674Z ============================================================
2025-11-26T17:37:26.951416217Z examples/cloud_gsm8k/gsm8k_grpo_train.py FAILED
2025-11-26T17:37:26.951419092Z ------------------------------------------------------------
2025-11-26T17:37:26.951421085Z Failures:
2025-11-26T17:37:26.951423058Z   <NO_OTHER_FAILURES>
2025-11-26T17:37:26.951425031Z ------------------------------------------------------------
2025-11-26T17:37:26.951427044Z Root Cause (first observed failure):
2025-11-26T17:37:26.951429077Z [0]:
2025-11-26T17:37:26.951431431Z   time      : 2025-11-26_17:37:26
2025-11-26T17:37:26.951433474Z   host      : cef7c503fdea
2025-11-26T17:37:26.951435577Z   rank      : 0 (local_rank: 0)
2025-11-26T17:37:26.951437690Z   exitcode  : 1 (pid: 1032)
2025-11-26T17:37:26.951439703Z   error_file: <N/A>
2025-11-26T17:37:26.951441686Z   traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
2025-11-26T17:37:26.951443759Z ============================================================
2025-11-26T17:37:28.763332190Z [37m20251126-17:37:28.762 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [315][0m
2025-11-26T17:37:28.881029827Z Killed
2025-11-26T17:37:28.890410789Z [37m20251126-17:37:28.890 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [965][0m
2025-11-26T17:37:28.891439100Z Traceback (most recent call last):
2025-11-26T17:37:28.891445489Z   File "<frozen runpy>", line 198, in _run_module_as_main
2025-11-26T17:37:28.891448293Z   File "<frozen runpy>", line 88, in _run_code
2025-11-26T17:37:28.891450367Z   File "/workspace/AReaL/areal/launcher/local.py", line 405, in <module>
2025-11-26T17:37:28.891607952Z     main()
2025-11-26T17:37:28.891630586Z   File "/workspace/AReaL/areal/launcher/local.py", line 260, in main
2025-11-26T17:37:28.891677867Z     local_main(config, run_id=0)
2025-11-26T17:37:28.891682534Z   File "/workspace/AReaL/areal/launcher/local.py", line 399, in local_main
2025-11-26T17:37:28.891773089Z     raise e
2025-11-26T17:37:28.891777776Z   File "/workspace/AReaL/areal/launcher/local.py", line 375, in local_main
2025-11-26T17:37:28.891836073Z     launcher.wait(
2025-11-26T17:37:28.891839639Z   File "/workspace/AReaL/areal/launcher/local.py", line 235, in wait
2025-11-26T17:37:28.891879799Z     raise JobException(
2025-11-26T17:37:28.891882594Z areal.utils.launcher.JobException: Job gsm8k-grpo-cloud-2gpu-2000samples_trial_20251126_173641:trainer JobState.COMPLETED at node local
2025-11-26T17:37:29.189004687Z [37m20251126-17:37:29.188 Local Scheduler INFO: Waiting for 0 local running processes, pids: [0m
2025-11-26T17:37:44.457597200Z ==========
2025-11-26T17:37:44.457606845Z == CUDA ==
2025-11-26T17:37:44.457666083Z ==========
2025-11-26T17:37:44.461848078Z CUDA Version 12.9.1
2025-11-26T17:37:44.463378840Z Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
2025-11-26T17:37:44.464760661Z This container image and its contents are governed by the NVIDIA Deep Learning Container License.
2025-11-26T17:37:44.464763785Z By pulling and using the container, you accept the terms and conditions of this license:
2025-11-26T17:37:44.464766770Z https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license
2025-11-26T17:37:44.464771156Z A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
2025-11-26T17:37:44.630022432Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:37:44.789024718Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:37:44.979860499Z Branch 'feature/reasoning_model' set up to track remote branch 'feature/reasoning_model' from 'origin'.
2025-11-26T17:37:44.979904775Z Your branch is up to date with 'origin/feature/reasoning_model'.
2025-11-26T17:37:45.050330023Z Checking AReaL installation...
2025-11-26T17:37:45.108580194Z AReaL already installed. Skipping installation.
2025-11-26T17:37:45.108609899Z Cleaning up any leftover GPU processes...
2025-11-26T17:37:48.128025863Z Checking for processes holding GPU device files...
2025-11-26T17:37:50.662218209Z Found processes holding GPU devices: 1
2025-11-26T17:37:50.662254213Z 20
2025-11-26T17:37:50.662257308Z 71
2025-11-26T17:37:50.662259741Z 72
2025-11-26T17:37:50.662261824Z Killing process 1...
2025-11-26T17:37:50.662264127Z Killing process 71...
2025-11-26T17:37:50.662431289Z Killing process 72...
2025-11-26T17:37:52.667279781Z Using fuser to kill processes on GPU devices...
2025-11-26T17:37:54.692520219Z Checking GPU...
2025-11-26T17:37:54.726718564Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:37:54.726749310Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:37:54.743622083Z Set PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True for better memory management
2025-11-26T17:37:54.743643155Z Detected 2 GPU(s)
2025-11-26T17:37:54.743647170Z Checking GPU status...
2025-11-26T17:37:54.773035391Z index, name, utilization.gpu [%], memory.used [MiB], compute_mode
2025-11-26T17:37:54.774465783Z 0, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:37:54.774855537Z 1, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:37:54.818779170Z Verifying GPU accessibility...
2025-11-26T17:37:55.368725864Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:37:55.368794536Z   import pynvml  # type: ignore[import]
2025-11-26T17:37:56.476919244Z GPU accessibility verified on attempt 1
2025-11-26T17:37:57.010906083Z Starting training...
2025-11-26T17:38:00.013669152Z Using STANDARD 2000 SAMPLES 2 GPUs configuration
2025-11-26T17:38:00.013705667Z Note: GRPO only (no reasoning XML). Dataset capped at 2000 samples (~6 hours).
2025-11-26T17:38:00.013708902Z GPU count: 2 (required: 2)
2025-11-26T17:38:00.015959473Z ==========================================
2025-11-26T17:38:00.015962166Z Starting GRPO Training (Cloud)
2025-11-26T17:38:00.015979673Z ==========================================
2025-11-26T17:38:00.015981956Z Config: standard_2000samples_2GPUs
2025-11-26T17:38:00.015983979Z Config file: examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml
2025-11-26T17:38:00.015986082Z Training script: examples/cloud_gsm8k/gsm8k_grpo_train.py
2025-11-26T17:38:00.015988656Z Experiment: gsm8k-grpo-cloud-2gpu-2000samples
2025-11-26T17:38:00.015990840Z Trial: trial_20251126_173800
2025-11-26T17:38:00.015992893Z GPU: NVIDIA A100 80GB PCIe NVIDIA A100 80GB PCIe (81920 MB)
2025-11-26T17:38:00.015994966Z WandB API key: e1adc5be02...
2025-11-26T17:38:00.015997149Z ==========================================
2025-11-26T17:38:00.716965376Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:38:00.717001299Z   import pynvml  # type: ignore[import]
2025-11-26T17:38:04.757214395Z [37m20251126-17:38:04.756 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:38:04.757263769Z [37m20251126-17:38:04.756 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:38:04.757515015Z [37m20251126-17:38:04.757 name-resolve INFO: No such name resolve path: ./tmp/areal/name_resolve/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_173800[0m
2025-11-26T17:38:04.862672429Z [37m20251126-17:38:04.862 Local Scheduler INFO: LocalLauncher: experiment_name=gsm8k-grpo-cloud-2gpu-2000samples, trial_name=trial_20251126_173800, fileroot=/workspace/outputs/grpo, run_id=0, is_recover_run=False[0m
2025-11-26T17:38:04.870875646Z [37m20251126-17:38:04.870 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL CUDA_VISIBLE_DEVICES=0 stdbuf -oL python3 -m areal.launcher.sglang_server examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_173800 sglang.random_seed=1 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_173800/llm_server.log[0m
2025-11-26T17:38:05.592880813Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:38:05.592920052Z   import pynvml  # type: ignore[import]
2025-11-26T17:38:07.061214891Z [37m20251126-17:38:07.060 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:38:07.061946607Z [37m20251126-17:38:07.060 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:38:07.162238813Z [37m20251126-17:38:07.161 SGLangServer Wrapper INFO: Launch command: python3 -m sglang.launch_server --host 172.21.0.2 --port 13284 --tokenizer-path Qwen/Qwen2.5-0.5B-Instruct --tokenizer-mode auto --load-format auto --trust-remote-code --device cuda --tp-size 1 --base-gpu-id 0 --nnodes 1 --node-rank 0 --dist-init-addr localhost:28054 --model-path Qwen/Qwen2.5-0.5B-Instruct --random-seed 1 --skip-tokenizer-init --disable-radix-cache --torch-compile-max-bs 32 --triton-attention-num-kv-splits 8 --num-continuous-decode-steps 1 --attention-backend flashinfer --context-length 4096 --mem-fraction-static 0.6 --chunked-prefill-size -1 --max-prefill-tokens 32768 --schedule-policy lpm --schedule-conservativeness 1.0 --cpu-offload-gb 0 --dtype bfloat16 --kv-cache-dtype auto --dp-size 1 --ep-size 1 --max-loaded-loras 1 --max-loras-per-batch 1 --lora-backend triton --log-level warning --log-level-http warning --log-requests-level 0 --enable-metrics --decode-log-interval 1[0m
2025-11-26T17:38:08.207754340Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:38:08.207796914Z   import pynvml  # type: ignore[import]
2025-11-26T17:38:13.499842925Z INFO 11-26 17:38:13 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:38:14.135572802Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:38:15.150743306Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:38:15.150783987Z   import pynvml  # type: ignore[import]
2025-11-26T17:38:15.178283097Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:38:15.178317729Z   import pynvml  # type: ignore[import]
2025-11-26T17:38:20.375669609Z INFO 11-26 17:38:20 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:38:20.705447357Z INFO 11-26 17:38:20 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:38:20.954692797Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:38:21.180900579Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:38:21.184470446Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:38:21.185332558Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:38:21.186194939Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:38:21.219031375Z [2025-11-26 17:38:21] MOE_RUNNER_BACKEND is not initialized, using triton backend
2025-11-26T17:38:21.700995259Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:38:21.701033436Z   warnings.warn(
2025-11-26T17:38:21.701036901Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:38:21.701039214Z   warnings.warn(
2025-11-26T17:38:22.824224662Z Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
2025-11-26T17:38:22.945833497Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  8.23it/s]
2025-11-26T17:38:22.946369800Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  8.22it/s]
2025-11-26T17:38:25.382671839Z   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   4%|â–         | 1/23 [00:00<00:11,  1.89it/s]Capturing batches (bs=152 avail_mem=30.62 GB):   4%|â–         | 1/23 [00:00<00:11,  1.89it/s]Capturing batches (bs=144 avail_mem=30.60 GB):   4%|â–         | 1/23 [00:00<00:11,  1.89it/s]Capturing batches (bs=136 avail_mem=30.59 GB):   4%|â–         | 1/23 [00:00<00:11,  1.89it/s]Capturing batches (bs=136 avail_mem=30.59 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.41it/s]Capturing batches (bs=128 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.41it/s]Capturing batches (bs=120 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.41it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.41it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.74it/s]Capturing batches (bs=104 avail_mem=30.54 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.74it/s]Capturing batches (bs=96 avail_mem=30.53 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.74it/s] Capturing batches (bs=88 avail_mem=30.51 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.74it/s]Capturing batches (bs=88 avail_mem=30.51 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 15.11it/s]Capturing batches (bs=80 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 15.11it/s]Capturing batches (bs=72 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 15.11it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 15.11it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.60it/s]Capturing batches (bs=56 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.60it/s]Capturing batches (bs=48 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.60it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.60it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.63it/s]Capturing batches (bs=32 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.63it/s]Capturing batches (bs=24 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.63it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.63it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.94it/s]Capturing batches (bs=8 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.94it/s] Capturing batches (bs=4 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.94it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.94it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.79it/s]Capturing batches (bs=1 avail_mem=30.35 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.79it/s]Capturing batches (bs=1 avail_mem=30.35 GB): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00, 15.18it/s]
2025-11-26T17:38:31.189597287Z [37m20251126-17:38:31.189 SGLangServer Wrapper INFO: SGLang server launched at: http://172.21.0.2:13284[0m
2025-11-26T17:38:31.878094093Z [37m20251126-17:38:31.877 Launcher Utils INFO: Found 1 rollout servers: 172.21.0.2:13284[0m
2025-11-26T17:38:31.878182115Z [37m20251126-17:38:31.877 Local Scheduler INFO: LLM inference server launched at: AREAL_LLM_SERVER_ADDRS=172.21.0.2:13284[0m
2025-11-26T17:38:31.881370331Z [37m20251126-17:38:31.881 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL AREAL_LLM_SERVER_ADDRS=172.21.0.2:13284 AREAL_RECOVER_RUN=0 NCCL_CUMEM_ENABLE=0 NCCL_NVLS_ENABLE=0 CUDA_VISIBLE_DEVICES=1 stdbuf -oL torchrun --nnodes 1 --nproc-per-node 1 --master-addr localhost --master-port 43168 examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_173800 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_173800/trainer.log[0m
2025-11-26T17:38:31.881977190Z [37m20251126-17:38:31.881 Local Scheduler INFO: Waiting for 2 local running processes, pids: 315 965[0m
2025-11-26T17:38:32.397829254Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:38:32.397883175Z   import pynvml  # type: ignore[import]
2025-11-26T17:38:33.601098778Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:38:33.601183455Z   import pynvml  # type: ignore[import]
2025-11-26T17:38:40.276990334Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:38:40.277030103Z   warnings.warn(
2025-11-26T17:38:40.277033168Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:38:40.277035652Z   warnings.warn(
2025-11-26T17:38:40.706870733Z Traceback (most recent call last):
2025-11-26T17:38:40.706907278Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 665, in <module>
2025-11-26T17:38:40.707554917Z     main(sys.argv[1:])
2025-11-26T17:38:40.707565473Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 102, in main
2025-11-26T17:38:40.707568537Z     config, _ = load_expr_config(args_with_overrides, GRPOConfig)
2025-11-26T17:38:40.707571222Z                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:38:40.707573295Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1282, in load_expr_config
2025-11-26T17:38:40.707575408Z     cfg = to_structured_cfg(cfg, config_cls=config_cls)
2025-11-26T17:38:40.708029609Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:38:40.708032693Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1276, in to_structured_cfg
2025-11-26T17:38:40.708035457Z     cfg = OmegaConf.merge(default_cfg, cfg)
2025-11-26T17:38:40.708037611Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:38:40.708039674Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/omegaconf.py", line 274, in merge
2025-11-26T17:38:40.708041797Z     target.merge_with(
2025-11-26T17:38:40.708044461Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 507, in merge_with
2025-11-26T17:38:40.708516438Z     self._format_and_raise(key=None, value=None, cause=e)
2025-11-26T17:38:40.708520614Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:38:40.708523418Z     format_and_raise(
2025-11-26T17:38:40.708525802Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:38:40.708535406Z     _raise(ex, cause)
2025-11-26T17:38:40.708537920Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:38:40.708540053Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:38:40.709031399Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:38:40.709055565Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 502, in merge_with
2025-11-26T17:38:40.709058670Z     self._merge_with(
2025-11-26T17:38:40.709061524Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:38:40.709063837Z     BaseContainer._map_merge(
2025-11-26T17:38:40.709066392Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:38:40.709068495Z     dest_node._merge_with(
2025-11-26T17:38:40.709070547Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:38:40.709072631Z     BaseContainer._map_merge(
2025-11-26T17:38:40.709074594Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:38:40.709076576Z     dest_node._merge_with(
2025-11-26T17:38:40.709078600Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:38:40.709349285Z     BaseContainer._map_merge(
2025-11-26T17:38:40.709355354Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 432, in _map_merge
2025-11-26T17:38:40.709358068Z     dest[key] = src._get_node(key)
2025-11-26T17:38:40.709360882Z     ~~~~^^^^^
2025-11-26T17:38:40.709363506Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 308, in __setitem__
2025-11-26T17:38:40.709365850Z     self._format_and_raise(
2025-11-26T17:38:40.709368654Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:38:40.709370848Z     format_and_raise(
2025-11-26T17:38:40.709373161Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:38:40.709952980Z     _raise(ex, cause)
2025-11-26T17:38:40.709957166Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:38:40.709959930Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:38:40.709962133Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:38:40.709964747Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 306, in __setitem__
2025-11-26T17:38:40.709967161Z     self.__set_impl(key=key, value=value)
2025-11-26T17:38:40.709969364Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 316, in __set_impl
2025-11-26T17:38:40.709971918Z     self._set_item_impl(key, value)
2025-11-26T17:38:40.709974071Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 579, in _set_item_impl
2025-11-26T17:38:40.710444336Z     target_node_ref = self._get_node(key)
2025-11-26T17:38:40.710450075Z                       ^^^^^^^^^^^^^^^^^^^
2025-11-26T17:38:40.710452338Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 473, in _get_node
2025-11-26T17:38:40.710454842Z     self._validate_get(key)
2025-11-26T17:38:40.710456945Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 163, in _validate_get
2025-11-26T17:38:40.710459228Z     self._format_and_raise(
2025-11-26T17:38:40.710461452Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:38:40.710463784Z     format_and_raise(
2025-11-26T17:38:40.710466168Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 906, in format_and_raise
2025-11-26T17:38:40.710767449Z     _raise(ex, cause)
2025-11-26T17:38:40.710772036Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:38:40.710774390Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:38:40.710791515Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:38:40.710793979Z omegaconf.errors.ConfigKeyError: Key 'max_new_tokens' not in 'NormConfig'
2025-11-26T17:38:40.710796613Z     full_key: actor.adv_norm.max_new_tokens
2025-11-26T17:38:40.710798726Z     reference_type=Optional[NormConfig]
2025-11-26T17:38:40.710800759Z     object_type=NormConfig
2025-11-26T17:38:43.111372438Z E1126 17:38:43.110000 966 torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 0 (pid: 1032) of binary: /usr/bin/python3
2025-11-26T17:38:43.112094530Z Traceback (most recent call last):
2025-11-26T17:38:43.112098996Z   File "/usr/local/bin/torchrun", line 7, in <module>
2025-11-26T17:38:43.112101611Z     sys.exit(main())
2025-11-26T17:38:43.112104996Z              ^^^^^^
2025-11-26T17:38:43.112107079Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
2025-11-26T17:38:43.112110173Z     return f(*args, **kwargs)
2025-11-26T17:38:43.112173479Z            ^^^^^^^^^^^^^^^^^^
2025-11-26T17:38:43.112177745Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 901, in main
2025-11-26T17:38:43.112630222Z     run(args)
2025-11-26T17:38:43.112653447Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 892, in run
2025-11-26T17:38:43.112656632Z     elastic_launch(
2025-11-26T17:38:43.112659676Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 143, in __call__
2025-11-26T17:38:43.112662300Z     return launch_agent(self._config, self._entrypoint, list(args))
2025-11-26T17:38:43.112665215Z            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:38:43.112667368Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 277, in launch_agent
2025-11-26T17:38:43.112669862Z     raise ChildFailedError(
2025-11-26T17:38:43.112672546Z torch.distributed.elastic.multiprocessing.errors.ChildFailedError:
2025-11-26T17:38:43.112678935Z ============================================================
2025-11-26T17:38:43.112681599Z examples/cloud_gsm8k/gsm8k_grpo_train.py FAILED
2025-11-26T17:38:43.112684273Z ------------------------------------------------------------
2025-11-26T17:38:43.112686336Z Failures:
2025-11-26T17:38:43.112688610Z   <NO_OTHER_FAILURES>
2025-11-26T17:38:43.112690593Z ------------------------------------------------------------
2025-11-26T17:38:43.112692716Z Root Cause (first observed failure):
2025-11-26T17:38:43.112694719Z [0]:
2025-11-26T17:38:43.112696732Z   time      : 2025-11-26_17:38:43
2025-11-26T17:38:43.112698775Z   host      : cef7c503fdea
2025-11-26T17:38:43.112700828Z   rank      : 0 (local_rank: 0)
2025-11-26T17:38:43.112702841Z   exitcode  : 1 (pid: 1032)
2025-11-26T17:38:43.112704844Z   error_file: <N/A>
2025-11-26T17:38:43.112706827Z   traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
2025-11-26T17:38:43.112721689Z ============================================================
2025-11-26T17:38:43.885307059Z [37m20251126-17:38:43.884 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [315][0m
2025-11-26T17:38:44.004530972Z Killed
2025-11-26T17:38:44.015059663Z [37m20251126-17:38:44.014 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [965][0m
2025-11-26T17:38:44.016259801Z Traceback (most recent call last):
2025-11-26T17:38:44.016275515Z   File "<frozen runpy>", line 198, in _run_module_as_main
2025-11-26T17:38:44.016278780Z   File "<frozen runpy>", line 88, in _run_code
2025-11-26T17:38:44.016281253Z   File "/workspace/AReaL/areal/launcher/local.py", line 405, in <module>
2025-11-26T17:38:44.016437378Z     main()
2025-11-26T17:38:44.016442555Z   File "/workspace/AReaL/areal/launcher/local.py", line 260, in main
2025-11-26T17:38:44.016562384Z     local_main(config, run_id=0)
2025-11-26T17:38:44.016566180Z   File "/workspace/AReaL/areal/launcher/local.py", line 399, in local_main
2025-11-26T17:38:44.016689725Z     raise e
2025-11-26T17:38:44.016692049Z   File "/workspace/AReaL/areal/launcher/local.py", line 375, in local_main
2025-11-26T17:38:44.016791958Z     launcher.wait(
2025-11-26T17:38:44.016798097Z   File "/workspace/AReaL/areal/launcher/local.py", line 235, in wait
2025-11-26T17:38:44.016863055Z     raise JobException(
2025-11-26T17:38:44.016868733Z areal.utils.launcher.JobException: Job gsm8k-grpo-cloud-2gpu-2000samples_trial_20251126_173800:trainer JobState.COMPLETED at node local
2025-11-26T17:38:44.222579213Z [37m20251126-17:38:44.221 Local Scheduler INFO: Waiting for 0 local running processes, pids: [0m
2025-11-26T17:38:47.234023967Z ==========
2025-11-26T17:38:47.234027312Z == CUDA ==
2025-11-26T17:38:47.234041263Z ==========
2025-11-26T17:38:47.238694863Z CUDA Version 12.9.1
2025-11-26T17:38:47.240337774Z Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
2025-11-26T17:38:47.242269166Z This container image and its contents are governed by the NVIDIA Deep Learning Container License.
2025-11-26T17:38:47.242272661Z By pulling and using the container, you accept the terms and conditions of this license:
2025-11-26T17:38:47.242275216Z https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license
2025-11-26T17:38:47.242279772Z A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
2025-11-26T17:38:47.408643095Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:38:47.568179190Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:38:47.751623799Z Branch 'feature/reasoning_model' set up to track remote branch 'feature/reasoning_model' from 'origin'.
2025-11-26T17:38:47.751655957Z Your branch is up to date with 'origin/feature/reasoning_model'.
2025-11-26T17:38:47.826472173Z Checking AReaL installation...
2025-11-26T17:38:47.890489003Z AReaL already installed. Skipping installation.
2025-11-26T17:38:47.890519228Z Cleaning up any leftover GPU processes...
2025-11-26T17:38:50.910980497Z Checking for processes holding GPU device files...
2025-11-26T17:38:53.014790522Z Found processes holding GPU devices: 1
2025-11-26T17:38:53.014822800Z 20
2025-11-26T17:38:53.014825344Z 71
2025-11-26T17:38:53.014828118Z 72
2025-11-26T17:38:53.014830131Z Killing process 1...
2025-11-26T17:38:53.014833066Z Killing process 71...
2025-11-26T17:38:53.014894097Z Killing process 72...
2025-11-26T17:38:55.018214692Z Using fuser to kill processes on GPU devices...
2025-11-26T17:38:57.040322266Z Checking GPU...
2025-11-26T17:38:57.073999902Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:38:57.074032059Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:38:57.092634884Z Set PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True for better memory management
2025-11-26T17:38:57.092650247Z Detected 2 GPU(s)
2025-11-26T17:38:57.092653622Z Checking GPU status...
2025-11-26T17:38:57.121303656Z index, name, utilization.gpu [%], memory.used [MiB], compute_mode
2025-11-26T17:38:57.122749833Z 0, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:38:57.123068341Z 1, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:38:57.170008411Z Verifying GPU accessibility...
2025-11-26T17:38:57.708624603Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:38:57.708682681Z   import pynvml  # type: ignore[import]
2025-11-26T17:38:58.823470920Z GPU accessibility verified on attempt 1
2025-11-26T17:38:59.298498233Z Starting training...
2025-11-26T17:39:02.300964278Z Using STANDARD 2000 SAMPLES 2 GPUs configuration
2025-11-26T17:39:02.301010517Z Note: GRPO only (no reasoning XML). Dataset capped at 2000 samples (~6 hours).
2025-11-26T17:39:02.301013963Z GPU count: 2 (required: 2)
2025-11-26T17:39:02.303900696Z ==========================================
2025-11-26T17:39:02.303903991Z Starting GRPO Training (Cloud)
2025-11-26T17:39:02.303907276Z ==========================================
2025-11-26T17:39:02.303910050Z Config: standard_2000samples_2GPUs
2025-11-26T17:39:02.303912825Z Config file: examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml
2025-11-26T17:39:02.303924091Z Training script: examples/cloud_gsm8k/gsm8k_grpo_train.py
2025-11-26T17:39:02.303927777Z Experiment: gsm8k-grpo-cloud-2gpu-2000samples
2025-11-26T17:39:02.303930691Z Trial: trial_20251126_173902
2025-11-26T17:39:02.303933335Z GPU: NVIDIA A100 80GB PCIe NVIDIA A100 80GB PCIe (81920 MB)
2025-11-26T17:39:02.303936009Z WandB API key: e1adc5be02...
2025-11-26T17:39:02.303938633Z ==========================================
2025-11-26T17:39:02.996510694Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:39:02.996546597Z   import pynvml  # type: ignore[import]
2025-11-26T17:39:06.896106340Z [37m20251126-17:39:06.895 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:39:06.896174602Z [37m20251126-17:39:06.895 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:39:06.896393139Z [37m20251126-17:39:06.896 name-resolve INFO: No such name resolve path: ./tmp/areal/name_resolve/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_173902[0m
2025-11-26T17:39:07.001462000Z [37m20251126-17:39:07.001 Local Scheduler INFO: LocalLauncher: experiment_name=gsm8k-grpo-cloud-2gpu-2000samples, trial_name=trial_20251126_173902, fileroot=/workspace/outputs/grpo, run_id=0, is_recover_run=False[0m
2025-11-26T17:39:07.008918940Z [37m20251126-17:39:07.008 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL CUDA_VISIBLE_DEVICES=0 stdbuf -oL python3 -m areal.launcher.sglang_server examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_173902 sglang.random_seed=1 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_173902/llm_server.log[0m
2025-11-26T17:39:07.732688009Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:39:07.732729862Z   import pynvml  # type: ignore[import]
2025-11-26T17:39:09.184598657Z [37m20251126-17:39:09.184 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:39:09.185140128Z [37m20251126-17:39:09.184 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:39:09.285677832Z [37m20251126-17:39:09.285 SGLangServer Wrapper INFO: Launch command: python3 -m sglang.launch_server --host 172.21.0.2 --port 10329 --tokenizer-path Qwen/Qwen2.5-0.5B-Instruct --tokenizer-mode auto --load-format auto --trust-remote-code --device cuda --tp-size 1 --base-gpu-id 0 --nnodes 1 --node-rank 0 --dist-init-addr localhost:25165 --model-path Qwen/Qwen2.5-0.5B-Instruct --random-seed 1 --skip-tokenizer-init --disable-radix-cache --torch-compile-max-bs 32 --triton-attention-num-kv-splits 8 --num-continuous-decode-steps 1 --attention-backend flashinfer --context-length 4096 --mem-fraction-static 0.6 --chunked-prefill-size -1 --max-prefill-tokens 32768 --schedule-policy lpm --schedule-conservativeness 1.0 --cpu-offload-gb 0 --dtype bfloat16 --kv-cache-dtype auto --dp-size 1 --ep-size 1 --max-loaded-loras 1 --max-loras-per-batch 1 --lora-backend triton --log-level warning --log-level-http warning --log-requests-level 0 --enable-metrics --decode-log-interval 1[0m
2025-11-26T17:39:10.366092293Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:39:10.366187415Z   import pynvml  # type: ignore[import]
2025-11-26T17:39:16.183375777Z INFO 11-26 17:39:16 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:39:16.852822908Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:39:17.918001158Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:39:17.918041718Z   import pynvml  # type: ignore[import]
2025-11-26T17:39:17.954532978Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:39:17.954554040Z   import pynvml  # type: ignore[import]
2025-11-26T17:39:23.029380412Z INFO 11-26 17:39:23 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:39:23.325702376Z INFO 11-26 17:39:23 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:39:23.909541908Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:39:24.135189611Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:39:24.139109332Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:39:24.139953007Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:39:24.140927496Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:39:24.173948138Z [2025-11-26 17:39:24] MOE_RUNNER_BACKEND is not initialized, using triton backend
2025-11-26T17:39:24.659883350Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:39:24.659921948Z   warnings.warn(
2025-11-26T17:39:24.659925082Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:39:24.659927446Z   warnings.warn(
2025-11-26T17:39:25.766175112Z Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
2025-11-26T17:39:25.871544032Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  9.51it/s]
2025-11-26T17:39:25.872100325Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  9.48it/s]
2025-11-26T17:39:28.313470015Z   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   4%|â–         | 1/23 [00:00<00:11,  1.89it/s]Capturing batches (bs=152 avail_mem=30.62 GB):   4%|â–         | 1/23 [00:00<00:11,  1.89it/s]Capturing batches (bs=144 avail_mem=30.60 GB):   4%|â–         | 1/23 [00:00<00:11,  1.89it/s]Capturing batches (bs=136 avail_mem=30.59 GB):   4%|â–         | 1/23 [00:00<00:11,  1.89it/s]Capturing batches (bs=136 avail_mem=30.59 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.39it/s]Capturing batches (bs=128 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.39it/s]Capturing batches (bs=120 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.39it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.39it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.74it/s]Capturing batches (bs=104 avail_mem=30.54 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.74it/s]Capturing batches (bs=96 avail_mem=30.53 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.74it/s] Capturing batches (bs=88 avail_mem=30.51 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.74it/s]Capturing batches (bs=88 avail_mem=30.51 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 15.06it/s]Capturing batches (bs=80 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 15.06it/s]Capturing batches (bs=72 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 15.06it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 15.06it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.56it/s]Capturing batches (bs=56 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.56it/s]Capturing batches (bs=48 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.56it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.56it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.57it/s]Capturing batches (bs=32 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.57it/s]Capturing batches (bs=24 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.57it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.57it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.87it/s]Capturing batches (bs=8 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.87it/s] Capturing batches (bs=4 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.87it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.87it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.60it/s]Capturing batches (bs=1 avail_mem=30.35 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.60it/s]Capturing batches (bs=1 avail_mem=30.35 GB): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00, 15.10it/s]
2025-11-26T17:39:34.323968031Z [37m20251126-17:39:34.323 SGLangServer Wrapper INFO: SGLang server launched at: http://172.21.0.2:10329[0m
2025-11-26T17:39:35.015670608Z [37m20251126-17:39:35.015 Launcher Utils INFO: Found 1 rollout servers: 172.21.0.2:10329[0m
2025-11-26T17:39:35.015707564Z [37m20251126-17:39:35.015 Local Scheduler INFO: LLM inference server launched at: AREAL_LLM_SERVER_ADDRS=172.21.0.2:10329[0m
2025-11-26T17:39:35.018279215Z [37m20251126-17:39:35.018 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL AREAL_LLM_SERVER_ADDRS=172.21.0.2:10329 AREAL_RECOVER_RUN=0 NCCL_CUMEM_ENABLE=0 NCCL_NVLS_ENABLE=0 CUDA_VISIBLE_DEVICES=1 stdbuf -oL torchrun --nnodes 1 --nproc-per-node 1 --master-addr localhost --master-port 10753 examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_173902 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_173902/trainer.log[0m
2025-11-26T17:39:35.018965374Z [37m20251126-17:39:35.018 Local Scheduler INFO: Waiting for 2 local running processes, pids: 315 965[0m
2025-11-26T17:39:35.573868161Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:39:35.573913089Z   import pynvml  # type: ignore[import]
2025-11-26T17:39:36.771540301Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:39:36.771594743Z   import pynvml  # type: ignore[import]
2025-11-26T17:39:43.899139500Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:39:43.899179921Z   warnings.warn(
2025-11-26T17:39:43.899183617Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:39:43.899186060Z   warnings.warn(
2025-11-26T17:39:44.348510815Z Traceback (most recent call last):
2025-11-26T17:39:44.348555882Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 665, in <module>
2025-11-26T17:39:44.349215941Z     main(sys.argv[1:])
2025-11-26T17:39:44.349226948Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 102, in main
2025-11-26T17:39:44.349230393Z     config, _ = load_expr_config(args_with_overrides, GRPOConfig)
2025-11-26T17:39:44.349233297Z                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:39:44.349235310Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1282, in load_expr_config
2025-11-26T17:39:44.349237644Z     cfg = to_structured_cfg(cfg, config_cls=config_cls)
2025-11-26T17:39:44.349747076Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:39:44.349750191Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1276, in to_structured_cfg
2025-11-26T17:39:44.349752855Z     cfg = OmegaConf.merge(default_cfg, cfg)
2025-11-26T17:39:44.349754948Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:39:44.349757042Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/omegaconf.py", line 274, in merge
2025-11-26T17:39:44.349759245Z     target.merge_with(
2025-11-26T17:39:44.349761809Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 507, in merge_with
2025-11-26T17:39:44.349764562Z     self._format_and_raise(key=None, value=None, cause=e)
2025-11-26T17:39:44.350666874Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:39:44.350671621Z     format_and_raise(
2025-11-26T17:39:44.350673845Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:39:44.350675948Z     _raise(ex, cause)
2025-11-26T17:39:44.350678041Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:39:44.350690510Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:39:44.350692693Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:39:44.350695537Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 502, in merge_with
2025-11-26T17:39:44.350697571Z     self._merge_with(
2025-11-26T17:39:44.350699583Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:39:44.350701677Z     BaseContainer._map_merge(
2025-11-26T17:39:44.350704341Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:39:44.350706333Z     dest_node._merge_with(
2025-11-26T17:39:44.350708327Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:39:44.350710339Z     BaseContainer._map_merge(
2025-11-26T17:39:44.350712322Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:39:44.351205251Z     dest_node._merge_with(
2025-11-26T17:39:44.351242747Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:39:44.351245821Z     BaseContainer._map_merge(
2025-11-26T17:39:44.351248035Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 432, in _map_merge
2025-11-26T17:39:44.351250789Z     dest[key] = src._get_node(key)
2025-11-26T17:39:44.351253733Z     ~~~~^^^^^
2025-11-26T17:39:44.351256237Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 308, in __setitem__
2025-11-26T17:39:44.351258390Z     self._format_and_raise(
2025-11-26T17:39:44.351260523Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:39:44.351930297Z     format_and_raise(
2025-11-26T17:39:44.351934504Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:39:44.351937157Z     _raise(ex, cause)
2025-11-26T17:39:44.351939251Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:39:44.351941434Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:39:44.351943627Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:39:44.351945970Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 306, in __setitem__
2025-11-26T17:39:44.351948645Z     self.__set_impl(key=key, value=value)
2025-11-26T17:39:44.351950657Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 316, in __set_impl
2025-11-26T17:39:44.351952731Z     self._set_item_impl(key, value)
2025-11-26T17:39:44.351954724Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 579, in _set_item_impl
2025-11-26T17:39:44.351956837Z     target_node_ref = self._get_node(key)
2025-11-26T17:39:44.352363235Z                       ^^^^^^^^^^^^^^^^^^^
2025-11-26T17:39:44.352369214Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 473, in _get_node
2025-11-26T17:39:44.352372479Z     self._validate_get(key)
2025-11-26T17:39:44.352374552Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 163, in _validate_get
2025-11-26T17:39:44.352376735Z     self._format_and_raise(
2025-11-26T17:39:44.352378858Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:39:44.352381312Z     format_and_raise(
2025-11-26T17:39:44.352384076Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 906, in format_and_raise
2025-11-26T17:39:44.352748592Z     _raise(ex, cause)
2025-11-26T17:39:44.352752378Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:39:44.352754702Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:39:44.352756895Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:39:44.352759279Z omegaconf.errors.ConfigKeyError: Key 'max_new_tokens' not in 'NormConfig'
2025-11-26T17:39:44.352764547Z     full_key: actor.adv_norm.max_new_tokens
2025-11-26T17:39:44.352766860Z     reference_type=Optional[NormConfig]
2025-11-26T17:39:44.352768953Z     object_type=NormConfig
2025-11-26T17:39:46.880815493Z E1126 17:39:46.879000 966 torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 0 (pid: 1032) of binary: /usr/bin/python3
2025-11-26T17:39:46.881462032Z Traceback (most recent call last):
2025-11-26T17:39:46.881472368Z   File "/usr/local/bin/torchrun", line 7, in <module>
2025-11-26T17:39:46.881475502Z     sys.exit(main())
2025-11-26T17:39:46.881478466Z              ^^^^^^
2025-11-26T17:39:46.881480760Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
2025-11-26T17:39:46.882057454Z     return f(*args, **kwargs)
2025-11-26T17:39:46.882079787Z            ^^^^^^^^^^^^^^^^^^
2025-11-26T17:39:46.882082311Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 901, in main
2025-11-26T17:39:46.882084955Z     run(args)
2025-11-26T17:39:46.882087759Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 892, in run
2025-11-26T17:39:46.882089842Z     elastic_launch(
2025-11-26T17:39:46.882092697Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 143, in __call__
2025-11-26T17:39:46.882095000Z     return launch_agent(self._config, self._entrypoint, list(args))
2025-11-26T17:39:46.882097614Z            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:39:46.882099677Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 277, in launch_agent
2025-11-26T17:39:46.882534208Z     raise ChildFailedError(
2025-11-26T17:39:46.882540858Z torch.distributed.elastic.multiprocessing.errors.ChildFailedError:
2025-11-26T17:39:46.882545746Z ============================================================
2025-11-26T17:39:46.882547839Z examples/cloud_gsm8k/gsm8k_grpo_train.py FAILED
2025-11-26T17:39:46.882549892Z ------------------------------------------------------------
2025-11-26T17:39:46.882552356Z Failures:
2025-11-26T17:39:46.882555440Z   <NO_OTHER_FAILURES>
2025-11-26T17:39:46.882557944Z ------------------------------------------------------------
2025-11-26T17:39:46.882559977Z Root Cause (first observed failure):
2025-11-26T17:39:46.882562040Z [0]:
2025-11-26T17:39:46.882564233Z   time      : 2025-11-26_17:39:46
2025-11-26T17:39:46.882566397Z   host      : cef7c503fdea
2025-11-26T17:39:46.882568550Z   rank      : 0 (local_rank: 0)
2025-11-26T17:39:46.882570553Z   exitcode  : 1 (pid: 1032)
2025-11-26T17:39:46.882572566Z   error_file: <N/A>
2025-11-26T17:39:46.882574619Z   traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
2025-11-26T17:39:46.882577333Z ============================================================
2025-11-26T17:39:49.022719229Z [37m20251126-17:39:49.022 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [315][0m
2025-11-26T17:39:49.210362896Z Killed
2025-11-26T17:39:49.222553887Z [37m20251126-17:39:49.222 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [965][0m
2025-11-26T17:39:49.223737019Z Traceback (most recent call last):
2025-11-26T17:39:49.223750950Z   File "<frozen runpy>", line 198, in _run_module_as_main
2025-11-26T17:39:49.223753734Z   File "<frozen runpy>", line 88, in _run_code
2025-11-26T17:39:49.223755908Z   File "/workspace/AReaL/areal/launcher/local.py", line 405, in <module>
2025-11-26T17:39:49.223884230Z     main()
2025-11-26T17:39:49.223887715Z   File "/workspace/AReaL/areal/launcher/local.py", line 260, in main
2025-11-26T17:39:49.223998380Z     local_main(config, run_id=0)
2025-11-26T17:39:49.224001555Z   File "/workspace/AReaL/areal/launcher/local.py", line 399, in local_main
2025-11-26T17:39:49.224150449Z     raise e
2025-11-26T17:39:49.224154955Z   File "/workspace/AReaL/areal/launcher/local.py", line 375, in local_main
2025-11-26T17:39:49.224230929Z     launcher.wait(
2025-11-26T17:39:49.224234385Z   File "/workspace/AReaL/areal/launcher/local.py", line 235, in wait
2025-11-26T17:39:49.224319412Z     raise JobException(
2025-11-26T17:39:49.224329346Z areal.utils.launcher.JobException: Job gsm8k-grpo-cloud-2gpu-2000samples_trial_20251126_173902:trainer JobState.COMPLETED at node local
2025-11-26T17:39:49.411725724Z [37m20251126-17:39:49.411 Local Scheduler INFO: Waiting for 0 local running processes, pids: [0m
2025-11-26T17:40:05.771332254Z ==========
2025-11-26T17:40:05.771335680Z == CUDA ==
2025-11-26T17:40:05.771368649Z ==========
2025-11-26T17:40:05.775500929Z CUDA Version 12.9.1
2025-11-26T17:40:05.777070119Z Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
2025-11-26T17:40:05.778815083Z This container image and its contents are governed by the NVIDIA Deep Learning Container License.
2025-11-26T17:40:05.778817787Z By pulling and using the container, you accept the terms and conditions of this license:
2025-11-26T17:40:05.778820281Z https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license
2025-11-26T17:40:05.778824868Z A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
2025-11-26T17:40:05.944296335Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:40:06.103380643Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:40:06.291568817Z Branch 'feature/reasoning_model' set up to track remote branch 'feature/reasoning_model' from 'origin'.
2025-11-26T17:40:06.291601105Z Your branch is up to date with 'origin/feature/reasoning_model'.
2025-11-26T17:40:06.361945913Z Checking AReaL installation...
2025-11-26T17:40:06.422224573Z AReaL already installed. Skipping installation.
2025-11-26T17:40:06.422256901Z Cleaning up any leftover GPU processes...
2025-11-26T17:40:09.441497833Z Checking for processes holding GPU device files...
2025-11-26T17:40:12.148185196Z Found processes holding GPU devices: 1
2025-11-26T17:40:12.148222813Z 20
2025-11-26T17:40:12.148225877Z 71
2025-11-26T17:40:12.148228080Z 72
2025-11-26T17:40:12.148230273Z Killing process 1...
2025-11-26T17:40:12.148232848Z Killing process 71...
2025-11-26T17:40:12.148400819Z Killing process 72...
2025-11-26T17:40:14.151728464Z Using fuser to kill processes on GPU devices...
2025-11-26T17:40:16.175222185Z Checking GPU...
2025-11-26T17:40:16.214644405Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:40:16.214687149Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:40:16.231281334Z Set PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True for better memory management
2025-11-26T17:40:16.231316247Z Detected 2 GPU(s)
2025-11-26T17:40:16.231320944Z Checking GPU status...
2025-11-26T17:40:16.259458821Z index, name, utilization.gpu [%], memory.used [MiB], compute_mode
2025-11-26T17:40:16.260945748Z 0, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:40:16.261281281Z 1, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:40:16.308725087Z Verifying GPU accessibility...
2025-11-26T17:40:16.845069927Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:40:16.845168394Z   import pynvml  # type: ignore[import]
2025-11-26T17:40:17.937371203Z GPU accessibility verified on attempt 1
2025-11-26T17:40:18.400686684Z Starting training...
2025-11-26T17:40:21.403364957Z Using STANDARD 2000 SAMPLES 2 GPUs configuration
2025-11-26T17:40:21.403415622Z Note: GRPO only (no reasoning XML). Dataset capped at 2000 samples (~6 hours).
2025-11-26T17:40:21.403419057Z GPU count: 2 (required: 2)
2025-11-26T17:40:21.405974045Z ==========================================
2025-11-26T17:40:21.405976879Z Starting GRPO Training (Cloud)
2025-11-26T17:40:21.405979143Z ==========================================
2025-11-26T17:40:21.405981186Z Config: standard_2000samples_2GPUs
2025-11-26T17:40:21.405983218Z Config file: examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml
2025-11-26T17:40:21.405985402Z Training script: examples/cloud_gsm8k/gsm8k_grpo_train.py
2025-11-26T17:40:21.405995187Z Experiment: gsm8k-grpo-cloud-2gpu-2000samples
2025-11-26T17:40:21.405997420Z Trial: trial_20251126_174021
2025-11-26T17:40:21.405999493Z GPU: NVIDIA A100 80GB PCIe NVIDIA A100 80GB PCIe (81920 MB)
2025-11-26T17:40:21.406001536Z WandB API key: e1adc5be02...
2025-11-26T17:40:21.406003599Z ==========================================
2025-11-26T17:40:22.091990746Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:40:22.092042813Z   import pynvml  # type: ignore[import]
2025-11-26T17:40:26.032184113Z [37m20251126-17:40:26.031 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:40:26.032226266Z [37m20251126-17:40:26.031 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:40:26.032432295Z [37m20251126-17:40:26.032 name-resolve INFO: No such name resolve path: ./tmp/areal/name_resolve/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_174021[0m
2025-11-26T17:40:26.137172584Z [37m20251126-17:40:26.136 Local Scheduler INFO: LocalLauncher: experiment_name=gsm8k-grpo-cloud-2gpu-2000samples, trial_name=trial_20251126_174021, fileroot=/workspace/outputs/grpo, run_id=0, is_recover_run=False[0m
2025-11-26T17:40:26.144748531Z [37m20251126-17:40:26.144 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL CUDA_VISIBLE_DEVICES=0 stdbuf -oL python3 -m areal.launcher.sglang_server examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_174021 sglang.random_seed=1 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_174021/llm_server.log[0m
2025-11-26T17:40:26.860589665Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:40:26.860627933Z   import pynvml  # type: ignore[import]
2025-11-26T17:40:28.319424445Z [37m20251126-17:40:28.318 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:40:28.320216572Z [37m20251126-17:40:28.319 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:40:28.420957820Z [37m20251126-17:40:28.420 SGLangServer Wrapper INFO: Launch command: python3 -m sglang.launch_server --host 172.21.0.2 --port 14199 --tokenizer-path Qwen/Qwen2.5-0.5B-Instruct --tokenizer-mode auto --load-format auto --trust-remote-code --device cuda --tp-size 1 --base-gpu-id 0 --nnodes 1 --node-rank 0 --dist-init-addr localhost:15144 --model-path Qwen/Qwen2.5-0.5B-Instruct --random-seed 1 --skip-tokenizer-init --disable-radix-cache --torch-compile-max-bs 32 --triton-attention-num-kv-splits 8 --num-continuous-decode-steps 1 --attention-backend flashinfer --context-length 4096 --mem-fraction-static 0.6 --chunked-prefill-size -1 --max-prefill-tokens 32768 --schedule-policy lpm --schedule-conservativeness 1.0 --cpu-offload-gb 0 --dtype bfloat16 --kv-cache-dtype auto --dp-size 1 --ep-size 1 --max-loaded-loras 1 --max-loras-per-batch 1 --lora-backend triton --log-level warning --log-level-http warning --log-requests-level 0 --enable-metrics --decode-log-interval 1[0m
2025-11-26T17:40:29.499610953Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:40:29.499666196Z   import pynvml  # type: ignore[import]
2025-11-26T17:40:35.093239679Z INFO 11-26 17:40:35 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:40:35.853107219Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:40:36.880840160Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:40:36.880873320Z   import pynvml  # type: ignore[import]
2025-11-26T17:40:36.957332727Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:40:36.957367329Z   import pynvml  # type: ignore[import]
2025-11-26T17:40:42.530880283Z INFO 11-26 17:40:42 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:40:42.642942028Z INFO 11-26 17:40:42 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:40:43.136226810Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:40:43.378393997Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:40:43.382099527Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:40:43.382957402Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:40:43.383873114Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:40:43.418328173Z [2025-11-26 17:40:43] MOE_RUNNER_BACKEND is not initialized, using triton backend
2025-11-26T17:40:43.935245344Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:40:43.935282790Z   warnings.warn(
2025-11-26T17:40:43.935285794Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:40:43.935288438Z   warnings.warn(
2025-11-26T17:40:45.192478909Z Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
2025-11-26T17:40:45.303487577Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  9.03it/s]
2025-11-26T17:40:45.304575997Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  9.00it/s]
2025-11-26T17:40:47.891438007Z   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   4%|â–         | 1/23 [00:00<00:11,  1.87it/s]Capturing batches (bs=152 avail_mem=30.62 GB):   4%|â–         | 1/23 [00:00<00:11,  1.87it/s]Capturing batches (bs=144 avail_mem=30.60 GB):   4%|â–         | 1/23 [00:00<00:11,  1.87it/s]Capturing batches (bs=136 avail_mem=30.59 GB):   4%|â–         | 1/23 [00:00<00:11,  1.87it/s]Capturing batches (bs=136 avail_mem=30.59 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.35it/s]Capturing batches (bs=128 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.35it/s]Capturing batches (bs=120 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.35it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.35it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.67it/s]Capturing batches (bs=104 avail_mem=30.54 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.67it/s]Capturing batches (bs=96 avail_mem=30.53 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.67it/s] Capturing batches (bs=88 avail_mem=30.51 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.67it/s]Capturing batches (bs=88 avail_mem=30.51 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 15.02it/s]Capturing batches (bs=80 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 15.02it/s]Capturing batches (bs=72 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 15.02it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 15.02it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.51it/s]Capturing batches (bs=56 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.51it/s]Capturing batches (bs=48 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.51it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.51it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.45it/s]Capturing batches (bs=32 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.45it/s]Capturing batches (bs=24 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.45it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.45it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.50it/s]Capturing batches (bs=8 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.50it/s] Capturing batches (bs=4 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.50it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.50it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.29it/s]Capturing batches (bs=1 avail_mem=30.35 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.29it/s]Capturing batches (bs=1 avail_mem=30.35 GB): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00, 14.95it/s]
2025-11-26T17:40:53.447896865Z [37m20251126-17:40:53.447 SGLangServer Wrapper INFO: SGLang server launched at: http://172.21.0.2:14199[0m
2025-11-26T17:40:54.151765327Z [37m20251126-17:40:54.151 Launcher Utils INFO: Found 1 rollout servers: 172.21.0.2:14199[0m
2025-11-26T17:40:54.151790935Z [37m20251126-17:40:54.151 Local Scheduler INFO: LLM inference server launched at: AREAL_LLM_SERVER_ADDRS=172.21.0.2:14199[0m
2025-11-26T17:40:54.154173053Z [37m20251126-17:40:54.153 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL AREAL_LLM_SERVER_ADDRS=172.21.0.2:14199 AREAL_RECOVER_RUN=0 NCCL_CUMEM_ENABLE=0 NCCL_NVLS_ENABLE=0 CUDA_VISIBLE_DEVICES=1 stdbuf -oL torchrun --nnodes 1 --nproc-per-node 1 --master-addr localhost --master-port 12596 examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_174021 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_174021/trainer.log[0m
2025-11-26T17:40:54.154838900Z [37m20251126-17:40:54.154 Local Scheduler INFO: Waiting for 2 local running processes, pids: 315 965[0m
2025-11-26T17:40:54.665284337Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:40:54.665323956Z   import pynvml  # type: ignore[import]
2025-11-26T17:40:55.841514117Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:40:55.841552726Z   import pynvml  # type: ignore[import]
2025-11-26T17:41:03.310724791Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:41:03.310772402Z   warnings.warn(
2025-11-26T17:41:03.310775447Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:41:03.310777790Z   warnings.warn(
2025-11-26T17:41:03.923241708Z Traceback (most recent call last):
2025-11-26T17:41:03.923281377Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 665, in <module>
2025-11-26T17:41:03.923973975Z     main(sys.argv[1:])
2025-11-26T17:41:03.923981785Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 102, in main
2025-11-26T17:41:03.923984840Z     config, _ = load_expr_config(args_with_overrides, GRPOConfig)
2025-11-26T17:41:03.923987674Z                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:41:03.923989968Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1282, in load_expr_config
2025-11-26T17:41:03.924432761Z     cfg = to_structured_cfg(cfg, config_cls=config_cls)
2025-11-26T17:41:03.924438200Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:41:03.924440493Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1276, in to_structured_cfg
2025-11-26T17:41:03.924834894Z     cfg = OmegaConf.merge(default_cfg, cfg)
2025-11-26T17:41:03.924837969Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:41:03.924840052Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/omegaconf.py", line 274, in merge
2025-11-26T17:41:03.925413040Z     target.merge_with(
2025-11-26T17:41:03.925418949Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 507, in merge_with
2025-11-26T17:41:03.925421783Z     self._format_and_raise(key=None, value=None, cause=e)
2025-11-26T17:41:03.925424027Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:41:03.925426020Z     format_and_raise(
2025-11-26T17:41:03.925428063Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:41:03.925430106Z     _raise(ex, cause)
2025-11-26T17:41:03.925432149Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:41:03.925860300Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:41:03.925894711Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:41:03.925897926Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 502, in merge_with
2025-11-26T17:41:03.926178136Z     self._merge_with(
2025-11-26T17:41:03.926185306Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:41:03.926187680Z     BaseContainer._map_merge(
2025-11-26T17:41:03.926190274Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:41:03.926192337Z     dest_node._merge_with(
2025-11-26T17:41:03.926506608Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:41:03.926509763Z     BaseContainer._map_merge(
2025-11-26T17:41:03.926512407Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:41:03.926514550Z     dest_node._merge_with(
2025-11-26T17:41:03.926516653Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:41:03.926868440Z     BaseContainer._map_merge(
2025-11-26T17:41:03.926871475Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 432, in _map_merge
2025-11-26T17:41:03.926874379Z     dest[key] = src._get_node(key)
2025-11-26T17:41:03.926877454Z     ~~~~^^^^^
2025-11-26T17:41:03.926881069Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 308, in __setitem__
2025-11-26T17:41:03.927527206Z     self._format_and_raise(
2025-11-26T17:41:03.927533656Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:41:03.927535849Z     format_and_raise(
2025-11-26T17:41:03.927537892Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:41:03.927539926Z     _raise(ex, cause)
2025-11-26T17:41:03.927541929Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:41:03.927544232Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:41:03.927910891Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:41:03.927916109Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 306, in __setitem__
2025-11-26T17:41:03.927918683Z     self.__set_impl(key=key, value=value)
2025-11-26T17:41:03.927920736Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 316, in __set_impl
2025-11-26T17:41:03.927923410Z     self._set_item_impl(key, value)
2025-11-26T17:41:03.927925473Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 579, in _set_item_impl
2025-11-26T17:41:03.928238502Z     target_node_ref = self._get_node(key)
2025-11-26T17:41:03.928245543Z                       ^^^^^^^^^^^^^^^^^^^
2025-11-26T17:41:03.928247876Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 473, in _get_node
2025-11-26T17:41:03.928577320Z     self._validate_get(key)
2025-11-26T17:41:03.928579793Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 163, in _validate_get
2025-11-26T17:41:03.928582067Z     self._format_and_raise(
2025-11-26T17:41:03.928584160Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:41:03.928586193Z     format_and_raise(
2025-11-26T17:41:03.928588366Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 906, in format_and_raise
2025-11-26T17:41:03.928909237Z     _raise(ex, cause)
2025-11-26T17:41:03.928911721Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:41:03.928913884Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:41:03.929168195Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:41:03.929172281Z omegaconf.errors.ConfigKeyError: Key 'max_new_tokens' not in 'NormConfig'
2025-11-26T17:41:03.929174885Z     full_key: actor.adv_norm.max_new_tokens
2025-11-26T17:41:03.929177118Z     reference_type=Optional[NormConfig]
2025-11-26T17:41:03.929188405Z     object_type=NormConfig
2025-11-26T17:41:06.759074636Z E1126 17:41:06.758000 966 torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 0 (pid: 1032) of binary: /usr/bin/python3
2025-11-26T17:41:06.759668916Z Traceback (most recent call last):
2025-11-26T17:41:06.759706561Z   File "/usr/local/bin/torchrun", line 7, in <module>
2025-11-26T17:41:06.759710067Z     sys.exit(main())
2025-11-26T17:41:06.759712881Z              ^^^^^^
2025-11-26T17:41:06.759714994Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
2025-11-26T17:41:06.760520842Z     return f(*args, **kwargs)
2025-11-26T17:41:06.760532419Z            ^^^^^^^^^^^^^^^^^^
2025-11-26T17:41:06.760535063Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 901, in main
2025-11-26T17:41:06.760537697Z     run(args)
2025-11-26T17:41:06.760540672Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 892, in run
2025-11-26T17:41:06.760543235Z     elastic_launch(
2025-11-26T17:41:06.760545890Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 143, in __call__
2025-11-26T17:41:06.760548684Z     return launch_agent(self._config, self._entrypoint, list(args))
2025-11-26T17:41:06.760551338Z            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:41:06.760553401Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 277, in launch_agent
2025-11-26T17:41:06.760555434Z     raise ChildFailedError(
2025-11-26T17:41:06.760557467Z torch.distributed.elastic.multiprocessing.errors.ChildFailedError:
2025-11-26T17:41:06.760559430Z ============================================================
2025-11-26T17:41:06.760562284Z examples/cloud_gsm8k/gsm8k_grpo_train.py FAILED
2025-11-26T17:41:06.760564918Z ------------------------------------------------------------
2025-11-26T17:41:06.760566981Z Failures:
2025-11-26T17:41:06.760568974Z   <NO_OTHER_FAILURES>
2025-11-26T17:41:06.760570947Z ------------------------------------------------------------
2025-11-26T17:41:06.760572960Z Root Cause (first observed failure):
2025-11-26T17:41:06.760574943Z [0]:
2025-11-26T17:41:06.760576996Z   time      : 2025-11-26_17:41:06
2025-11-26T17:41:06.760579120Z   host      : cef7c503fdea
2025-11-26T17:41:06.760581092Z   rank      : 0 (local_rank: 0)
2025-11-26T17:41:06.760583075Z   exitcode  : 1 (pid: 1032)
2025-11-26T17:41:06.760585278Z   error_file: <N/A>
2025-11-26T17:41:06.760587331Z   traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
2025-11-26T17:41:06.760589394Z ============================================================
2025-11-26T17:41:08.158557653Z [37m20251126-17:41:08.158 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [315][0m
2025-11-26T17:41:08.279426952Z Killed
2025-11-26T17:41:08.289273100Z [37m20251126-17:41:08.288 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [965][0m
2025-11-26T17:41:08.290325565Z Traceback (most recent call last):
2025-11-26T17:41:08.290339276Z   File "<frozen runpy>", line 198, in _run_module_as_main
2025-11-26T17:41:08.290342261Z   File "<frozen runpy>", line 88, in _run_code
2025-11-26T17:41:08.290344434Z   File "/workspace/AReaL/areal/launcher/local.py", line 405, in <module>
2025-11-26T17:41:08.290504845Z     main()
2025-11-26T17:41:08.290510253Z   File "/workspace/AReaL/areal/launcher/local.py", line 260, in main
2025-11-26T17:41:08.290583933Z     local_main(config, run_id=0)
2025-11-26T17:41:08.290587759Z   File "/workspace/AReaL/areal/launcher/local.py", line 399, in local_main
2025-11-26T17:41:08.290687488Z     raise e
2025-11-26T17:41:08.290689942Z   File "/workspace/AReaL/areal/launcher/local.py", line 375, in local_main
2025-11-26T17:41:08.290744313Z     launcher.wait(
2025-11-26T17:41:08.290747007Z   File "/workspace/AReaL/areal/launcher/local.py", line 235, in wait
2025-11-26T17:41:08.290812015Z     raise JobException(
2025-11-26T17:41:08.290815110Z areal.utils.launcher.JobException: Job gsm8k-grpo-cloud-2gpu-2000samples_trial_20251126_174021:trainer JobState.COMPLETED at node local
2025-11-26T17:41:08.600512629Z [37m20251126-17:41:08.599 Local Scheduler INFO: Waiting for 0 local running processes, pids: [0m
2025-11-26T17:41:24.119233764Z ==========
2025-11-26T17:41:24.119249077Z == CUDA ==
2025-11-26T17:41:24.119251511Z ==========
2025-11-26T17:41:24.124379692Z CUDA Version 12.9.1
2025-11-26T17:41:24.126631004Z Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
2025-11-26T17:41:24.128145362Z This container image and its contents are governed by the NVIDIA Deep Learning Container License.
2025-11-26T17:41:24.128148878Z By pulling and using the container, you accept the terms and conditions of this license:
2025-11-26T17:41:24.128151862Z https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license
2025-11-26T17:41:24.128156129Z A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
2025-11-26T17:41:24.292807256Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:41:24.449454014Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:41:24.731179225Z Branch 'feature/reasoning_model' set up to track remote branch 'feature/reasoning_model' from 'origin'.
2025-11-26T17:41:24.731217432Z Your branch is up to date with 'origin/feature/reasoning_model'.
2025-11-26T17:41:24.807747114Z Checking AReaL installation...
2025-11-26T17:41:24.872827747Z AReaL already installed. Skipping installation.
2025-11-26T17:41:24.872860476Z Cleaning up any leftover GPU processes...
2025-11-26T17:41:27.891966246Z Checking for processes holding GPU device files...
2025-11-26T17:41:30.006804470Z Found processes holding GPU devices: 1
2025-11-26T17:41:30.006851470Z 20
2025-11-26T17:41:30.006856046Z 71
2025-11-26T17:41:30.006859822Z 72
2025-11-26T17:41:30.006863087Z Killing process 1...
2025-11-26T17:41:30.006866132Z Killing process 71...
2025-11-26T17:41:30.006923067Z Killing process 72...
2025-11-26T17:41:32.009327559Z Using fuser to kill processes on GPU devices...
2025-11-26T17:41:34.032329123Z Checking GPU...
2025-11-26T17:41:34.067209529Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:41:34.067250270Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:41:34.083414923Z Set PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True for better memory management
2025-11-26T17:41:34.083452490Z Detected 2 GPU(s)
2025-11-26T17:41:34.083455865Z Checking GPU status...
2025-11-26T17:41:34.118057114Z index, name, utilization.gpu [%], memory.used [MiB], compute_mode
2025-11-26T17:41:34.119567054Z 0, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:41:34.119869918Z 1, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:41:34.163612019Z Verifying GPU accessibility...
2025-11-26T17:41:34.713146836Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:41:34.713186005Z   import pynvml  # type: ignore[import]
2025-11-26T17:41:35.839926587Z GPU accessibility verified on attempt 1
2025-11-26T17:41:36.379388597Z Starting training...
2025-11-26T17:41:39.382637223Z Using STANDARD 2000 SAMPLES 2 GPUs configuration
2025-11-26T17:41:39.382677624Z Note: GRPO only (no reasoning XML). Dataset capped at 2000 samples (~6 hours).
2025-11-26T17:41:39.382681380Z GPU count: 2 (required: 2)
2025-11-26T17:41:39.385226702Z ==========================================
2025-11-26T17:41:39.385229746Z Starting GRPO Training (Cloud)
2025-11-26T17:41:39.385232241Z ==========================================
2025-11-26T17:41:39.385234293Z Config: standard_2000samples_2GPUs
2025-11-26T17:41:39.385236296Z Config file: examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml
2025-11-26T17:41:39.385238860Z Training script: examples/cloud_gsm8k/gsm8k_grpo_train.py
2025-11-26T17:41:39.385241034Z Experiment: gsm8k-grpo-cloud-2gpu-2000samples
2025-11-26T17:41:39.385243177Z Trial: trial_20251126_174139
2025-11-26T17:41:39.385256898Z GPU: NVIDIA A100 80GB PCIe NVIDIA A100 80GB PCIe (81920 MB)
2025-11-26T17:41:39.385264449Z WandB API key: e1adc5be02...
2025-11-26T17:41:39.385266592Z ==========================================
2025-11-26T17:41:40.086669600Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:41:40.086717071Z   import pynvml  # type: ignore[import]
2025-11-26T17:41:44.134403731Z [37m20251126-17:41:44.133 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:41:44.134444592Z [37m20251126-17:41:44.134 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:41:44.134686855Z [37m20251126-17:41:44.134 name-resolve INFO: No such name resolve path: ./tmp/areal/name_resolve/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_174139[0m
2025-11-26T17:41:44.240577896Z [37m20251126-17:41:44.240 Local Scheduler INFO: LocalLauncher: experiment_name=gsm8k-grpo-cloud-2gpu-2000samples, trial_name=trial_20251126_174139, fileroot=/workspace/outputs/grpo, run_id=0, is_recover_run=False[0m
2025-11-26T17:41:44.248186393Z [37m20251126-17:41:44.247 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL CUDA_VISIBLE_DEVICES=0 stdbuf -oL python3 -m areal.launcher.sglang_server examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_174139 sglang.random_seed=1 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_174139/llm_server.log[0m
2025-11-26T17:41:44.960911620Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:41:44.960948746Z   import pynvml  # type: ignore[import]
2025-11-26T17:41:46.424387501Z [37m20251126-17:41:46.423 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:41:46.425050775Z [37m20251126-17:41:46.424 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:41:46.526042719Z [37m20251126-17:41:46.525 SGLangServer Wrapper INFO: Launch command: python3 -m sglang.launch_server --host 172.21.0.2 --port 13098 --tokenizer-path Qwen/Qwen2.5-0.5B-Instruct --tokenizer-mode auto --load-format auto --trust-remote-code --device cuda --tp-size 1 --base-gpu-id 0 --nnodes 1 --node-rank 0 --dist-init-addr localhost:22711 --model-path Qwen/Qwen2.5-0.5B-Instruct --random-seed 1 --skip-tokenizer-init --disable-radix-cache --torch-compile-max-bs 32 --triton-attention-num-kv-splits 8 --num-continuous-decode-steps 1 --attention-backend flashinfer --context-length 4096 --mem-fraction-static 0.6 --chunked-prefill-size -1 --max-prefill-tokens 32768 --schedule-policy lpm --schedule-conservativeness 1.0 --cpu-offload-gb 0 --dtype bfloat16 --kv-cache-dtype auto --dp-size 1 --ep-size 1 --max-loaded-loras 1 --max-loras-per-batch 1 --lora-backend triton --log-level warning --log-level-http warning --log-requests-level 0 --enable-metrics --decode-log-interval 1[0m
2025-11-26T17:41:47.568213426Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:41:47.568252965Z   import pynvml  # type: ignore[import]
2025-11-26T17:41:52.837890520Z INFO 11-26 17:41:52 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:41:53.484693113Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:41:54.545920925Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:41:54.545967916Z   import pynvml  # type: ignore[import]
2025-11-26T17:41:54.568281519Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:41:54.568303672Z   import pynvml  # type: ignore[import]
2025-11-26T17:42:00.023629788Z INFO 11-26 17:42:00 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:42:00.500942785Z INFO 11-26 17:42:00 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:42:00.613413383Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:42:00.858232252Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:42:00.861811163Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:42:00.862584932Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:42:00.863418901Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:42:00.896211711Z [2025-11-26 17:42:00] MOE_RUNNER_BACKEND is not initialized, using triton backend
2025-11-26T17:42:01.384631835Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:42:01.384671285Z   warnings.warn(
2025-11-26T17:42:01.384674650Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:42:01.384676833Z   warnings.warn(
2025-11-26T17:42:02.501909514Z Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
2025-11-26T17:42:02.607296641Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  9.51it/s]
2025-11-26T17:42:02.607681126Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  9.49it/s]
2025-11-26T17:42:05.087208071Z   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   4%|â–         | 1/23 [00:00<00:12,  1.80it/s]Capturing batches (bs=152 avail_mem=30.62 GB):   4%|â–         | 1/23 [00:00<00:12,  1.80it/s]Capturing batches (bs=144 avail_mem=30.60 GB):   4%|â–         | 1/23 [00:00<00:12,  1.80it/s]Capturing batches (bs=136 avail_mem=30.59 GB):   4%|â–         | 1/23 [00:00<00:12,  1.80it/s]Capturing batches (bs=136 avail_mem=30.59 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.16it/s]Capturing batches (bs=128 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.16it/s]Capturing batches (bs=120 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.16it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.16it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.47it/s]Capturing batches (bs=104 avail_mem=30.54 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.47it/s]Capturing batches (bs=96 avail_mem=30.53 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.47it/s] Capturing batches (bs=88 avail_mem=30.51 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.47it/s]Capturing batches (bs=88 avail_mem=30.51 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.86it/s]Capturing batches (bs=80 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.86it/s]Capturing batches (bs=72 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.86it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:01<00:00, 14.86it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.42it/s]Capturing batches (bs=56 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.42it/s]Capturing batches (bs=48 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.42it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.42it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.47it/s]Capturing batches (bs=32 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.47it/s]Capturing batches (bs=24 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.47it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.47it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.88it/s]Capturing batches (bs=8 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.88it/s] Capturing batches (bs=4 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.88it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.88it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.72it/s]Capturing batches (bs=1 avail_mem=30.35 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.72it/s]Capturing batches (bs=1 avail_mem=30.35 GB): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00, 14.94it/s]
2025-11-26T17:42:10.556432864Z [37m20251126-17:42:10.556 SGLangServer Wrapper INFO: SGLang server launched at: http://172.21.0.2:13098[0m
2025-11-26T17:42:11.255498802Z [37m20251126-17:42:11.255 Launcher Utils INFO: Found 1 rollout servers: 172.21.0.2:13098[0m
2025-11-26T17:42:11.255536919Z [37m20251126-17:42:11.255 Local Scheduler INFO: LLM inference server launched at: AREAL_LLM_SERVER_ADDRS=172.21.0.2:13098[0m
2025-11-26T17:42:11.258238986Z [37m20251126-17:42:11.258 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL AREAL_LLM_SERVER_ADDRS=172.21.0.2:13098 AREAL_RECOVER_RUN=0 NCCL_CUMEM_ENABLE=0 NCCL_NVLS_ENABLE=0 CUDA_VISIBLE_DEVICES=1 stdbuf -oL torchrun --nnodes 1 --nproc-per-node 1 --master-addr localhost --master-port 43690 examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_174139 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_174139/trainer.log[0m
2025-11-26T17:42:11.258996731Z [37m20251126-17:42:11.258 Local Scheduler INFO: Waiting for 2 local running processes, pids: 315 965[0m
2025-11-26T17:42:11.802889007Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:42:11.802948336Z   import pynvml  # type: ignore[import]
2025-11-26T17:42:13.012924655Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:42:13.012961790Z   import pynvml  # type: ignore[import]
2025-11-26T17:42:20.200285301Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:42:20.200328414Z   warnings.warn(
2025-11-26T17:42:20.200331939Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:42:20.200334473Z   warnings.warn(
2025-11-26T17:42:20.627929570Z Traceback (most recent call last):
2025-11-26T17:42:20.628645763Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 665, in <module>
2025-11-26T17:42:20.628659323Z     main(sys.argv[1:])
2025-11-26T17:42:20.628663810Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 102, in main
2025-11-26T17:42:20.628667155Z     config, _ = load_expr_config(args_with_overrides, GRPOConfig)
2025-11-26T17:42:20.628671061Z                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:42:20.628674145Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1282, in load_expr_config
2025-11-26T17:42:20.629170158Z     cfg = to_structured_cfg(cfg, config_cls=config_cls)
2025-11-26T17:42:20.629180363Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:42:20.629183498Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1276, in to_structured_cfg
2025-11-26T17:42:20.629187224Z     cfg = OmegaConf.merge(default_cfg, cfg)
2025-11-26T17:42:20.629538019Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:42:20.629544729Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/omegaconf.py", line 274, in merge
2025-11-26T17:42:20.629547704Z     target.merge_with(
2025-11-26T17:42:20.629550669Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 507, in merge_with
2025-11-26T17:42:20.629553433Z     self._format_and_raise(key=None, value=None, cause=e)
2025-11-26T17:42:20.629555536Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:42:20.629557969Z     format_and_raise(
2025-11-26T17:42:20.629560052Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:42:20.630486439Z     _raise(ex, cause)
2025-11-26T17:42:20.630496214Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:42:20.630499609Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:42:20.630502754Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:42:20.630505808Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 502, in merge_with
2025-11-26T17:42:20.630530596Z     self._merge_with(
2025-11-26T17:42:20.630533910Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:42:20.630537486Z     BaseContainer._map_merge(
2025-11-26T17:42:20.630541241Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:42:20.630544416Z     dest_node._merge_with(
2025-11-26T17:42:20.630547371Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:42:20.630555032Z     BaseContainer._map_merge(
2025-11-26T17:42:20.630558007Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:42:20.630561031Z     dest_node._merge_with(
2025-11-26T17:42:20.630563935Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:42:20.630907931Z     BaseContainer._map_merge(
2025-11-26T17:42:20.630910946Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 432, in _map_merge
2025-11-26T17:42:20.630913149Z     dest[key] = src._get_node(key)
2025-11-26T17:42:20.630915112Z     ~~~~^^^^^
2025-11-26T17:42:20.630917285Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 308, in __setitem__
2025-11-26T17:42:20.630919308Z     self._format_and_raise(
2025-11-26T17:42:20.630921261Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:42:20.630923304Z     format_and_raise(
2025-11-26T17:42:20.630925297Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:42:20.631564695Z     _raise(ex, cause)
2025-11-26T17:42:20.631572166Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:42:20.631574389Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:42:20.631576443Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:42:20.631578856Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 306, in __setitem__
2025-11-26T17:42:20.631581420Z     self.__set_impl(key=key, value=value)
2025-11-26T17:42:20.631583413Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 316, in __set_impl
2025-11-26T17:42:20.631585406Z     self._set_item_impl(key, value)
2025-11-26T17:42:20.631587419Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 579, in _set_item_impl
2025-11-26T17:42:20.631589442Z     target_node_ref = self._get_node(key)
2025-11-26T17:42:20.631838395Z                       ^^^^^^^^^^^^^^^^^^^
2025-11-26T17:42:20.631840889Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 473, in _get_node
2025-11-26T17:42:20.631843172Z     self._validate_get(key)
2025-11-26T17:42:20.631845225Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 163, in _validate_get
2025-11-26T17:42:20.631847268Z     self._format_and_raise(
2025-11-26T17:42:20.631849281Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:42:20.632209932Z     format_and_raise(
2025-11-26T17:42:20.632213928Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 906, in format_and_raise
2025-11-26T17:42:20.632216001Z     _raise(ex, cause)
2025-11-26T17:42:20.632218003Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:42:20.632220036Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:42:20.632588719Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:42:20.632591983Z omegaconf.errors.ConfigKeyError: Key 'max_new_tokens' not in 'NormConfig'
2025-11-26T17:42:20.632594397Z     full_key: actor.adv_norm.max_new_tokens
2025-11-26T17:42:20.632596420Z     reference_type=Optional[NormConfig]
2025-11-26T17:42:20.632598463Z     object_type=NormConfig
2025-11-26T17:42:23.115298761Z E1126 17:42:23.114000 966 torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 0 (pid: 1032) of binary: /usr/bin/python3
2025-11-26T17:42:23.115904799Z Traceback (most recent call last):
2025-11-26T17:42:23.115908484Z   File "/usr/local/bin/torchrun", line 7, in <module>
2025-11-26T17:42:23.115911038Z     sys.exit(main())
2025-11-26T17:42:23.115913823Z              ^^^^^^
2025-11-26T17:42:23.115915906Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
2025-11-26T17:42:23.115918770Z     return f(*args, **kwargs)
2025-11-26T17:42:23.115921444Z            ^^^^^^^^^^^^^^^^^^
2025-11-26T17:42:23.115923907Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 901, in main
2025-11-26T17:42:23.116307311Z     run(args)
2025-11-26T17:42:23.116312740Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 892, in run
2025-11-26T17:42:23.116316315Z     elastic_launch(
2025-11-26T17:42:23.116320200Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 143, in __call__
2025-11-26T17:42:23.116323465Z     return launch_agent(self._config, self._entrypoint, list(args))
2025-11-26T17:42:23.116326700Z            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:42:23.116329474Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 277, in launch_agent
2025-11-26T17:42:23.116837576Z     raise ChildFailedError(
2025-11-26T17:42:23.116860760Z torch.distributed.elastic.multiprocessing.errors.ChildFailedError:
2025-11-26T17:42:23.116864346Z ============================================================
2025-11-26T17:42:23.116871807Z examples/cloud_gsm8k/gsm8k_grpo_train.py FAILED
2025-11-26T17:42:23.116874350Z ------------------------------------------------------------
2025-11-26T17:42:23.116876393Z Failures:
2025-11-26T17:42:23.116878867Z   <NO_OTHER_FAILURES>
2025-11-26T17:42:23.116881721Z ------------------------------------------------------------
2025-11-26T17:42:23.116883744Z Root Cause (first observed failure):
2025-11-26T17:42:23.116885808Z [0]:
2025-11-26T17:42:23.116887841Z   time      : 2025-11-26_17:42:23
2025-11-26T17:42:23.116889914Z   host      : cef7c503fdea
2025-11-26T17:42:23.116891957Z   rank      : 0 (local_rank: 0)
2025-11-26T17:42:23.116893990Z   exitcode  : 1 (pid: 1032)
2025-11-26T17:42:23.116895953Z   error_file: <N/A>
2025-11-26T17:42:23.116897926Z   traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
2025-11-26T17:42:23.116900409Z ============================================================
2025-11-26T17:42:25.262539801Z [37m20251126-17:42:25.262 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [315][0m
2025-11-26T17:42:25.439982208Z Killed
2025-11-26T17:42:25.449588938Z [37m20251126-17:42:25.449 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [965][0m
2025-11-26T17:42:25.450601314Z Traceback (most recent call last):
2025-11-26T17:42:25.450613683Z   File "<frozen runpy>", line 198, in _run_module_as_main
2025-11-26T17:42:25.450616488Z   File "<frozen runpy>", line 88, in _run_code
2025-11-26T17:42:25.450618560Z   File "/workspace/AReaL/areal/launcher/local.py", line 405, in <module>
2025-11-26T17:42:25.450757548Z     main()
2025-11-26T17:42:25.450762375Z   File "/workspace/AReaL/areal/launcher/local.py", line 260, in main
2025-11-26T17:42:25.450854324Z     local_main(config, run_id=0)
2025-11-26T17:42:25.450858780Z   File "/workspace/AReaL/areal/launcher/local.py", line 399, in local_main
2025-11-26T17:42:25.450945489Z     raise e
2025-11-26T17:42:25.450947833Z   File "/workspace/AReaL/areal/launcher/local.py", line 375, in local_main
2025-11-26T17:42:25.451010767Z     launcher.wait(
2025-11-26T17:42:25.451013682Z   File "/workspace/AReaL/areal/launcher/local.py", line 235, in wait
2025-11-26T17:42:25.451071288Z     raise JobException(
2025-11-26T17:42:25.451074373Z areal.utils.launcher.JobException: Job gsm8k-grpo-cloud-2gpu-2000samples_trial_20251126_174139:trainer JobState.COMPLETED at node local
2025-11-26T17:42:25.656962789Z [37m20251126-17:42:25.656 Local Scheduler INFO: Waiting for 0 local running processes, pids: [0m
2025-11-26T17:42:42.511506056Z ==========
2025-11-26T17:42:42.511509000Z == CUDA ==
2025-11-26T17:42:42.511513897Z ==========
2025-11-26T17:42:42.516329971Z CUDA Version 12.9.1
2025-11-26T17:42:42.518292421Z Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
2025-11-26T17:42:42.520195031Z This container image and its contents are governed by the NVIDIA Deep Learning Container License.
2025-11-26T17:42:42.520197314Z By pulling and using the container, you accept the terms and conditions of this license:
2025-11-26T17:42:42.520199727Z https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license
2025-11-26T17:42:42.520204034Z A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
2025-11-26T17:42:42.684489224Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:42:42.842238713Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:42:43.026724882Z Branch 'feature/reasoning_model' set up to track remote branch 'feature/reasoning_model' from 'origin'.
2025-11-26T17:42:43.026767746Z Your branch is up to date with 'origin/feature/reasoning_model'.
2025-11-26T17:42:43.097007396Z Checking AReaL installation...
2025-11-26T17:42:43.156080411Z AReaL already installed. Skipping installation.
2025-11-26T17:42:43.156126390Z Cleaning up any leftover GPU processes...
2025-11-26T17:42:46.174538109Z Checking for processes holding GPU device files...
2025-11-26T17:42:48.335737086Z Found processes holding GPU devices: 1
2025-11-26T17:42:48.335768904Z 20
2025-11-26T17:42:48.335772169Z 71
2025-11-26T17:42:48.335774262Z 72
2025-11-26T17:42:48.335776355Z Killing process 1...
2025-11-26T17:42:48.335779349Z Killing process 71...
2025-11-26T17:42:48.335835674Z Killing process 72...
2025-11-26T17:42:50.338365965Z Using fuser to kill processes on GPU devices...
2025-11-26T17:42:52.390338875Z Checking GPU...
2025-11-26T17:42:52.423835780Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:42:52.423860858Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:42:52.441479108Z Set PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True for better memory management
2025-11-26T17:42:52.441497044Z Detected 2 GPU(s)
2025-11-26T17:42:52.441500049Z Checking GPU status...
2025-11-26T17:42:52.468576897Z index, name, utilization.gpu [%], memory.used [MiB], compute_mode
2025-11-26T17:42:52.470025747Z 0, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:42:52.470400228Z 1, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:42:52.516032449Z Verifying GPU accessibility...
2025-11-26T17:42:53.040570425Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:42:53.040627281Z   import pynvml  # type: ignore[import]
2025-11-26T17:42:54.144560160Z GPU accessibility verified on attempt 1
2025-11-26T17:42:54.598438996Z Starting training...
2025-11-26T17:42:57.600969788Z Using STANDARD 2000 SAMPLES 2 GPUs configuration
2025-11-26T17:42:57.601012572Z Note: GRPO only (no reasoning XML). Dataset capped at 2000 samples (~6 hours).
2025-11-26T17:42:57.601015786Z GPU count: 2 (required: 2)
2025-11-26T17:42:57.603757303Z ==========================================
2025-11-26T17:42:57.603760498Z Starting GRPO Training (Cloud)
2025-11-26T17:42:57.603763102Z ==========================================
2025-11-26T17:42:57.603765125Z Config: standard_2000samples_2GPUs
2025-11-26T17:42:57.603767178Z Config file: examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml
2025-11-26T17:42:57.603769842Z Training script: examples/cloud_gsm8k/gsm8k_grpo_train.py
2025-11-26T17:42:57.603772386Z Experiment: gsm8k-grpo-cloud-2gpu-2000samples
2025-11-26T17:42:57.603774369Z Trial: trial_20251126_174257
2025-11-26T17:42:57.603776452Z GPU: NVIDIA A100 80GB PCIe NVIDIA A100 80GB PCIe (81920 MB)
2025-11-26T17:42:57.603778445Z WandB API key: e1adc5be02...
2025-11-26T17:42:57.603780448Z ==========================================
2025-11-26T17:42:58.300947440Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:42:58.300984876Z   import pynvml  # type: ignore[import]
2025-11-26T17:43:02.412851480Z [37m20251126-17:43:02.412 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:43:02.412893042Z [37m20251126-17:43:02.412 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:43:02.413288915Z [37m20251126-17:43:02.412 name-resolve INFO: No such name resolve path: ./tmp/areal/name_resolve/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_174257[0m
2025-11-26T17:43:02.517789285Z [37m20251126-17:43:02.517 Local Scheduler INFO: LocalLauncher: experiment_name=gsm8k-grpo-cloud-2gpu-2000samples, trial_name=trial_20251126_174257, fileroot=/workspace/outputs/grpo, run_id=0, is_recover_run=False[0m
2025-11-26T17:43:02.525184992Z [37m20251126-17:43:02.524 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL CUDA_VISIBLE_DEVICES=0 stdbuf -oL python3 -m areal.launcher.sglang_server examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_174257 sglang.random_seed=1 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_174257/llm_server.log[0m
2025-11-26T17:43:03.265577702Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:43:03.265617141Z   import pynvml  # type: ignore[import]
2025-11-26T17:43:04.759098898Z [37m20251126-17:43:04.758 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:43:04.759645917Z [37m20251126-17:43:04.758 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:43:04.875269207Z [37m20251126-17:43:04.874 SGLangServer Wrapper INFO: Launch command: python3 -m sglang.launch_server --host 172.21.0.2 --port 18099 --tokenizer-path Qwen/Qwen2.5-0.5B-Instruct --tokenizer-mode auto --load-format auto --trust-remote-code --device cuda --tp-size 1 --base-gpu-id 0 --nnodes 1 --node-rank 0 --dist-init-addr localhost:18889 --model-path Qwen/Qwen2.5-0.5B-Instruct --random-seed 1 --skip-tokenizer-init --disable-radix-cache --torch-compile-max-bs 32 --triton-attention-num-kv-splits 8 --num-continuous-decode-steps 1 --attention-backend flashinfer --context-length 4096 --mem-fraction-static 0.6 --chunked-prefill-size -1 --max-prefill-tokens 32768 --schedule-policy lpm --schedule-conservativeness 1.0 --cpu-offload-gb 0 --dtype bfloat16 --kv-cache-dtype auto --dp-size 1 --ep-size 1 --max-loaded-loras 1 --max-loras-per-batch 1 --lora-backend triton --log-level warning --log-level-http warning --log-requests-level 0 --enable-metrics --decode-log-interval 1[0m
2025-11-26T17:43:05.911758784Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:43:05.911802830Z   import pynvml  # type: ignore[import]
2025-11-26T17:43:11.892661900Z INFO 11-26 17:43:11 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:43:12.578418321Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:43:13.646207111Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:43:13.646259750Z   import pynvml  # type: ignore[import]
2025-11-26T17:43:13.647606356Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:43:13.647642551Z   import pynvml  # type: ignore[import]
2025-11-26T17:43:18.934566549Z INFO 11-26 17:43:18 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:43:19.097602497Z INFO 11-26 17:43:19 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:43:19.702390007Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:43:19.929048184Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:43:19.932643029Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:43:19.933398050Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:43:19.934198678Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:43:19.968296093Z [2025-11-26 17:43:19] MOE_RUNNER_BACKEND is not initialized, using triton backend
2025-11-26T17:43:20.463278728Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:43:20.463317715Z   warnings.warn(
2025-11-26T17:43:20.463320599Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:43:20.463323063Z   warnings.warn(
2025-11-26T17:43:21.599874001Z Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
2025-11-26T17:43:21.717698098Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  8.50it/s]
2025-11-26T17:43:21.718407750Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  8.49it/s]
2025-11-26T17:43:24.187413485Z   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   4%|â–         | 1/23 [00:00<00:12,  1.79it/s]Capturing batches (bs=152 avail_mem=30.62 GB):   4%|â–         | 1/23 [00:00<00:12,  1.79it/s]Capturing batches (bs=144 avail_mem=30.60 GB):   4%|â–         | 1/23 [00:00<00:12,  1.79it/s]Capturing batches (bs=136 avail_mem=30.59 GB):   4%|â–         | 1/23 [00:00<00:12,  1.79it/s]Capturing batches (bs=136 avail_mem=30.59 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.10it/s]Capturing batches (bs=128 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.10it/s]Capturing batches (bs=120 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.10it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.10it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.36it/s]Capturing batches (bs=104 avail_mem=30.54 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.36it/s]Capturing batches (bs=96 avail_mem=30.53 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.36it/s] Capturing batches (bs=88 avail_mem=30.51 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.36it/s]Capturing batches (bs=88 avail_mem=30.51 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.67it/s]Capturing batches (bs=80 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.67it/s]Capturing batches (bs=72 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.67it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:01<00:00, 14.67it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.18it/s]Capturing batches (bs=56 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.18it/s]Capturing batches (bs=48 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.18it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.18it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.18it/s]Capturing batches (bs=32 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.18it/s]Capturing batches (bs=24 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.18it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.18it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.70it/s]Capturing batches (bs=8 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.70it/s] Capturing batches (bs=4 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.70it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.70it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.54it/s]Capturing batches (bs=1 avail_mem=30.35 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.54it/s]Capturing batches (bs=1 avail_mem=30.35 GB): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00, 14.77it/s]
2025-11-26T17:43:29.906265050Z [37m20251126-17:43:29.905 SGLangServer Wrapper INFO: SGLang server launched at: http://172.21.0.2:18099[0m
2025-11-26T17:43:30.532756588Z [37m20251126-17:43:30.532 Launcher Utils INFO: Found 1 rollout servers: 172.21.0.2:18099[0m
2025-11-26T17:43:30.532798041Z [37m20251126-17:43:30.532 Local Scheduler INFO: LLM inference server launched at: AREAL_LLM_SERVER_ADDRS=172.21.0.2:18099[0m
2025-11-26T17:43:30.535722331Z [37m20251126-17:43:30.535 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL AREAL_LLM_SERVER_ADDRS=172.21.0.2:18099 AREAL_RECOVER_RUN=0 NCCL_CUMEM_ENABLE=0 NCCL_NVLS_ENABLE=0 CUDA_VISIBLE_DEVICES=1 stdbuf -oL torchrun --nnodes 1 --nproc-per-node 1 --master-addr localhost --master-port 22779 examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_174257 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_174257/trainer.log[0m
2025-11-26T17:43:30.536552815Z [37m20251126-17:43:30.536 Local Scheduler INFO: Waiting for 2 local running processes, pids: 315 965[0m
2025-11-26T17:43:31.076774453Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:43:31.076825268Z   import pynvml  # type: ignore[import]
2025-11-26T17:43:32.296328428Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:43:32.296367297Z   import pynvml  # type: ignore[import]
2025-11-26T17:43:39.439830679Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:43:39.439867565Z   warnings.warn(
2025-11-26T17:43:39.439870979Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:43:39.439873393Z   warnings.warn(
2025-11-26T17:43:39.873566813Z Traceback (most recent call last):
2025-11-26T17:43:39.873607374Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 665, in <module>
2025-11-26T17:43:39.874281314Z     main(sys.argv[1:])
2025-11-26T17:43:39.874286672Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 102, in main
2025-11-26T17:43:39.874289496Z     config, _ = load_expr_config(args_with_overrides, GRPOConfig)
2025-11-26T17:43:39.874292020Z                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:43:39.874294053Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1282, in load_expr_config
2025-11-26T17:43:39.874296046Z     cfg = to_structured_cfg(cfg, config_cls=config_cls)
2025-11-26T17:43:39.874903135Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:43:39.874906170Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1276, in to_structured_cfg
2025-11-26T17:43:39.874908593Z     cfg = OmegaConf.merge(default_cfg, cfg)
2025-11-26T17:43:39.874910596Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:43:39.874913661Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/omegaconf.py", line 274, in merge
2025-11-26T17:43:39.874925979Z     target.merge_with(
2025-11-26T17:43:39.874929224Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 507, in merge_with
2025-11-26T17:43:39.875462823Z     self._format_and_raise(key=None, value=None, cause=e)
2025-11-26T17:43:39.875495933Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:43:39.875499268Z     format_and_raise(
2025-11-26T17:43:39.875502142Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:43:39.875504276Z     _raise(ex, cause)
2025-11-26T17:43:39.875506279Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:43:39.875508913Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:43:39.875511056Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:43:39.875514301Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 502, in merge_with
2025-11-26T17:43:39.875861812Z     self._merge_with(
2025-11-26T17:43:39.875865738Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:43:39.875878035Z     BaseContainer._map_merge(
2025-11-26T17:43:39.875880839Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:43:39.875882922Z     dest_node._merge_with(
2025-11-26T17:43:39.875884965Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:43:39.875887049Z     BaseContainer._map_merge(
2025-11-26T17:43:39.875889072Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:43:39.875891124Z     dest_node._merge_with(
2025-11-26T17:43:39.875893087Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:43:39.876224895Z     BaseContainer._map_merge(
2025-11-26T17:43:39.876231585Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 432, in _map_merge
2025-11-26T17:43:39.876234008Z     dest[key] = src._get_node(key)
2025-11-26T17:43:39.876236181Z     ~~~~^^^^^
2025-11-26T17:43:39.876238986Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 308, in __setitem__
2025-11-26T17:43:39.876241159Z     self._format_and_raise(
2025-11-26T17:43:39.876243152Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:43:39.876245766Z     format_and_raise(
2025-11-26T17:43:39.876248039Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:43:39.876819695Z     _raise(ex, cause)
2025-11-26T17:43:39.876823761Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:43:39.876826105Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:43:39.876828208Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:43:39.876830572Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 306, in __setitem__
2025-11-26T17:43:39.876832915Z     self.__set_impl(key=key, value=value)
2025-11-26T17:43:39.876835038Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 316, in __set_impl
2025-11-26T17:43:39.876837252Z     self._set_item_impl(key, value)
2025-11-26T17:43:39.876839305Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 579, in _set_item_impl
2025-11-26T17:43:39.876842129Z     target_node_ref = self._get_node(key)
2025-11-26T17:43:39.877247236Z                       ^^^^^^^^^^^^^^^^^^^
2025-11-26T17:43:39.877252835Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 473, in _get_node
2025-11-26T17:43:39.877255319Z     self._validate_get(key)
2025-11-26T17:43:39.877257792Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 163, in _validate_get
2025-11-26T17:43:39.877260046Z     self._format_and_raise(
2025-11-26T17:43:39.877262018Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:43:39.877264312Z     format_and_raise(
2025-11-26T17:43:39.877266766Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 906, in format_and_raise
2025-11-26T17:43:39.877590220Z     _raise(ex, cause)
2025-11-26T17:43:39.877594717Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:43:39.877596920Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:43:39.877602799Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:43:39.877605173Z omegaconf.errors.ConfigKeyError: Key 'max_new_tokens' not in 'NormConfig'
2025-11-26T17:43:39.877607526Z     full_key: actor.adv_norm.max_new_tokens
2025-11-26T17:43:39.877609970Z     reference_type=Optional[NormConfig]
2025-11-26T17:43:39.877612043Z     object_type=NormConfig
2025-11-26T17:43:42.482176508Z E1126 17:43:42.481000 966 torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 0 (pid: 1032) of binary: /usr/bin/python3
2025-11-26T17:43:42.482771399Z Traceback (most recent call last):
2025-11-26T17:43:42.482784519Z   File "/usr/local/bin/torchrun", line 7, in <module>
2025-11-26T17:43:42.482787173Z     sys.exit(main())
2025-11-26T17:43:42.482790198Z              ^^^^^^
2025-11-26T17:43:42.482792261Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
2025-11-26T17:43:42.482795175Z     return f(*args, **kwargs)
2025-11-26T17:43:42.482797729Z            ^^^^^^^^^^^^^^^^^^
2025-11-26T17:43:42.482799802Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 901, in main
2025-11-26T17:43:42.483321233Z     run(args)
2025-11-26T17:43:42.483326281Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 892, in run
2025-11-26T17:43:42.483329074Z     elastic_launch(
2025-11-26T17:43:42.483331839Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 143, in __call__
2025-11-26T17:43:42.483334442Z     return launch_agent(self._config, self._entrypoint, list(args))
2025-11-26T17:43:42.483336856Z            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:43:42.483338909Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 277, in launch_agent
2025-11-26T17:43:42.483340952Z     raise ChildFailedError(
2025-11-26T17:43:42.483343486Z torch.distributed.elastic.multiprocessing.errors.ChildFailedError:
2025-11-26T17:43:42.483345579Z ============================================================
2025-11-26T17:43:42.483348734Z examples/cloud_gsm8k/gsm8k_grpo_train.py FAILED
2025-11-26T17:43:42.483351308Z ------------------------------------------------------------
2025-11-26T17:43:42.483353321Z Failures:
2025-11-26T17:43:42.483355344Z   <NO_OTHER_FAILURES>
2025-11-26T17:43:42.483357347Z ------------------------------------------------------------
2025-11-26T17:43:42.483359360Z Root Cause (first observed failure):
2025-11-26T17:43:42.483361383Z [0]:
2025-11-26T17:43:42.483363506Z   time      : 2025-11-26_17:43:42
2025-11-26T17:43:42.483365539Z   host      : cef7c503fdea
2025-11-26T17:43:42.483367532Z   rank      : 0 (local_rank: 0)
2025-11-26T17:43:42.483369535Z   exitcode  : 1 (pid: 1032)
2025-11-26T17:43:42.483371538Z   error_file: <N/A>
2025-11-26T17:43:42.483373572Z   traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
2025-11-26T17:43:42.483375795Z ============================================================
2025-11-26T17:43:44.540285249Z [37m20251126-17:43:44.539 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [315][0m
2025-11-26T17:43:44.669135541Z Killed
2025-11-26T17:43:44.679681127Z [37m20251126-17:43:44.679 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [965][0m
2025-11-26T17:43:44.680679903Z Traceback (most recent call last):
2025-11-26T17:43:44.680698571Z   File "<frozen runpy>", line 198, in _run_module_as_main
2025-11-26T17:43:44.680701715Z   File "<frozen runpy>", line 88, in _run_code
2025-11-26T17:43:44.680704319Z   File "/workspace/AReaL/areal/launcher/local.py", line 405, in <module>
2025-11-26T17:43:44.680839212Z     main()
2025-11-26T17:43:44.680844240Z   File "/workspace/AReaL/areal/launcher/local.py", line 260, in main
2025-11-26T17:43:44.680924199Z     local_main(config, run_id=0)
2025-11-26T17:43:44.680927824Z   File "/workspace/AReaL/areal/launcher/local.py", line 399, in local_main
2025-11-26T17:43:44.681016417Z     raise e
2025-11-26T17:43:44.681018741Z   File "/workspace/AReaL/areal/launcher/local.py", line 375, in local_main
2025-11-26T17:43:44.681085100Z     launcher.wait(
2025-11-26T17:43:44.681087974Z   File "/workspace/AReaL/areal/launcher/local.py", line 235, in wait
2025-11-26T17:43:44.681168174Z     raise JobException(
2025-11-26T17:43:44.681173922Z areal.utils.launcher.JobException: Job gsm8k-grpo-cloud-2gpu-2000samples_trial_20251126_174257:trainer JobState.COMPLETED at node local
2025-11-26T17:43:44.917046391Z [37m20251126-17:43:44.916 Local Scheduler INFO: Waiting for 0 local running processes, pids: [0m
2025-11-26T17:44:01.115522017Z ==========
2025-11-26T17:44:01.115525162Z == CUDA ==
2025-11-26T17:44:01.115527345Z ==========
2025-11-26T17:44:01.119886775Z CUDA Version 12.9.1
2025-11-26T17:44:01.121632520Z Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
2025-11-26T17:44:01.123121791Z This container image and its contents are governed by the NVIDIA Deep Learning Container License.
2025-11-26T17:44:01.123125587Z By pulling and using the container, you accept the terms and conditions of this license:
2025-11-26T17:44:01.123128260Z https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license
2025-11-26T17:44:01.123132657Z A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
2025-11-26T17:44:01.287653229Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:44:01.444493558Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:44:01.650182695Z Branch 'feature/reasoning_model' set up to track remote branch 'feature/reasoning_model' from 'origin'.
2025-11-26T17:44:01.650227142Z Your branch is up to date with 'origin/feature/reasoning_model'.
2025-11-26T17:44:01.722632626Z Checking AReaL installation...
2025-11-26T17:44:01.781544249Z AReaL already installed. Skipping installation.
2025-11-26T17:44:01.781578139Z Cleaning up any leftover GPU processes...
2025-11-26T17:44:04.801489324Z Checking for processes holding GPU device files...
2025-11-26T17:44:06.966722304Z Found processes holding GPU devices: 1
2025-11-26T17:44:06.966759960Z 20
2025-11-26T17:44:06.966763556Z 71
2025-11-26T17:44:06.966765679Z 72
2025-11-26T17:44:06.966768133Z Killing process 1...
2025-11-26T17:44:06.966770787Z Killing process 71...
2025-11-26T17:44:06.966860752Z Killing process 72...
2025-11-26T17:44:08.969403020Z Using fuser to kill processes on GPU devices...
2025-11-26T17:44:10.990056416Z Checking GPU...
2025-11-26T17:44:11.031001478Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:44:11.031028649Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:44:11.047387492Z Set PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True for better memory management
2025-11-26T17:44:11.047401693Z Detected 2 GPU(s)
2025-11-26T17:44:11.047404808Z Checking GPU status...
2025-11-26T17:44:11.075273221Z index, name, utilization.gpu [%], memory.used [MiB], compute_mode
2025-11-26T17:44:11.076688892Z 0, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:44:11.076994580Z 1, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:44:11.124626346Z Verifying GPU accessibility...
2025-11-26T17:44:11.684441512Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:44:11.684497146Z   import pynvml  # type: ignore[import]
2025-11-26T17:44:12.809325294Z GPU accessibility verified on attempt 1
2025-11-26T17:44:13.352014346Z Starting training...
2025-11-26T17:44:16.355007340Z Using STANDARD 2000 SAMPLES 2 GPUs configuration
2025-11-26T17:44:16.355053750Z Note: GRPO only (no reasoning XML). Dataset capped at 2000 samples (~6 hours).
2025-11-26T17:44:16.355057536Z GPU count: 2 (required: 2)
2025-11-26T17:44:16.357578101Z ==========================================
2025-11-26T17:44:16.357581165Z Starting GRPO Training (Cloud)
2025-11-26T17:44:16.357583669Z ==========================================
2025-11-26T17:44:16.357586013Z Config: standard_2000samples_2GPUs
2025-11-26T17:44:16.357588016Z Config file: examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml
2025-11-26T17:44:16.357590559Z Training script: examples/cloud_gsm8k/gsm8k_grpo_train.py
2025-11-26T17:44:16.357592813Z Experiment: gsm8k-grpo-cloud-2gpu-2000samples
2025-11-26T17:44:16.357595026Z Trial: trial_20251126_174416
2025-11-26T17:44:16.357597109Z GPU: NVIDIA A100 80GB PCIe NVIDIA A100 80GB PCIe (81920 MB)
2025-11-26T17:44:16.357599343Z WandB API key: e1adc5be02...
2025-11-26T17:44:16.357601366Z ==========================================
2025-11-26T17:44:17.057797806Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:44:17.057852468Z   import pynvml  # type: ignore[import]
2025-11-26T17:44:21.116583851Z [37m20251126-17:44:21.116 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:44:21.116625624Z [37m20251126-17:44:21.116 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:44:21.116880926Z [37m20251126-17:44:21.116 name-resolve INFO: No such name resolve path: ./tmp/areal/name_resolve/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_174416[0m
2025-11-26T17:44:21.222182045Z [37m20251126-17:44:21.221 Local Scheduler INFO: LocalLauncher: experiment_name=gsm8k-grpo-cloud-2gpu-2000samples, trial_name=trial_20251126_174416, fileroot=/workspace/outputs/grpo, run_id=0, is_recover_run=False[0m
2025-11-26T17:44:21.229613005Z [37m20251126-17:44:21.229 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL CUDA_VISIBLE_DEVICES=0 stdbuf -oL python3 -m areal.launcher.sglang_server examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_174416 sglang.random_seed=1 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_174416/llm_server.log[0m
2025-11-26T17:44:21.974860717Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:44:21.974899285Z   import pynvml  # type: ignore[import]
2025-11-26T17:44:23.470063111Z [37m20251126-17:44:23.469 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:44:23.470758073Z [37m20251126-17:44:23.469 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:44:23.584991451Z [37m20251126-17:44:23.584 SGLangServer Wrapper INFO: Launch command: python3 -m sglang.launch_server --host 172.21.0.2 --port 16206 --tokenizer-path Qwen/Qwen2.5-0.5B-Instruct --tokenizer-mode auto --load-format auto --trust-remote-code --device cuda --tp-size 1 --base-gpu-id 0 --nnodes 1 --node-rank 0 --dist-init-addr localhost:19997 --model-path Qwen/Qwen2.5-0.5B-Instruct --random-seed 1 --skip-tokenizer-init --disable-radix-cache --torch-compile-max-bs 32 --triton-attention-num-kv-splits 8 --num-continuous-decode-steps 1 --attention-backend flashinfer --context-length 4096 --mem-fraction-static 0.6 --chunked-prefill-size -1 --max-prefill-tokens 32768 --schedule-policy lpm --schedule-conservativeness 1.0 --cpu-offload-gb 0 --dtype bfloat16 --kv-cache-dtype auto --dp-size 1 --ep-size 1 --max-loaded-loras 1 --max-loras-per-batch 1 --lora-backend triton --log-level warning --log-level-http warning --log-requests-level 0 --enable-metrics --decode-log-interval 1[0m
2025-11-26T17:44:24.609405990Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:44:24.609450297Z   import pynvml  # type: ignore[import]
2025-11-26T17:44:30.621698678Z INFO 11-26 17:44:30 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:44:31.327597385Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:44:32.403451126Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:44:32.403501762Z   import pynvml  # type: ignore[import]
2025-11-26T17:44:32.413172157Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:44:32.413190244Z   import pynvml  # type: ignore[import]
2025-11-26T17:44:37.816610635Z INFO 11-26 17:44:37 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:44:37.957539108Z INFO 11-26 17:44:37 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:44:38.545333950Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:44:38.758333116Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:44:38.761947489Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:44:38.762794297Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:44:38.763728196Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:44:38.797894473Z [2025-11-26 17:44:38] MOE_RUNNER_BACKEND is not initialized, using triton backend
2025-11-26T17:44:39.295178581Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:44:39.295218411Z   warnings.warn(
2025-11-26T17:44:39.295221445Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:44:39.295224029Z   warnings.warn(
2025-11-26T17:44:40.448566689Z Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
2025-11-26T17:44:40.564670157Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  8.63it/s]
2025-11-26T17:44:40.565565818Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  8.62it/s]
2025-11-26T17:44:43.066794098Z   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   4%|â–         | 1/23 [00:00<00:12,  1.80it/s]Capturing batches (bs=152 avail_mem=30.62 GB):   4%|â–         | 1/23 [00:00<00:12,  1.80it/s]Capturing batches (bs=144 avail_mem=30.60 GB):   4%|â–         | 1/23 [00:00<00:12,  1.80it/s]Capturing batches (bs=136 avail_mem=30.59 GB):   4%|â–         | 1/23 [00:00<00:12,  1.80it/s]Capturing batches (bs=136 avail_mem=30.59 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.08it/s]Capturing batches (bs=128 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.08it/s]Capturing batches (bs=120 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.08it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.08it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.32it/s]Capturing batches (bs=104 avail_mem=30.54 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.32it/s]Capturing batches (bs=96 avail_mem=30.53 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.32it/s] Capturing batches (bs=88 avail_mem=30.51 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.32it/s]Capturing batches (bs=88 avail_mem=30.51 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.65it/s]Capturing batches (bs=80 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.65it/s]Capturing batches (bs=72 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.65it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:01<00:00, 14.65it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.15it/s]Capturing batches (bs=56 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.15it/s]Capturing batches (bs=48 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.15it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.15it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.20it/s]Capturing batches (bs=32 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.20it/s]Capturing batches (bs=24 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.20it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.20it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.63it/s]Capturing batches (bs=8 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.63it/s] Capturing batches (bs=4 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.63it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.63it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.44it/s]Capturing batches (bs=1 avail_mem=30.35 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.44it/s]Capturing batches (bs=1 avail_mem=30.35 GB): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00, 14.75it/s]
2025-11-26T17:44:48.615680010Z [37m20251126-17:44:48.615 SGLangServer Wrapper INFO: SGLang server launched at: http://172.21.0.2:16206[0m
2025-11-26T17:44:49.241057565Z [37m20251126-17:44:49.240 Launcher Utils INFO: Found 1 rollout servers: 172.21.0.2:16206[0m
2025-11-26T17:44:49.241101791Z [37m20251126-17:44:49.240 Local Scheduler INFO: LLM inference server launched at: AREAL_LLM_SERVER_ADDRS=172.21.0.2:16206[0m
2025-11-26T17:44:49.246594668Z [37m20251126-17:44:49.246 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL AREAL_LLM_SERVER_ADDRS=172.21.0.2:16206 AREAL_RECOVER_RUN=0 NCCL_CUMEM_ENABLE=0 NCCL_NVLS_ENABLE=0 CUDA_VISIBLE_DEVICES=1 stdbuf -oL torchrun --nnodes 1 --nproc-per-node 1 --master-addr localhost --master-port 20138 examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_174416 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_174416/trainer.log[0m
2025-11-26T17:44:49.247341627Z [37m20251126-17:44:49.247 Local Scheduler INFO: Waiting for 2 local running processes, pids: 315 965[0m
2025-11-26T17:44:49.796029361Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:44:49.796073788Z   import pynvml  # type: ignore[import]
2025-11-26T17:44:50.997535774Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:44:50.997576185Z   import pynvml  # type: ignore[import]
2025-11-26T17:44:58.018430866Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:44:58.018476985Z   warnings.warn(
2025-11-26T17:44:58.018480962Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:44:58.018484106Z   warnings.warn(
2025-11-26T17:44:58.458848645Z Traceback (most recent call last):
2025-11-26T17:44:58.458886983Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 665, in <module>
2025-11-26T17:44:58.459517938Z     main(sys.argv[1:])
2025-11-26T17:44:58.459555475Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 102, in main
2025-11-26T17:44:58.459558589Z     config, _ = load_expr_config(args_with_overrides, GRPOConfig)
2025-11-26T17:44:58.459561223Z                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:44:58.459563306Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1282, in load_expr_config
2025-11-26T17:44:58.459565600Z     cfg = to_structured_cfg(cfg, config_cls=config_cls)
2025-11-26T17:44:58.460463505Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:44:58.460476704Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1276, in to_structured_cfg
2025-11-26T17:44:58.460480100Z     cfg = OmegaConf.merge(default_cfg, cfg)
2025-11-26T17:44:58.460482483Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:44:58.460484616Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/omegaconf.py", line 274, in merge
2025-11-26T17:44:58.460486850Z     target.merge_with(
2025-11-26T17:44:58.460489594Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 507, in merge_with
2025-11-26T17:44:58.460492188Z     self._format_and_raise(key=None, value=None, cause=e)
2025-11-26T17:44:58.460494221Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:44:58.460496264Z     format_and_raise(
2025-11-26T17:44:58.460498287Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:44:58.460500310Z     _raise(ex, cause)
2025-11-26T17:44:58.460502343Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:44:58.460970554Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:44:58.460974369Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:44:58.460977274Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 502, in merge_with
2025-11-26T17:44:58.460980018Z     self._merge_with(
2025-11-26T17:44:58.460982292Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:44:58.460984605Z     BaseContainer._map_merge(
2025-11-26T17:44:58.460987249Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:44:58.461001360Z     dest_node._merge_with(
2025-11-26T17:44:58.461003504Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:44:58.461483242Z     BaseContainer._map_merge(
2025-11-26T17:44:58.461490482Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:44:58.461492936Z     dest_node._merge_with(
2025-11-26T17:44:58.461495109Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:44:58.461497143Z     BaseContainer._map_merge(
2025-11-26T17:44:58.461499126Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 432, in _map_merge
2025-11-26T17:44:58.461501209Z     dest[key] = src._get_node(key)
2025-11-26T17:44:58.461503662Z     ~~~~^^^^^
2025-11-26T17:44:58.461506206Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 308, in __setitem__
2025-11-26T17:44:58.462275790Z     self._format_and_raise(
2025-11-26T17:44:58.462282970Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:44:58.462285334Z     format_and_raise(
2025-11-26T17:44:58.462287497Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:44:58.462289580Z     _raise(ex, cause)
2025-11-26T17:44:58.462291743Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:44:58.462293837Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:44:58.462295910Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:44:58.462298243Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 306, in __setitem__
2025-11-26T17:44:58.462300597Z     self.__set_impl(key=key, value=value)
2025-11-26T17:44:58.462302600Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 316, in __set_impl
2025-11-26T17:44:58.462304762Z     self._set_item_impl(key, value)
2025-11-26T17:44:58.462306805Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 579, in _set_item_impl
2025-11-26T17:44:58.462728837Z     target_node_ref = self._get_node(key)
2025-11-26T17:44:58.462732663Z                       ^^^^^^^^^^^^^^^^^^^
2025-11-26T17:44:58.462734897Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 473, in _get_node
2025-11-26T17:44:58.462737701Z     self._validate_get(key)
2025-11-26T17:44:58.462739854Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 163, in _validate_get
2025-11-26T17:44:58.462742168Z     self._format_and_raise(
2025-11-26T17:44:58.462744361Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:44:58.462746775Z     format_and_raise(
2025-11-26T17:44:58.462749098Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 906, in format_and_raise
2025-11-26T17:44:58.463075027Z     _raise(ex, cause)
2025-11-26T17:44:58.463078992Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:44:58.463081456Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:44:58.463503277Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:44:58.463514244Z omegaconf.errors.ConfigKeyError: Key 'max_new_tokens' not in 'NormConfig'
2025-11-26T17:44:58.463516988Z     full_key: actor.adv_norm.max_new_tokens
2025-11-26T17:44:58.463519271Z     reference_type=Optional[NormConfig]
2025-11-26T17:44:58.463521455Z     object_type=NormConfig
2025-11-26T17:45:01.006914953Z E1126 17:45:01.005000 966 torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 0 (pid: 1032) of binary: /usr/bin/python3
2025-11-26T17:45:01.007582833Z Traceback (most recent call last):
2025-11-26T17:45:01.007594861Z   File "/usr/local/bin/torchrun", line 7, in <module>
2025-11-26T17:45:01.007597104Z     sys.exit(main())
2025-11-26T17:45:01.007608171Z              ^^^^^^
2025-11-26T17:45:01.007610344Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
2025-11-26T17:45:01.007613729Z     return f(*args, **kwargs)
2025-11-26T17:45:01.007616233Z            ^^^^^^^^^^^^^^^^^^
2025-11-26T17:45:01.007618236Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 901, in main
2025-11-26T17:45:01.007993448Z     run(args)
2025-11-26T17:45:01.007996162Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 892, in run
2025-11-26T17:45:01.007998796Z     elastic_launch(
2025-11-26T17:45:01.008001110Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 143, in __call__
2025-11-26T17:45:01.008003573Z     return launch_agent(self._config, self._entrypoint, list(args))
2025-11-26T17:45:01.008494579Z            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:45:01.008500127Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 277, in launch_agent
2025-11-26T17:45:01.008503031Z     raise ChildFailedError(
2025-11-26T17:45:01.008505014Z torch.distributed.elastic.multiprocessing.errors.ChildFailedError:
2025-11-26T17:45:01.008507077Z ============================================================
2025-11-26T17:45:01.008509090Z examples/cloud_gsm8k/gsm8k_grpo_train.py FAILED
2025-11-26T17:45:01.008511124Z ------------------------------------------------------------
2025-11-26T17:45:01.008513316Z Failures:
2025-11-26T17:45:01.008516171Z   <NO_OTHER_FAILURES>
2025-11-26T17:45:01.008518204Z ------------------------------------------------------------
2025-11-26T17:45:01.008520438Z Root Cause (first observed failure):
2025-11-26T17:45:01.008522441Z [0]:
2025-11-26T17:45:01.008524533Z   time      : 2025-11-26_17:45:01
2025-11-26T17:45:01.008526576Z   host      : cef7c503fdea
2025-11-26T17:45:01.008528610Z   rank      : 0 (local_rank: 0)
2025-11-26T17:45:01.008530582Z   exitcode  : 1 (pid: 1032)
2025-11-26T17:45:01.008532585Z   error_file: <N/A>
2025-11-26T17:45:01.008534588Z   traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
2025-11-26T17:45:01.008536702Z ============================================================
2025-11-26T17:45:03.251317761Z [37m20251126-17:45:03.250 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [315][0m
2025-11-26T17:45:03.382361057Z Killed
2025-11-26T17:45:03.394078458Z [37m20251126-17:45:03.393 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [965][0m
2025-11-26T17:45:03.395302412Z Traceback (most recent call last):
2025-11-26T17:45:03.395317515Z   File "<frozen runpy>", line 198, in _run_module_as_main
2025-11-26T17:45:03.395320499Z   File "<frozen runpy>", line 88, in _run_code
2025-11-26T17:45:03.395322652Z   File "/workspace/AReaL/areal/launcher/local.py", line 405, in <module>
2025-11-26T17:45:03.395492957Z     main()
2025-11-26T17:45:03.395499577Z   File "/workspace/AReaL/areal/launcher/local.py", line 260, in main
2025-11-26T17:45:03.395609181Z     local_main(config, run_id=0)
2025-11-26T17:45:03.395613097Z   File "/workspace/AReaL/areal/launcher/local.py", line 399, in local_main
2025-11-26T17:45:03.395722470Z     raise e
2025-11-26T17:45:03.395725194Z   File "/workspace/AReaL/areal/launcher/local.py", line 375, in local_main
2025-11-26T17:45:03.395806196Z     launcher.wait(
2025-11-26T17:45:03.395808940Z   File "/workspace/AReaL/areal/launcher/local.py", line 235, in wait
2025-11-26T17:45:03.395871574Z     raise JobException(
2025-11-26T17:45:03.395874158Z areal.utils.launcher.JobException: Job gsm8k-grpo-cloud-2gpu-2000samples_trial_20251126_174416:trainer JobState.COMPLETED at node local
2025-11-26T17:45:03.604018070Z [37m20251126-17:45:03.603 Local Scheduler INFO: Waiting for 0 local running processes, pids: [0m
2025-11-26T17:45:19.434583711Z ==========
2025-11-26T17:45:19.434589450Z == CUDA ==
2025-11-26T17:45:19.434591773Z ==========
2025-11-26T17:45:19.438986225Z CUDA Version 12.9.1
2025-11-26T17:45:19.440834434Z Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
2025-11-26T17:45:19.442735382Z This container image and its contents are governed by the NVIDIA Deep Learning Container License.
2025-11-26T17:45:19.442738526Z By pulling and using the container, you accept the terms and conditions of this license:
2025-11-26T17:45:19.442741331Z https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license
2025-11-26T17:45:19.442745907Z A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
2025-11-26T17:45:19.613885863Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:45:19.773934155Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:45:19.966179925Z Branch 'feature/reasoning_model' set up to track remote branch 'feature/reasoning_model' from 'origin'.
2025-11-26T17:45:19.966222018Z Your branch is up to date with 'origin/feature/reasoning_model'.
2025-11-26T17:45:20.038417516Z Checking AReaL installation...
2025-11-26T17:45:20.096223814Z AReaL already installed. Skipping installation.
2025-11-26T17:45:20.096261940Z Cleaning up any leftover GPU processes...
2025-11-26T17:45:23.115978860Z Checking for processes holding GPU device files...
2025-11-26T17:45:25.780057388Z Found processes holding GPU devices: 1
2025-11-26T17:45:25.780102506Z 20
2025-11-26T17:45:25.780105049Z 71
2025-11-26T17:45:25.780107483Z 72
2025-11-26T17:45:25.780109616Z Killing process 1...
2025-11-26T17:45:25.780154884Z Killing process 71...
2025-11-26T17:45:25.780193332Z Killing process 72...
2025-11-26T17:45:27.783209794Z Using fuser to kill processes on GPU devices...
2025-11-26T17:45:29.810174668Z Checking GPU...
2025-11-26T17:45:29.847272646Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:45:29.847310713Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:45:29.864377968Z Set PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True for better memory management
2025-11-26T17:45:29.864412259Z Detected 2 GPU(s)
2025-11-26T17:45:29.864415214Z Checking GPU status...
2025-11-26T17:45:29.892546510Z index, name, utilization.gpu [%], memory.used [MiB], compute_mode
2025-11-26T17:45:29.894019747Z 0, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:45:29.894359676Z 1, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:45:29.945930583Z Verifying GPU accessibility...
2025-11-26T17:45:30.482961937Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:45:30.483022518Z   import pynvml  # type: ignore[import]
2025-11-26T17:45:31.604251516Z GPU accessibility verified on attempt 1
2025-11-26T17:45:32.063289034Z Starting training...
2025-11-26T17:45:35.066239270Z Using STANDARD 2000 SAMPLES 2 GPUs configuration
2025-11-26T17:45:35.066278279Z Note: GRPO only (no reasoning XML). Dataset capped at 2000 samples (~6 hours).
2025-11-26T17:45:35.066281945Z GPU count: 2 (required: 2)
2025-11-26T17:45:35.068829160Z ==========================================
2025-11-26T17:45:35.068831864Z Starting GRPO Training (Cloud)
2025-11-26T17:45:35.068834818Z ==========================================
2025-11-26T17:45:35.068837161Z Config: standard_2000samples_2GPUs
2025-11-26T17:45:35.068839285Z Config file: examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml
2025-11-26T17:45:35.068841638Z Training script: examples/cloud_gsm8k/gsm8k_grpo_train.py
2025-11-26T17:45:35.068843691Z Experiment: gsm8k-grpo-cloud-2gpu-2000samples
2025-11-26T17:45:35.068848168Z Trial: trial_20251126_174535
2025-11-26T17:45:35.068850191Z GPU: NVIDIA A100 80GB PCIe NVIDIA A100 80GB PCIe (81920 MB)
2025-11-26T17:45:35.068852204Z WandB API key: e1adc5be02...
2025-11-26T17:45:35.068854187Z ==========================================
2025-11-26T17:45:35.753542622Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:45:35.753584625Z   import pynvml  # type: ignore[import]
2025-11-26T17:45:39.713520012Z [37m20251126-17:45:39.713 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:45:39.713565400Z [37m20251126-17:45:39.713 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:45:39.713931458Z [37m20251126-17:45:39.713 name-resolve INFO: No such name resolve path: ./tmp/areal/name_resolve/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_174535[0m
2025-11-26T17:45:39.820025663Z [37m20251126-17:45:39.819 Local Scheduler INFO: LocalLauncher: experiment_name=gsm8k-grpo-cloud-2gpu-2000samples, trial_name=trial_20251126_174535, fileroot=/workspace/outputs/grpo, run_id=0, is_recover_run=False[0m
2025-11-26T17:45:39.827586439Z [37m20251126-17:45:39.827 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL CUDA_VISIBLE_DEVICES=0 stdbuf -oL python3 -m areal.launcher.sglang_server examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_174535 sglang.random_seed=1 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_174535/llm_server.log[0m
2025-11-26T17:45:40.566412565Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:45:40.566445595Z   import pynvml  # type: ignore[import]
2025-11-26T17:45:42.080253685Z [37m20251126-17:45:42.079 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:45:42.080917410Z [37m20251126-17:45:42.079 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:45:42.196713488Z [37m20251126-17:45:42.196 SGLangServer Wrapper INFO: Launch command: python3 -m sglang.launch_server --host 172.21.0.2 --port 13416 --tokenizer-path Qwen/Qwen2.5-0.5B-Instruct --tokenizer-mode auto --load-format auto --trust-remote-code --device cuda --tp-size 1 --base-gpu-id 0 --nnodes 1 --node-rank 0 --dist-init-addr localhost:29267 --model-path Qwen/Qwen2.5-0.5B-Instruct --random-seed 1 --skip-tokenizer-init --disable-radix-cache --torch-compile-max-bs 32 --triton-attention-num-kv-splits 8 --num-continuous-decode-steps 1 --attention-backend flashinfer --context-length 4096 --mem-fraction-static 0.6 --chunked-prefill-size -1 --max-prefill-tokens 32768 --schedule-policy lpm --schedule-conservativeness 1.0 --cpu-offload-gb 0 --dtype bfloat16 --kv-cache-dtype auto --dp-size 1 --ep-size 1 --max-loaded-loras 1 --max-loras-per-batch 1 --lora-backend triton --log-level warning --log-level-http warning --log-requests-level 0 --enable-metrics --decode-log-interval 1[0m
2025-11-26T17:45:43.283872222Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:45:43.283906824Z   import pynvml  # type: ignore[import]
2025-11-26T17:45:49.097597258Z INFO 11-26 17:45:49 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:45:49.992203304Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:45:50.993183273Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:45:50.993220749Z   import pynvml  # type: ignore[import]
2025-11-26T17:45:51.050173357Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:45:51.050211484Z   import pynvml  # type: ignore[import]
2025-11-26T17:45:58.232354315Z INFO 11-26 17:45:58 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:45:58.237056078Z INFO 11-26 17:45:58 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:45:58.977367369Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:45:59.193749362Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:45:59.197162243Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:45:59.197931996Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:45:59.198779857Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:45:59.231319617Z [2025-11-26 17:45:59] MOE_RUNNER_BACKEND is not initialized, using triton backend
2025-11-26T17:45:59.710177505Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:45:59.710214681Z   warnings.warn(
2025-11-26T17:45:59.710217875Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:45:59.710220169Z   warnings.warn(
2025-11-26T17:46:00.809821520Z Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
2025-11-26T17:46:00.915879461Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  9.45it/s]
2025-11-26T17:46:00.916308144Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  9.42it/s]
2025-11-26T17:46:03.354509897Z   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   4%|â–         | 1/23 [00:00<00:12,  1.82it/s]Capturing batches (bs=152 avail_mem=30.62 GB):   4%|â–         | 1/23 [00:00<00:12,  1.82it/s]Capturing batches (bs=144 avail_mem=30.60 GB):   4%|â–         | 1/23 [00:00<00:12,  1.82it/s]Capturing batches (bs=136 avail_mem=30.59 GB):   4%|â–         | 1/23 [00:00<00:12,  1.82it/s]Capturing batches (bs=136 avail_mem=30.59 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.23it/s]Capturing batches (bs=128 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.23it/s]Capturing batches (bs=120 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.23it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.23it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.55it/s]Capturing batches (bs=104 avail_mem=30.54 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.55it/s]Capturing batches (bs=96 avail_mem=30.53 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.55it/s] Capturing batches (bs=88 avail_mem=30.51 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.55it/s]Capturing batches (bs=88 avail_mem=30.51 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.96it/s]Capturing batches (bs=80 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.96it/s]Capturing batches (bs=72 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.96it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:01<00:00, 14.96it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.51it/s]Capturing batches (bs=56 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.51it/s]Capturing batches (bs=48 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.51it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.51it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.56it/s]Capturing batches (bs=32 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.56it/s]Capturing batches (bs=24 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.56it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.56it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.98it/s]Capturing batches (bs=8 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.98it/s] Capturing batches (bs=4 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.98it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.98it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.82it/s]Capturing batches (bs=1 avail_mem=30.35 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.82it/s]Capturing batches (bs=1 avail_mem=30.35 GB): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00, 15.04it/s]
2025-11-26T17:46:09.229347373Z [37m20251126-17:46:09.228 SGLangServer Wrapper INFO: SGLang server launched at: http://172.21.0.2:13416[0m
2025-11-26T17:46:09.835446181Z [37m20251126-17:46:09.834 Launcher Utils INFO: Found 1 rollout servers: 172.21.0.2:13416[0m
2025-11-26T17:46:09.835497218Z [37m20251126-17:46:09.835 Local Scheduler INFO: LLM inference server launched at: AREAL_LLM_SERVER_ADDRS=172.21.0.2:13416[0m
2025-11-26T17:46:09.842212626Z [37m20251126-17:46:09.841 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL AREAL_LLM_SERVER_ADDRS=172.21.0.2:13416 AREAL_RECOVER_RUN=0 NCCL_CUMEM_ENABLE=0 NCCL_NVLS_ENABLE=0 CUDA_VISIBLE_DEVICES=1 stdbuf -oL torchrun --nnodes 1 --nproc-per-node 1 --master-addr localhost --master-port 15317 examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_174535 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_174535/trainer.log[0m
2025-11-26T17:46:09.842918053Z [37m20251126-17:46:09.842 Local Scheduler INFO: Waiting for 2 local running processes, pids: 315 965[0m
2025-11-26T17:46:10.388883779Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:46:10.388924009Z   import pynvml  # type: ignore[import]
2025-11-26T17:46:11.934799513Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:46:11.934851101Z   import pynvml  # type: ignore[import]
2025-11-26T17:46:19.812444527Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:46:19.812488923Z   warnings.warn(
2025-11-26T17:46:19.812492279Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:46:19.812494642Z   warnings.warn(
2025-11-26T17:46:20.227719446Z Traceback (most recent call last):
2025-11-26T17:46:20.227761058Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 665, in <module>
2025-11-26T17:46:20.228266215Z     main(sys.argv[1:])
2025-11-26T17:46:20.228272334Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 102, in main
2025-11-26T17:46:20.228274648Z     config, _ = load_expr_config(args_with_overrides, GRPOConfig)
2025-11-26T17:46:20.228277292Z                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:46:20.228279395Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1282, in load_expr_config
2025-11-26T17:46:20.228281398Z     cfg = to_structured_cfg(cfg, config_cls=config_cls)
2025-11-26T17:46:20.228796770Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:46:20.228799804Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1276, in to_structured_cfg
2025-11-26T17:46:20.228802107Z     cfg = OmegaConf.merge(default_cfg, cfg)
2025-11-26T17:46:20.228804571Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:46:20.228806814Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/omegaconf.py", line 274, in merge
2025-11-26T17:46:20.228809369Z     target.merge_with(
2025-11-26T17:46:20.228811652Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 507, in merge_with
2025-11-26T17:46:20.229287945Z     self._format_and_raise(key=None, value=None, cause=e)
2025-11-26T17:46:20.229292962Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:46:20.229295256Z     format_and_raise(
2025-11-26T17:46:20.229297329Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:46:20.229299502Z     _raise(ex, cause)
2025-11-26T17:46:20.229301555Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:46:20.229303678Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:46:20.229721255Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:46:20.229723919Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 502, in merge_with
2025-11-26T17:46:20.229725991Z     self._merge_with(
2025-11-26T17:46:20.229728014Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:46:20.229730278Z     BaseContainer._map_merge(
2025-11-26T17:46:20.229732952Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:46:20.229734995Z     dest_node._merge_with(
2025-11-26T17:46:20.229750138Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:46:20.229752591Z     BaseContainer._map_merge(
2025-11-26T17:46:20.229754685Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:46:20.229756737Z     dest_node._merge_with(
2025-11-26T17:46:20.229758851Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:46:20.230501062Z     BaseContainer._map_merge(
2025-11-26T17:46:20.230507061Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 432, in _map_merge
2025-11-26T17:46:20.230509665Z     dest[key] = src._get_node(key)
2025-11-26T17:46:20.230512209Z     ~~~~^^^^^
2025-11-26T17:46:20.230514542Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 308, in __setitem__
2025-11-26T17:46:20.230516706Z     self._format_and_raise(
2025-11-26T17:46:20.230518769Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:46:20.230520782Z     format_and_raise(
2025-11-26T17:46:20.230523476Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:46:20.230525559Z     _raise(ex, cause)
2025-11-26T17:46:20.230527522Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:46:20.230530006Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:46:20.230532038Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:46:20.231147540Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 306, in __setitem__
2025-11-26T17:46:20.231152618Z     self.__set_impl(key=key, value=value)
2025-11-26T17:46:20.231155082Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 316, in __set_impl
2025-11-26T17:46:20.231157666Z     self._set_item_impl(key, value)
2025-11-26T17:46:20.231160139Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 579, in _set_item_impl
2025-11-26T17:46:20.231162843Z     target_node_ref = self._get_node(key)
2025-11-26T17:46:20.231165327Z                       ^^^^^^^^^^^^^^^^^^^
2025-11-26T17:46:20.231167991Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 473, in _get_node
2025-11-26T17:46:20.231170485Z     self._validate_get(key)
2025-11-26T17:46:20.231172858Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 163, in _validate_get
2025-11-26T17:46:20.231175623Z     self._format_and_raise(
2025-11-26T17:46:20.231178327Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:46:20.231181031Z     format_and_raise(
2025-11-26T17:46:20.231183545Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 906, in format_and_raise
2025-11-26T17:46:20.231452007Z     _raise(ex, cause)
2025-11-26T17:46:20.231455732Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:46:20.231457916Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:46:20.231830324Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:46:20.231833158Z omegaconf.errors.ConfigKeyError: Key 'max_new_tokens' not in 'NormConfig'
2025-11-26T17:46:20.231835702Z     full_key: actor.adv_norm.max_new_tokens
2025-11-26T17:46:20.231837655Z     reference_type=Optional[NormConfig]
2025-11-26T17:46:20.231839658Z     object_type=NormConfig
2025-11-26T17:46:23.405362519Z E1126 17:46:23.404000 966 torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 0 (pid: 1032) of binary: /usr/bin/python3
2025-11-26T17:46:23.405961396Z Traceback (most recent call last):
2025-11-26T17:46:23.405969417Z   File "/usr/local/bin/torchrun", line 7, in <module>
2025-11-26T17:46:23.405972061Z     sys.exit(main())
2025-11-26T17:46:23.405975647Z              ^^^^^^
2025-11-26T17:46:23.405977760Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
2025-11-26T17:46:23.405988857Z     return f(*args, **kwargs)
2025-11-26T17:46:23.405991621Z            ^^^^^^^^^^^^^^^^^^
2025-11-26T17:46:23.405993594Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 901, in main
2025-11-26T17:46:23.406461464Z     run(args)
2025-11-26T17:46:23.406499161Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 892, in run
2025-11-26T17:46:23.406502315Z     elastic_launch(
2025-11-26T17:46:23.406505580Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 143, in __call__
2025-11-26T17:46:23.406508324Z     return launch_agent(self._config, self._entrypoint, list(args))
2025-11-26T17:46:23.406510828Z            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:46:23.406513102Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 277, in launch_agent
2025-11-26T17:46:23.406515225Z     raise ChildFailedError(
2025-11-26T17:46:23.406518049Z torch.distributed.elastic.multiprocessing.errors.ChildFailedError:
2025-11-26T17:46:23.406520052Z ============================================================
2025-11-26T17:46:23.406522426Z examples/cloud_gsm8k/gsm8k_grpo_train.py FAILED
2025-11-26T17:46:23.406524989Z ------------------------------------------------------------
2025-11-26T17:46:23.406527023Z Failures:
2025-11-26T17:46:23.406529276Z   <NO_OTHER_FAILURES>
2025-11-26T17:46:23.406531359Z ------------------------------------------------------------
2025-11-26T17:46:23.406533402Z Root Cause (first observed failure):
2025-11-26T17:46:23.406535425Z [0]:
2025-11-26T17:46:23.406537729Z   time      : 2025-11-26_17:46:23
2025-11-26T17:46:23.406539792Z   host      : cef7c503fdea
2025-11-26T17:46:23.406541785Z   rank      : 0 (local_rank: 0)
2025-11-26T17:46:23.406543878Z   exitcode  : 1 (pid: 1032)
2025-11-26T17:46:23.406545881Z   error_file: <N/A>
2025-11-26T17:46:23.406547994Z   traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
2025-11-26T17:46:23.406550107Z ============================================================
2025-11-26T17:46:23.846345684Z [37m20251126-17:46:23.845 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [315][0m
2025-11-26T17:46:24.015202160Z Killed
2025-11-26T17:46:24.018220722Z [37m20251126-17:46:24.017 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [965][0m
2025-11-26T17:46:24.019164946Z Traceback (most recent call last):
2025-11-26T17:46:24.019175732Z   File "<frozen runpy>", line 198, in _run_module_as_main
2025-11-26T17:46:24.019179558Z   File "<frozen runpy>", line 88, in _run_code
2025-11-26T17:46:24.019181831Z   File "/workspace/AReaL/areal/launcher/local.py", line 405, in <module>
2025-11-26T17:46:24.019311155Z     main()
2025-11-26T17:46:24.019314279Z   File "/workspace/AReaL/areal/launcher/local.py", line 260, in main
2025-11-26T17:46:24.019394199Z     local_main(config, run_id=0)
2025-11-26T17:46:24.019397214Z   File "/workspace/AReaL/areal/launcher/local.py", line 399, in local_main
2025-11-26T17:46:24.019509091Z     raise e
2025-11-26T17:46:24.019511615Z   File "/workspace/AReaL/areal/launcher/local.py", line 375, in local_main
2025-11-26T17:46:24.019564935Z     launcher.wait(
2025-11-26T17:46:24.019567889Z   File "/workspace/AReaL/areal/launcher/local.py", line 235, in wait
2025-11-26T17:46:24.019634900Z     raise JobException(
2025-11-26T17:46:24.019637904Z areal.utils.launcher.JobException: Job gsm8k-grpo-cloud-2gpu-2000samples_trial_20251126_174535:trainer JobState.COMPLETED at node local
2025-11-26T17:46:24.303018281Z [37m20251126-17:46:24.302 Local Scheduler INFO: Waiting for 0 local running processes, pids: [0m
2025-11-26T17:46:37.696602416Z ==========
2025-11-26T17:46:37.696607775Z == CUDA ==
2025-11-26T17:46:37.696649998Z ==========
2025-11-26T17:46:37.701494013Z CUDA Version 12.9.1
2025-11-26T17:46:37.703425746Z Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
2025-11-26T17:46:37.705403259Z This container image and its contents are governed by the NVIDIA Deep Learning Container License.
2025-11-26T17:46:37.705417049Z By pulling and using the container, you accept the terms and conditions of this license:
2025-11-26T17:46:37.705420163Z https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license
2025-11-26T17:46:37.705424560Z A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
2025-11-26T17:46:37.869733324Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:46:38.026097237Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:46:38.256039141Z Branch 'feature/reasoning_model' set up to track remote branch 'feature/reasoning_model' from 'origin'.
2025-11-26T17:46:38.256079371Z Your branch is up to date with 'origin/feature/reasoning_model'.
2025-11-26T17:46:38.330318872Z Checking AReaL installation...
2025-11-26T17:46:38.389299758Z AReaL already installed. Skipping installation.
2025-11-26T17:46:38.389334319Z Cleaning up any leftover GPU processes...
2025-11-26T17:46:41.409367253Z Checking for processes holding GPU device files...
2025-11-26T17:46:43.887324515Z Found processes holding GPU devices: 1
2025-11-26T17:46:43.887357594Z 20
2025-11-26T17:46:43.887360048Z 71
2025-11-26T17:46:43.887362622Z 72
2025-11-26T17:46:43.887364725Z Killing process 1...
2025-11-26T17:46:43.887371255Z Killing process 71...
2025-11-26T17:46:43.887556163Z Killing process 72...
2025-11-26T17:46:45.890166175Z Using fuser to kill processes on GPU devices...
2025-11-26T17:46:47.917049267Z Checking GPU...
2025-11-26T17:46:47.951718277Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:46:47.951744746Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:46:47.968043410Z Set PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True for better memory management
2025-11-26T17:46:47.968061126Z Detected 2 GPU(s)
2025-11-26T17:46:47.968064331Z Checking GPU status...
2025-11-26T17:46:47.996763809Z index, name, utilization.gpu [%], memory.used [MiB], compute_mode
2025-11-26T17:46:47.998324206Z 0, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:46:47.998774751Z 1, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:46:48.043320445Z Verifying GPU accessibility...
2025-11-26T17:46:48.580544107Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:46:48.580599720Z   import pynvml  # type: ignore[import]
2025-11-26T17:46:49.688001797Z GPU accessibility verified on attempt 1
2025-11-26T17:46:50.157626275Z Starting training...
2025-11-26T17:46:53.160571782Z Using STANDARD 2000 SAMPLES 2 GPUs configuration
2025-11-26T17:46:53.160608027Z Note: GRPO only (no reasoning XML). Dataset capped at 2000 samples (~6 hours).
2025-11-26T17:46:53.160611352Z GPU count: 2 (required: 2)
2025-11-26T17:46:53.163188252Z ==========================================
2025-11-26T17:46:53.163191266Z Starting GRPO Training (Cloud)
2025-11-26T17:46:53.163194100Z ==========================================
2025-11-26T17:46:53.163196103Z Config: standard_2000samples_2GPUs
2025-11-26T17:46:53.163198167Z Config file: examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml
2025-11-26T17:46:53.163200840Z Training script: examples/cloud_gsm8k/gsm8k_grpo_train.py
2025-11-26T17:46:53.163203014Z Experiment: gsm8k-grpo-cloud-2gpu-2000samples
2025-11-26T17:46:53.163205087Z Trial: trial_20251126_174653
2025-11-26T17:46:53.163207110Z GPU: NVIDIA A100 80GB PCIe NVIDIA A100 80GB PCIe (81920 MB)
2025-11-26T17:46:53.163209133Z WandB API key: e1adc5be02...
2025-11-26T17:46:53.163211146Z ==========================================
2025-11-26T17:46:53.871645470Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:46:53.871683937Z   import pynvml  # type: ignore[import]
2025-11-26T17:46:57.792202813Z [37m20251126-17:46:57.791 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:46:57.792246859Z [37m20251126-17:46:57.791 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:46:57.792502381Z [37m20251126-17:46:57.792 name-resolve INFO: No such name resolve path: ./tmp/areal/name_resolve/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_174653[0m
2025-11-26T17:46:57.898190118Z [37m20251126-17:46:57.897 Local Scheduler INFO: LocalLauncher: experiment_name=gsm8k-grpo-cloud-2gpu-2000samples, trial_name=trial_20251126_174653, fileroot=/workspace/outputs/grpo, run_id=0, is_recover_run=False[0m
2025-11-26T17:46:57.906863940Z [37m20251126-17:46:57.906 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL CUDA_VISIBLE_DEVICES=0 stdbuf -oL python3 -m areal.launcher.sglang_server examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_174653 sglang.random_seed=1 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_174653/llm_server.log[0m
2025-11-26T17:46:58.611376070Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:46:58.611415348Z   import pynvml  # type: ignore[import]
2025-11-26T17:47:00.080846758Z [37m20251126-17:47:00.080 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:47:00.081635160Z [37m20251126-17:47:00.080 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:47:00.182956736Z [37m20251126-17:47:00.182 SGLangServer Wrapper INFO: Launch command: python3 -m sglang.launch_server --host 172.21.0.2 --port 20644 --tokenizer-path Qwen/Qwen2.5-0.5B-Instruct --tokenizer-mode auto --load-format auto --trust-remote-code --device cuda --tp-size 1 --base-gpu-id 0 --nnodes 1 --node-rank 0 --dist-init-addr localhost:21267 --model-path Qwen/Qwen2.5-0.5B-Instruct --random-seed 1 --skip-tokenizer-init --disable-radix-cache --torch-compile-max-bs 32 --triton-attention-num-kv-splits 8 --num-continuous-decode-steps 1 --attention-backend flashinfer --context-length 4096 --mem-fraction-static 0.6 --chunked-prefill-size -1 --max-prefill-tokens 32768 --schedule-policy lpm --schedule-conservativeness 1.0 --cpu-offload-gb 0 --dtype bfloat16 --kv-cache-dtype auto --dp-size 1 --ep-size 1 --max-loaded-loras 1 --max-loras-per-batch 1 --lora-backend triton --log-level warning --log-level-http warning --log-requests-level 0 --enable-metrics --decode-log-interval 1[0m
2025-11-26T17:47:01.248605672Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:47:01.248652131Z   import pynvml  # type: ignore[import]
2025-11-26T17:47:06.813510347Z INFO 11-26 17:47:06 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:47:07.459594708Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:47:08.488986324Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:47:08.489022028Z   import pynvml  # type: ignore[import]
2025-11-26T17:47:08.527969457Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:47:08.528007204Z   import pynvml  # type: ignore[import]
2025-11-26T17:47:13.686076340Z INFO 11-26 17:47:13 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:47:14.187877705Z INFO 11-26 17:47:14 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:47:14.309411877Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:47:14.543417338Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:47:14.546781346Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:47:14.548673631Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:47:14.549665166Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:47:14.586966239Z [2025-11-26 17:47:14] MOE_RUNNER_BACKEND is not initialized, using triton backend
2025-11-26T17:47:15.109409682Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:47:15.109452195Z   warnings.warn(
2025-11-26T17:47:15.109455640Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:47:15.109458195Z   warnings.warn(
2025-11-26T17:47:16.440460055Z Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
2025-11-26T17:47:16.555075373Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  8.74it/s]
2025-11-26T17:47:16.555567882Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  8.72it/s]
2025-11-26T17:47:19.069000812Z   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   4%|â–         | 1/23 [00:00<00:11,  1.85it/s]Capturing batches (bs=152 avail_mem=30.62 GB):   4%|â–         | 1/23 [00:00<00:11,  1.85it/s]Capturing batches (bs=144 avail_mem=30.60 GB):   4%|â–         | 1/23 [00:00<00:11,  1.85it/s]Capturing batches (bs=136 avail_mem=30.59 GB):   4%|â–         | 1/23 [00:00<00:11,  1.85it/s]Capturing batches (bs=136 avail_mem=30.59 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.26it/s]Capturing batches (bs=128 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.26it/s]Capturing batches (bs=120 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.26it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.26it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.55it/s]Capturing batches (bs=104 avail_mem=30.54 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.55it/s]Capturing batches (bs=96 avail_mem=30.53 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.55it/s] Capturing batches (bs=88 avail_mem=30.51 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.55it/s]Capturing batches (bs=88 avail_mem=30.51 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.88it/s]Capturing batches (bs=80 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.88it/s]Capturing batches (bs=72 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.88it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:01<00:00, 14.88it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.36it/s]Capturing batches (bs=56 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.36it/s]Capturing batches (bs=48 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.36it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.36it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.27it/s]Capturing batches (bs=32 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.27it/s]Capturing batches (bs=24 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.27it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.27it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.72it/s]Capturing batches (bs=8 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.72it/s] Capturing batches (bs=4 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.72it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.72it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.53it/s]Capturing batches (bs=1 avail_mem=30.35 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.53it/s]Capturing batches (bs=1 avail_mem=30.35 GB): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00, 14.94it/s]
2025-11-26T17:47:25.209844440Z [37m20251126-17:47:25.209 SGLangServer Wrapper INFO: SGLang server launched at: http://172.21.0.2:20644[0m
2025-11-26T17:47:25.913779354Z [37m20251126-17:47:25.913 Launcher Utils INFO: Found 1 rollout servers: 172.21.0.2:20644[0m
2025-11-26T17:47:25.913804652Z [37m20251126-17:47:25.913 Local Scheduler INFO: LLM inference server launched at: AREAL_LLM_SERVER_ADDRS=172.21.0.2:20644[0m
2025-11-26T17:47:25.916378807Z [37m20251126-17:47:25.916 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL AREAL_LLM_SERVER_ADDRS=172.21.0.2:20644 AREAL_RECOVER_RUN=0 NCCL_CUMEM_ENABLE=0 NCCL_NVLS_ENABLE=0 CUDA_VISIBLE_DEVICES=1 stdbuf -oL torchrun --nnodes 1 --nproc-per-node 1 --master-addr localhost --master-port 31916 examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_174653 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_174653/trainer.log[0m
2025-11-26T17:47:25.917026678Z [37m20251126-17:47:25.916 Local Scheduler INFO: Waiting for 2 local running processes, pids: 315 965[0m
2025-11-26T17:47:26.456758497Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:47:26.456807320Z   import pynvml  # type: ignore[import]
2025-11-26T17:47:27.661968748Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:47:27.662022850Z   import pynvml  # type: ignore[import]
2025-11-26T17:47:34.651306722Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:47:34.651349415Z   warnings.warn(
2025-11-26T17:47:34.651352730Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:47:34.651355434Z   warnings.warn(
2025-11-26T17:47:35.182415635Z Traceback (most recent call last):
2025-11-26T17:47:35.182456516Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 665, in <module>
2025-11-26T17:47:35.182993150Z     main(sys.argv[1:])
2025-11-26T17:47:35.182996495Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 102, in main
2025-11-26T17:47:35.182999189Z     config, _ = load_expr_config(args_with_overrides, GRPOConfig)
2025-11-26T17:47:35.183429073Z                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:47:35.183434410Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1282, in load_expr_config
2025-11-26T17:47:35.183436884Z     cfg = to_structured_cfg(cfg, config_cls=config_cls)
2025-11-26T17:47:35.183849884Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:47:35.183852577Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1276, in to_structured_cfg
2025-11-26T17:47:35.183854660Z     cfg = OmegaConf.merge(default_cfg, cfg)
2025-11-26T17:47:35.184292546Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:47:35.184296942Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/omegaconf.py", line 274, in merge
2025-11-26T17:47:35.184299416Z     target.merge_with(
2025-11-26T17:47:35.184302181Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 507, in merge_with
2025-11-26T17:47:35.184305014Z     self._format_and_raise(key=None, value=None, cause=e)
2025-11-26T17:47:35.184773436Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:47:35.184776560Z     format_and_raise(
2025-11-26T17:47:35.184778614Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:47:35.184780687Z     _raise(ex, cause)
2025-11-26T17:47:35.184782850Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:47:35.184785264Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:47:35.185396729Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:47:35.185403219Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 502, in merge_with
2025-11-26T17:47:35.185405803Z     self._merge_with(
2025-11-26T17:47:35.185407906Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:47:35.185409949Z     BaseContainer._map_merge(
2025-11-26T17:47:35.185412733Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:47:35.185415067Z     dest_node._merge_with(
2025-11-26T17:47:35.185417110Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:47:35.185758051Z     BaseContainer._map_merge(
2025-11-26T17:47:35.185786163Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:47:35.185789298Z     dest_node._merge_with(
2025-11-26T17:47:35.185791471Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:47:35.186051120Z     BaseContainer._map_merge(
2025-11-26T17:47:35.186057379Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 432, in _map_merge
2025-11-26T17:47:35.186060624Z     dest[key] = src._get_node(key)
2025-11-26T17:47:35.186063519Z     ~~~~^^^^^
2025-11-26T17:47:35.186066633Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 308, in __setitem__
2025-11-26T17:47:35.186890017Z     self._format_and_raise(
2025-11-26T17:47:35.186912851Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:47:35.186915645Z     format_and_raise(
2025-11-26T17:47:35.186919030Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:47:35.186921864Z     _raise(ex, cause)
2025-11-26T17:47:35.186924057Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:47:35.186926721Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:47:35.186929165Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:47:35.186932250Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 306, in __setitem__
2025-11-26T17:47:35.187236365Z     self.__set_impl(key=key, value=value)
2025-11-26T17:47:35.187244818Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 316, in __set_impl
2025-11-26T17:47:35.187247372Z     self._set_item_impl(key, value)
2025-11-26T17:47:35.187249505Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 579, in _set_item_impl
2025-11-26T17:47:35.187251648Z     target_node_ref = self._get_node(key)
2025-11-26T17:47:35.187629104Z                       ^^^^^^^^^^^^^^^^^^^
2025-11-26T17:47:35.187631949Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 473, in _get_node
2025-11-26T17:47:35.187634212Z     self._validate_get(key)
2025-11-26T17:47:35.187637086Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 163, in _validate_get
2025-11-26T17:47:35.187639159Z     self._format_and_raise(
2025-11-26T17:47:35.187954401Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:47:35.187957386Z     format_and_raise(
2025-11-26T17:47:35.187959749Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 906, in format_and_raise
2025-11-26T17:47:35.187961913Z     _raise(ex, cause)
2025-11-26T17:47:35.187964006Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:47:35.188273680Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:47:35.188566288Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:47:35.188568731Z omegaconf.errors.ConfigKeyError: Key 'max_new_tokens' not in 'NormConfig'
2025-11-26T17:47:35.188571024Z     full_key: actor.adv_norm.max_new_tokens
2025-11-26T17:47:35.188573258Z     reference_type=Optional[NormConfig]
2025-11-26T17:47:35.188575411Z     object_type=NormConfig
2025-11-26T17:47:38.276835941Z E1126 17:47:38.275000 966 torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 0 (pid: 1032) of binary: /usr/bin/python3
2025-11-26T17:47:38.277499183Z Traceback (most recent call last):
2025-11-26T17:47:38.277509329Z   File "/usr/local/bin/torchrun", line 7, in <module>
2025-11-26T17:47:38.277512353Z     sys.exit(main())
2025-11-26T17:47:38.277515718Z              ^^^^^^
2025-11-26T17:47:38.277517911Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
2025-11-26T17:47:38.278042968Z     return f(*args, **kwargs)
2025-11-26T17:47:38.278046383Z            ^^^^^^^^^^^^^^^^^^
2025-11-26T17:47:38.278056628Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 901, in main
2025-11-26T17:47:38.278059132Z     run(args)
2025-11-26T17:47:38.278061926Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 892, in run
2025-11-26T17:47:38.278064120Z     elastic_launch(
2025-11-26T17:47:38.278066703Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 143, in __call__
2025-11-26T17:47:38.278069588Z     return launch_agent(self._config, self._entrypoint, list(args))
2025-11-26T17:47:38.278071931Z            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:47:38.278074124Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 277, in launch_agent
2025-11-26T17:47:38.278554725Z     raise ChildFailedError(
2025-11-26T17:47:38.278593683Z torch.distributed.elastic.multiprocessing.errors.ChildFailedError:
2025-11-26T17:47:38.278597379Z ============================================================
2025-11-26T17:47:38.278600033Z examples/cloud_gsm8k/gsm8k_grpo_train.py FAILED
2025-11-26T17:47:38.278603308Z ------------------------------------------------------------
2025-11-26T17:47:38.278605421Z Failures:
2025-11-26T17:47:38.278608165Z   <NO_OTHER_FAILURES>
2025-11-26T17:47:38.278611100Z ------------------------------------------------------------
2025-11-26T17:47:38.278613323Z Root Cause (first observed failure):
2025-11-26T17:47:38.278615376Z [0]:
2025-11-26T17:47:38.278617689Z   time      : 2025-11-26_17:47:38
2025-11-26T17:47:38.278619812Z   host      : cef7c503fdea
2025-11-26T17:47:38.278621835Z   rank      : 0 (local_rank: 0)
2025-11-26T17:47:38.278623878Z   exitcode  : 1 (pid: 1032)
2025-11-26T17:47:38.278625901Z   error_file: <N/A>
2025-11-26T17:47:38.278627914Z   traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
2025-11-26T17:47:38.278630588Z ============================================================
2025-11-26T17:47:39.920690734Z [37m20251126-17:47:39.920 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [315][0m
2025-11-26T17:47:40.101057611Z Killed
2025-11-26T17:47:40.110235257Z [37m20251126-17:47:40.109 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [965][0m
2025-11-26T17:47:40.111225821Z Traceback (most recent call last):
2025-11-26T17:47:40.111237769Z   File "<frozen runpy>", line 198, in _run_module_as_main
2025-11-26T17:47:40.111240303Z   File "<frozen runpy>", line 88, in _run_code
2025-11-26T17:47:40.111242276Z   File "/workspace/AReaL/areal/launcher/local.py", line 405, in <module>
2025-11-26T17:47:40.111326562Z     main()
2025-11-26T17:47:40.111336548Z   File "/workspace/AReaL/areal/launcher/local.py", line 260, in main
2025-11-26T17:47:40.111432771Z     local_main(config, run_id=0)
2025-11-26T17:47:40.111435665Z   File "/workspace/AReaL/areal/launcher/local.py", line 399, in local_main
2025-11-26T17:47:40.111529867Z     raise e
2025-11-26T17:47:40.111532490Z   File "/workspace/AReaL/areal/launcher/local.py", line 375, in local_main
2025-11-26T17:47:40.111597708Z     launcher.wait(
2025-11-26T17:47:40.111600543Z   File "/workspace/AReaL/areal/launcher/local.py", line 235, in wait
2025-11-26T17:47:40.111652390Z     raise JobException(
2025-11-26T17:47:40.111655165Z areal.utils.launcher.JobException: Job gsm8k-grpo-cloud-2gpu-2000samples_trial_20251126_174653:trainer JobState.COMPLETED at node local
2025-11-26T17:47:40.289410349Z [37m20251126-17:47:40.288 Local Scheduler INFO: Waiting for 0 local running processes, pids: [0m
2025-11-26T17:47:56.019283386Z ==========
2025-11-26T17:47:56.019288163Z == CUDA ==
2025-11-26T17:47:56.019320532Z ==========
2025-11-26T17:47:56.024083536Z CUDA Version 12.9.1
2025-11-26T17:47:56.025700008Z Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
2025-11-26T17:47:56.027521986Z This container image and its contents are governed by the NVIDIA Deep Learning Container License.
2025-11-26T17:47:56.027524991Z By pulling and using the container, you accept the terms and conditions of this license:
2025-11-26T17:47:56.027544350Z https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license
2025-11-26T17:47:56.027548837Z A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
2025-11-26T17:47:56.192327424Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:47:56.351314156Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:47:56.618159866Z Branch 'feature/reasoning_model' set up to track remote branch 'feature/reasoning_model' from 'origin'.
2025-11-26T17:47:56.618194017Z Your branch is up to date with 'origin/feature/reasoning_model'.
2025-11-26T17:47:56.696816243Z Checking AReaL installation...
2025-11-26T17:47:56.760783358Z AReaL already installed. Skipping installation.
2025-11-26T17:47:56.760815887Z Cleaning up any leftover GPU processes...
2025-11-26T17:47:59.781872222Z Checking for processes holding GPU device files...
2025-11-26T17:48:01.914855379Z Found processes holding GPU devices: 1
2025-11-26T17:48:01.914890311Z 20
2025-11-26T17:48:01.914893135Z 71
2025-11-26T17:48:01.914895269Z 72
2025-11-26T17:48:01.914897321Z Killing process 1...
2025-11-26T17:48:01.914900275Z Killing process 71...
2025-11-26T17:48:01.915006645Z Killing process 72...
2025-11-26T17:48:03.917538071Z Using fuser to kill processes on GPU devices...
2025-11-26T17:48:05.940548281Z Checking GPU...
2025-11-26T17:48:05.975069880Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:48:05.975096289Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:48:05.992166198Z Set PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True for better memory management
2025-11-26T17:48:05.992182072Z Detected 2 GPU(s)
2025-11-26T17:48:05.992185227Z Checking GPU status...
2025-11-26T17:48:06.020257766Z index, name, utilization.gpu [%], memory.used [MiB], compute_mode
2025-11-26T17:48:06.021672044Z 0, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:48:06.021992715Z 1, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:48:06.065711219Z Verifying GPU accessibility...
2025-11-26T17:48:06.610374024Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:48:06.610430409Z   import pynvml  # type: ignore[import]
2025-11-26T17:48:07.743690266Z GPU accessibility verified on attempt 1
2025-11-26T17:48:08.276605616Z Starting training...
2025-11-26T17:48:11.279554098Z Using STANDARD 2000 SAMPLES 2 GPUs configuration
2025-11-26T17:48:11.279594599Z Note: GRPO only (no reasoning XML). Dataset capped at 2000 samples (~6 hours).
2025-11-26T17:48:11.279597743Z GPU count: 2 (required: 2)
2025-11-26T17:48:11.282133492Z ==========================================
2025-11-26T17:48:11.282137117Z Starting GRPO Training (Cloud)
2025-11-26T17:48:11.282139550Z ==========================================
2025-11-26T17:48:11.282141744Z Config: standard_2000samples_2GPUs
2025-11-26T17:48:11.282143827Z Config file: examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml
2025-11-26T17:48:11.282146752Z Training script: examples/cloud_gsm8k/gsm8k_grpo_train.py
2025-11-26T17:48:11.282149215Z Experiment: gsm8k-grpo-cloud-2gpu-2000samples
2025-11-26T17:48:11.282151208Z Trial: trial_20251126_174811
2025-11-26T17:48:11.282153311Z GPU: NVIDIA A100 80GB PCIe NVIDIA A100 80GB PCIe (81920 MB)
2025-11-26T17:48:11.282191789Z WandB API key: e1adc5be02...
2025-11-26T17:48:11.282212660Z ==========================================
2025-11-26T17:48:12.002438696Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:48:12.002479357Z   import pynvml  # type: ignore[import]
2025-11-26T17:48:16.061923836Z [37m20251126-17:48:16.061 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:48:16.061980320Z [37m20251126-17:48:16.061 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:48:16.062394400Z [37m20251126-17:48:16.061 name-resolve INFO: No such name resolve path: ./tmp/areal/name_resolve/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_174811[0m
2025-11-26T17:48:16.168296769Z [37m20251126-17:48:16.167 Local Scheduler INFO: LocalLauncher: experiment_name=gsm8k-grpo-cloud-2gpu-2000samples, trial_name=trial_20251126_174811, fileroot=/workspace/outputs/grpo, run_id=0, is_recover_run=False[0m
2025-11-26T17:48:16.176151494Z [37m20251126-17:48:16.175 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL CUDA_VISIBLE_DEVICES=0 stdbuf -oL python3 -m areal.launcher.sglang_server examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_174811 sglang.random_seed=1 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_174811/llm_server.log[0m
2025-11-26T17:48:16.936294371Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:48:16.936354681Z   import pynvml  # type: ignore[import]
2025-11-26T17:48:18.433479473Z [37m20251126-17:48:18.432 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:48:18.434341905Z [37m20251126-17:48:18.433 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:48:18.548250815Z [37m20251126-17:48:18.547 SGLangServer Wrapper INFO: Launch command: python3 -m sglang.launch_server --host 172.21.0.2 --port 16992 --tokenizer-path Qwen/Qwen2.5-0.5B-Instruct --tokenizer-mode auto --load-format auto --trust-remote-code --device cuda --tp-size 1 --base-gpu-id 0 --nnodes 1 --node-rank 0 --dist-init-addr localhost:23210 --model-path Qwen/Qwen2.5-0.5B-Instruct --random-seed 1 --skip-tokenizer-init --disable-radix-cache --torch-compile-max-bs 32 --triton-attention-num-kv-splits 8 --num-continuous-decode-steps 1 --attention-backend flashinfer --context-length 4096 --mem-fraction-static 0.6 --chunked-prefill-size -1 --max-prefill-tokens 32768 --schedule-policy lpm --schedule-conservativeness 1.0 --cpu-offload-gb 0 --dtype bfloat16 --kv-cache-dtype auto --dp-size 1 --ep-size 1 --max-loaded-loras 1 --max-loras-per-batch 1 --lora-backend triton --log-level warning --log-level-http warning --log-requests-level 0 --enable-metrics --decode-log-interval 1[0m
2025-11-26T17:48:19.611159246Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:48:19.611207849Z   import pynvml  # type: ignore[import]
2025-11-26T17:48:24.911238847Z INFO 11-26 17:48:24 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:48:25.592890393Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:48:26.622851053Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:48:26.622894307Z   import pynvml  # type: ignore[import]
2025-11-26T17:48:26.630009215Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:48:26.630039991Z   import pynvml  # type: ignore[import]
2025-11-26T17:48:31.866905895Z INFO 11-26 17:48:31 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:48:32.233492185Z INFO 11-26 17:48:32 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:48:32.451551660Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:48:32.689366115Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:48:32.692775052Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:48:32.693586697Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:48:32.694388268Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:48:32.726734169Z [2025-11-26 17:48:32] MOE_RUNNER_BACKEND is not initialized, using triton backend
2025-11-26T17:48:33.211188619Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:48:33.211227307Z   warnings.warn(
2025-11-26T17:48:33.211230672Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:48:33.211233065Z   warnings.warn(
2025-11-26T17:48:34.302053505Z Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
2025-11-26T17:48:34.407195695Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  9.53it/s]
2025-11-26T17:48:34.407544747Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  9.51it/s]
2025-11-26T17:48:36.824720157Z   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   4%|â–         | 1/23 [00:00<00:11,  1.90it/s]Capturing batches (bs=152 avail_mem=30.62 GB):   4%|â–         | 1/23 [00:00<00:11,  1.90it/s]Capturing batches (bs=144 avail_mem=30.60 GB):   4%|â–         | 1/23 [00:00<00:11,  1.90it/s]Capturing batches (bs=136 avail_mem=30.59 GB):   4%|â–         | 1/23 [00:00<00:11,  1.90it/s]Capturing batches (bs=136 avail_mem=30.59 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.44it/s]Capturing batches (bs=128 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.44it/s]Capturing batches (bs=120 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.44it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.44it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.81it/s]Capturing batches (bs=104 avail_mem=30.54 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.81it/s]Capturing batches (bs=96 avail_mem=30.53 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.81it/s] Capturing batches (bs=88 avail_mem=30.51 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.81it/s]Capturing batches (bs=88 avail_mem=30.51 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 15.15it/s]Capturing batches (bs=80 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 15.15it/s]Capturing batches (bs=72 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 15.15it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 15.15it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.56it/s]Capturing batches (bs=56 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.56it/s]Capturing batches (bs=48 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.56it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.56it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.53it/s]Capturing batches (bs=32 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.53it/s]Capturing batches (bs=24 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.53it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.53it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.96it/s]Capturing batches (bs=8 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.96it/s] Capturing batches (bs=4 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.96it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.96it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.82it/s]Capturing batches (bs=1 avail_mem=30.35 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.82it/s]Capturing batches (bs=1 avail_mem=30.35 GB): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00, 15.20it/s]
2025-11-26T17:48:42.577188137Z [37m20251126-17:48:42.576 SGLangServer Wrapper INFO: SGLang server launched at: http://172.21.0.2:16992[0m
2025-11-26T17:48:43.183477611Z [37m20251126-17:48:43.183 Launcher Utils INFO: Found 1 rollout servers: 172.21.0.2:16992[0m
2025-11-26T17:48:43.183517241Z [37m20251126-17:48:43.183 Local Scheduler INFO: LLM inference server launched at: AREAL_LLM_SERVER_ADDRS=172.21.0.2:16992[0m
2025-11-26T17:48:43.186187260Z [37m20251126-17:48:43.185 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL AREAL_LLM_SERVER_ADDRS=172.21.0.2:16992 AREAL_RECOVER_RUN=0 NCCL_CUMEM_ENABLE=0 NCCL_NVLS_ENABLE=0 CUDA_VISIBLE_DEVICES=1 stdbuf -oL torchrun --nnodes 1 --nproc-per-node 1 --master-addr localhost --master-port 38740 examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_174811 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_174811/trainer.log[0m
2025-11-26T17:48:43.186805495Z [37m20251126-17:48:43.186 Local Scheduler INFO: Waiting for 2 local running processes, pids: 315 965[0m
2025-11-26T17:48:43.909488993Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:48:43.909526159Z   import pynvml  # type: ignore[import]
2025-11-26T17:48:45.133191292Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:48:45.133241458Z   import pynvml  # type: ignore[import]
2025-11-26T17:48:52.390855164Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:48:52.390901093Z   warnings.warn(
2025-11-26T17:48:52.390904278Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:48:52.390906621Z   warnings.warn(
2025-11-26T17:48:52.826811230Z Traceback (most recent call last):
2025-11-26T17:48:52.826853053Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 665, in <module>
2025-11-26T17:48:52.827453262Z     main(sys.argv[1:])
2025-11-26T17:48:52.827463598Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 102, in main
2025-11-26T17:48:52.827466752Z     config, _ = load_expr_config(args_with_overrides, GRPOConfig)
2025-11-26T17:48:52.827469777Z                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:48:52.827471800Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1282, in load_expr_config
2025-11-26T17:48:52.827473973Z     cfg = to_structured_cfg(cfg, config_cls=config_cls)
2025-11-26T17:48:52.828010867Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:48:52.828034813Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1276, in to_structured_cfg
2025-11-26T17:48:52.828038439Z     cfg = OmegaConf.merge(default_cfg, cfg)
2025-11-26T17:48:52.828041203Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:48:52.828043255Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/omegaconf.py", line 274, in merge
2025-11-26T17:48:52.828045970Z     target.merge_with(
2025-11-26T17:48:52.828048634Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 507, in merge_with
2025-11-26T17:48:52.828051227Z     self._format_and_raise(key=None, value=None, cause=e)
2025-11-26T17:48:52.828053351Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:48:52.828535864Z     format_and_raise(
2025-11-26T17:48:52.828541562Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:48:52.828544657Z     _raise(ex, cause)
2025-11-26T17:48:52.828546840Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:48:52.828549023Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:48:52.828551106Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:48:52.828553660Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 502, in merge_with
2025-11-26T17:48:52.828884876Z     self._merge_with(
2025-11-26T17:48:52.828888792Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:48:52.828891246Z     BaseContainer._map_merge(
2025-11-26T17:48:52.828893829Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:48:52.828896353Z     dest_node._merge_with(
2025-11-26T17:48:52.828898436Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:48:52.829269332Z     BaseContainer._map_merge(
2025-11-26T17:48:52.829287991Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:48:52.829299247Z     dest_node._merge_with(
2025-11-26T17:48:52.829301641Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:48:52.829303734Z     BaseContainer._map_merge(
2025-11-26T17:48:52.829309863Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 432, in _map_merge
2025-11-26T17:48:52.829312067Z     dest[key] = src._get_node(key)
2025-11-26T17:48:52.829867378Z     ~~~~^^^^^
2025-11-26T17:48:52.829873437Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 308, in __setitem__
2025-11-26T17:48:52.829876131Z     self._format_and_raise(
2025-11-26T17:48:52.829878775Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:48:52.829880819Z     format_and_raise(
2025-11-26T17:48:52.829883382Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:48:52.829885335Z     _raise(ex, cause)
2025-11-26T17:48:52.829887759Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:48:52.829889842Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:48:52.829891845Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:48:52.829894219Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 306, in __setitem__
2025-11-26T17:48:52.830365193Z     self.__set_impl(key=key, value=value)
2025-11-26T17:48:52.830371914Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 316, in __set_impl
2025-11-26T17:48:52.830374197Z     self._set_item_impl(key, value)
2025-11-26T17:48:52.830376340Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 579, in _set_item_impl
2025-11-26T17:48:52.830378464Z     target_node_ref = self._get_node(key)
2025-11-26T17:48:52.830380647Z                       ^^^^^^^^^^^^^^^^^^^
2025-11-26T17:48:52.830382760Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 473, in _get_node
2025-11-26T17:48:52.830641117Z     self._validate_get(key)
2025-11-26T17:48:52.830643761Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 163, in _validate_get
2025-11-26T17:48:52.830648087Z     self._format_and_raise(
2025-11-26T17:48:52.830650291Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:48:52.830652283Z     format_and_raise(
2025-11-26T17:48:52.830654297Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 906, in format_and_raise
2025-11-26T17:48:52.830928147Z     _raise(ex, cause)
2025-11-26T17:48:52.830931352Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:48:52.830933615Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:48:52.831168456Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:48:52.831173103Z omegaconf.errors.ConfigKeyError: Key 'max_new_tokens' not in 'NormConfig'
2025-11-26T17:48:52.831175687Z     full_key: actor.adv_norm.max_new_tokens
2025-11-26T17:48:52.831177941Z     reference_type=Optional[NormConfig]
2025-11-26T17:48:52.831179934Z     object_type=NormConfig
2025-11-26T17:48:55.614644778Z E1126 17:48:55.613000 966 torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 0 (pid: 1032) of binary: /usr/bin/python3
2025-11-26T17:48:55.615512839Z Traceback (most recent call last):
2025-11-26T17:48:55.615518807Z   File "/usr/local/bin/torchrun", line 7, in <module>
2025-11-26T17:48:55.615521661Z     sys.exit(main())
2025-11-26T17:48:55.615524396Z              ^^^^^^
2025-11-26T17:48:55.615526449Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
2025-11-26T17:48:55.615529213Z     return f(*args, **kwargs)
2025-11-26T17:48:55.615531616Z            ^^^^^^^^^^^^^^^^^^
2025-11-26T17:48:55.615533590Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 901, in main
2025-11-26T17:48:55.615542824Z     run(args)
2025-11-26T17:48:55.615545488Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 892, in run
2025-11-26T17:48:55.615955672Z     elastic_launch(
2025-11-26T17:48:55.615959037Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 143, in __call__
2025-11-26T17:48:55.615961521Z     return launch_agent(self._config, self._entrypoint, list(args))
2025-11-26T17:48:55.615963803Z            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:48:55.615966057Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 277, in launch_agent
2025-11-26T17:48:55.615968410Z     raise ChildFailedError(
2025-11-26T17:48:55.615970964Z torch.distributed.elastic.multiprocessing.errors.ChildFailedError:
2025-11-26T17:48:55.615972957Z ============================================================
2025-11-26T17:48:55.615975821Z examples/cloud_gsm8k/gsm8k_grpo_train.py FAILED
2025-11-26T17:48:55.615978786Z ------------------------------------------------------------
2025-11-26T17:48:55.615980849Z Failures:
2025-11-26T17:48:55.615983292Z   <NO_OTHER_FAILURES>
2025-11-26T17:48:55.615985275Z ------------------------------------------------------------
2025-11-26T17:48:55.615987669Z Root Cause (first observed failure):
2025-11-26T17:48:55.615989642Z [0]:
2025-11-26T17:48:55.615991756Z   time      : 2025-11-26_17:48:55
2025-11-26T17:48:55.615993808Z   host      : cef7c503fdea
2025-11-26T17:48:55.615995782Z   rank      : 0 (local_rank: 0)
2025-11-26T17:48:55.615997794Z   exitcode  : 1 (pid: 1032)
2025-11-26T17:48:55.615999788Z   error_file: <N/A>
2025-11-26T17:48:55.616001800Z   traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
2025-11-26T17:48:55.616004555Z ============================================================
2025-11-26T17:48:57.190758656Z [37m20251126-17:48:57.190 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [315][0m
2025-11-26T17:48:57.310335716Z Killed
2025-11-26T17:48:57.320525869Z [37m20251126-17:48:57.320 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [965][0m
2025-11-26T17:48:57.321545778Z Traceback (most recent call last):
2025-11-26T17:48:57.321557124Z   File "<frozen runpy>", line 198, in _run_module_as_main
2025-11-26T17:48:57.321560099Z   File "<frozen runpy>", line 88, in _run_code
2025-11-26T17:48:57.321562683Z   File "/workspace/AReaL/areal/launcher/local.py", line 405, in <module>
2025-11-26T17:48:57.321714660Z     main()
2025-11-26T17:48:57.321719607Z   File "/workspace/AReaL/areal/launcher/local.py", line 260, in main
2025-11-26T17:48:57.321794029Z     local_main(config, run_id=0)
2025-11-26T17:48:57.321798075Z   File "/workspace/AReaL/areal/launcher/local.py", line 399, in local_main
2025-11-26T17:48:57.321905687Z     raise e
2025-11-26T17:48:57.321908190Z   File "/workspace/AReaL/areal/launcher/local.py", line 375, in local_main
2025-11-26T17:48:57.321989161Z     launcher.wait(
2025-11-26T17:48:57.321992336Z   File "/workspace/AReaL/areal/launcher/local.py", line 235, in wait
2025-11-26T17:48:57.322042942Z     raise JobException(
2025-11-26T17:48:57.322049061Z areal.utils.launcher.JobException: Job gsm8k-grpo-cloud-2gpu-2000samples_trial_20251126_174811:trainer JobState.COMPLETED at node local
2025-11-26T17:48:57.534574978Z [37m20251126-17:48:57.533 Local Scheduler INFO: Waiting for 0 local running processes, pids: [0m
2025-11-26T17:49:14.320998942Z ==========
2025-11-26T17:49:14.321004651Z == CUDA ==
2025-11-26T17:49:14.321007635Z ==========
2025-11-26T17:49:14.325598552Z CUDA Version 12.9.1
2025-11-26T17:49:14.327196045Z Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
2025-11-26T17:49:14.328939105Z This container image and its contents are governed by the NVIDIA Deep Learning Container License.
2025-11-26T17:49:14.328941559Z By pulling and using the container, you accept the terms and conditions of this license:
2025-11-26T17:49:14.328943863Z https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license
2025-11-26T17:49:14.328954799Z A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
2025-11-26T17:49:14.495524709Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:49:14.656806228Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:49:14.868941550Z Branch 'feature/reasoning_model' set up to track remote branch 'feature/reasoning_model' from 'origin'.
2025-11-26T17:49:14.868982071Z Your branch is up to date with 'origin/feature/reasoning_model'.
2025-11-26T17:49:14.949159345Z Checking AReaL installation...
2025-11-26T17:49:15.015191874Z AReaL already installed. Skipping installation.
2025-11-26T17:49:15.015223010Z Cleaning up any leftover GPU processes...
2025-11-26T17:49:18.034477888Z Checking for processes holding GPU device files...
2025-11-26T17:49:20.088873540Z Found processes holding GPU devices: 1
2025-11-26T17:49:20.088915883Z 20
2025-11-26T17:49:20.088918768Z 71
2025-11-26T17:49:20.088920891Z 72
2025-11-26T17:49:20.088922943Z Killing process 1...
2025-11-26T17:49:20.088925607Z Killing process 71...
2025-11-26T17:49:20.088937936Z Killing process 72...
2025-11-26T17:49:22.091683042Z Using fuser to kill processes on GPU devices...
2025-11-26T17:49:24.118216249Z Checking GPU...
2025-11-26T17:49:24.157005951Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:49:24.157029707Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:49:24.173913346Z Set PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True for better memory management
2025-11-26T17:49:24.173930882Z Detected 2 GPU(s)
2025-11-26T17:49:24.173934027Z Checking GPU status...
2025-11-26T17:49:24.202175429Z index, name, utilization.gpu [%], memory.used [MiB], compute_mode
2025-11-26T17:49:24.203602376Z 0, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:49:24.204447202Z 1, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:49:24.247031668Z Verifying GPU accessibility...
2025-11-26T17:49:24.773037127Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:49:24.773109005Z   import pynvml  # type: ignore[import]
2025-11-26T17:49:25.871320324Z GPU accessibility verified on attempt 1
2025-11-26T17:49:26.334298147Z Starting training...
2025-11-26T17:49:29.346536333Z Using STANDARD 2000 SAMPLES 2 GPUs configuration
2025-11-26T17:49:29.346574400Z Note: GRPO only (no reasoning XML). Dataset capped at 2000 samples (~6 hours).
2025-11-26T17:49:29.346577515Z GPU count: 2 (required: 2)
2025-11-26T17:49:29.346582583Z ==========================================
2025-11-26T17:49:29.346584656Z Starting GRPO Training (Cloud)
2025-11-26T17:49:29.346587240Z ==========================================
2025-11-26T17:49:29.346589283Z Config: standard_2000samples_2GPUs
2025-11-26T17:49:29.346591316Z Config file: examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml
2025-11-26T17:49:29.346593449Z Training script: examples/cloud_gsm8k/gsm8k_grpo_train.py
2025-11-26T17:49:29.346596073Z Experiment: gsm8k-grpo-cloud-2gpu-2000samples
2025-11-26T17:49:29.346598126Z Trial: trial_20251126_174929
2025-11-26T17:49:29.346600179Z GPU: NVIDIA A100 80GB PCIe NVIDIA A100 80GB PCIe (81920 MB)
2025-11-26T17:49:29.346602182Z WandB API key: e1adc5be02...
2025-11-26T17:49:29.346604445Z ==========================================
2025-11-26T17:49:30.020046765Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:49:30.020090211Z   import pynvml  # type: ignore[import]
2025-11-26T17:49:33.937510785Z [37m20251126-17:49:33.937 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:49:33.937557365Z [37m20251126-17:49:33.937 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:49:33.937736453Z [37m20251126-17:49:33.937 name-resolve INFO: No such name resolve path: ./tmp/areal/name_resolve/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_174929[0m
2025-11-26T17:49:34.043088608Z [37m20251126-17:49:34.042 Local Scheduler INFO: LocalLauncher: experiment_name=gsm8k-grpo-cloud-2gpu-2000samples, trial_name=trial_20251126_174929, fileroot=/workspace/outputs/grpo, run_id=0, is_recover_run=False[0m
2025-11-26T17:49:34.050638646Z [37m20251126-17:49:34.050 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL CUDA_VISIBLE_DEVICES=0 stdbuf -oL python3 -m areal.launcher.sglang_server examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_174929 sglang.random_seed=1 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_174929/llm_server.log[0m
2025-11-26T17:49:34.787561272Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:49:34.787607902Z   import pynvml  # type: ignore[import]
2025-11-26T17:49:36.251213426Z [37m20251126-17:49:36.250 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:49:36.251711682Z [37m20251126-17:49:36.250 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:49:36.370552009Z [37m20251126-17:49:36.369 SGLangServer Wrapper INFO: Launch command: python3 -m sglang.launch_server --host 172.21.0.2 --port 16789 --tokenizer-path Qwen/Qwen2.5-0.5B-Instruct --tokenizer-mode auto --load-format auto --trust-remote-code --device cuda --tp-size 1 --base-gpu-id 0 --nnodes 1 --node-rank 0 --dist-init-addr localhost:18863 --model-path Qwen/Qwen2.5-0.5B-Instruct --random-seed 1 --skip-tokenizer-init --disable-radix-cache --torch-compile-max-bs 32 --triton-attention-num-kv-splits 8 --num-continuous-decode-steps 1 --attention-backend flashinfer --context-length 4096 --mem-fraction-static 0.6 --chunked-prefill-size -1 --max-prefill-tokens 32768 --schedule-policy lpm --schedule-conservativeness 1.0 --cpu-offload-gb 0 --dtype bfloat16 --kv-cache-dtype auto --dp-size 1 --ep-size 1 --max-loaded-loras 1 --max-loras-per-batch 1 --lora-backend triton --log-level warning --log-level-http warning --log-requests-level 0 --enable-metrics --decode-log-interval 1[0m
2025-11-26T17:49:37.427557789Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:49:37.427596908Z   import pynvml  # type: ignore[import]
2025-11-26T17:49:42.704185412Z INFO 11-26 17:49:42 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:49:43.342832713Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:49:44.308004486Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:49:44.308042964Z   import pynvml  # type: ignore[import]
2025-11-26T17:49:44.360086830Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:49:44.360158006Z   import pynvml  # type: ignore[import]
2025-11-26T17:49:49.441207788Z INFO 11-26 17:49:49 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:49:49.935067667Z INFO 11-26 17:49:49 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:49:50.028630082Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:49:50.269130811Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:49:50.273009221Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:49:50.273907196Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:49:50.274829838Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:49:50.307693773Z [2025-11-26 17:49:50] MOE_RUNNER_BACKEND is not initialized, using triton backend
2025-11-26T17:49:50.791346032Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:49:50.791384250Z   warnings.warn(
2025-11-26T17:49:50.791387435Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:49:50.791389728Z   warnings.warn(
2025-11-26T17:49:51.893617274Z Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
2025-11-26T17:49:52.012746935Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  8.41it/s]
2025-11-26T17:49:52.013392251Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  8.39it/s]
2025-11-26T17:49:54.729700953Z   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   4%|â–         | 1/23 [00:00<00:12,  1.80it/s]Capturing batches (bs=152 avail_mem=30.62 GB):   4%|â–         | 1/23 [00:00<00:12,  1.80it/s]Capturing batches (bs=144 avail_mem=30.60 GB):   4%|â–         | 1/23 [00:00<00:12,  1.80it/s]Capturing batches (bs=136 avail_mem=30.59 GB):   4%|â–         | 1/23 [00:00<00:12,  1.80it/s]Capturing batches (bs=136 avail_mem=30.59 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.11it/s]Capturing batches (bs=128 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.11it/s]Capturing batches (bs=120 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.11it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.11it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.29it/s]Capturing batches (bs=104 avail_mem=30.54 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.29it/s]Capturing batches (bs=96 avail_mem=30.53 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.29it/s] Capturing batches (bs=88 avail_mem=30.51 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.29it/s]Capturing batches (bs=88 avail_mem=30.51 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.54it/s]Capturing batches (bs=80 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.54it/s]Capturing batches (bs=72 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.54it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:01<00:00, 14.54it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 16.98it/s]Capturing batches (bs=56 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 16.98it/s]Capturing batches (bs=48 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 16.98it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 16.98it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 18.82it/s]Capturing batches (bs=32 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 18.82it/s]Capturing batches (bs=24 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 18.82it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 18.82it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.37it/s]Capturing batches (bs=8 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.37it/s] Capturing batches (bs=4 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.37it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.37it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.14it/s]Capturing batches (bs=1 avail_mem=30.35 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.14it/s]Capturing batches (bs=1 avail_mem=30.35 GB): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00, 14.62it/s]
2025-11-26T17:50:00.396316649Z [37m20251126-17:50:00.395 SGLangServer Wrapper INFO: SGLang server launched at: http://172.21.0.2:16789[0m
2025-11-26T17:50:01.057191144Z [37m20251126-17:50:01.056 Launcher Utils INFO: Found 1 rollout servers: 172.21.0.2:16789[0m
2025-11-26T17:50:01.057214079Z [37m20251126-17:50:01.057 Local Scheduler INFO: LLM inference server launched at: AREAL_LLM_SERVER_ADDRS=172.21.0.2:16789[0m
2025-11-26T17:50:01.059012903Z [37m20251126-17:50:01.058 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL AREAL_LLM_SERVER_ADDRS=172.21.0.2:16789 AREAL_RECOVER_RUN=0 NCCL_CUMEM_ENABLE=0 NCCL_NVLS_ENABLE=0 CUDA_VISIBLE_DEVICES=1 stdbuf -oL torchrun --nnodes 1 --nproc-per-node 1 --master-addr localhost --master-port 37809 examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_174929 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_174929/trainer.log[0m
2025-11-26T17:50:01.059625081Z [37m20251126-17:50:01.059 Local Scheduler INFO: Waiting for 2 local running processes, pids: 315 965[0m
2025-11-26T17:50:01.619563346Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:50:01.619601323Z   import pynvml  # type: ignore[import]
2025-11-26T17:50:02.823959547Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:50:02.824003173Z   import pynvml  # type: ignore[import]
2025-11-26T17:50:09.467426500Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:50:09.467476486Z   warnings.warn(
2025-11-26T17:50:09.467479570Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:50:09.467481974Z   warnings.warn(
2025-11-26T17:50:09.917753542Z Traceback (most recent call last):
2025-11-26T17:50:09.917782616Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 665, in <module>
2025-11-26T17:50:09.918311198Z     main(sys.argv[1:])
2025-11-26T17:50:09.918321723Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 102, in main
2025-11-26T17:50:09.918324788Z     config, _ = load_expr_config(args_with_overrides, GRPOConfig)
2025-11-26T17:50:09.918327762Z                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:50:09.918330136Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1282, in load_expr_config
2025-11-26T17:50:09.918757246Z     cfg = to_structured_cfg(cfg, config_cls=config_cls)
2025-11-26T17:50:09.918760441Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:50:09.918762794Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1276, in to_structured_cfg
2025-11-26T17:50:09.918765479Z     cfg = OmegaConf.merge(default_cfg, cfg)
2025-11-26T17:50:09.919200049Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:50:09.919205006Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/omegaconf.py", line 274, in merge
2025-11-26T17:50:09.919207180Z     target.merge_with(
2025-11-26T17:50:09.919209252Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 507, in merge_with
2025-11-26T17:50:09.919212047Z     self._format_and_raise(key=None, value=None, cause=e)
2025-11-26T17:50:09.919214731Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:50:09.919216764Z     format_and_raise(
2025-11-26T17:50:09.919218857Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:50:09.919221441Z     _raise(ex, cause)
2025-11-26T17:50:09.919565056Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:50:09.919589593Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:50:09.919592226Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:50:09.919594841Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 502, in merge_with
2025-11-26T17:50:09.920381709Z     self._merge_with(
2025-11-26T17:50:09.920387768Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:50:09.920390121Z     BaseContainer._map_merge(
2025-11-26T17:50:09.920392715Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:50:09.920394768Z     dest_node._merge_with(
2025-11-26T17:50:09.920396742Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:50:09.920398714Z     BaseContainer._map_merge(
2025-11-26T17:50:09.920400848Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:50:09.920402981Z     dest_node._merge_with(
2025-11-26T17:50:09.920404954Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:50:09.920414898Z     BaseContainer._map_merge(
2025-11-26T17:50:09.920417112Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 432, in _map_merge
2025-11-26T17:50:09.920419105Z     dest[key] = src._get_node(key)
2025-11-26T17:50:09.920421278Z     ~~~~^^^^^
2025-11-26T17:50:09.920423812Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 308, in __setitem__
2025-11-26T17:50:09.920425825Z     self._format_and_raise(
2025-11-26T17:50:09.920427848Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:50:09.920434508Z     format_and_raise(
2025-11-26T17:50:09.920436641Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:50:09.920981347Z     _raise(ex, cause)
2025-11-26T17:50:09.920987096Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:50:09.920989309Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:50:09.920991452Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:50:09.920993656Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 306, in __setitem__
2025-11-26T17:50:09.920996329Z     self.__set_impl(key=key, value=value)
2025-11-26T17:50:09.920998773Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 316, in __set_impl
2025-11-26T17:50:09.921000836Z     self._set_item_impl(key, value)
2025-11-26T17:50:09.921003019Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 579, in _set_item_impl
2025-11-26T17:50:09.921005183Z     target_node_ref = self._get_node(key)
2025-11-26T17:50:09.921241286Z                       ^^^^^^^^^^^^^^^^^^^
2025-11-26T17:50:09.921247916Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 473, in _get_node
2025-11-26T17:50:09.921250530Z     self._validate_get(key)
2025-11-26T17:50:09.921252724Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 163, in _validate_get
2025-11-26T17:50:09.921254947Z     self._format_and_raise(
2025-11-26T17:50:09.921257020Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:50:09.921543088Z     format_and_raise(
2025-11-26T17:50:09.921546834Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 906, in format_and_raise
2025-11-26T17:50:09.921549228Z     _raise(ex, cause)
2025-11-26T17:50:09.921551341Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:50:09.921553654Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:50:09.921909127Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:50:09.921913133Z omegaconf.errors.ConfigKeyError: Key 'max_new_tokens' not in 'NormConfig'
2025-11-26T17:50:09.921915827Z     full_key: actor.adv_norm.max_new_tokens
2025-11-26T17:50:09.921917850Z     reference_type=Optional[NormConfig]
2025-11-26T17:50:09.921919963Z     object_type=NormConfig
2025-11-26T17:50:13.825361389Z E1126 17:50:13.824000 966 torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 0 (pid: 1032) of binary: /usr/bin/python3
2025-11-26T17:50:13.825994357Z Traceback (most recent call last):
2025-11-26T17:50:13.826001487Z   File "/usr/local/bin/torchrun", line 7, in <module>
2025-11-26T17:50:13.826004522Z     sys.exit(main())
2025-11-26T17:50:13.826007095Z              ^^^^^^
2025-11-26T17:50:13.826009198Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
2025-11-26T17:50:13.826014907Z     return f(*args, **kwargs)
2025-11-26T17:50:13.826018583Z            ^^^^^^^^^^^^^^^^^^
2025-11-26T17:50:13.826021507Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 901, in main
2025-11-26T17:50:13.826539694Z     run(args)
2025-11-26T17:50:13.826545853Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 892, in run
2025-11-26T17:50:13.826559594Z     elastic_launch(
2025-11-26T17:50:13.826562328Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 143, in __call__
2025-11-26T17:50:13.826564922Z     return launch_agent(self._config, self._entrypoint, list(args))
2025-11-26T17:50:13.826567786Z            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:50:13.826569919Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 277, in launch_agent
2025-11-26T17:50:13.826572022Z     raise ChildFailedError(
2025-11-26T17:50:13.826574966Z torch.distributed.elastic.multiprocessing.errors.ChildFailedError:
2025-11-26T17:50:13.826577009Z ============================================================
2025-11-26T17:50:13.826579513Z examples/cloud_gsm8k/gsm8k_grpo_train.py FAILED
2025-11-26T17:50:13.826582056Z ------------------------------------------------------------
2025-11-26T17:50:13.826584070Z Failures:
2025-11-26T17:50:13.826586113Z   <NO_OTHER_FAILURES>
2025-11-26T17:50:13.826588126Z ------------------------------------------------------------
2025-11-26T17:50:13.826590159Z Root Cause (first observed failure):
2025-11-26T17:50:13.826592182Z [0]:
2025-11-26T17:50:13.826594195Z   time      : 2025-11-26_17:50:13
2025-11-26T17:50:13.826596208Z   host      : cef7c503fdea
2025-11-26T17:50:13.826598231Z   rank      : 0 (local_rank: 0)
2025-11-26T17:50:13.826600214Z   exitcode  : 1 (pid: 1032)
2025-11-26T17:50:13.826602217Z   error_file: <N/A>
2025-11-26T17:50:13.826604240Z   traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
2025-11-26T17:50:13.826606313Z ============================================================
2025-11-26T17:50:15.063125721Z [37m20251126-17:50:15.062 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [315][0m
2025-11-26T17:50:15.180744570Z Killed
2025-11-26T17:50:15.192305415Z [37m20251126-17:50:15.192 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [965][0m
2025-11-26T17:50:15.193269640Z Traceback (most recent call last):
2025-11-26T17:50:15.193286906Z   File "<frozen runpy>", line 198, in _run_module_as_main
2025-11-26T17:50:15.193291553Z   File "<frozen runpy>", line 88, in _run_code
2025-11-26T17:50:15.193293736Z   File "/workspace/AReaL/areal/launcher/local.py", line 405, in <module>
2025-11-26T17:50:15.193415739Z     main()
2025-11-26T17:50:15.193420345Z   File "/workspace/AReaL/areal/launcher/local.py", line 260, in main
2025-11-26T17:50:15.193509890Z     local_main(config, run_id=0)
2025-11-26T17:50:15.193515438Z   File "/workspace/AReaL/areal/launcher/local.py", line 399, in local_main
2025-11-26T17:50:15.193592174Z     raise e
2025-11-26T17:50:15.193595869Z   File "/workspace/AReaL/areal/launcher/local.py", line 375, in local_main
2025-11-26T17:50:15.193659444Z     launcher.wait(
2025-11-26T17:50:15.193663000Z   File "/workspace/AReaL/areal/launcher/local.py", line 235, in wait
2025-11-26T17:50:15.193719704Z     raise JobException(
2025-11-26T17:50:15.193722869Z areal.utils.launcher.JobException: Job gsm8k-grpo-cloud-2gpu-2000samples_trial_20251126_174929:trainer JobState.COMPLETED at node local
2025-11-26T17:50:15.383857407Z [37m20251126-17:50:15.383 Local Scheduler INFO: Waiting for 0 local running processes, pids: [0m
2025-11-26T17:50:32.685295927Z ==========
2025-11-26T17:50:32.685304960Z == CUDA ==
2025-11-26T17:50:32.685307604Z ==========
2025-11-26T17:50:32.690834913Z CUDA Version 12.9.1
2025-11-26T17:50:32.693220457Z Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
2025-11-26T17:50:32.695096406Z This container image and its contents are governed by the NVIDIA Deep Learning Container License.
2025-11-26T17:50:32.695098659Z By pulling and using the container, you accept the terms and conditions of this license:
2025-11-26T17:50:32.695101443Z https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license
2025-11-26T17:50:32.695105620Z A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
2025-11-26T17:50:32.860822503Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:50:33.020470755Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:50:33.262206354Z Branch 'feature/reasoning_model' set up to track remote branch 'feature/reasoning_model' from 'origin'.
2025-11-26T17:50:33.262235217Z Your branch is up to date with 'origin/feature/reasoning_model'.
2025-11-26T17:50:33.332804501Z Checking AReaL installation...
2025-11-26T17:50:33.391337997Z AReaL already installed. Skipping installation.
2025-11-26T17:50:33.391364086Z Cleaning up any leftover GPU processes...
2025-11-26T17:50:36.409694979Z Checking for processes holding GPU device files...
2025-11-26T17:50:39.056289528Z Found processes holding GPU devices: 1
2025-11-26T17:50:39.056333064Z 20
2025-11-26T17:50:39.056336299Z 71
2025-11-26T17:50:39.056338482Z 72
2025-11-26T17:50:39.056340565Z Killing process 1...
2025-11-26T17:50:39.056343269Z Killing process 71...
2025-11-26T17:50:39.056467386Z Killing process 72...
2025-11-26T17:50:41.059108455Z Using fuser to kill processes on GPU devices...
2025-11-26T17:50:43.083001388Z Checking GPU...
2025-11-26T17:50:43.116577020Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:50:43.116599734Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:50:43.131419912Z Set PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True for better memory management
2025-11-26T17:50:43.131432491Z Detected 2 GPU(s)
2025-11-26T17:50:43.131435546Z Checking GPU status...
2025-11-26T17:50:43.158530831Z index, name, utilization.gpu [%], memory.used [MiB], compute_mode
2025-11-26T17:50:43.160017277Z 0, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:50:43.160298979Z 1, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:50:43.208178157Z Verifying GPU accessibility...
2025-11-26T17:50:43.729634232Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:50:43.729694391Z   import pynvml  # type: ignore[import]
2025-11-26T17:50:44.856293022Z GPU accessibility verified on attempt 1
2025-11-26T17:50:45.337290143Z Starting training...
2025-11-26T17:50:48.340213218Z Using STANDARD 2000 SAMPLES 2 GPUs configuration
2025-11-26T17:50:48.340250344Z Note: GRPO only (no reasoning XML). Dataset capped at 2000 samples (~6 hours).
2025-11-26T17:50:48.340253598Z GPU count: 2 (required: 2)
2025-11-26T17:50:48.342676367Z ==========================================
2025-11-26T17:50:48.342679362Z Starting GRPO Training (Cloud)
2025-11-26T17:50:48.342682407Z ==========================================
2025-11-26T17:50:48.342684430Z Config: standard_2000samples_2GPUs
2025-11-26T17:50:48.342686503Z Config file: examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml
2025-11-26T17:50:48.342689066Z Training script: examples/cloud_gsm8k/gsm8k_grpo_train.py
2025-11-26T17:50:48.342691490Z Experiment: gsm8k-grpo-cloud-2gpu-2000samples
2025-11-26T17:50:48.342693533Z Trial: trial_20251126_175048
2025-11-26T17:50:48.342695656Z GPU: NVIDIA A100 80GB PCIe NVIDIA A100 80GB PCIe (81920 MB)
2025-11-26T17:50:48.342697679Z WandB API key: e1adc5be02...
2025-11-26T17:50:48.342699713Z ==========================================
2025-11-26T17:50:49.002104337Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:50:49.002152468Z   import pynvml  # type: ignore[import]
2025-11-26T17:50:52.933672572Z [37m20251126-17:50:52.933 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:50:52.933715407Z [37m20251126-17:50:52.933 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:50:52.933971960Z [37m20251126-17:50:52.933 name-resolve INFO: No such name resolve path: ./tmp/areal/name_resolve/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_175048[0m
2025-11-26T17:50:53.039006659Z [37m20251126-17:50:53.038 Local Scheduler INFO: LocalLauncher: experiment_name=gsm8k-grpo-cloud-2gpu-2000samples, trial_name=trial_20251126_175048, fileroot=/workspace/outputs/grpo, run_id=0, is_recover_run=False[0m
2025-11-26T17:50:53.046803989Z [37m20251126-17:50:53.046 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL CUDA_VISIBLE_DEVICES=0 stdbuf -oL python3 -m areal.launcher.sglang_server examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_175048 sglang.random_seed=1 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_175048/llm_server.log[0m
2025-11-26T17:50:53.750396670Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:50:53.750437361Z   import pynvml  # type: ignore[import]
2025-11-26T17:50:55.213289306Z [37m20251126-17:50:55.212 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:50:55.214060221Z [37m20251126-17:50:55.212 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:50:55.316069337Z [37m20251126-17:50:55.315 SGLangServer Wrapper INFO: Launch command: python3 -m sglang.launch_server --host 172.21.0.2 --port 10504 --tokenizer-path Qwen/Qwen2.5-0.5B-Instruct --tokenizer-mode auto --load-format auto --trust-remote-code --device cuda --tp-size 1 --base-gpu-id 0 --nnodes 1 --node-rank 0 --dist-init-addr localhost:19797 --model-path Qwen/Qwen2.5-0.5B-Instruct --random-seed 1 --skip-tokenizer-init --disable-radix-cache --torch-compile-max-bs 32 --triton-attention-num-kv-splits 8 --num-continuous-decode-steps 1 --attention-backend flashinfer --context-length 4096 --mem-fraction-static 0.6 --chunked-prefill-size -1 --max-prefill-tokens 32768 --schedule-policy lpm --schedule-conservativeness 1.0 --cpu-offload-gb 0 --dtype bfloat16 --kv-cache-dtype auto --dp-size 1 --ep-size 1 --max-loaded-loras 1 --max-loras-per-batch 1 --lora-backend triton --log-level warning --log-level-http warning --log-requests-level 0 --enable-metrics --decode-log-interval 1[0m
2025-11-26T17:50:56.361208833Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:50:56.361249924Z   import pynvml  # type: ignore[import]
2025-11-26T17:51:01.693724779Z INFO 11-26 17:51:01 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:51:02.413786499Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:51:03.427655315Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:51:03.427692910Z   import pynvml  # type: ignore[import]
2025-11-26T17:51:03.487688937Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:51:03.487727175Z   import pynvml  # type: ignore[import]
2025-11-26T17:51:08.750765332Z INFO 11-26 17:51:08 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:51:09.039486199Z INFO 11-26 17:51:09 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:51:09.329753612Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:51:09.573314646Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:51:09.576985975Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:51:09.577816549Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:51:09.578732220Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:51:09.611179993Z [2025-11-26 17:51:09] MOE_RUNNER_BACKEND is not initialized, using triton backend
2025-11-26T17:51:10.091446881Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:51:10.091487983Z   warnings.warn(
2025-11-26T17:51:10.091491098Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:51:10.091493722Z   warnings.warn(
2025-11-26T17:51:11.177817015Z Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
2025-11-26T17:51:11.281022514Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  9.71it/s]
2025-11-26T17:51:11.281417395Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  9.69it/s]
2025-11-26T17:51:13.722335728Z   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   4%|â–         | 1/23 [00:00<00:11,  1.84it/s]Capturing batches (bs=152 avail_mem=30.62 GB):   4%|â–         | 1/23 [00:00<00:11,  1.84it/s]Capturing batches (bs=144 avail_mem=30.60 GB):   4%|â–         | 1/23 [00:00<00:11,  1.84it/s]Capturing batches (bs=136 avail_mem=30.59 GB):   4%|â–         | 1/23 [00:00<00:11,  1.84it/s]Capturing batches (bs=136 avail_mem=30.59 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.29it/s]Capturing batches (bs=128 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.29it/s]Capturing batches (bs=120 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.29it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.29it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.63it/s]Capturing batches (bs=104 avail_mem=30.54 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.63it/s]Capturing batches (bs=96 avail_mem=30.53 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.63it/s] Capturing batches (bs=88 avail_mem=30.51 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.63it/s]Capturing batches (bs=88 avail_mem=30.51 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 15.02it/s]Capturing batches (bs=80 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 15.02it/s]Capturing batches (bs=72 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 15.02it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:01<00:00, 15.02it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.55it/s]Capturing batches (bs=56 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.55it/s]Capturing batches (bs=48 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.55it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.55it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.58it/s]Capturing batches (bs=32 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.58it/s]Capturing batches (bs=24 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.58it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.58it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 18.07it/s]Capturing batches (bs=8 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 18.07it/s] Capturing batches (bs=4 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 18.07it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 18.07it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.90it/s]Capturing batches (bs=1 avail_mem=30.35 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.90it/s]Capturing batches (bs=1 avail_mem=30.35 GB): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00, 15.12it/s]
2025-11-26T17:51:19.342353275Z [37m20251126-17:51:19.341 SGLangServer Wrapper INFO: SGLang server launched at: http://172.21.0.2:10504[0m
2025-11-26T17:51:20.053326682Z [37m20251126-17:51:20.052 Launcher Utils INFO: Found 1 rollout servers: 172.21.0.2:10504[0m
2025-11-26T17:51:20.053369396Z [37m20251126-17:51:20.053 Local Scheduler INFO: LLM inference server launched at: AREAL_LLM_SERVER_ADDRS=172.21.0.2:10504[0m
2025-11-26T17:51:20.056105545Z [37m20251126-17:51:20.055 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL AREAL_LLM_SERVER_ADDRS=172.21.0.2:10504 AREAL_RECOVER_RUN=0 NCCL_CUMEM_ENABLE=0 NCCL_NVLS_ENABLE=0 CUDA_VISIBLE_DEVICES=1 stdbuf -oL torchrun --nnodes 1 --nproc-per-node 1 --master-addr localhost --master-port 45770 examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_175048 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_175048/trainer.log[0m
2025-11-26T17:51:20.056670491Z [37m20251126-17:51:20.056 Local Scheduler INFO: Waiting for 2 local running processes, pids: 315 965[0m
2025-11-26T17:51:20.615824522Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:51:20.615861897Z   import pynvml  # type: ignore[import]
2025-11-26T17:51:21.802179619Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:51:21.802218768Z   import pynvml  # type: ignore[import]
2025-11-26T17:51:28.958972699Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:51:28.959024838Z   warnings.warn(
2025-11-26T17:51:28.959029034Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:51:28.959057246Z   warnings.warn(
2025-11-26T17:51:29.385555746Z Traceback (most recent call last):
2025-11-26T17:51:29.385597389Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 665, in <module>
2025-11-26T17:51:29.386085871Z     main(sys.argv[1:])
2025-11-26T17:51:29.386093312Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 102, in main
2025-11-26T17:51:29.386096476Z     config, _ = load_expr_config(args_with_overrides, GRPOConfig)
2025-11-26T17:51:29.386099171Z                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:51:29.386101283Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1282, in load_expr_config
2025-11-26T17:51:29.386569705Z     cfg = to_structured_cfg(cfg, config_cls=config_cls)
2025-11-26T17:51:29.386576535Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:51:29.386578758Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1276, in to_structured_cfg
2025-11-26T17:51:29.386581623Z     cfg = OmegaConf.merge(default_cfg, cfg)
2025-11-26T17:51:29.387039369Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:51:29.387042594Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/omegaconf.py", line 274, in merge
2025-11-26T17:51:29.387044747Z     target.merge_with(
2025-11-26T17:51:29.387046920Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 507, in merge_with
2025-11-26T17:51:29.387049764Z     self._format_and_raise(key=None, value=None, cause=e)
2025-11-26T17:51:29.387052188Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:51:29.387054371Z     format_and_raise(
2025-11-26T17:51:29.387056425Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:51:29.387058448Z     _raise(ex, cause)
2025-11-26T17:51:29.387060521Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:51:29.387409643Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:51:29.387414029Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:51:29.387416203Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 502, in merge_with
2025-11-26T17:51:29.387419057Z     self._merge_with(
2025-11-26T17:51:29.387804184Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:51:29.387806578Z     BaseContainer._map_merge(
2025-11-26T17:51:29.387809312Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:51:29.387811425Z     dest_node._merge_with(
2025-11-26T17:51:29.387813739Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:51:29.387815751Z     BaseContainer._map_merge(
2025-11-26T17:51:29.387818125Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:51:29.387820178Z     dest_node._merge_with(
2025-11-26T17:51:29.387822221Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:51:29.388139837Z     BaseContainer._map_merge(
2025-11-26T17:51:29.388144915Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 432, in _map_merge
2025-11-26T17:51:29.388155801Z     dest[key] = src._get_node(key)
2025-11-26T17:51:29.388158044Z     ~~~~^^^^^
2025-11-26T17:51:29.388160538Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 308, in __setitem__
2025-11-26T17:51:29.388162611Z     self._format_and_raise(
2025-11-26T17:51:29.388164624Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:51:29.388740316Z     format_and_raise(
2025-11-26T17:51:29.388742811Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:51:29.388744874Z     _raise(ex, cause)
2025-11-26T17:51:29.388746866Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:51:29.388749440Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:51:29.388751413Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:51:29.388753446Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 306, in __setitem__
2025-11-26T17:51:29.388755479Z     self.__set_impl(key=key, value=value)
2025-11-26T17:51:29.388757493Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 316, in __set_impl
2025-11-26T17:51:29.388759585Z     self._set_item_impl(key, value)
2025-11-26T17:51:29.388761579Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 579, in _set_item_impl
2025-11-26T17:51:29.389053917Z     target_node_ref = self._get_node(key)
2025-11-26T17:51:29.389056320Z                       ^^^^^^^^^^^^^^^^^^^
2025-11-26T17:51:29.389058524Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 473, in _get_node
2025-11-26T17:51:29.389060737Z     self._validate_get(key)
2025-11-26T17:51:29.389063371Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 163, in _validate_get
2025-11-26T17:51:29.389433065Z     self._format_and_raise(
2025-11-26T17:51:29.389437612Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:51:29.389439835Z     format_and_raise(
2025-11-26T17:51:29.389442077Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 906, in format_and_raise
2025-11-26T17:51:29.389444080Z     _raise(ex, cause)
2025-11-26T17:51:29.389446093Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:51:29.389678462Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:51:29.389681126Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:51:29.389683129Z omegaconf.errors.ConfigKeyError: Key 'max_new_tokens' not in 'NormConfig'
2025-11-26T17:51:29.389685252Z     full_key: actor.adv_norm.max_new_tokens
2025-11-26T17:51:29.389687526Z     reference_type=Optional[NormConfig]
2025-11-26T17:51:29.389689589Z     object_type=NormConfig
2025-11-26T17:51:32.125149897Z E1126 17:51:32.124000 966 torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 0 (pid: 1032) of binary: /usr/bin/python3
2025-11-26T17:51:32.125847252Z Traceback (most recent call last):
2025-11-26T17:51:32.125869856Z   File "/usr/local/bin/torchrun", line 7, in <module>
2025-11-26T17:51:32.125872710Z     sys.exit(main())
2025-11-26T17:51:32.125875775Z              ^^^^^^
2025-11-26T17:51:32.125877978Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
2025-11-26T17:51:32.125883747Z     return f(*args, **kwargs)
2025-11-26T17:51:32.125886351Z            ^^^^^^^^^^^^^^^^^^
2025-11-26T17:51:32.125888424Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 901, in main
2025-11-26T17:51:32.126265529Z     run(args)
2025-11-26T17:51:32.126276656Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 892, in run
2025-11-26T17:51:32.126279871Z     elastic_launch(
2025-11-26T17:51:32.126282855Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 143, in __call__
2025-11-26T17:51:32.126292590Z     return launch_agent(self._config, self._entrypoint, list(args))
2025-11-26T17:51:32.126296596Z            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:51:32.126298699Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 277, in launch_agent
2025-11-26T17:51:32.126300672Z     raise ChildFailedError(
2025-11-26T17:51:32.126303366Z torch.distributed.elastic.multiprocessing.errors.ChildFailedError:
2025-11-26T17:51:32.126305619Z ============================================================
2025-11-26T17:51:32.126307833Z examples/cloud_gsm8k/gsm8k_grpo_train.py FAILED
2025-11-26T17:51:32.126310357Z ------------------------------------------------------------
2025-11-26T17:51:32.126312409Z Failures:
2025-11-26T17:51:32.126314412Z   <NO_OTHER_FAILURES>
2025-11-26T17:51:32.126316406Z ------------------------------------------------------------
2025-11-26T17:51:32.126318589Z Root Cause (first observed failure):
2025-11-26T17:51:32.126320562Z [0]:
2025-11-26T17:51:32.126322834Z   time      : 2025-11-26_17:51:32
2025-11-26T17:51:32.126324937Z   host      : cef7c503fdea
2025-11-26T17:51:32.126326920Z   rank      : 0 (local_rank: 0)
2025-11-26T17:51:32.126328893Z   exitcode  : 1 (pid: 1032)
2025-11-26T17:51:32.126330916Z   error_file: <N/A>
2025-11-26T17:51:32.126333059Z   traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
2025-11-26T17:51:32.126594422Z ============================================================
2025-11-26T17:51:34.060317231Z [37m20251126-17:51:34.059 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [315][0m
2025-11-26T17:51:34.233749119Z Killed
2025-11-26T17:51:34.236818537Z [37m20251126-17:51:34.236 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [965][0m
2025-11-26T17:51:34.237745276Z Traceback (most recent call last):
2025-11-26T17:51:34.237753007Z   File "<frozen runpy>", line 198, in _run_module_as_main
2025-11-26T17:51:34.237755781Z   File "<frozen runpy>", line 88, in _run_code
2025-11-26T17:51:34.237757964Z   File "/workspace/AReaL/areal/launcher/local.py", line 405, in <module>
2025-11-26T17:51:34.237893727Z     main()
2025-11-26T17:51:34.237896652Z   File "/workspace/AReaL/areal/launcher/local.py", line 260, in main
2025-11-26T17:51:34.238008830Z     local_main(config, run_id=0)
2025-11-26T17:51:34.238011975Z   File "/workspace/AReaL/areal/launcher/local.py", line 399, in local_main
2025-11-26T17:51:34.238104643Z     raise e
2025-11-26T17:51:34.238106917Z   File "/workspace/AReaL/areal/launcher/local.py", line 375, in local_main
2025-11-26T17:51:34.238241058Z     launcher.wait(
2025-11-26T17:51:34.238255600Z   File "/workspace/AReaL/areal/launcher/local.py", line 235, in wait
2025-11-26T17:51:34.238262991Z     raise JobException(
2025-11-26T17:51:34.238265384Z areal.utils.launcher.JobException: Job gsm8k-grpo-cloud-2gpu-2000samples_trial_20251126_175048:trainer JobState.COMPLETED at node local
2025-11-26T17:51:34.540672422Z [37m20251126-17:51:34.539 Local Scheduler INFO: Waiting for 0 local running processes, pids: [0m
2025-11-26T17:51:50.910797543Z ==========
2025-11-26T17:51:50.910800778Z == CUDA ==
2025-11-26T17:51:50.910815490Z ==========
2025-11-26T17:51:50.914909782Z CUDA Version 12.9.1
2025-11-26T17:51:50.916432023Z Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
2025-11-26T17:51:50.917941543Z This container image and its contents are governed by the NVIDIA Deep Learning Container License.
2025-11-26T17:51:50.917943797Z By pulling and using the container, you accept the terms and conditions of this license:
2025-11-26T17:51:50.917956776Z https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license
2025-11-26T17:51:50.917961112Z A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
2025-11-26T17:51:51.080934886Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:51:51.240021348Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:51:51.569473826Z Branch 'feature/reasoning_model' set up to track remote branch 'feature/reasoning_model' from 'origin'.
2025-11-26T17:51:51.569498543Z Your branch is up to date with 'origin/feature/reasoning_model'.
2025-11-26T17:51:51.648183272Z Checking AReaL installation...
2025-11-26T17:51:51.711681775Z AReaL already installed. Skipping installation.
2025-11-26T17:51:51.711709276Z Cleaning up any leftover GPU processes...
2025-11-26T17:51:54.729932037Z Checking for processes holding GPU device files...
2025-11-26T17:51:56.838072581Z Found processes holding GPU devices: 1
2025-11-26T17:51:56.838145411Z 20
2025-11-26T17:51:56.838149857Z 71
2025-11-26T17:51:56.838152572Z 72
2025-11-26T17:51:56.838154635Z Killing process 1...
2025-11-26T17:51:56.838157279Z Killing process 71...
2025-11-26T17:51:56.838167594Z Killing process 72...
2025-11-26T17:51:58.840653071Z Using fuser to kill processes on GPU devices...
2025-11-26T17:52:00.862579839Z Checking GPU...
2025-11-26T17:52:00.901987406Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:52:00.902012043Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:52:00.917260333Z Set PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True for better memory management
2025-11-26T17:52:00.917275245Z Detected 2 GPU(s)
2025-11-26T17:52:00.917278690Z Checking GPU status...
2025-11-26T17:52:00.944752502Z index, name, utilization.gpu [%], memory.used [MiB], compute_mode
2025-11-26T17:52:00.946363736Z 0, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:52:00.946813830Z 1, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:52:00.991063971Z Verifying GPU accessibility...
2025-11-26T17:52:01.541852221Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:52:01.541909006Z   import pynvml  # type: ignore[import]
2025-11-26T17:52:02.668816941Z GPU accessibility verified on attempt 1
2025-11-26T17:52:03.196203218Z Starting training...
2025-11-26T17:52:06.198863027Z Using STANDARD 2000 SAMPLES 2 GPUs configuration
2025-11-26T17:52:06.198900554Z Note: GRPO only (no reasoning XML). Dataset capped at 2000 samples (~6 hours).
2025-11-26T17:52:06.198903448Z GPU count: 2 (required: 2)
2025-11-26T17:52:06.201143114Z ==========================================
2025-11-26T17:52:06.201146148Z Starting GRPO Training (Cloud)
2025-11-26T17:52:06.201148742Z ==========================================
2025-11-26T17:52:06.201150915Z Config: standard_2000samples_2GPUs
2025-11-26T17:52:06.201152958Z Config file: examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml
2025-11-26T17:52:06.201155713Z Training script: examples/cloud_gsm8k/gsm8k_grpo_train.py
2025-11-26T17:52:06.201158405Z Experiment: gsm8k-grpo-cloud-2gpu-2000samples
2025-11-26T17:52:06.201160408Z Trial: trial_20251126_175206
2025-11-26T17:52:06.201162402Z GPU: NVIDIA A100 80GB PCIe NVIDIA A100 80GB PCIe (81920 MB)
2025-11-26T17:52:06.201164374Z WandB API key: e1adc5be02...
2025-11-26T17:52:06.201166357Z ==========================================
2025-11-26T17:52:06.879933354Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:52:06.879971511Z   import pynvml  # type: ignore[import]
2025-11-26T17:52:10.798022369Z [37m20251126-17:52:10.797 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:52:10.798065404Z [37m20251126-17:52:10.797 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:52:10.798327366Z [37m20251126-17:52:10.798 name-resolve INFO: No such name resolve path: ./tmp/areal/name_resolve/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_175206[0m
2025-11-26T17:52:10.901983060Z [37m20251126-17:52:10.901 Local Scheduler INFO: LocalLauncher: experiment_name=gsm8k-grpo-cloud-2gpu-2000samples, trial_name=trial_20251126_175206, fileroot=/workspace/outputs/grpo, run_id=0, is_recover_run=False[0m
2025-11-26T17:52:10.909569884Z [37m20251126-17:52:10.909 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL CUDA_VISIBLE_DEVICES=0 stdbuf -oL python3 -m areal.launcher.sglang_server examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_175206 sglang.random_seed=1 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_175206/llm_server.log[0m
2025-11-26T17:52:11.611762028Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:52:11.611800976Z   import pynvml  # type: ignore[import]
2025-11-26T17:52:13.065932739Z [37m20251126-17:52:13.065 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:52:13.066648601Z [37m20251126-17:52:13.065 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:52:13.167774194Z [37m20251126-17:52:13.167 SGLangServer Wrapper INFO: Launch command: python3 -m sglang.launch_server --host 172.21.0.2 --port 25360 --tokenizer-path Qwen/Qwen2.5-0.5B-Instruct --tokenizer-mode auto --load-format auto --trust-remote-code --device cuda --tp-size 1 --base-gpu-id 0 --nnodes 1 --node-rank 0 --dist-init-addr localhost:26910 --model-path Qwen/Qwen2.5-0.5B-Instruct --random-seed 1 --skip-tokenizer-init --disable-radix-cache --torch-compile-max-bs 32 --triton-attention-num-kv-splits 8 --num-continuous-decode-steps 1 --attention-backend flashinfer --context-length 4096 --mem-fraction-static 0.6 --chunked-prefill-size -1 --max-prefill-tokens 32768 --schedule-policy lpm --schedule-conservativeness 1.0 --cpu-offload-gb 0 --dtype bfloat16 --kv-cache-dtype auto --dp-size 1 --ep-size 1 --max-loaded-loras 1 --max-loras-per-batch 1 --lora-backend triton --log-level warning --log-level-http warning --log-requests-level 0 --enable-metrics --decode-log-interval 1[0m
2025-11-26T17:52:14.196952031Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:52:14.196991711Z   import pynvml  # type: ignore[import]
2025-11-26T17:52:19.502665170Z INFO 11-26 17:52:19 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:52:20.213726228Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:52:21.212908566Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:52:21.212951190Z   import pynvml  # type: ignore[import]
2025-11-26T17:52:21.219249043Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:52:21.219268111Z   import pynvml  # type: ignore[import]
2025-11-26T17:52:26.392428013Z INFO 11-26 17:52:26 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:52:27.052735199Z INFO 11-26 17:52:27 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:52:27.666628642Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:52:27.895486663Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:52:27.899241747Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:52:27.900064499Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:52:27.904222217Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:52:27.935294410Z [2025-11-26 17:52:27] MOE_RUNNER_BACKEND is not initialized, using triton backend
2025-11-26T17:52:28.447106048Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:52:28.447193909Z   warnings.warn(
2025-11-26T17:52:28.447197484Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:52:28.447199798Z   warnings.warn(
2025-11-26T17:52:29.751103259Z Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
2025-11-26T17:52:29.872595459Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  8.24it/s]
2025-11-26T17:52:29.873263508Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  8.22it/s]
2025-11-26T17:52:32.397298981Z   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   4%|â–         | 1/23 [00:00<00:11,  1.84it/s]Capturing batches (bs=152 avail_mem=30.62 GB):   4%|â–         | 1/23 [00:00<00:11,  1.84it/s]Capturing batches (bs=144 avail_mem=30.60 GB):   4%|â–         | 1/23 [00:00<00:11,  1.84it/s]Capturing batches (bs=136 avail_mem=30.59 GB):   4%|â–         | 1/23 [00:00<00:11,  1.84it/s]Capturing batches (bs=136 avail_mem=30.59 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.26it/s]Capturing batches (bs=128 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.26it/s]Capturing batches (bs=120 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.26it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.26it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.57it/s]Capturing batches (bs=104 avail_mem=30.54 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.57it/s]Capturing batches (bs=96 avail_mem=30.53 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.57it/s] Capturing batches (bs=88 avail_mem=30.51 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.57it/s]Capturing batches (bs=88 avail_mem=30.51 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.92it/s]Capturing batches (bs=80 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.92it/s]Capturing batches (bs=72 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.92it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:01<00:00, 14.92it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.42it/s]Capturing batches (bs=56 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.42it/s]Capturing batches (bs=48 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.42it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.42it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.45it/s]Capturing batches (bs=32 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.45it/s]Capturing batches (bs=24 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.45it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.45it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.86it/s]Capturing batches (bs=8 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.86it/s] Capturing batches (bs=4 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.86it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.86it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.64it/s]Capturing batches (bs=1 avail_mem=30.35 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.64it/s]Capturing batches (bs=1 avail_mem=30.35 GB): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00, 14.98it/s]
2025-11-26T17:52:38.196639882Z [37m20251126-17:52:38.196 SGLangServer Wrapper INFO: SGLang server launched at: http://172.21.0.2:25360[0m
2025-11-26T17:52:38.916320702Z [37m20251126-17:52:38.915 Launcher Utils INFO: Found 1 rollout servers: 172.21.0.2:25360[0m
2025-11-26T17:52:38.916352800Z [37m20251126-17:52:38.916 Local Scheduler INFO: LLM inference server launched at: AREAL_LLM_SERVER_ADDRS=172.21.0.2:25360[0m
2025-11-26T17:52:38.919088749Z [37m20251126-17:52:38.918 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL AREAL_LLM_SERVER_ADDRS=172.21.0.2:25360 AREAL_RECOVER_RUN=0 NCCL_CUMEM_ENABLE=0 NCCL_NVLS_ENABLE=0 CUDA_VISIBLE_DEVICES=1 stdbuf -oL torchrun --nnodes 1 --nproc-per-node 1 --master-addr localhost --master-port 17965 examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_175206 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_175206/trainer.log[0m
2025-11-26T17:52:38.919675197Z [37m20251126-17:52:38.919 Local Scheduler INFO: Waiting for 2 local running processes, pids: 315 965[0m
2025-11-26T17:52:39.454748107Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:52:39.454793856Z   import pynvml  # type: ignore[import]
2025-11-26T17:52:40.679911124Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:52:40.679952597Z   import pynvml  # type: ignore[import]
2025-11-26T17:52:47.331201706Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:52:47.331253764Z   warnings.warn(
2025-11-26T17:52:47.331257019Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:52:47.331259323Z   warnings.warn(
2025-11-26T17:52:47.753863039Z Traceback (most recent call last):
2025-11-26T17:52:47.753907245Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 665, in <module>
2025-11-26T17:52:47.754512983Z     main(sys.argv[1:])
2025-11-26T17:52:47.754523498Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 102, in main
2025-11-26T17:52:47.754526823Z     config, _ = load_expr_config(args_with_overrides, GRPOConfig)
2025-11-26T17:52:47.754529668Z                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:52:47.754531760Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1282, in load_expr_config
2025-11-26T17:52:47.754533954Z     cfg = to_structured_cfg(cfg, config_cls=config_cls)
2025-11-26T17:52:47.755481173Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:52:47.755492039Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1276, in to_structured_cfg
2025-11-26T17:52:47.755495484Z     cfg = OmegaConf.merge(default_cfg, cfg)
2025-11-26T17:52:47.755497758Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:52:47.755499851Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/omegaconf.py", line 274, in merge
2025-11-26T17:52:47.755502385Z     target.merge_with(
2025-11-26T17:52:47.755504898Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 507, in merge_with
2025-11-26T17:52:47.755507393Z     self._format_and_raise(key=None, value=None, cause=e)
2025-11-26T17:52:47.755509596Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:52:47.755511609Z     format_and_raise(
2025-11-26T17:52:47.755513602Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:52:47.755515725Z     _raise(ex, cause)
2025-11-26T17:52:47.755517848Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:52:47.755519981Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:52:47.755972939Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:52:47.755997606Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 502, in merge_with
2025-11-26T17:52:47.756000921Z     self._merge_with(
2025-11-26T17:52:47.756003725Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:52:47.756006460Z     BaseContainer._map_merge(
2025-11-26T17:52:47.756009995Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:52:47.756012188Z     dest_node._merge_with(
2025-11-26T17:52:47.756014231Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:52:47.756016344Z     BaseContainer._map_merge(
2025-11-26T17:52:47.756018398Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:52:47.756020470Z     dest_node._merge_with(
2025-11-26T17:52:47.756022544Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:52:47.756360360Z     BaseContainer._map_merge(
2025-11-26T17:52:47.756366660Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 432, in _map_merge
2025-11-26T17:52:47.756369003Z     dest[key] = src._get_node(key)
2025-11-26T17:52:47.756371296Z     ~~~~^^^^^
2025-11-26T17:52:47.756386469Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 308, in __setitem__
2025-11-26T17:52:47.756388833Z     self._format_and_raise(
2025-11-26T17:52:47.756390876Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:52:47.756393199Z     format_and_raise(
2025-11-26T17:52:47.756395392Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:52:47.756850043Z     _raise(ex, cause)
2025-11-26T17:52:47.756854830Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:52:47.756858045Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:52:47.756860188Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:52:47.756862462Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 306, in __setitem__
2025-11-26T17:52:47.756864906Z     self.__set_impl(key=key, value=value)
2025-11-26T17:52:47.756866909Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 316, in __set_impl
2025-11-26T17:52:47.756869262Z     self._set_item_impl(key, value)
2025-11-26T17:52:47.756871505Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 579, in _set_item_impl
2025-11-26T17:52:47.757248340Z     target_node_ref = self._get_node(key)
2025-11-26T17:52:47.757253978Z                       ^^^^^^^^^^^^^^^^^^^
2025-11-26T17:52:47.757256182Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 473, in _get_node
2025-11-26T17:52:47.757258576Z     self._validate_get(key)
2025-11-26T17:52:47.757260599Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 163, in _validate_get
2025-11-26T17:52:47.757262872Z     self._format_and_raise(
2025-11-26T17:52:47.757265175Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:52:47.757636381Z     format_and_raise(
2025-11-26T17:52:47.757640176Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 906, in format_and_raise
2025-11-26T17:52:47.757642570Z     _raise(ex, cause)
2025-11-26T17:52:47.757644673Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:52:47.757647026Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:52:47.757981798Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:52:47.757985754Z omegaconf.errors.ConfigKeyError: Key 'max_new_tokens' not in 'NormConfig'
2025-11-26T17:52:47.757988819Z     full_key: actor.adv_norm.max_new_tokens
2025-11-26T17:52:47.757990832Z     reference_type=Optional[NormConfig]
2025-11-26T17:52:47.757992885Z     object_type=NormConfig
2025-11-26T17:52:50.082850765Z E1126 17:52:50.081000 966 torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 0 (pid: 1032) of binary: /usr/bin/python3
2025-11-26T17:52:50.083476461Z Traceback (most recent call last):
2025-11-26T17:52:50.083483331Z   File "/usr/local/bin/torchrun", line 7, in <module>
2025-11-26T17:52:50.083485975Z     sys.exit(main())
2025-11-26T17:52:50.083489260Z              ^^^^^^
2025-11-26T17:52:50.083491314Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
2025-11-26T17:52:50.083493947Z     return f(*args, **kwargs)
2025-11-26T17:52:50.083496511Z            ^^^^^^^^^^^^^^^^^^
2025-11-26T17:52:50.083498474Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 901, in main
2025-11-26T17:52:50.083804973Z     run(args)
2025-11-26T17:52:50.083808458Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 892, in run
2025-11-26T17:52:50.083811243Z     elastic_launch(
2025-11-26T17:52:50.083813606Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 143, in __call__
2025-11-26T17:52:50.083816490Z     return launch_agent(self._config, self._entrypoint, list(args))
2025-11-26T17:52:50.083819385Z            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:52:50.083841879Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 277, in launch_agent
2025-11-26T17:52:50.084416910Z     raise ChildFailedError(
2025-11-26T17:52:50.084458172Z torch.distributed.elastic.multiprocessing.errors.ChildFailedError:
2025-11-26T17:52:50.084461467Z ============================================================
2025-11-26T17:52:50.084463931Z examples/cloud_gsm8k/gsm8k_grpo_train.py FAILED
2025-11-26T17:52:50.084466815Z ------------------------------------------------------------
2025-11-26T17:52:50.084468818Z Failures:
2025-11-26T17:52:50.084471552Z   <NO_OTHER_FAILURES>
2025-11-26T17:52:50.084474467Z ------------------------------------------------------------
2025-11-26T17:52:50.084476550Z Root Cause (first observed failure):
2025-11-26T17:52:50.084478603Z [0]:
2025-11-26T17:52:50.084480716Z   time      : 2025-11-26_17:52:50
2025-11-26T17:52:50.084482749Z   host      : cef7c503fdea
2025-11-26T17:52:50.084484912Z   rank      : 0 (local_rank: 0)
2025-11-26T17:52:50.084487025Z   exitcode  : 1 (pid: 1032)
2025-11-26T17:52:50.084489089Z   error_file: <N/A>
2025-11-26T17:52:50.084491052Z   traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
2025-11-26T17:52:50.084493856Z ============================================================
2025-11-26T17:52:50.922715935Z [37m20251126-17:52:50.922 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [315][0m
2025-11-26T17:52:51.041107470Z Killed
2025-11-26T17:52:51.051166377Z [37m20251126-17:52:51.050 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [965][0m
2025-11-26T17:52:51.052817650Z Traceback (most recent call last):
2025-11-26T17:52:51.052832112Z   File "<frozen runpy>", line 198, in _run_module_as_main
2025-11-26T17:52:51.052835467Z   File "<frozen runpy>", line 88, in _run_code
2025-11-26T17:52:51.052837611Z   File "/workspace/AReaL/areal/launcher/local.py", line 405, in <module>
2025-11-26T17:52:51.052840335Z     main()
2025-11-26T17:52:51.052842738Z   File "/workspace/AReaL/areal/launcher/local.py", line 260, in main
2025-11-26T17:52:51.052844751Z     local_main(config, run_id=0)
2025-11-26T17:52:51.052847425Z   File "/workspace/AReaL/areal/launcher/local.py", line 399, in local_main
2025-11-26T17:52:51.052849518Z     raise e
2025-11-26T17:52:51.052851491Z   File "/workspace/AReaL/areal/launcher/local.py", line 375, in local_main
2025-11-26T17:52:51.052853444Z     launcher.wait(
2025-11-26T17:52:51.052856088Z   File "/workspace/AReaL/areal/launcher/local.py", line 235, in wait
2025-11-26T17:52:51.052858091Z     raise JobException(
2025-11-26T17:52:51.052860114Z areal.utils.launcher.JobException: Job gsm8k-grpo-cloud-2gpu-2000samples_trial_20251126_175206:trainer JobState.COMPLETED at node local
2025-11-26T17:52:51.230694637Z [37m20251126-17:52:51.230 Local Scheduler INFO: Waiting for 0 local running processes, pids: [0m
2025-11-26T17:52:53.847440037Z ==========
2025-11-26T17:52:53.847443493Z == CUDA ==
2025-11-26T17:52:53.847486346Z ==========
2025-11-26T17:52:53.852413968Z CUDA Version 12.9.1
2025-11-26T17:52:53.854074935Z Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
2025-11-26T17:52:53.856045066Z This container image and its contents are governed by the NVIDIA Deep Learning Container License.
2025-11-26T17:52:53.856047700Z By pulling and using the container, you accept the terms and conditions of this license:
2025-11-26T17:52:53.856050244Z https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license
2025-11-26T17:52:53.856054771Z A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
2025-11-26T17:52:54.020257295Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:52:54.179033501Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:52:54.361246704Z Branch 'feature/reasoning_model' set up to track remote branch 'feature/reasoning_model' from 'origin'.
2025-11-26T17:52:54.361286003Z Your branch is up to date with 'origin/feature/reasoning_model'.
2025-11-26T17:52:54.432978148Z Checking AReaL installation...
2025-11-26T17:52:54.492495958Z AReaL already installed. Skipping installation.
2025-11-26T17:52:54.492526764Z Cleaning up any leftover GPU processes...
2025-11-26T17:52:57.512650333Z Checking for processes holding GPU device files...
2025-11-26T17:53:00.168288329Z Found processes holding GPU devices: 1
2025-11-26T17:53:00.168332084Z 20
2025-11-26T17:53:00.168334598Z 71
2025-11-26T17:53:00.168337212Z 72
2025-11-26T17:53:00.168339255Z Killing process 1...
2025-11-26T17:53:00.168341959Z Killing process 71...
2025-11-26T17:53:00.168492955Z Killing process 72...
2025-11-26T17:53:02.171334505Z Using fuser to kill processes on GPU devices...
2025-11-26T17:53:04.195503031Z Checking GPU...
2025-11-26T17:53:04.230691068Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:53:04.230722675Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:53:04.249000674Z Set PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True for better memory management
2025-11-26T17:53:04.249021034Z Detected 2 GPU(s)
2025-11-26T17:53:04.249024099Z Checking GPU status...
2025-11-26T17:53:04.276425813Z index, name, utilization.gpu [%], memory.used [MiB], compute_mode
2025-11-26T17:53:04.277923867Z 0, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:53:04.278258618Z 1, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:53:04.319785880Z Verifying GPU accessibility...
2025-11-26T17:53:04.881065896Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:53:04.881169242Z   import pynvml  # type: ignore[import]
2025-11-26T17:53:06.003983162Z GPU accessibility verified on attempt 1
2025-11-26T17:53:06.551782546Z Starting training...
2025-11-26T17:53:09.554842616Z Using STANDARD 2000 SAMPLES 2 GPUs configuration
2025-11-26T17:53:09.554879761Z Note: GRPO only (no reasoning XML). Dataset capped at 2000 samples (~6 hours).
2025-11-26T17:53:09.554883486Z GPU count: 2 (required: 2)
2025-11-26T17:53:09.557346416Z ==========================================
2025-11-26T17:53:09.557349561Z Starting GRPO Training (Cloud)
2025-11-26T17:53:09.557352475Z ==========================================
2025-11-26T17:53:09.557354578Z Config: standard_2000samples_2GPUs
2025-11-26T17:53:09.557356721Z Config file: examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml
2025-11-26T17:53:09.557359445Z Training script: examples/cloud_gsm8k/gsm8k_grpo_train.py
2025-11-26T17:53:09.557362209Z Experiment: gsm8k-grpo-cloud-2gpu-2000samples
2025-11-26T17:53:09.557364212Z Trial: trial_20251126_175309
2025-11-26T17:53:09.557366486Z GPU: NVIDIA A100 80GB PCIe NVIDIA A100 80GB PCIe (81920 MB)
2025-11-26T17:53:09.557375019Z WandB API key: e1adc5be02...
2025-11-26T17:53:09.557377242Z ==========================================
2025-11-26T17:53:10.224694747Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:53:10.224732815Z   import pynvml  # type: ignore[import]
2025-11-26T17:53:14.129908578Z [37m20251126-17:53:14.129 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:53:14.129964001Z [37m20251126-17:53:14.129 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:53:14.130203099Z [37m20251126-17:53:14.129 name-resolve INFO: No such name resolve path: ./tmp/areal/name_resolve/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_175309[0m
2025-11-26T17:53:14.238309379Z [37m20251126-17:53:14.237 Local Scheduler INFO: LocalLauncher: experiment_name=gsm8k-grpo-cloud-2gpu-2000samples, trial_name=trial_20251126_175309, fileroot=/workspace/outputs/grpo, run_id=0, is_recover_run=False[0m
2025-11-26T17:53:14.245795412Z [37m20251126-17:53:14.245 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL CUDA_VISIBLE_DEVICES=0 stdbuf -oL python3 -m areal.launcher.sglang_server examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_175309 sglang.random_seed=1 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_175309/llm_server.log[0m
2025-11-26T17:53:14.945452358Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:53:14.945485388Z   import pynvml  # type: ignore[import]
2025-11-26T17:53:16.428602608Z [37m20251126-17:53:16.428 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:53:16.429266553Z [37m20251126-17:53:16.428 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:53:16.533519900Z [37m20251126-17:53:16.532 SGLangServer Wrapper INFO: Launch command: python3 -m sglang.launch_server --host 172.21.0.2 --port 26333 --tokenizer-path Qwen/Qwen2.5-0.5B-Instruct --tokenizer-mode auto --load-format auto --trust-remote-code --device cuda --tp-size 1 --base-gpu-id 0 --nnodes 1 --node-rank 0 --dist-init-addr localhost:27210 --model-path Qwen/Qwen2.5-0.5B-Instruct --random-seed 1 --skip-tokenizer-init --disable-radix-cache --torch-compile-max-bs 32 --triton-attention-num-kv-splits 8 --num-continuous-decode-steps 1 --attention-backend flashinfer --context-length 4096 --mem-fraction-static 0.6 --chunked-prefill-size -1 --max-prefill-tokens 32768 --schedule-policy lpm --schedule-conservativeness 1.0 --cpu-offload-gb 0 --dtype bfloat16 --kv-cache-dtype auto --dp-size 1 --ep-size 1 --max-loaded-loras 1 --max-loras-per-batch 1 --lora-backend triton --log-level warning --log-level-http warning --log-requests-level 0 --enable-metrics --decode-log-interval 1[0m
2025-11-26T17:53:17.828363941Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:53:17.828415368Z   import pynvml  # type: ignore[import]
2025-11-26T17:53:23.151900287Z INFO 11-26 17:53:23 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:53:23.777307057Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:53:24.769226505Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:53:24.769263841Z   import pynvml  # type: ignore[import]
2025-11-26T17:53:24.820562989Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:53:24.820596690Z   import pynvml  # type: ignore[import]
2025-11-26T17:53:29.925193573Z INFO 11-26 17:53:29 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:53:30.496757463Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:53:30.603792187Z INFO 11-26 17:53:30 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:53:30.705878920Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:53:30.709352343Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:53:30.710226772Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:53:30.711039179Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:53:30.743205921Z [2025-11-26 17:53:30] MOE_RUNNER_BACKEND is not initialized, using triton backend
2025-11-26T17:53:31.220927357Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:53:31.220966434Z   warnings.warn(
2025-11-26T17:53:31.220969950Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:53:31.220972403Z   warnings.warn(
2025-11-26T17:53:32.305815310Z Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
2025-11-26T17:53:32.411624187Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  9.46it/s]
2025-11-26T17:53:32.412269685Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  9.44it/s]
2025-11-26T17:53:34.808315805Z   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   4%|â–         | 1/23 [00:00<00:11,  1.88it/s]Capturing batches (bs=152 avail_mem=30.62 GB):   4%|â–         | 1/23 [00:00<00:11,  1.88it/s]Capturing batches (bs=144 avail_mem=30.60 GB):   4%|â–         | 1/23 [00:00<00:11,  1.88it/s]Capturing batches (bs=136 avail_mem=30.59 GB):   4%|â–         | 1/23 [00:00<00:11,  1.88it/s]Capturing batches (bs=136 avail_mem=30.59 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.38it/s]Capturing batches (bs=128 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.38it/s]Capturing batches (bs=120 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.38it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.38it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.73it/s]Capturing batches (bs=104 avail_mem=30.54 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.73it/s]Capturing batches (bs=96 avail_mem=30.53 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.73it/s] Capturing batches (bs=88 avail_mem=30.51 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.73it/s]Capturing batches (bs=88 avail_mem=30.51 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 15.09it/s]Capturing batches (bs=80 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 15.09it/s]Capturing batches (bs=72 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 15.09it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 15.09it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.63it/s]Capturing batches (bs=56 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.63it/s]Capturing batches (bs=48 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.63it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.63it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.68it/s]Capturing batches (bs=32 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.68it/s]Capturing batches (bs=24 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.68it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.68it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 18.10it/s]Capturing batches (bs=8 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 18.10it/s] Capturing batches (bs=4 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 18.10it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 18.10it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.93it/s]Capturing batches (bs=1 avail_mem=30.35 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.93it/s]Capturing batches (bs=1 avail_mem=30.35 GB): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00, 15.21it/s]
2025-11-26T17:53:40.564700102Z [37m20251126-17:53:40.564 SGLangServer Wrapper INFO: SGLang server launched at: http://172.21.0.2:26333[0m
2025-11-26T17:53:41.253026096Z [37m20251126-17:53:41.252 Launcher Utils INFO: Found 1 rollout servers: 172.21.0.2:26333[0m
2025-11-26T17:53:41.253067168Z [37m20251126-17:53:41.252 Local Scheduler INFO: LLM inference server launched at: AREAL_LLM_SERVER_ADDRS=172.21.0.2:26333[0m
2025-11-26T17:53:41.256236845Z [37m20251126-17:53:41.256 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL AREAL_LLM_SERVER_ADDRS=172.21.0.2:26333 AREAL_RECOVER_RUN=0 NCCL_CUMEM_ENABLE=0 NCCL_NVLS_ENABLE=0 CUDA_VISIBLE_DEVICES=1 stdbuf -oL torchrun --nnodes 1 --nproc-per-node 1 --master-addr localhost --master-port 13713 examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_175309 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_175309/trainer.log[0m
2025-11-26T17:53:41.257336533Z [37m20251126-17:53:41.257 Local Scheduler INFO: Waiting for 2 local running processes, pids: 315 965[0m
2025-11-26T17:53:41.828405821Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:53:41.828451440Z   import pynvml  # type: ignore[import]
2025-11-26T17:53:43.029969240Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:53:43.030007546Z   import pynvml  # type: ignore[import]
2025-11-26T17:53:49.833928840Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:53:49.833983732Z   warnings.warn(
2025-11-26T17:53:49.833986947Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:53:49.833997203Z   warnings.warn(
2025-11-26T17:53:50.273492009Z Traceback (most recent call last):
2025-11-26T17:53:50.273533151Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 665, in <module>
2025-11-26T17:53:50.274295053Z     main(sys.argv[1:])
2025-11-26T17:53:50.274305257Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 102, in main
2025-11-26T17:53:50.274309223Z     config, _ = load_expr_config(args_with_overrides, GRPOConfig)
2025-11-26T17:53:50.274311777Z                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:53:50.274313790Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1282, in load_expr_config
2025-11-26T17:53:50.274315803Z     cfg = to_structured_cfg(cfg, config_cls=config_cls)
2025-11-26T17:53:50.274318857Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:53:50.274321031Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1276, in to_structured_cfg
2025-11-26T17:53:50.274719949Z     cfg = OmegaConf.merge(default_cfg, cfg)
2025-11-26T17:53:50.274722813Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:53:50.274724846Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/omegaconf.py", line 274, in merge
2025-11-26T17:53:50.274726989Z     target.merge_with(
2025-11-26T17:53:50.274729593Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 507, in merge_with
2025-11-26T17:53:50.274732247Z     self._format_and_raise(key=None, value=None, cause=e)
2025-11-26T17:53:50.274734921Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:53:50.275298175Z     format_and_raise(
2025-11-26T17:53:50.275303212Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:53:50.275306026Z     _raise(ex, cause)
2025-11-26T17:53:50.275308039Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:53:50.275310042Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:53:50.275312015Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:53:50.275314559Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 502, in merge_with
2025-11-26T17:53:50.275316542Z     self._merge_with(
2025-11-26T17:53:50.275318815Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:53:50.275737694Z     BaseContainer._map_merge(
2025-11-26T17:53:50.275761198Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:53:50.275764313Z     dest_node._merge_with(
2025-11-26T17:53:50.275766465Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:53:50.275768859Z     BaseContainer._map_merge(
2025-11-26T17:53:50.275770932Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:53:50.275773276Z     dest_node._merge_with(
2025-11-26T17:53:50.275775339Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:53:50.275777402Z     BaseContainer._map_merge(
2025-11-26T17:53:50.275779355Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 432, in _map_merge
2025-11-26T17:53:50.276545003Z     dest[key] = src._get_node(key)
2025-11-26T17:53:50.276551192Z     ~~~~^^^^^
2025-11-26T17:53:50.276553956Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 308, in __setitem__
2025-11-26T17:53:50.276567496Z     self._format_and_raise(
2025-11-26T17:53:50.276570531Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:53:50.276572594Z     format_and_raise(
2025-11-26T17:53:50.276574587Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:53:50.276576630Z     _raise(ex, cause)
2025-11-26T17:53:50.276578573Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:53:50.276580626Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:53:50.276582589Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:53:50.276584772Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 306, in __setitem__
2025-11-26T17:53:50.276586825Z     self.__set_impl(key=key, value=value)
2025-11-26T17:53:50.276588808Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 316, in __set_impl
2025-11-26T17:53:50.276590911Z     self._set_item_impl(key, value)
2025-11-26T17:53:50.276592924Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 579, in _set_item_impl
2025-11-26T17:53:50.276595078Z     target_node_ref = self._get_node(key)
2025-11-26T17:53:50.276922218Z                       ^^^^^^^^^^^^^^^^^^^
2025-11-26T17:53:50.276928798Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 473, in _get_node
2025-11-26T17:53:50.276932403Z     self._validate_get(key)
2025-11-26T17:53:50.276934626Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 163, in _validate_get
2025-11-26T17:53:50.276936859Z     self._format_and_raise(
2025-11-26T17:53:50.276938942Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:53:50.276941245Z     format_and_raise(
2025-11-26T17:53:50.276944009Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 906, in format_and_raise
2025-11-26T17:53:50.277288856Z     _raise(ex, cause)
2025-11-26T17:53:50.277294494Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:53:50.277296788Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:53:50.277298941Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:53:50.277301305Z omegaconf.errors.ConfigKeyError: Key 'max_new_tokens' not in 'NormConfig'
2025-11-26T17:53:50.277303408Z     full_key: actor.adv_norm.max_new_tokens
2025-11-26T17:53:50.277305511Z     reference_type=Optional[NormConfig]
2025-11-26T17:53:50.277307814Z     object_type=NormConfig
2025-11-26T17:53:52.636062237Z E1126 17:53:52.635000 966 torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 0 (pid: 1032) of binary: /usr/bin/python3
2025-11-26T17:53:52.636851129Z Traceback (most recent call last):
2025-11-26T17:53:52.636857629Z   File "/usr/local/bin/torchrun", line 7, in <module>
2025-11-26T17:53:52.636859832Z     sys.exit(main())
2025-11-26T17:53:52.636862265Z              ^^^^^^
2025-11-26T17:53:52.636864288Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
2025-11-26T17:53:52.636866862Z     return f(*args, **kwargs)
2025-11-26T17:53:52.636868955Z            ^^^^^^^^^^^^^^^^^^
2025-11-26T17:53:52.636871018Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 901, in main
2025-11-26T17:53:52.637583636Z     run(args)
2025-11-26T17:53:52.637589124Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 892, in run
2025-11-26T17:53:52.637591918Z     elastic_launch(
2025-11-26T17:53:52.637594412Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 143, in __call__
2025-11-26T17:53:52.637596905Z     return launch_agent(self._config, self._entrypoint, list(args))
2025-11-26T17:53:52.637599609Z            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:53:52.637601623Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 277, in launch_agent
2025-11-26T17:53:52.637612439Z     raise ChildFailedError(
2025-11-26T17:53:52.637614983Z torch.distributed.elastic.multiprocessing.errors.ChildFailedError:
2025-11-26T17:53:52.637616975Z ============================================================
2025-11-26T17:53:52.637619018Z examples/cloud_gsm8k/gsm8k_grpo_train.py FAILED
2025-11-26T17:53:52.637621422Z ------------------------------------------------------------
2025-11-26T17:53:52.637623495Z Failures:
2025-11-26T17:53:52.637625799Z   <NO_OTHER_FAILURES>
2025-11-26T17:53:52.637627852Z ------------------------------------------------------------
2025-11-26T17:53:52.637629815Z Root Cause (first observed failure):
2025-11-26T17:53:52.637631808Z [0]:
2025-11-26T17:53:52.637634011Z   time      : 2025-11-26_17:53:52
2025-11-26T17:53:52.637636014Z   host      : cef7c503fdea
2025-11-26T17:53:52.637637997Z   rank      : 0 (local_rank: 0)
2025-11-26T17:53:52.637639990Z   exitcode  : 1 (pid: 1032)
2025-11-26T17:53:52.637642023Z   error_file: <N/A>
2025-11-26T17:53:52.637644056Z   traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
2025-11-26T17:53:52.637646099Z ============================================================
2025-11-26T17:53:53.260790209Z [37m20251126-17:53:53.260 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [315][0m
2025-11-26T17:53:53.376136363Z Killed
2025-11-26T17:53:53.386261489Z [37m20251126-17:53:53.386 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [965][0m
2025-11-26T17:53:53.387223580Z Traceback (most recent call last):
2025-11-26T17:53:53.387234927Z   File "<frozen runpy>", line 198, in _run_module_as_main
2025-11-26T17:53:53.387237682Z   File "<frozen runpy>", line 88, in _run_code
2025-11-26T17:53:53.387239794Z   File "/workspace/AReaL/areal/launcher/local.py", line 405, in <module>
2025-11-26T17:53:53.387378273Z     main()
2025-11-26T17:53:53.387383190Z   File "/workspace/AReaL/areal/launcher/local.py", line 260, in main
2025-11-26T17:53:53.387477120Z     local_main(config, run_id=0)
2025-11-26T17:53:53.387480886Z   File "/workspace/AReaL/areal/launcher/local.py", line 399, in local_main
2025-11-26T17:53:53.387560425Z     raise e
2025-11-26T17:53:53.387562949Z   File "/workspace/AReaL/areal/launcher/local.py", line 375, in local_main
2025-11-26T17:53:53.387637631Z     launcher.wait(
2025-11-26T17:53:53.387640345Z   File "/workspace/AReaL/areal/launcher/local.py", line 235, in wait
2025-11-26T17:53:53.387689719Z     raise JobException(
2025-11-26T17:53:53.387692593Z areal.utils.launcher.JobException: Job gsm8k-grpo-cloud-2gpu-2000samples_trial_20251126_175309:trainer JobState.COMPLETED at node local
2025-11-26T17:53:53.564577895Z [37m20251126-17:53:53.563 Local Scheduler INFO: Waiting for 0 local running processes, pids: [0m
2025-11-26T17:53:56.573260927Z ==========
2025-11-26T17:53:56.573264002Z == CUDA ==
2025-11-26T17:53:56.573267076Z ==========
2025-11-26T17:53:56.577936250Z CUDA Version 12.9.1
2025-11-26T17:53:56.579894002Z Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
2025-11-26T17:53:56.581375571Z This container image and its contents are governed by the NVIDIA Deep Learning Container License.
2025-11-26T17:53:56.581378396Z By pulling and using the container, you accept the terms and conditions of this license:
2025-11-26T17:53:56.581381049Z https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license
2025-11-26T17:53:56.581385246Z A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
2025-11-26T17:53:56.752170910Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:53:56.912008507Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:53:57.102690904Z Branch 'feature/reasoning_model' set up to track remote branch 'feature/reasoning_model' from 'origin'.
2025-11-26T17:53:57.102727479Z Your branch is up to date with 'origin/feature/reasoning_model'.
2025-11-26T17:53:57.174104063Z Checking AReaL installation...
2025-11-26T17:53:57.231889668Z AReaL already installed. Skipping installation.
2025-11-26T17:53:57.231930359Z Cleaning up any leftover GPU processes...
2025-11-26T17:54:00.255641401Z Checking for processes holding GPU device files...
2025-11-26T17:54:02.331244288Z Found processes holding GPU devices: 1
2025-11-26T17:54:02.331285590Z 20
2025-11-26T17:54:02.331288906Z 71
2025-11-26T17:54:02.331291049Z 72
2025-11-26T17:54:02.331293092Z Killing process 1...
2025-11-26T17:54:02.331296086Z Killing process 71...
2025-11-26T17:54:02.331368634Z Killing process 72...
2025-11-26T17:54:04.334706017Z Using fuser to kill processes on GPU devices...
2025-11-26T17:54:06.359058278Z Checking GPU...
2025-11-26T17:54:06.397205878Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:54:06.397233029Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:54:06.414045211Z Set PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True for better memory management
2025-11-26T17:54:06.414064911Z Detected 2 GPU(s)
2025-11-26T17:54:06.414068286Z Checking GPU status...
2025-11-26T17:54:06.441192616Z index, name, utilization.gpu [%], memory.used [MiB], compute_mode
2025-11-26T17:54:06.442679972Z 0, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:54:06.442917519Z 1, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:54:06.484130691Z Verifying GPU accessibility...
2025-11-26T17:54:07.018325015Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:54:07.018393298Z   import pynvml  # type: ignore[import]
2025-11-26T17:54:08.107921952Z GPU accessibility verified on attempt 1
2025-11-26T17:54:08.565236250Z Starting training...
2025-11-26T17:54:11.567871894Z Using STANDARD 2000 SAMPLES 2 GPUs configuration
2025-11-26T17:54:11.567911102Z Note: GRPO only (no reasoning XML). Dataset capped at 2000 samples (~6 hours).
2025-11-26T17:54:11.567915038Z GPU count: 2 (required: 2)
2025-11-26T17:54:11.570883585Z ==========================================
2025-11-26T17:54:11.570886890Z Starting GRPO Training (Cloud)
2025-11-26T17:54:11.570889844Z ==========================================
2025-11-26T17:54:11.570891948Z Config: standard_2000samples_2GPUs
2025-11-26T17:54:11.570894051Z Config file: examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml
2025-11-26T17:54:11.570900911Z Training script: examples/cloud_gsm8k/gsm8k_grpo_train.py
2025-11-26T17:54:11.570903485Z Experiment: gsm8k-grpo-cloud-2gpu-2000samples
2025-11-26T17:54:11.570905548Z Trial: trial_20251126_175411
2025-11-26T17:54:11.570907541Z GPU: NVIDIA A100 80GB PCIe NVIDIA A100 80GB PCIe (81920 MB)
2025-11-26T17:54:11.570909554Z WandB API key: e1adc5be02...
2025-11-26T17:54:11.570911847Z ==========================================
2025-11-26T17:54:12.285179108Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:54:12.285216725Z   import pynvml  # type: ignore[import]
2025-11-26T17:54:16.497358664Z [37m20251126-17:54:16.496 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:54:16.497406947Z [37m20251126-17:54:16.497 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:54:16.497805473Z [37m20251126-17:54:16.497 name-resolve INFO: No such name resolve path: ./tmp/areal/name_resolve/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_175411[0m
2025-11-26T17:54:16.605751703Z [37m20251126-17:54:16.605 Local Scheduler INFO: LocalLauncher: experiment_name=gsm8k-grpo-cloud-2gpu-2000samples, trial_name=trial_20251126_175411, fileroot=/workspace/outputs/grpo, run_id=0, is_recover_run=False[0m
2025-11-26T17:54:16.613197045Z [37m20251126-17:54:16.612 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL CUDA_VISIBLE_DEVICES=0 stdbuf -oL python3 -m areal.launcher.sglang_server examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_175411 sglang.random_seed=1 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_175411/llm_server.log[0m
2025-11-26T17:54:17.355322044Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:54:17.355372920Z   import pynvml  # type: ignore[import]
2025-11-26T17:54:18.864768231Z [37m20251126-17:54:18.864 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:54:18.865787708Z [37m20251126-17:54:18.864 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:54:18.982864894Z [37m20251126-17:54:18.982 SGLangServer Wrapper INFO: Launch command: python3 -m sglang.launch_server --host 172.21.0.2 --port 23015 --tokenizer-path Qwen/Qwen2.5-0.5B-Instruct --tokenizer-mode auto --load-format auto --trust-remote-code --device cuda --tp-size 1 --base-gpu-id 0 --nnodes 1 --node-rank 0 --dist-init-addr localhost:27603 --model-path Qwen/Qwen2.5-0.5B-Instruct --random-seed 1 --skip-tokenizer-init --disable-radix-cache --torch-compile-max-bs 32 --triton-attention-num-kv-splits 8 --num-continuous-decode-steps 1 --attention-backend flashinfer --context-length 4096 --mem-fraction-static 0.6 --chunked-prefill-size -1 --max-prefill-tokens 32768 --schedule-policy lpm --schedule-conservativeness 1.0 --cpu-offload-gb 0 --dtype bfloat16 --kv-cache-dtype auto --dp-size 1 --ep-size 1 --max-loaded-loras 1 --max-loras-per-batch 1 --lora-backend triton --log-level warning --log-level-http warning --log-requests-level 0 --enable-metrics --decode-log-interval 1[0m
2025-11-26T17:54:20.016353928Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:54:20.016388320Z   import pynvml  # type: ignore[import]
2025-11-26T17:54:25.667326031Z INFO 11-26 17:54:25 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:54:26.351195260Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:54:27.361155331Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:54:27.361196362Z   import pynvml  # type: ignore[import]
2025-11-26T17:54:27.392006192Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:54:27.392043317Z   import pynvml  # type: ignore[import]
2025-11-26T17:54:32.552958598Z INFO 11-26 17:54:32 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:54:32.671698564Z INFO 11-26 17:54:32 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:54:33.275848354Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:54:33.504409930Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:54:33.507937423Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:54:33.508798313Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:54:33.509618652Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:54:33.542104461Z [2025-11-26 17:54:33] MOE_RUNNER_BACKEND is not initialized, using triton backend
2025-11-26T17:54:34.022348516Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:54:34.022387594Z   warnings.warn(
2025-11-26T17:54:34.022390839Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:54:34.022393123Z   warnings.warn(
2025-11-26T17:54:35.116215588Z Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
2025-11-26T17:54:35.219812774Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  9.67it/s]
2025-11-26T17:54:35.220395457Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  9.65it/s]
2025-11-26T17:54:37.672392013Z   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   4%|â–         | 1/23 [00:00<00:11,  1.84it/s]Capturing batches (bs=152 avail_mem=30.62 GB):   4%|â–         | 1/23 [00:00<00:11,  1.84it/s]Capturing batches (bs=144 avail_mem=30.60 GB):   4%|â–         | 1/23 [00:00<00:11,  1.84it/s]Capturing batches (bs=136 avail_mem=30.59 GB):   4%|â–         | 1/23 [00:00<00:11,  1.84it/s]Capturing batches (bs=136 avail_mem=30.59 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.22it/s]Capturing batches (bs=128 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.22it/s]Capturing batches (bs=120 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.22it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.22it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.41it/s]Capturing batches (bs=104 avail_mem=30.54 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.41it/s]Capturing batches (bs=96 avail_mem=30.53 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.41it/s] Capturing batches (bs=88 avail_mem=30.51 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.41it/s]Capturing batches (bs=88 avail_mem=30.51 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.63it/s]Capturing batches (bs=80 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.63it/s]Capturing batches (bs=72 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.63it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:01<00:00, 14.63it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.18it/s]Capturing batches (bs=56 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.18it/s]Capturing batches (bs=48 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.18it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.18it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.12it/s]Capturing batches (bs=32 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.12it/s]Capturing batches (bs=24 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.12it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.12it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.73it/s]Capturing batches (bs=8 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.73it/s] Capturing batches (bs=4 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.73it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.73it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.60it/s]Capturing batches (bs=1 avail_mem=30.35 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.60it/s]Capturing batches (bs=1 avail_mem=30.35 GB): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00, 14.88it/s]
2025-11-26T17:54:43.011200846Z [37m20251126-17:54:43.010 SGLangServer Wrapper INFO: SGLang server launched at: http://172.21.0.2:23015[0m
2025-11-26T17:54:43.620482661Z [37m20251126-17:54:43.620 Launcher Utils INFO: Found 1 rollout servers: 172.21.0.2:23015[0m
2025-11-26T17:54:43.620519066Z [37m20251126-17:54:43.620 Local Scheduler INFO: LLM inference server launched at: AREAL_LLM_SERVER_ADDRS=172.21.0.2:23015[0m
2025-11-26T17:54:43.623308605Z [37m20251126-17:54:43.623 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL AREAL_LLM_SERVER_ADDRS=172.21.0.2:23015 AREAL_RECOVER_RUN=0 NCCL_CUMEM_ENABLE=0 NCCL_NVLS_ENABLE=0 CUDA_VISIBLE_DEVICES=1 stdbuf -oL torchrun --nnodes 1 --nproc-per-node 1 --master-addr localhost --master-port 40603 examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_175411 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_175411/trainer.log[0m
2025-11-26T17:54:43.623895123Z [37m20251126-17:54:43.623 Local Scheduler INFO: Waiting for 2 local running processes, pids: 315 965[0m
2025-11-26T17:54:44.164193931Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:54:44.164230316Z   import pynvml  # type: ignore[import]
2025-11-26T17:54:45.373538114Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:54:45.373575250Z   import pynvml  # type: ignore[import]
2025-11-26T17:54:52.525990432Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:54:52.526035118Z   warnings.warn(
2025-11-26T17:54:52.526038394Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:54:52.526050481Z   warnings.warn(
2025-11-26T17:54:52.955628355Z Traceback (most recent call last):
2025-11-26T17:54:52.955663567Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 665, in <module>
2025-11-26T17:54:52.956433030Z     main(sys.argv[1:])
2025-11-26T17:54:52.956444417Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 102, in main
2025-11-26T17:54:52.956447432Z     config, _ = load_expr_config(args_with_overrides, GRPOConfig)
2025-11-26T17:54:52.956450225Z                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:54:52.956452259Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1282, in load_expr_config
2025-11-26T17:54:52.956454222Z     cfg = to_structured_cfg(cfg, config_cls=config_cls)
2025-11-26T17:54:52.956456234Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:54:52.956458258Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1276, in to_structured_cfg
2025-11-26T17:54:52.956855072Z     cfg = OmegaConf.merge(default_cfg, cfg)
2025-11-26T17:54:52.956858368Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:54:52.956860921Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/omegaconf.py", line 274, in merge
2025-11-26T17:54:52.956863225Z     target.merge_with(
2025-11-26T17:54:52.956865739Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 507, in merge_with
2025-11-26T17:54:52.956868492Z     self._format_and_raise(key=None, value=None, cause=e)
2025-11-26T17:54:52.956871217Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:54:52.956876344Z     format_and_raise(
2025-11-26T17:54:52.956878878Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:54:52.957290614Z     _raise(ex, cause)
2025-11-26T17:54:52.957328131Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:54:52.957331465Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:54:52.957333729Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:54:52.957336653Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 502, in merge_with
2025-11-26T17:54:52.957721630Z     self._merge_with(
2025-11-26T17:54:52.957725356Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:54:52.957728291Z     BaseContainer._map_merge(
2025-11-26T17:54:52.957730704Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:54:52.957732677Z     dest_node._merge_with(
2025-11-26T17:54:52.957734690Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:54:52.957736653Z     BaseContainer._map_merge(
2025-11-26T17:54:52.957738596Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:54:52.957740930Z     dest_node._merge_with(
2025-11-26T17:54:52.957742942Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:54:52.957744936Z     BaseContainer._map_merge(
2025-11-26T17:54:52.958169371Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 432, in _map_merge
2025-11-26T17:54:52.958175640Z     dest[key] = src._get_node(key)
2025-11-26T17:54:52.958179235Z     ~~~~^^^^^
2025-11-26T17:54:52.958181849Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 308, in __setitem__
2025-11-26T17:54:52.958184574Z     self._format_and_raise(
2025-11-26T17:54:52.958187057Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:54:52.958198584Z     format_and_raise(
2025-11-26T17:54:52.958200998Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:54:52.958202991Z     _raise(ex, cause)
2025-11-26T17:54:52.958205064Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:54:52.958797802Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:54:52.958802519Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:54:52.958805293Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 306, in __setitem__
2025-11-26T17:54:52.958807467Z     self.__set_impl(key=key, value=value)
2025-11-26T17:54:52.958809550Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 316, in __set_impl
2025-11-26T17:54:52.958811613Z     self._set_item_impl(key, value)
2025-11-26T17:54:52.958813656Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 579, in _set_item_impl
2025-11-26T17:54:52.958815789Z     target_node_ref = self._get_node(key)
2025-11-26T17:54:52.958817892Z                       ^^^^^^^^^^^^^^^^^^^
2025-11-26T17:54:52.958820266Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 473, in _get_node
2025-11-26T17:54:52.959071843Z     self._validate_get(key)
2025-11-26T17:54:52.959075949Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 163, in _validate_get
2025-11-26T17:54:52.959078302Z     self._format_and_raise(
2025-11-26T17:54:52.959080355Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:54:52.959082428Z     format_and_raise(
2025-11-26T17:54:52.959084531Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 906, in format_and_raise
2025-11-26T17:54:52.959408507Z     _raise(ex, cause)
2025-11-26T17:54:52.959416108Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:54:52.959418762Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:54:52.959420835Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:54:52.959424151Z omegaconf.errors.ConfigKeyError: Key 'max_new_tokens' not in 'NormConfig'
2025-11-26T17:54:52.959427576Z     full_key: actor.adv_norm.max_new_tokens
2025-11-26T17:54:52.959429599Z     reference_type=Optional[NormConfig]
2025-11-26T17:54:52.959431712Z     object_type=NormConfig
2025-11-26T17:54:55.688196583Z E1126 17:54:55.687000 966 torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 0 (pid: 1032) of binary: /usr/bin/python3
2025-11-26T17:54:55.688843971Z Traceback (most recent call last):
2025-11-26T17:54:55.688850742Z   File "/usr/local/bin/torchrun", line 7, in <module>
2025-11-26T17:54:55.688853656Z     sys.exit(main())
2025-11-26T17:54:55.688856350Z              ^^^^^^
2025-11-26T17:54:55.688858493Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
2025-11-26T17:54:55.688861628Z     return f(*args, **kwargs)
2025-11-26T17:54:55.688864151Z            ^^^^^^^^^^^^^^^^^^
2025-11-26T17:54:55.688866535Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 901, in main
2025-11-26T17:54:55.689325894Z     run(args)
2025-11-26T17:54:55.689334256Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 892, in run
2025-11-26T17:54:55.689337120Z     elastic_launch(
2025-11-26T17:54:55.689339624Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 143, in __call__
2025-11-26T17:54:55.689342008Z     return launch_agent(self._config, self._entrypoint, list(args))
2025-11-26T17:54:55.689344422Z            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:54:55.689346625Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 277, in launch_agent
2025-11-26T17:54:55.689348848Z     raise ChildFailedError(
2025-11-26T17:54:55.689351212Z torch.distributed.elastic.multiprocessing.errors.ChildFailedError:
2025-11-26T17:54:55.689363751Z ============================================================
2025-11-26T17:54:55.689366435Z examples/cloud_gsm8k/gsm8k_grpo_train.py FAILED
2025-11-26T17:54:55.689369479Z ------------------------------------------------------------
2025-11-26T17:54:55.689371462Z Failures:
2025-11-26T17:54:55.689373455Z   <NO_OTHER_FAILURES>
2025-11-26T17:54:55.689375869Z ------------------------------------------------------------
2025-11-26T17:54:55.689378022Z Root Cause (first observed failure):
2025-11-26T17:54:55.689380035Z [0]:
2025-11-26T17:54:55.689382078Z   time      : 2025-11-26_17:54:55
2025-11-26T17:54:55.689384111Z   host      : cef7c503fdea
2025-11-26T17:54:55.689386154Z   rank      : 0 (local_rank: 0)
2025-11-26T17:54:55.689388137Z   exitcode  : 1 (pid: 1032)
2025-11-26T17:54:55.689390140Z   error_file: <N/A>
2025-11-26T17:54:55.689392173Z   traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
2025-11-26T17:54:55.689394236Z ============================================================
2025-11-26T17:54:57.627833430Z [37m20251126-17:54:57.627 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [315][0m
2025-11-26T17:54:57.749445138Z Killed
2025-11-26T17:54:57.759512137Z [37m20251126-17:54:57.759 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [965][0m
2025-11-26T17:54:57.760607428Z Traceback (most recent call last):
2025-11-26T17:54:57.760619936Z   File "<frozen runpy>", line 198, in _run_module_as_main
2025-11-26T17:54:57.760624283Z   File "<frozen runpy>", line 88, in _run_code
2025-11-26T17:54:57.760626376Z   File "/workspace/AReaL/areal/launcher/local.py", line 405, in <module>
2025-11-26T17:54:57.760783262Z     main()
2025-11-26T17:54:57.760788510Z   File "/workspace/AReaL/areal/launcher/local.py", line 260, in main
2025-11-26T17:54:57.760881939Z     local_main(config, run_id=0)
2025-11-26T17:54:57.760885805Z   File "/workspace/AReaL/areal/launcher/local.py", line 399, in local_main
2025-11-26T17:54:57.760996280Z     raise e
2025-11-26T17:54:57.760998604Z   File "/workspace/AReaL/areal/launcher/local.py", line 375, in local_main
2025-11-26T17:54:57.761102971Z     launcher.wait(
2025-11-26T17:54:57.761105835Z   File "/workspace/AReaL/areal/launcher/local.py", line 235, in wait
2025-11-26T17:54:57.761186335Z     raise JobException(
2025-11-26T17:54:57.761191993Z areal.utils.launcher.JobException: Job gsm8k-grpo-cloud-2gpu-2000samples_trial_20251126_175411:trainer JobState.COMPLETED at node local
2025-11-26T17:54:57.989246891Z [37m20251126-17:54:57.988 Local Scheduler INFO: Waiting for 0 local running processes, pids: [0m
2025-11-26T17:55:14.885915717Z ==========
2025-11-26T17:55:14.885919112Z == CUDA ==
2025-11-26T17:55:14.885924791Z ==========
2025-11-26T17:55:14.890738812Z CUDA Version 12.9.1
2025-11-26T17:55:14.892228593Z Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
2025-11-26T17:55:14.894158975Z This container image and its contents are governed by the NVIDIA Deep Learning Container License.
2025-11-26T17:55:14.894161929Z By pulling and using the container, you accept the terms and conditions of this license:
2025-11-26T17:55:14.894164643Z https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license
2025-11-26T17:55:14.894168830Z A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
2025-11-26T17:55:15.062565336Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:55:15.219724491Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:55:15.403493433Z Branch 'feature/reasoning_model' set up to track remote branch 'feature/reasoning_model' from 'origin'.
2025-11-26T17:55:15.403529257Z Your branch is up to date with 'origin/feature/reasoning_model'.
2025-11-26T17:55:15.475298798Z Checking AReaL installation...
2025-11-26T17:55:15.535235115Z AReaL already installed. Skipping installation.
2025-11-26T17:55:15.535266472Z Cleaning up any leftover GPU processes...
2025-11-26T17:55:18.555376900Z Checking for processes holding GPU device files...
2025-11-26T17:55:20.645792866Z Found processes holding GPU devices: 1
2025-11-26T17:55:20.645827428Z 20
2025-11-26T17:55:20.645830472Z 71
2025-11-26T17:55:20.645833107Z 72
2025-11-26T17:55:20.645835150Z Killing process 1...
2025-11-26T17:55:20.645841429Z Killing process 71...
2025-11-26T17:55:20.645852085Z Killing process 72...
2025-11-26T17:55:22.648570591Z Using fuser to kill processes on GPU devices...
2025-11-26T17:55:24.669861426Z Checking GPU...
2025-11-26T17:55:24.705867718Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:55:24.705890842Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:55:24.722173042Z Set PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True for better memory management
2025-11-26T17:55:24.722190859Z Detected 2 GPU(s)
2025-11-26T17:55:24.722194264Z Checking GPU status...
2025-11-26T17:55:24.749344702Z index, name, utilization.gpu [%], memory.used [MiB], compute_mode
2025-11-26T17:55:24.750815745Z 0, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:55:24.751154011Z 1, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:55:24.793479320Z Verifying GPU accessibility...
2025-11-26T17:55:25.325049944Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:55:25.325106159Z   import pynvml  # type: ignore[import]
2025-11-26T17:55:26.424386600Z GPU accessibility verified on attempt 1
2025-11-26T17:55:26.895849712Z Starting training...
2025-11-26T17:55:29.898581469Z Using STANDARD 2000 SAMPLES 2 GPUs configuration
2025-11-26T17:55:29.898619827Z Note: GRPO only (no reasoning XML). Dataset capped at 2000 samples (~6 hours).
2025-11-26T17:55:29.898623331Z GPU count: 2 (required: 2)
2025-11-26T17:55:29.900922035Z ==========================================
2025-11-26T17:55:29.900924869Z Starting GRPO Training (Cloud)
2025-11-26T17:55:29.900927082Z ==========================================
2025-11-26T17:55:29.900929176Z Config: standard_2000samples_2GPUs
2025-11-26T17:55:29.900931239Z Config file: examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml
2025-11-26T17:55:29.900933322Z Training script: examples/cloud_gsm8k/gsm8k_grpo_train.py
2025-11-26T17:55:29.900935996Z Experiment: gsm8k-grpo-cloud-2gpu-2000samples
2025-11-26T17:55:29.900938059Z Trial: trial_20251126_175529
2025-11-26T17:55:29.900940102Z GPU: NVIDIA A100 80GB PCIe NVIDIA A100 80GB PCIe (81920 MB)
2025-11-26T17:55:29.900942125Z WandB API key: e1adc5be02...
2025-11-26T17:55:29.900944178Z ==========================================
2025-11-26T17:55:30.592301162Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:55:30.592348654Z   import pynvml  # type: ignore[import]
2025-11-26T17:55:34.527905513Z [37m20251126-17:55:34.527 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:55:34.527942849Z [37m20251126-17:55:34.527 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:55:34.528201587Z [37m20251126-17:55:34.527 name-resolve INFO: No such name resolve path: ./tmp/areal/name_resolve/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_175529[0m
2025-11-26T17:55:34.633256556Z [37m20251126-17:55:34.632 Local Scheduler INFO: LocalLauncher: experiment_name=gsm8k-grpo-cloud-2gpu-2000samples, trial_name=trial_20251126_175529, fileroot=/workspace/outputs/grpo, run_id=0, is_recover_run=False[0m
2025-11-26T17:55:34.640989749Z [37m20251126-17:55:34.640 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL CUDA_VISIBLE_DEVICES=0 stdbuf -oL python3 -m areal.launcher.sglang_server examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_175529 sglang.random_seed=1 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_175529/llm_server.log[0m
2025-11-26T17:55:35.383334156Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:55:35.383374417Z   import pynvml  # type: ignore[import]
2025-11-26T17:55:36.839877381Z [37m20251126-17:55:36.839 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:55:36.840613634Z [37m20251126-17:55:36.839 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:55:36.940577247Z [37m20251126-17:55:36.940 SGLangServer Wrapper INFO: Launch command: python3 -m sglang.launch_server --host 172.21.0.2 --port 27310 --tokenizer-path Qwen/Qwen2.5-0.5B-Instruct --tokenizer-mode auto --load-format auto --trust-remote-code --device cuda --tp-size 1 --base-gpu-id 0 --nnodes 1 --node-rank 0 --dist-init-addr localhost:28988 --model-path Qwen/Qwen2.5-0.5B-Instruct --random-seed 1 --skip-tokenizer-init --disable-radix-cache --torch-compile-max-bs 32 --triton-attention-num-kv-splits 8 --num-continuous-decode-steps 1 --attention-backend flashinfer --context-length 4096 --mem-fraction-static 0.6 --chunked-prefill-size -1 --max-prefill-tokens 32768 --schedule-policy lpm --schedule-conservativeness 1.0 --cpu-offload-gb 0 --dtype bfloat16 --kv-cache-dtype auto --dp-size 1 --ep-size 1 --max-loaded-loras 1 --max-loras-per-batch 1 --lora-backend triton --log-level warning --log-level-http warning --log-requests-level 0 --enable-metrics --decode-log-interval 1[0m
2025-11-26T17:55:38.032701770Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:55:38.032741490Z   import pynvml  # type: ignore[import]
2025-11-26T17:55:43.570306923Z INFO 11-26 17:55:43 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:55:44.221996791Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:55:45.222799966Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:55:45.222835519Z   import pynvml  # type: ignore[import]
2025-11-26T17:55:45.223409359Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:55:45.223424141Z   import pynvml  # type: ignore[import]
2025-11-26T17:55:50.469893651Z INFO 11-26 17:55:50 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:55:50.502924347Z INFO 11-26 17:55:50 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:55:51.085192069Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:55:51.305189738Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:55:51.308671623Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:55:51.309456999Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:55:51.310241445Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:55:51.342454475Z [2025-11-26 17:55:51] MOE_RUNNER_BACKEND is not initialized, using triton backend
2025-11-26T17:55:51.825334127Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:55:51.825374367Z   warnings.warn(
2025-11-26T17:55:51.825378023Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:55:51.825380827Z   warnings.warn(
2025-11-26T17:55:52.911656449Z Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
2025-11-26T17:55:53.015669688Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  9.63it/s]
2025-11-26T17:55:53.016175075Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  9.61it/s]
2025-11-26T17:55:55.407377199Z   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   4%|â–         | 1/23 [00:00<00:11,  1.91it/s]Capturing batches (bs=152 avail_mem=30.62 GB):   4%|â–         | 1/23 [00:00<00:11,  1.91it/s]Capturing batches (bs=144 avail_mem=30.60 GB):   4%|â–         | 1/23 [00:00<00:11,  1.91it/s]Capturing batches (bs=136 avail_mem=30.59 GB):   4%|â–         | 1/23 [00:00<00:11,  1.91it/s]Capturing batches (bs=136 avail_mem=30.59 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.46it/s]Capturing batches (bs=128 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.46it/s]Capturing batches (bs=120 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.46it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.46it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.83it/s]Capturing batches (bs=104 avail_mem=30.54 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.83it/s]Capturing batches (bs=96 avail_mem=30.53 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.83it/s] Capturing batches (bs=88 avail_mem=30.51 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.83it/s]Capturing batches (bs=88 avail_mem=30.51 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 15.18it/s]Capturing batches (bs=80 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 15.18it/s]Capturing batches (bs=72 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 15.18it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 15.18it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.69it/s]Capturing batches (bs=56 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.69it/s]Capturing batches (bs=48 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.69it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.69it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.76it/s]Capturing batches (bs=32 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.76it/s]Capturing batches (bs=24 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.76it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.76it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 18.28it/s]Capturing batches (bs=8 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 18.28it/s] Capturing batches (bs=4 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 18.28it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 18.28it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 20.08it/s]Capturing batches (bs=1 avail_mem=30.35 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 20.08it/s]Capturing batches (bs=1 avail_mem=30.35 GB): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00, 15.33it/s]
2025-11-26T17:56:00.966204891Z [37m20251126-17:56:00.965 SGLangServer Wrapper INFO: SGLang server launched at: http://172.21.0.2:27310[0m
2025-11-26T17:56:01.647441056Z [37m20251126-17:56:01.647 Launcher Utils INFO: Found 1 rollout servers: 172.21.0.2:27310[0m
2025-11-26T17:56:01.647476729Z [37m20251126-17:56:01.647 Local Scheduler INFO: LLM inference server launched at: AREAL_LLM_SERVER_ADDRS=172.21.0.2:27310[0m
2025-11-26T17:56:01.650667428Z [37m20251126-17:56:01.650 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL AREAL_LLM_SERVER_ADDRS=172.21.0.2:27310 AREAL_RECOVER_RUN=0 NCCL_CUMEM_ENABLE=0 NCCL_NVLS_ENABLE=0 CUDA_VISIBLE_DEVICES=1 stdbuf -oL torchrun --nnodes 1 --nproc-per-node 1 --master-addr localhost --master-port 14983 examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_175529 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_175529/trainer.log[0m
2025-11-26T17:56:01.651330332Z [37m20251126-17:56:01.651 Local Scheduler INFO: Waiting for 2 local running processes, pids: 315 965[0m
2025-11-26T17:56:02.168355659Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:56:02.168398263Z   import pynvml  # type: ignore[import]
2025-11-26T17:56:03.368372301Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:56:03.368420012Z   import pynvml  # type: ignore[import]
2025-11-26T17:56:10.420270141Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:56:10.420315038Z   warnings.warn(
2025-11-26T17:56:10.420317943Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:56:10.420328418Z   warnings.warn(
2025-11-26T17:56:10.864325008Z Traceback (most recent call last):
2025-11-26T17:56:10.864368844Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 665, in <module>
2025-11-26T17:56:10.865053739Z     main(sys.argv[1:])
2025-11-26T17:56:10.865058076Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 102, in main
2025-11-26T17:56:10.865060941Z     config, _ = load_expr_config(args_with_overrides, GRPOConfig)
2025-11-26T17:56:10.865063554Z                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:56:10.865065537Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1282, in load_expr_config
2025-11-26T17:56:10.865067580Z     cfg = to_structured_cfg(cfg, config_cls=config_cls)
2025-11-26T17:56:10.865070144Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:56:10.865072147Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1276, in to_structured_cfg
2025-11-26T17:56:10.865504695Z     cfg = OmegaConf.merge(default_cfg, cfg)
2025-11-26T17:56:10.865509362Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:56:10.865511506Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/omegaconf.py", line 274, in merge
2025-11-26T17:56:10.865513529Z     target.merge_with(
2025-11-26T17:56:10.865516182Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 507, in merge_with
2025-11-26T17:56:10.865519026Z     self._format_and_raise(key=None, value=None, cause=e)
2025-11-26T17:56:10.865521039Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:56:10.865523302Z     format_and_raise(
2025-11-26T17:56:10.865525686Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:56:10.866033187Z     _raise(ex, cause)
2025-11-26T17:56:10.866057563Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:56:10.866060959Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:56:10.866063062Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:56:10.866065646Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 502, in merge_with
2025-11-26T17:56:10.866068300Z     self._merge_with(
2025-11-26T17:56:10.866070714Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:56:10.866469931Z     BaseContainer._map_merge(
2025-11-26T17:56:10.866475669Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:56:10.866477963Z     dest_node._merge_with(
2025-11-26T17:56:10.866479966Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:56:10.866482129Z     BaseContainer._map_merge(
2025-11-26T17:56:10.866484072Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:56:10.866486285Z     dest_node._merge_with(
2025-11-26T17:56:10.866488488Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:56:10.866490511Z     BaseContainer._map_merge(
2025-11-26T17:56:10.866492434Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 432, in _map_merge
2025-11-26T17:56:10.866892294Z     dest[key] = src._get_node(key)
2025-11-26T17:56:10.866896170Z     ~~~~^^^^^
2025-11-26T17:56:10.866898754Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 308, in __setitem__
2025-11-26T17:56:10.866901087Z     self._format_and_raise(
2025-11-26T17:56:10.866903901Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:56:10.866906025Z     format_and_raise(
2025-11-26T17:56:10.866908498Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:56:10.866924302Z     _raise(ex, cause)
2025-11-26T17:56:10.866926455Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:56:10.866928548Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:56:10.867447896Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:56:10.867454206Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 306, in __setitem__
2025-11-26T17:56:10.867456739Z     self.__set_impl(key=key, value=value)
2025-11-26T17:56:10.867458802Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 316, in __set_impl
2025-11-26T17:56:10.867460865Z     self._set_item_impl(key, value)
2025-11-26T17:56:10.867462839Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 579, in _set_item_impl
2025-11-26T17:56:10.867464962Z     target_node_ref = self._get_node(key)
2025-11-26T17:56:10.867467435Z                       ^^^^^^^^^^^^^^^^^^^
2025-11-26T17:56:10.867469618Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 473, in _get_node
2025-11-26T17:56:10.867833724Z     self._validate_get(key)
2025-11-26T17:56:10.867837720Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 163, in _validate_get
2025-11-26T17:56:10.867839953Z     self._format_and_raise(
2025-11-26T17:56:10.867842016Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:56:10.867844220Z     format_and_raise(
2025-11-26T17:56:10.867846303Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 906, in format_and_raise
2025-11-26T17:56:10.867848617Z     _raise(ex, cause)
2025-11-26T17:56:10.867850770Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:56:10.868185110Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:56:10.868191299Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:56:10.868193332Z omegaconf.errors.ConfigKeyError: Key 'max_new_tokens' not in 'NormConfig'
2025-11-26T17:56:10.868196266Z     full_key: actor.adv_norm.max_new_tokens
2025-11-26T17:56:10.868198620Z     reference_type=Optional[NormConfig]
2025-11-26T17:56:10.868200823Z     object_type=NormConfig
2025-11-26T17:56:13.366165535Z E1126 17:56:13.365000 966 torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 0 (pid: 1032) of binary: /usr/bin/python3
2025-11-26T17:56:13.367066825Z Traceback (most recent call last):
2025-11-26T17:56:13.367089840Z   File "/usr/local/bin/torchrun", line 7, in <module>
2025-11-26T17:56:13.367092884Z     sys.exit(main())
2025-11-26T17:56:13.367095478Z              ^^^^^^
2025-11-26T17:56:13.367097852Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
2025-11-26T17:56:13.367100916Z     return f(*args, **kwargs)
2025-11-26T17:56:13.367103590Z            ^^^^^^^^^^^^^^^^^^
2025-11-26T17:56:13.367105653Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 901, in main
2025-11-26T17:56:13.367108357Z     run(args)
2025-11-26T17:56:13.367110560Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 892, in run
2025-11-26T17:56:13.367550600Z     elastic_launch(
2025-11-26T17:56:13.367560043Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 143, in __call__
2025-11-26T17:56:13.367562728Z     return launch_agent(self._config, self._entrypoint, list(args))
2025-11-26T17:56:13.367564831Z            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:56:13.367566924Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 277, in launch_agent
2025-11-26T17:56:13.367568997Z     raise ChildFailedError(
2025-11-26T17:56:13.367571200Z torch.distributed.elastic.multiprocessing.errors.ChildFailedError:
2025-11-26T17:56:13.367573233Z ============================================================
2025-11-26T17:56:13.367584040Z examples/cloud_gsm8k/gsm8k_grpo_train.py FAILED
2025-11-26T17:56:13.367586403Z ------------------------------------------------------------
2025-11-26T17:56:13.367588486Z Failures:
2025-11-26T17:56:13.367590629Z   <NO_OTHER_FAILURES>
2025-11-26T17:56:13.367593083Z ------------------------------------------------------------
2025-11-26T17:56:13.367595246Z Root Cause (first observed failure):
2025-11-26T17:56:13.367597209Z [0]:
2025-11-26T17:56:13.367599272Z   time      : 2025-11-26_17:56:13
2025-11-26T17:56:13.367601265Z   host      : cef7c503fdea
2025-11-26T17:56:13.367603298Z   rank      : 0 (local_rank: 0)
2025-11-26T17:56:13.367605261Z   exitcode  : 1 (pid: 1032)
2025-11-26T17:56:13.367607294Z   error_file: <N/A>
2025-11-26T17:56:13.367609297Z   traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
2025-11-26T17:56:13.367611911Z ============================================================
2025-11-26T17:56:13.654300705Z [37m20251126-17:56:13.653 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [315][0m
2025-11-26T17:56:13.863745687Z Killed
2025-11-26T17:56:13.874499324Z [37m20251126-17:56:13.874 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [965][0m
2025-11-26T17:56:13.875612291Z Traceback (most recent call last):
2025-11-26T17:56:13.875618620Z   File "<frozen runpy>", line 198, in _run_module_as_main
2025-11-26T17:56:13.875621144Z   File "<frozen runpy>", line 88, in _run_code
2025-11-26T17:56:13.875623367Z   File "/workspace/AReaL/areal/launcher/local.py", line 405, in <module>
2025-11-26T17:56:13.875771820Z     main()
2025-11-26T17:56:13.875774785Z   File "/workspace/AReaL/areal/launcher/local.py", line 260, in main
2025-11-26T17:56:13.875871469Z     local_main(config, run_id=0)
2025-11-26T17:56:13.875874353Z   File "/workspace/AReaL/areal/launcher/local.py", line 399, in local_main
2025-11-26T17:56:13.875955505Z     raise e
2025-11-26T17:56:13.875957828Z   File "/workspace/AReaL/areal/launcher/local.py", line 375, in local_main
2025-11-26T17:56:13.876050338Z     launcher.wait(
2025-11-26T17:56:13.876055345Z   File "/workspace/AReaL/areal/launcher/local.py", line 235, in wait
2025-11-26T17:56:13.876089366Z     raise JobException(
2025-11-26T17:56:13.876091689Z areal.utils.launcher.JobException: Job gsm8k-grpo-cloud-2gpu-2000samples_trial_20251126_175529:trainer JobState.COMPLETED at node local
2025-11-26T17:56:14.053889097Z [37m20251126-17:56:14.053 Local Scheduler INFO: Waiting for 0 local running processes, pids: [0m
2025-11-26T17:56:17.687671187Z ==========
2025-11-26T17:56:17.687674572Z == CUDA ==
2025-11-26T17:56:17.687680031Z ==========
2025-11-26T17:56:17.692036677Z CUDA Version 12.9.1
2025-11-26T17:56:17.693537965Z Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
2025-11-26T17:56:17.695718721Z This container image and its contents are governed by the NVIDIA Deep Learning Container License.
2025-11-26T17:56:17.695721565Z By pulling and using the container, you accept the terms and conditions of this license:
2025-11-26T17:56:17.695724360Z https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license
2025-11-26T17:56:17.695728896Z A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
2025-11-26T17:56:17.862342442Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:56:18.021642353Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:56:18.290632096Z Branch 'feature/reasoning_model' set up to track remote branch 'feature/reasoning_model' from 'origin'.
2025-11-26T17:56:18.290672065Z Your branch is up to date with 'origin/feature/reasoning_model'.
2025-11-26T17:56:18.361299356Z Checking AReaL installation...
2025-11-26T17:56:18.420990886Z AReaL already installed. Skipping installation.
2025-11-26T17:56:18.421026970Z Cleaning up any leftover GPU processes...
2025-11-26T17:56:21.440007838Z Checking for processes holding GPU device files...
2025-11-26T17:56:23.633838745Z Found processes holding GPU devices: 1
2025-11-26T17:56:23.633872766Z 20
2025-11-26T17:56:23.633894247Z 71
2025-11-26T17:56:23.633896491Z 72
2025-11-26T17:56:23.633898915Z Killing process 1...
2025-11-26T17:56:23.633901629Z Killing process 71...
2025-11-26T17:56:23.634077873Z Killing process 72...
2025-11-26T17:56:25.636672965Z Using fuser to kill processes on GPU devices...
2025-11-26T17:56:27.659143035Z Checking GPU...
2025-11-26T17:56:27.693923462Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:56:27.693962050Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:56:27.716598666Z Set PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True for better memory management
2025-11-26T17:56:27.716620669Z Detected 2 GPU(s)
2025-11-26T17:56:27.716624234Z Checking GPU status...
2025-11-26T17:56:27.744482493Z index, name, utilization.gpu [%], memory.used [MiB], compute_mode
2025-11-26T17:56:27.745967778Z 0, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:56:27.746235068Z 1, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:56:27.790100533Z Verifying GPU accessibility...
2025-11-26T17:56:28.336069755Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:56:28.336158669Z   import pynvml  # type: ignore[import]
2025-11-26T17:56:29.431500190Z GPU accessibility verified on attempt 1
2025-11-26T17:56:29.902636431Z Starting training...
2025-11-26T17:56:32.905635720Z Using STANDARD 2000 SAMPLES 2 GPUs configuration
2025-11-26T17:56:32.905678133Z Note: GRPO only (no reasoning XML). Dataset capped at 2000 samples (~6 hours).
2025-11-26T17:56:32.905681298Z GPU count: 2 (required: 2)
2025-11-26T17:56:32.908552188Z ==========================================
2025-11-26T17:56:32.908555694Z Starting GRPO Training (Cloud)
2025-11-26T17:56:32.908558518Z ==========================================
2025-11-26T17:56:32.908560721Z Config: standard_2000samples_2GPUs
2025-11-26T17:56:32.908563185Z Config file: examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml
2025-11-26T17:56:32.908566079Z Training script: examples/cloud_gsm8k/gsm8k_grpo_train.py
2025-11-26T17:56:32.908568633Z Experiment: gsm8k-grpo-cloud-2gpu-2000samples
2025-11-26T17:56:32.908570606Z Trial: trial_20251126_175632
2025-11-26T17:56:32.908572609Z GPU: NVIDIA A100 80GB PCIe NVIDIA A100 80GB PCIe (81920 MB)
2025-11-26T17:56:32.908574672Z WandB API key: e1adc5be02...
2025-11-26T17:56:32.908576665Z ==========================================
2025-11-26T17:56:33.604586047Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:56:33.604632998Z   import pynvml  # type: ignore[import]
2025-11-26T17:56:37.562613136Z [37m20251126-17:56:37.562 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:56:37.562657212Z [37m20251126-17:56:37.562 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:56:37.563031833Z [37m20251126-17:56:37.562 name-resolve INFO: No such name resolve path: ./tmp/areal/name_resolve/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_175632[0m
2025-11-26T17:56:37.670314489Z [37m20251126-17:56:37.669 Local Scheduler INFO: LocalLauncher: experiment_name=gsm8k-grpo-cloud-2gpu-2000samples, trial_name=trial_20251126_175632, fileroot=/workspace/outputs/grpo, run_id=0, is_recover_run=False[0m
2025-11-26T17:56:37.677847592Z [37m20251126-17:56:37.677 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL CUDA_VISIBLE_DEVICES=0 stdbuf -oL python3 -m areal.launcher.sglang_server examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_175632 sglang.random_seed=1 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_175632/llm_server.log[0m
2025-11-26T17:56:38.629447437Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:56:38.629485644Z   import pynvml  # type: ignore[import]
2025-11-26T17:56:40.146589722Z [37m20251126-17:56:40.145 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:56:40.146629271Z [37m20251126-17:56:40.146 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:56:40.255389359Z [37m20251126-17:56:40.254 SGLangServer Wrapper INFO: Launch command: python3 -m sglang.launch_server --host 172.21.0.2 --port 23571 --tokenizer-path Qwen/Qwen2.5-0.5B-Instruct --tokenizer-mode auto --load-format auto --trust-remote-code --device cuda --tp-size 1 --base-gpu-id 0 --nnodes 1 --node-rank 0 --dist-init-addr localhost:27624 --model-path Qwen/Qwen2.5-0.5B-Instruct --random-seed 1 --skip-tokenizer-init --disable-radix-cache --torch-compile-max-bs 32 --triton-attention-num-kv-splits 8 --num-continuous-decode-steps 1 --attention-backend flashinfer --context-length 4096 --mem-fraction-static 0.6 --chunked-prefill-size -1 --max-prefill-tokens 32768 --schedule-policy lpm --schedule-conservativeness 1.0 --cpu-offload-gb 0 --dtype bfloat16 --kv-cache-dtype auto --dp-size 1 --ep-size 1 --max-loaded-loras 1 --max-loras-per-batch 1 --lora-backend triton --log-level warning --log-level-http warning --log-requests-level 0 --enable-metrics --decode-log-interval 1[0m
2025-11-26T17:56:41.376155134Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:56:41.376195303Z   import pynvml  # type: ignore[import]
2025-11-26T17:56:47.024676465Z INFO 11-26 17:56:47 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:56:47.699828326Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:56:48.690662318Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:56:48.690707366Z   import pynvml  # type: ignore[import]
2025-11-26T17:56:48.904460000Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:56:48.904507822Z   import pynvml  # type: ignore[import]
2025-11-26T17:56:53.841335878Z INFO 11-26 17:56:53 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:56:54.444035875Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:56:54.525172948Z INFO 11-26 17:56:54 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:56:54.663300967Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:56:54.666815371Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:56:54.667662300Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:56:54.668490931Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:56:54.700789700Z [2025-11-26 17:56:54] MOE_RUNNER_BACKEND is not initialized, using triton backend
2025-11-26T17:56:55.179558975Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:56:55.179609791Z   warnings.warn(
2025-11-26T17:56:55.179613016Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:56:55.179615219Z   warnings.warn(
2025-11-26T17:56:56.290017270Z Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
2025-11-26T17:56:56.396018045Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  9.45it/s]
2025-11-26T17:56:56.396598184Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  9.43it/s]
2025-11-26T17:56:58.810576826Z   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   4%|â–         | 1/23 [00:00<00:11,  1.88it/s]Capturing batches (bs=152 avail_mem=30.62 GB):   4%|â–         | 1/23 [00:00<00:11,  1.88it/s]Capturing batches (bs=144 avail_mem=30.60 GB):   4%|â–         | 1/23 [00:00<00:11,  1.88it/s]Capturing batches (bs=136 avail_mem=30.59 GB):   4%|â–         | 1/23 [00:00<00:11,  1.88it/s]Capturing batches (bs=136 avail_mem=30.59 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.34it/s]Capturing batches (bs=128 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.34it/s]Capturing batches (bs=120 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.34it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.34it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.69it/s]Capturing batches (bs=104 avail_mem=30.54 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.69it/s]Capturing batches (bs=96 avail_mem=30.53 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.69it/s] Capturing batches (bs=88 avail_mem=30.51 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.69it/s]Capturing batches (bs=88 avail_mem=30.51 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 15.04it/s]Capturing batches (bs=80 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 15.04it/s]Capturing batches (bs=72 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 15.04it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:01<00:00, 15.04it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.43it/s]Capturing batches (bs=56 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.43it/s]Capturing batches (bs=48 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.43it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.43it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.38it/s]Capturing batches (bs=32 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.38it/s]Capturing batches (bs=24 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.38it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.38it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.93it/s]Capturing batches (bs=8 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.93it/s] Capturing batches (bs=4 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.93it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.93it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.75it/s]Capturing batches (bs=1 avail_mem=30.35 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.75it/s]Capturing batches (bs=1 avail_mem=30.35 GB): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00, 15.09it/s]
2025-11-26T17:57:04.283816206Z [37m20251126-17:57:04.283 SGLangServer Wrapper INFO: SGLang server launched at: http://172.21.0.2:23571[0m
2025-11-26T17:57:04.685062333Z [37m20251126-17:57:04.684 Launcher Utils INFO: Found 1 rollout servers: 172.21.0.2:23571[0m
2025-11-26T17:57:04.685103304Z [37m20251126-17:57:04.684 Local Scheduler INFO: LLM inference server launched at: AREAL_LLM_SERVER_ADDRS=172.21.0.2:23571[0m
2025-11-26T17:57:04.688077609Z [37m20251126-17:57:04.687 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL AREAL_LLM_SERVER_ADDRS=172.21.0.2:23571 AREAL_RECOVER_RUN=0 NCCL_CUMEM_ENABLE=0 NCCL_NVLS_ENABLE=0 CUDA_VISIBLE_DEVICES=1 stdbuf -oL torchrun --nnodes 1 --nproc-per-node 1 --master-addr localhost --master-port 44937 examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_175632 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_175632/trainer.log[0m
2025-11-26T17:57:04.688740101Z [37m20251126-17:57:04.688 Local Scheduler INFO: Waiting for 2 local running processes, pids: 315 965[0m
2025-11-26T17:57:05.252179862Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:57:05.252215695Z   import pynvml  # type: ignore[import]
2025-11-26T17:57:06.490850862Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:57:06.490891734Z   import pynvml  # type: ignore[import]
2025-11-26T17:57:13.725245249Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:57:13.725288554Z   warnings.warn(
2025-11-26T17:57:13.725292119Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:57:13.725303456Z   warnings.warn(
2025-11-26T17:57:14.164377703Z Traceback (most recent call last):
2025-11-26T17:57:14.164403913Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 665, in <module>
2025-11-26T17:57:14.165410780Z     main(sys.argv[1:])
2025-11-26T17:57:14.165417140Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 102, in main
2025-11-26T17:57:14.165420094Z     config, _ = load_expr_config(args_with_overrides, GRPOConfig)
2025-11-26T17:57:14.165422558Z                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:57:14.165424551Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1282, in load_expr_config
2025-11-26T17:57:14.165426554Z     cfg = to_structured_cfg(cfg, config_cls=config_cls)
2025-11-26T17:57:14.165429028Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:57:14.165431000Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1276, in to_structured_cfg
2025-11-26T17:57:14.165433304Z     cfg = OmegaConf.merge(default_cfg, cfg)
2025-11-26T17:57:14.165435948Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:57:14.165437931Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/omegaconf.py", line 274, in merge
2025-11-26T17:57:14.165814786Z     target.merge_with(
2025-11-26T17:57:14.165817810Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 507, in merge_with
2025-11-26T17:57:14.165820895Z     self._format_and_raise(key=None, value=None, cause=e)
2025-11-26T17:57:14.165823088Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:57:14.165829017Z     format_and_raise(
2025-11-26T17:57:14.165831271Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:57:14.165833343Z     _raise(ex, cause)
2025-11-26T17:57:14.165835386Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:57:14.166376707Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:57:14.166417218Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:57:14.166420202Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 502, in merge_with
2025-11-26T17:57:14.166423217Z     self._merge_with(
2025-11-26T17:57:14.166426452Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:57:14.166429046Z     BaseContainer._map_merge(
2025-11-26T17:57:14.166431640Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:57:14.166696616Z     dest_node._merge_with(
2025-11-26T17:57:14.166700923Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:57:14.166703226Z     BaseContainer._map_merge(
2025-11-26T17:57:14.166705269Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:57:14.166708995Z     dest_node._merge_with(
2025-11-26T17:57:14.166711078Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:57:14.166713152Z     BaseContainer._map_merge(
2025-11-26T17:57:14.166715355Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 432, in _map_merge
2025-11-26T17:57:14.166717468Z     dest[key] = src._get_node(key)
2025-11-26T17:57:14.167433831Z     ~~~~^^^^^
2025-11-26T17:57:14.167440160Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 308, in __setitem__
2025-11-26T17:57:14.167443345Z     self._format_and_raise(
2025-11-26T17:57:14.167445598Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:57:14.167447761Z     format_and_raise(
2025-11-26T17:57:14.167450015Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:57:14.167452378Z     _raise(ex, cause)
2025-11-26T17:57:14.167454441Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:57:14.167467501Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:57:14.167469614Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:57:14.167471817Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 306, in __setitem__
2025-11-26T17:57:14.167473871Z     self.__set_impl(key=key, value=value)
2025-11-26T17:57:14.167475863Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 316, in __set_impl
2025-11-26T17:57:14.167477826Z     self._set_item_impl(key, value)
2025-11-26T17:57:14.167741000Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 579, in _set_item_impl
2025-11-26T17:57:14.167745417Z     target_node_ref = self._get_node(key)
2025-11-26T17:57:14.167747710Z                       ^^^^^^^^^^^^^^^^^^^
2025-11-26T17:57:14.167749794Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 473, in _get_node
2025-11-26T17:57:14.167751997Z     self._validate_get(key)
2025-11-26T17:57:14.168063884Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 163, in _validate_get
2025-11-26T17:57:14.168066849Z     self._format_and_raise(
2025-11-26T17:57:14.168069743Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:57:14.168071826Z     format_and_raise(
2025-11-26T17:57:14.168073789Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 906, in format_and_raise
2025-11-26T17:57:14.168076113Z     _raise(ex, cause)
2025-11-26T17:57:14.168078126Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:57:14.168408190Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:57:14.168414910Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:57:14.168417774Z omegaconf.errors.ConfigKeyError: Key 'max_new_tokens' not in 'NormConfig'
2025-11-26T17:57:14.168420689Z     full_key: actor.adv_norm.max_new_tokens
2025-11-26T17:57:14.168422702Z     reference_type=Optional[NormConfig]
2025-11-26T17:57:14.168425065Z     object_type=NormConfig
2025-11-26T17:57:16.567992470Z E1126 17:57:16.567000 966 torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 0 (pid: 1032) of binary: /usr/bin/python3
2025-11-26T17:57:16.568831778Z Traceback (most recent call last):
2025-11-26T17:57:16.568875924Z   File "/usr/local/bin/torchrun", line 7, in <module>
2025-11-26T17:57:16.568878608Z     sys.exit(main())
2025-11-26T17:57:16.568882254Z              ^^^^^^
2025-11-26T17:57:16.568884707Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
2025-11-26T17:57:16.568888243Z     return f(*args, **kwargs)
2025-11-26T17:57:16.568891577Z            ^^^^^^^^^^^^^^^^^^
2025-11-26T17:57:16.568893600Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 901, in main
2025-11-26T17:57:16.569332407Z     run(args)
2025-11-26T17:57:16.569366248Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 892, in run
2025-11-26T17:57:16.569369583Z     elastic_launch(
2025-11-26T17:57:16.569372307Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 143, in __call__
2025-11-26T17:57:16.569374791Z     return launch_agent(self._config, self._entrypoint, list(args))
2025-11-26T17:57:16.569378076Z            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:57:16.569380119Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 277, in launch_agent
2025-11-26T17:57:16.569382182Z     raise ChildFailedError(
2025-11-26T17:57:16.569384626Z torch.distributed.elastic.multiprocessing.errors.ChildFailedError:
2025-11-26T17:57:16.569386658Z ============================================================
2025-11-26T17:57:16.569388822Z examples/cloud_gsm8k/gsm8k_grpo_train.py FAILED
2025-11-26T17:57:16.569391325Z ------------------------------------------------------------
2025-11-26T17:57:16.569404305Z Failures:
2025-11-26T17:57:16.569406528Z   <NO_OTHER_FAILURES>
2025-11-26T17:57:16.569408522Z ------------------------------------------------------------
2025-11-26T17:57:16.569410565Z Root Cause (first observed failure):
2025-11-26T17:57:16.569412597Z [0]:
2025-11-26T17:57:16.569414731Z   time      : 2025-11-26_17:57:16
2025-11-26T17:57:16.569416764Z   host      : cef7c503fdea
2025-11-26T17:57:16.569418867Z   rank      : 0 (local_rank: 0)
2025-11-26T17:57:16.569420900Z   exitcode  : 1 (pid: 1032)
2025-11-26T17:57:16.569422953Z   error_file: <N/A>
2025-11-26T17:57:16.569425036Z   traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
2025-11-26T17:57:16.569427119Z ============================================================
2025-11-26T17:57:18.692763575Z [37m20251126-17:57:18.692 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [315][0m
2025-11-26T17:57:18.871938156Z Killed
2025-11-26T17:57:18.874918000Z [37m20251126-17:57:18.874 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [965][0m
2025-11-26T17:57:18.875924337Z Traceback (most recent call last):
2025-11-26T17:57:18.875936475Z   File "<frozen runpy>", line 198, in _run_module_as_main
2025-11-26T17:57:18.875938889Z   File "<frozen runpy>", line 88, in _run_code
2025-11-26T17:57:18.875941362Z   File "/workspace/AReaL/areal/launcher/local.py", line 405, in <module>
2025-11-26T17:57:18.876161363Z     main()
2025-11-26T17:57:18.876197056Z   File "/workspace/AReaL/areal/launcher/local.py", line 260, in main
2025-11-26T17:57:18.876217086Z     local_main(config, run_id=0)
2025-11-26T17:57:18.876220121Z   File "/workspace/AReaL/areal/launcher/local.py", line 399, in local_main
2025-11-26T17:57:18.876300190Z     raise e
2025-11-26T17:57:18.876303936Z   File "/workspace/AReaL/areal/launcher/local.py", line 375, in local_main
2025-11-26T17:57:18.876364216Z     launcher.wait(
2025-11-26T17:57:18.876367471Z   File "/workspace/AReaL/areal/launcher/local.py", line 235, in wait
2025-11-26T17:57:18.876409835Z     raise JobException(
2025-11-26T17:57:18.876412729Z areal.utils.launcher.JobException: Job gsm8k-grpo-cloud-2gpu-2000samples_trial_20251126_175632:trainer JobState.COMPLETED at node local
2025-11-26T17:57:19.109538351Z [37m20251126-17:57:19.108 Local Scheduler INFO: Waiting for 0 local running processes, pids: [0m
2025-11-26T17:57:35.972983024Z ==========
2025-11-26T17:57:35.972987831Z == CUDA ==
2025-11-26T17:57:35.973001942Z ==========
2025-11-26T17:57:35.978365767Z CUDA Version 12.9.1
2025-11-26T17:57:35.980625201Z Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
2025-11-26T17:57:35.982755913Z This container image and its contents are governed by the NVIDIA Deep Learning Container License.
2025-11-26T17:57:35.982759829Z By pulling and using the container, you accept the terms and conditions of this license:
2025-11-26T17:57:35.982762613Z https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license
2025-11-26T17:57:35.982767480Z A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
2025-11-26T17:57:36.146730425Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:57:36.304184341Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:57:36.531044569Z Branch 'feature/reasoning_model' set up to track remote branch 'feature/reasoning_model' from 'origin'.
2025-11-26T17:57:36.531079331Z Your branch is up to date with 'origin/feature/reasoning_model'.
2025-11-26T17:57:36.600001698Z Checking AReaL installation...
2025-11-26T17:57:36.658566460Z AReaL already installed. Skipping installation.
2025-11-26T17:57:36.658596084Z Cleaning up any leftover GPU processes...
2025-11-26T17:57:39.677491073Z Checking for processes holding GPU device files...
2025-11-26T17:57:41.907376656Z Found processes holding GPU devices: 1
2025-11-26T17:57:41.907417667Z 20
2025-11-26T17:57:41.907420591Z 71
2025-11-26T17:57:41.907423366Z 72
2025-11-26T17:57:41.907425629Z Killing process 1...
2025-11-26T17:57:41.907428353Z Killing process 71...
2025-11-26T17:57:41.907496335Z Killing process 72...
2025-11-26T17:57:43.910222092Z Using fuser to kill processes on GPU devices...
2025-11-26T17:57:45.934038149Z Checking GPU...
2025-11-26T17:57:45.971185231Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:57:45.971208095Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:57:45.987800669Z Set PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True for better memory management
2025-11-26T17:57:45.987816983Z Detected 2 GPU(s)
2025-11-26T17:57:45.987820699Z Checking GPU status...
2025-11-26T17:57:46.016643701Z index, name, utilization.gpu [%], memory.used [MiB], compute_mode
2025-11-26T17:57:46.018067834Z 0, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:57:46.018420834Z 1, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:57:46.062004747Z Verifying GPU accessibility...
2025-11-26T17:57:46.586599312Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:57:46.586656318Z   import pynvml  # type: ignore[import]
2025-11-26T17:57:47.687316426Z GPU accessibility verified on attempt 1
2025-11-26T17:57:48.152316075Z Starting training...
2025-11-26T17:57:51.154837999Z Using STANDARD 2000 SAMPLES 2 GPUs configuration
2025-11-26T17:57:51.154871960Z Note: GRPO only (no reasoning XML). Dataset capped at 2000 samples (~6 hours).
2025-11-26T17:57:51.154875606Z GPU count: 2 (required: 2)
2025-11-26T17:57:51.157823541Z ==========================================
2025-11-26T17:57:51.157826225Z Starting GRPO Training (Cloud)
2025-11-26T17:57:51.157828358Z ==========================================
2025-11-26T17:57:51.157830492Z Config: standard_2000samples_2GPUs
2025-11-26T17:57:51.157832755Z Config file: examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml
2025-11-26T17:57:51.157834888Z Training script: examples/cloud_gsm8k/gsm8k_grpo_train.py
2025-11-26T17:57:51.157837322Z Experiment: gsm8k-grpo-cloud-2gpu-2000samples
2025-11-26T17:57:51.157839365Z Trial: trial_20251126_175751
2025-11-26T17:57:51.157841398Z GPU: NVIDIA A100 80GB PCIe NVIDIA A100 80GB PCIe (81920 MB)
2025-11-26T17:57:51.157843461Z WandB API key: e1adc5be02...
2025-11-26T17:57:51.157845484Z ==========================================
2025-11-26T17:57:51.855238549Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:57:51.855275895Z   import pynvml  # type: ignore[import]
2025-11-26T17:57:55.885017273Z [37m20251126-17:57:55.884 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:57:55.885063241Z [37m20251126-17:57:55.884 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:57:55.885327287Z [37m20251126-17:57:55.885 name-resolve INFO: No such name resolve path: ./tmp/areal/name_resolve/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_175751[0m
2025-11-26T17:57:55.991978185Z [37m20251126-17:57:55.991 Local Scheduler INFO: LocalLauncher: experiment_name=gsm8k-grpo-cloud-2gpu-2000samples, trial_name=trial_20251126_175751, fileroot=/workspace/outputs/grpo, run_id=0, is_recover_run=False[0m
2025-11-26T17:57:55.999557719Z [37m20251126-17:57:55.999 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL CUDA_VISIBLE_DEVICES=0 stdbuf -oL python3 -m areal.launcher.sglang_server examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_175751 sglang.random_seed=1 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_175751/llm_server.log[0m
2025-11-26T17:57:56.704730427Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:57:56.704766020Z   import pynvml  # type: ignore[import]
2025-11-26T17:57:58.170551580Z [37m20251126-17:57:58.169 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:57:58.171304257Z [37m20251126-17:57:58.170 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:57:58.273033535Z [37m20251126-17:57:58.272 SGLangServer Wrapper INFO: Launch command: python3 -m sglang.launch_server --host 172.21.0.2 --port 12169 --tokenizer-path Qwen/Qwen2.5-0.5B-Instruct --tokenizer-mode auto --load-format auto --trust-remote-code --device cuda --tp-size 1 --base-gpu-id 0 --nnodes 1 --node-rank 0 --dist-init-addr localhost:16738 --model-path Qwen/Qwen2.5-0.5B-Instruct --random-seed 1 --skip-tokenizer-init --disable-radix-cache --torch-compile-max-bs 32 --triton-attention-num-kv-splits 8 --num-continuous-decode-steps 1 --attention-backend flashinfer --context-length 4096 --mem-fraction-static 0.6 --chunked-prefill-size -1 --max-prefill-tokens 32768 --schedule-policy lpm --schedule-conservativeness 1.0 --cpu-offload-gb 0 --dtype bfloat16 --kv-cache-dtype auto --dp-size 1 --ep-size 1 --max-loaded-loras 1 --max-loras-per-batch 1 --lora-backend triton --log-level warning --log-level-http warning --log-requests-level 0 --enable-metrics --decode-log-interval 1[0m
2025-11-26T17:57:59.365813700Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:57:59.365861011Z   import pynvml  # type: ignore[import]
2025-11-26T17:58:04.942428695Z INFO 11-26 17:58:04 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:58:05.593870381Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:58:06.602161382Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:58:06.602200480Z   import pynvml  # type: ignore[import]
2025-11-26T17:58:06.606446200Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:58:06.606484688Z   import pynvml  # type: ignore[import]
2025-11-26T17:58:12.048096926Z INFO 11-26 17:58:12 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:58:12.420025617Z INFO 11-26 17:58:12 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:58:13.017323934Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:58:13.241588003Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:58:13.245160965Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:58:13.246040452Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:58:13.246898508Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:58:13.280008902Z [2025-11-26 17:58:13] MOE_RUNNER_BACKEND is not initialized, using triton backend
2025-11-26T17:58:13.775851131Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:58:13.775901486Z   warnings.warn(
2025-11-26T17:58:13.775904591Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:58:13.775906874Z   warnings.warn(
2025-11-26T17:58:15.056750233Z Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
2025-11-26T17:58:15.163813241Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  9.35it/s]
2025-11-26T17:58:15.164372859Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  9.33it/s]
2025-11-26T17:58:17.661774236Z   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   4%|â–         | 1/23 [00:00<00:11,  1.87it/s]Capturing batches (bs=152 avail_mem=30.62 GB):   4%|â–         | 1/23 [00:00<00:11,  1.87it/s]Capturing batches (bs=144 avail_mem=30.60 GB):   4%|â–         | 1/23 [00:00<00:11,  1.87it/s]Capturing batches (bs=136 avail_mem=30.59 GB):   4%|â–         | 1/23 [00:00<00:11,  1.87it/s]Capturing batches (bs=136 avail_mem=30.59 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.35it/s]Capturing batches (bs=128 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.35it/s]Capturing batches (bs=120 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.35it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.35it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.72it/s]Capturing batches (bs=104 avail_mem=30.54 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.72it/s]Capturing batches (bs=96 avail_mem=30.53 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.72it/s] Capturing batches (bs=88 avail_mem=30.51 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.72it/s]Capturing batches (bs=88 avail_mem=30.51 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 15.09it/s]Capturing batches (bs=80 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 15.09it/s]Capturing batches (bs=72 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 15.09it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 15.09it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.61it/s]Capturing batches (bs=56 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.61it/s]Capturing batches (bs=48 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.61it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.61it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.63it/s]Capturing batches (bs=32 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.63it/s]Capturing batches (bs=24 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.63it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.63it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.76it/s]Capturing batches (bs=8 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.76it/s] Capturing batches (bs=4 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.76it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.76it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.61it/s]Capturing batches (bs=1 avail_mem=30.35 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.61it/s]Capturing batches (bs=1 avail_mem=30.35 GB): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00, 15.06it/s]
2025-11-26T17:58:23.300179535Z [37m20251126-17:58:23.299 SGLangServer Wrapper INFO: SGLang server launched at: http://172.21.0.2:12169[0m
2025-11-26T17:58:24.006379333Z [37m20251126-17:58:24.005 Launcher Utils INFO: Found 1 rollout servers: 172.21.0.2:12169[0m
2025-11-26T17:58:24.006424760Z [37m20251126-17:58:24.006 Local Scheduler INFO: LLM inference server launched at: AREAL_LLM_SERVER_ADDRS=172.21.0.2:12169[0m
2025-11-26T17:58:24.009164754Z [37m20251126-17:58:24.008 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL AREAL_LLM_SERVER_ADDRS=172.21.0.2:12169 AREAL_RECOVER_RUN=0 NCCL_CUMEM_ENABLE=0 NCCL_NVLS_ENABLE=0 CUDA_VISIBLE_DEVICES=1 stdbuf -oL torchrun --nnodes 1 --nproc-per-node 1 --master-addr localhost --master-port 43698 examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_175751 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_175751/trainer.log[0m
2025-11-26T17:58:24.009735980Z [37m20251126-17:58:24.009 Local Scheduler INFO: Waiting for 2 local running processes, pids: 315 965[0m
2025-11-26T17:58:24.528780362Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:58:24.528815855Z   import pynvml  # type: ignore[import]
2025-11-26T17:58:25.727829594Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:58:25.727871457Z   import pynvml  # type: ignore[import]
2025-11-26T17:58:32.394748104Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:58:32.394792290Z   warnings.warn(
2025-11-26T17:58:32.394795736Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:58:32.394797929Z   warnings.warn(
2025-11-26T17:58:32.814220130Z Traceback (most recent call last):
2025-11-26T17:58:32.814278147Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 665, in <module>
2025-11-26T17:58:32.814785086Z     main(sys.argv[1:])
2025-11-26T17:58:32.814790934Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 102, in main
2025-11-26T17:58:32.814794259Z     config, _ = load_expr_config(args_with_overrides, GRPOConfig)
2025-11-26T17:58:32.814797624Z                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:58:32.814799698Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1282, in load_expr_config
2025-11-26T17:58:32.814802202Z     cfg = to_structured_cfg(cfg, config_cls=config_cls)
2025-11-26T17:58:32.815319818Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:58:32.815326517Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1276, in to_structured_cfg
2025-11-26T17:58:32.815329963Z     cfg = OmegaConf.merge(default_cfg, cfg)
2025-11-26T17:58:32.815333087Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:58:32.815335882Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/omegaconf.py", line 274, in merge
2025-11-26T17:58:32.815338746Z     target.merge_with(
2025-11-26T17:58:32.815341921Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 507, in merge_with
2025-11-26T17:58:32.815750663Z     self._format_and_raise(key=None, value=None, cause=e)
2025-11-26T17:58:32.815774889Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:58:32.815778274Z     format_and_raise(
2025-11-26T17:58:32.815781168Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:58:32.815783252Z     _raise(ex, cause)
2025-11-26T17:58:32.815785384Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:58:32.815788740Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:58:32.816268027Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:58:32.816277081Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 502, in merge_with
2025-11-26T17:58:32.816280105Z     self._merge_with(
2025-11-26T17:58:32.816282479Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:58:32.816284672Z     BaseContainer._map_merge(
2025-11-26T17:58:32.816287717Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:58:32.816290231Z     dest_node._merge_with(
2025-11-26T17:58:32.816292274Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:58:32.816294397Z     BaseContainer._map_merge(
2025-11-26T17:58:32.816296440Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:58:32.816663831Z     dest_node._merge_with(
2025-11-26T17:58:32.816669088Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:58:32.816671762Z     BaseContainer._map_merge(
2025-11-26T17:58:32.816674006Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 432, in _map_merge
2025-11-26T17:58:32.816676269Z     dest[key] = src._get_node(key)
2025-11-26T17:58:32.816679033Z     ~~~~^^^^^
2025-11-26T17:58:32.816681587Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 308, in __setitem__
2025-11-26T17:58:32.816683620Z     self._format_and_raise(
2025-11-26T17:58:32.816685824Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:58:32.816687936Z     format_and_raise(
2025-11-26T17:58:32.816690130Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:58:32.817276137Z     _raise(ex, cause)
2025-11-26T17:58:32.817284670Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:58:32.817288066Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:58:32.817294235Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:58:32.817296598Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 306, in __setitem__
2025-11-26T17:58:32.817298762Z     self.__set_impl(key=key, value=value)
2025-11-26T17:58:32.817300754Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 316, in __set_impl
2025-11-26T17:58:32.817302828Z     self._set_item_impl(key, value)
2025-11-26T17:58:32.817304800Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 579, in _set_item_impl
2025-11-26T17:58:32.817670298Z     target_node_ref = self._get_node(key)
2025-11-26T17:58:32.817674844Z                       ^^^^^^^^^^^^^^^^^^^
2025-11-26T17:58:32.817676877Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 473, in _get_node
2025-11-26T17:58:32.817679401Z     self._validate_get(key)
2025-11-26T17:58:32.817681404Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 163, in _validate_get
2025-11-26T17:58:32.817683707Z     self._format_and_raise(
2025-11-26T17:58:32.817685701Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:58:32.817687984Z     format_and_raise(
2025-11-26T17:58:32.817690658Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 906, in format_and_raise
2025-11-26T17:58:32.818089446Z     _raise(ex, cause)
2025-11-26T17:58:32.818094503Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:58:32.818097528Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:58:32.818100803Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:58:32.818103907Z omegaconf.errors.ConfigKeyError: Key 'max_new_tokens' not in 'NormConfig'
2025-11-26T17:58:32.818107042Z     full_key: actor.adv_norm.max_new_tokens
2025-11-26T17:58:32.818109296Z     reference_type=Optional[NormConfig]
2025-11-26T17:58:32.818111439Z     object_type=NormConfig
2025-11-26T17:58:35.623284138Z E1126 17:58:35.622000 966 torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 0 (pid: 1032) of binary: /usr/bin/python3
2025-11-26T17:58:35.623900701Z Traceback (most recent call last):
2025-11-26T17:58:35.623909034Z   File "/usr/local/bin/torchrun", line 7, in <module>
2025-11-26T17:58:35.623912239Z     sys.exit(main())
2025-11-26T17:58:35.623915173Z              ^^^^^^
2025-11-26T17:58:35.623917226Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
2025-11-26T17:58:35.623920010Z     return f(*args, **kwargs)
2025-11-26T17:58:35.623922825Z            ^^^^^^^^^^^^^^^^^^
2025-11-26T17:58:35.623924858Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 901, in main
2025-11-26T17:58:35.624365148Z     run(args)
2025-11-26T17:58:35.624372559Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 892, in run
2025-11-26T17:58:35.624375814Z     elastic_launch(
2025-11-26T17:58:35.624379239Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 143, in __call__
2025-11-26T17:58:35.624382564Z     return launch_agent(self._config, self._entrypoint, list(args))
2025-11-26T17:58:35.624385758Z            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:58:35.624388792Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 277, in launch_agent
2025-11-26T17:58:35.624392288Z     raise ChildFailedError(
2025-11-26T17:58:35.624395412Z torch.distributed.elastic.multiprocessing.errors.ChildFailedError:
2025-11-26T17:58:35.624398197Z ============================================================
2025-11-26T17:58:35.624401091Z examples/cloud_gsm8k/gsm8k_grpo_train.py FAILED
2025-11-26T17:58:35.624404045Z ------------------------------------------------------------
2025-11-26T17:58:35.624407100Z Failures:
2025-11-26T17:58:35.624409934Z   <NO_OTHER_FAILURES>
2025-11-26T17:58:35.624412708Z ------------------------------------------------------------
2025-11-26T17:58:35.624438918Z Root Cause (first observed failure):
2025-11-26T17:58:35.624441992Z [0]:
2025-11-26T17:58:35.624445077Z   time      : 2025-11-26_17:58:35
2025-11-26T17:58:35.624447971Z   host      : cef7c503fdea
2025-11-26T17:58:35.624450756Z   rank      : 0 (local_rank: 0)
2025-11-26T17:58:35.624453520Z   exitcode  : 1 (pid: 1032)
2025-11-26T17:58:35.624456434Z   error_file: <N/A>
2025-11-26T17:58:35.624459398Z   traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
2025-11-26T17:58:35.624462403Z ============================================================
2025-11-26T17:58:36.013244428Z [37m20251126-17:58:36.012 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [315][0m
2025-11-26T17:58:36.161747498Z Killed
2025-11-26T17:58:36.165714679Z [37m20251126-17:58:36.165 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [965][0m
2025-11-26T17:58:36.166722559Z Traceback (most recent call last):
2025-11-26T17:58:36.166732665Z   File "<frozen runpy>", line 198, in _run_module_as_main
2025-11-26T17:58:36.166735639Z   File "<frozen runpy>", line 88, in _run_code
2025-11-26T17:58:36.166737762Z   File "/workspace/AReaL/areal/launcher/local.py", line 405, in <module>
2025-11-26T17:58:36.166875959Z     main()
2025-11-26T17:58:36.166879794Z   File "/workspace/AReaL/areal/launcher/local.py", line 260, in main
2025-11-26T17:58:36.166979985Z     local_main(config, run_id=0)
2025-11-26T17:58:36.166985363Z   File "/workspace/AReaL/areal/launcher/local.py", line 399, in local_main
2025-11-26T17:58:36.167078272Z     raise e
2025-11-26T17:58:36.167081577Z   File "/workspace/AReaL/areal/launcher/local.py", line 375, in local_main
2025-11-26T17:58:36.167190039Z     launcher.wait(
2025-11-26T17:58:36.167197140Z   File "/workspace/AReaL/areal/launcher/local.py", line 235, in wait
2025-11-26T17:58:36.167239103Z     raise JobException(
2025-11-26T17:58:36.167242598Z areal.utils.launcher.JobException: Job gsm8k-grpo-cloud-2gpu-2000samples_trial_20251126_175751:trainer JobState.COMPLETED at node local
2025-11-26T17:58:36.379618841Z [37m20251126-17:58:36.379 Local Scheduler INFO: Waiting for 0 local running processes, pids: [0m
2025-11-26T17:58:38.703822060Z ==========
2025-11-26T17:58:38.703827849Z == CUDA ==
2025-11-26T17:58:38.703830823Z ==========
2025-11-26T17:58:38.708465916Z CUDA Version 12.9.1
2025-11-26T17:58:38.710111730Z Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
2025-11-26T17:58:38.711896023Z This container image and its contents are governed by the NVIDIA Deep Learning Container License.
2025-11-26T17:58:38.711898427Z By pulling and using the container, you accept the terms and conditions of this license:
2025-11-26T17:58:38.711900950Z https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license
2025-11-26T17:58:38.711905027Z A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
2025-11-26T17:58:38.882698183Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:58:39.042678964Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:58:39.229615040Z Branch 'feature/reasoning_model' set up to track remote branch 'feature/reasoning_model' from 'origin'.
2025-11-26T17:58:39.229651715Z Your branch is up to date with 'origin/feature/reasoning_model'.
2025-11-26T17:58:39.305419486Z Checking AReaL installation...
2025-11-26T17:58:39.364352991Z AReaL already installed. Skipping installation.
2025-11-26T17:58:39.364380041Z Cleaning up any leftover GPU processes...
2025-11-26T17:58:42.383443371Z Checking for processes holding GPU device files...
2025-11-26T17:58:44.496882984Z Found processes holding GPU devices: 1
2025-11-26T17:58:44.496919568Z 20
2025-11-26T17:58:44.496922202Z 71
2025-11-26T17:58:44.496924976Z 72
2025-11-26T17:58:44.496927019Z Killing process 1...
2025-11-26T17:58:44.496930284Z Killing process 71...
2025-11-26T17:58:44.497019998Z Killing process 72...
2025-11-26T17:58:46.499764724Z Using fuser to kill processes on GPU devices...
2025-11-26T17:58:48.524167610Z Checking GPU...
2025-11-26T17:58:48.563595348Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:58:48.563633995Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T17:58:48.581346437Z Set PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True for better memory management
2025-11-26T17:58:48.581367128Z Detected 2 GPU(s)
2025-11-26T17:58:48.581370252Z Checking GPU status...
2025-11-26T17:58:48.609587027Z index, name, utilization.gpu [%], memory.used [MiB], compute_mode
2025-11-26T17:58:48.611011922Z 0, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:58:48.611371230Z 1, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T17:58:48.658557459Z Verifying GPU accessibility...
2025-11-26T17:58:49.211844502Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:58:49.211905253Z   import pynvml  # type: ignore[import]
2025-11-26T17:58:50.357813477Z GPU accessibility verified on attempt 1
2025-11-26T17:58:50.916095903Z Starting training...
2025-11-26T17:58:53.919036824Z Using STANDARD 2000 SAMPLES 2 GPUs configuration
2025-11-26T17:58:53.919075322Z Note: GRPO only (no reasoning XML). Dataset capped at 2000 samples (~6 hours).
2025-11-26T17:58:53.919078627Z GPU count: 2 (required: 2)
2025-11-26T17:58:53.921788555Z ==========================================
2025-11-26T17:58:53.921791510Z Starting GRPO Training (Cloud)
2025-11-26T17:58:53.921794194Z ==========================================
2025-11-26T17:58:53.921796387Z Config: standard_2000samples_2GPUs
2025-11-26T17:58:53.921798450Z Config file: examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml
2025-11-26T17:58:53.921801194Z Training script: examples/cloud_gsm8k/gsm8k_grpo_train.py
2025-11-26T17:58:53.921803838Z Experiment: gsm8k-grpo-cloud-2gpu-2000samples
2025-11-26T17:58:53.921805871Z Trial: trial_20251126_175853
2025-11-26T17:58:53.921807864Z GPU: NVIDIA A100 80GB PCIe NVIDIA A100 80GB PCIe (81920 MB)
2025-11-26T17:58:53.921809877Z WandB API key: e1adc5be02...
2025-11-26T17:58:53.921811860Z ==========================================
2025-11-26T17:58:54.603642104Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:58:54.603679120Z   import pynvml  # type: ignore[import]
2025-11-26T17:58:58.535812211Z [37m20251126-17:58:58.535 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:58:58.535855667Z [37m20251126-17:58:58.535 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:58:58.536101805Z [37m20251126-17:58:58.535 name-resolve INFO: No such name resolve path: ./tmp/areal/name_resolve/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_175853[0m
2025-11-26T17:58:58.645088173Z [37m20251126-17:58:58.644 Local Scheduler INFO: LocalLauncher: experiment_name=gsm8k-grpo-cloud-2gpu-2000samples, trial_name=trial_20251126_175853, fileroot=/workspace/outputs/grpo, run_id=0, is_recover_run=False[0m
2025-11-26T17:58:58.652649449Z [37m20251126-17:58:58.652 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL CUDA_VISIBLE_DEVICES=0 stdbuf -oL python3 -m areal.launcher.sglang_server examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_175853 sglang.random_seed=1 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_175853/llm_server.log[0m
2025-11-26T17:58:59.373955683Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:58:59.374006740Z   import pynvml  # type: ignore[import]
2025-11-26T17:59:00.847562658Z [37m20251126-17:59:00.847 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T17:59:00.847808797Z [37m20251126-17:59:00.847 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T17:59:00.956958389Z [37m20251126-17:59:00.956 SGLangServer Wrapper INFO: Launch command: python3 -m sglang.launch_server --host 172.21.0.2 --port 19900 --tokenizer-path Qwen/Qwen2.5-0.5B-Instruct --tokenizer-mode auto --load-format auto --trust-remote-code --device cuda --tp-size 1 --base-gpu-id 0 --nnodes 1 --node-rank 0 --dist-init-addr localhost:27701 --model-path Qwen/Qwen2.5-0.5B-Instruct --random-seed 1 --skip-tokenizer-init --disable-radix-cache --torch-compile-max-bs 32 --triton-attention-num-kv-splits 8 --num-continuous-decode-steps 1 --attention-backend flashinfer --context-length 4096 --mem-fraction-static 0.6 --chunked-prefill-size -1 --max-prefill-tokens 32768 --schedule-policy lpm --schedule-conservativeness 1.0 --cpu-offload-gb 0 --dtype bfloat16 --kv-cache-dtype auto --dp-size 1 --ep-size 1 --max-loaded-loras 1 --max-loras-per-batch 1 --lora-backend triton --log-level warning --log-level-http warning --log-requests-level 0 --enable-metrics --decode-log-interval 1[0m
2025-11-26T17:59:02.013527584Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:59:02.013571760Z   import pynvml  # type: ignore[import]
2025-11-26T17:59:07.954384397Z INFO 11-26 17:59:07 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:59:08.667612282Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:59:09.728860656Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:59:09.728899113Z   import pynvml  # type: ignore[import]
2025-11-26T17:59:09.739601373Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:59:09.739629045Z   import pynvml  # type: ignore[import]
2025-11-26T17:59:15.287975899Z INFO 11-26 17:59:15 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:59:15.577447470Z INFO 11-26 17:59:15 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T17:59:16.187196947Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T17:59:16.419338635Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:59:16.423278006Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:59:16.424105906Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:59:16.425028848Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T17:59:16.460069194Z [2025-11-26 17:59:16] MOE_RUNNER_BACKEND is not initialized, using triton backend
2025-11-26T17:59:16.972015204Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:59:16.972067742Z   warnings.warn(
2025-11-26T17:59:16.972070837Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:59:16.972073090Z   warnings.warn(
2025-11-26T17:59:18.123542123Z Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
2025-11-26T17:59:18.242524123Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  8.42it/s]
2025-11-26T17:59:18.242764163Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  8.40it/s]
2025-11-26T17:59:20.815353372Z   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   4%|â–         | 1/23 [00:00<00:12,  1.74it/s]Capturing batches (bs=152 avail_mem=30.62 GB):   4%|â–         | 1/23 [00:00<00:12,  1.74it/s]Capturing batches (bs=144 avail_mem=30.60 GB):   4%|â–         | 1/23 [00:00<00:12,  1.74it/s]Capturing batches (bs=136 avail_mem=30.59 GB):   4%|â–         | 1/23 [00:00<00:12,  1.74it/s]Capturing batches (bs=136 avail_mem=30.59 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  6.78it/s]Capturing batches (bs=128 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  6.78it/s]Capturing batches (bs=120 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  6.78it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  6.78it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 10.70it/s]Capturing batches (bs=104 avail_mem=30.54 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 10.70it/s]Capturing batches (bs=96 avail_mem=30.53 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 10.70it/s] Capturing batches (bs=88 avail_mem=30.51 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 10.70it/s]Capturing batches (bs=88 avail_mem=30.51 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 13.67it/s]Capturing batches (bs=80 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 13.67it/s]Capturing batches (bs=72 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:01<00:00, 13.67it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:01<00:00, 13.67it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 16.01it/s]Capturing batches (bs=56 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 16.01it/s]Capturing batches (bs=48 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 16.01it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 16.01it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 18.34it/s]Capturing batches (bs=32 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 18.34it/s]Capturing batches (bs=24 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 18.34it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 18.34it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.31it/s]Capturing batches (bs=8 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.31it/s] Capturing batches (bs=4 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.31it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.31it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.26it/s]Capturing batches (bs=1 avail_mem=30.35 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.26it/s]Capturing batches (bs=1 avail_mem=30.35 GB): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00, 14.26it/s]
2025-11-26T17:59:25.988079344Z [37m20251126-17:59:25.987 SGLangServer Wrapper INFO: SGLang server launched at: http://172.21.0.2:19900[0m
2025-11-26T17:59:26.659505114Z [37m20251126-17:59:26.659 Launcher Utils INFO: Found 1 rollout servers: 172.21.0.2:19900[0m
2025-11-26T17:59:26.659552033Z [37m20251126-17:59:26.659 Local Scheduler INFO: LLM inference server launched at: AREAL_LLM_SERVER_ADDRS=172.21.0.2:19900[0m
2025-11-26T17:59:26.661816265Z [37m20251126-17:59:26.661 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL AREAL_LLM_SERVER_ADDRS=172.21.0.2:19900 AREAL_RECOVER_RUN=0 NCCL_CUMEM_ENABLE=0 NCCL_NVLS_ENABLE=0 CUDA_VISIBLE_DEVICES=1 stdbuf -oL torchrun --nnodes 1 --nproc-per-node 1 --master-addr localhost --master-port 14141 examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_175853 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_175853/trainer.log[0m
2025-11-26T17:59:26.662424677Z [37m20251126-17:59:26.662 Local Scheduler INFO: Waiting for 2 local running processes, pids: 315 965[0m
2025-11-26T17:59:27.178076356Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:59:27.178143187Z   import pynvml  # type: ignore[import]
2025-11-26T17:59:28.352770348Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T17:59:28.352807544Z   import pynvml  # type: ignore[import]
2025-11-26T17:59:35.481287535Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:59:35.481331720Z   warnings.warn(
2025-11-26T17:59:35.481334785Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T17:59:35.481337509Z   warnings.warn(
2025-11-26T17:59:35.919045289Z Traceback (most recent call last):
2025-11-26T17:59:35.919082896Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 665, in <module>
2025-11-26T17:59:35.919228904Z     main(sys.argv[1:])
2025-11-26T17:59:35.919466571Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 102, in main
2025-11-26T17:59:35.919494091Z     config, _ = load_expr_config(args_with_overrides, GRPOConfig)
2025-11-26T17:59:35.919632328Z                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:59:35.919638748Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1282, in load_expr_config
2025-11-26T17:59:35.919641182Z     cfg = to_structured_cfg(cfg, config_cls=config_cls)
2025-11-26T17:59:35.920240650Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:59:35.920245497Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1276, in to_structured_cfg
2025-11-26T17:59:35.920248702Z     cfg = OmegaConf.merge(default_cfg, cfg)
2025-11-26T17:59:35.920250915Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:59:35.920252938Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/omegaconf.py", line 274, in merge
2025-11-26T17:59:35.920255342Z     target.merge_with(
2025-11-26T17:59:35.920258166Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 507, in merge_with
2025-11-26T17:59:35.920497494Z     self._format_and_raise(key=None, value=None, cause=e)
2025-11-26T17:59:35.920503233Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:59:35.920506608Z     format_and_raise(
2025-11-26T17:59:35.920509733Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:59:35.920511756Z     _raise(ex, cause)
2025-11-26T17:59:35.920513779Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:59:35.920725135Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:59:35.920730233Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:59:35.920732426Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 502, in merge_with
2025-11-26T17:59:35.920933438Z     self._merge_with(
2025-11-26T17:59:35.920936152Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:59:35.920939217Z     BaseContainer._map_merge(
2025-11-26T17:59:35.920942071Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:59:35.921161779Z     dest_node._merge_with(
2025-11-26T17:59:35.921169411Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:59:35.921171645Z     BaseContainer._map_merge(
2025-11-26T17:59:35.921173808Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T17:59:35.921175911Z     dest_node._merge_with(
2025-11-26T17:59:35.921177924Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T17:59:35.921372285Z     BaseContainer._map_merge(
2025-11-26T17:59:35.921378394Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 432, in _map_merge
2025-11-26T17:59:35.921380898Z     dest[key] = src._get_node(key)
2025-11-26T17:59:35.921383932Z     ~~~~^^^^^
2025-11-26T17:59:35.921790962Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 308, in __setitem__
2025-11-26T17:59:35.921794778Z     self._format_and_raise(
2025-11-26T17:59:35.921798113Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:59:35.921800476Z     format_and_raise(
2025-11-26T17:59:35.921803641Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T17:59:35.921806225Z     _raise(ex, cause)
2025-11-26T17:59:35.921808589Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:59:35.921810762Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:59:35.922006014Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:59:35.922011522Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 306, in __setitem__
2025-11-26T17:59:35.922017321Z     self.__set_impl(key=key, value=value)
2025-11-26T17:59:35.922019454Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 316, in __set_impl
2025-11-26T17:59:35.922230610Z     self._set_item_impl(key, value)
2025-11-26T17:59:35.922235658Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 579, in _set_item_impl
2025-11-26T17:59:35.922238102Z     target_node_ref = self._get_node(key)
2025-11-26T17:59:35.922452793Z                       ^^^^^^^^^^^^^^^^^^^
2025-11-26T17:59:35.922455417Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 473, in _get_node
2025-11-26T17:59:35.922458601Z     self._validate_get(key)
2025-11-26T17:59:35.922461035Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 163, in _validate_get
2025-11-26T17:59:35.922463098Z     self._format_and_raise(
2025-11-26T17:59:35.922465572Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T17:59:35.922649528Z     format_and_raise(
2025-11-26T17:59:35.922652192Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 906, in format_and_raise
2025-11-26T17:59:35.922654165Z     _raise(ex, cause)
2025-11-26T17:59:35.922656138Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T17:59:35.923001865Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T17:59:35.923025341Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:59:35.923029487Z omegaconf.errors.ConfigKeyError: Key 'max_new_tokens' not in 'NormConfig'
2025-11-26T17:59:35.923032641Z     full_key: actor.adv_norm.max_new_tokens
2025-11-26T17:59:35.923034995Z     reference_type=Optional[NormConfig]
2025-11-26T17:59:35.923037158Z     object_type=NormConfig
2025-11-26T17:59:38.570187201Z E1126 17:59:38.569000 966 torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 0 (pid: 1032) of binary: /usr/bin/python3
2025-11-26T17:59:38.570474181Z Traceback (most recent call last):
2025-11-26T17:59:38.570481752Z   File "/usr/local/bin/torchrun", line 7, in <module>
2025-11-26T17:59:38.570721231Z     sys.exit(main())
2025-11-26T17:59:38.570725006Z              ^^^^^^
2025-11-26T17:59:38.570727160Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
2025-11-26T17:59:38.570730124Z     return f(*args, **kwargs)
2025-11-26T17:59:38.570732858Z            ^^^^^^^^^^^^^^^^^^
2025-11-26T17:59:38.570734861Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 901, in main
2025-11-26T17:59:38.570988280Z     run(args)
2025-11-26T17:59:38.570991145Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 892, in run
2025-11-26T17:59:38.571273137Z     elastic_launch(
2025-11-26T17:59:38.571279336Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 143, in __call__
2025-11-26T17:59:38.571282761Z     return launch_agent(self._config, self._entrypoint, list(args))
2025-11-26T17:59:38.571285726Z            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T17:59:38.571287669Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 277, in launch_agent
2025-11-26T17:59:38.571290072Z     raise ChildFailedError(
2025-11-26T17:59:38.571292095Z torch.distributed.elastic.multiprocessing.errors.ChildFailedError:
2025-11-26T17:59:38.571294479Z ============================================================
2025-11-26T17:59:38.571297423Z examples/cloud_gsm8k/gsm8k_grpo_train.py FAILED
2025-11-26T17:59:38.571300799Z ------------------------------------------------------------
2025-11-26T17:59:38.571302791Z Failures:
2025-11-26T17:59:38.571304925Z   <NO_OTHER_FAILURES>
2025-11-26T17:59:38.571307158Z ------------------------------------------------------------
2025-11-26T17:59:38.571309221Z Root Cause (first observed failure):
2025-11-26T17:59:38.571311194Z [0]:
2025-11-26T17:59:38.571313207Z   time      : 2025-11-26_17:59:38
2025-11-26T17:59:38.571328080Z   host      : cef7c503fdea
2025-11-26T17:59:38.571330263Z   rank      : 0 (local_rank: 0)
2025-11-26T17:59:38.571332416Z   exitcode  : 1 (pid: 1032)
2025-11-26T17:59:38.571334549Z   error_file: <N/A>
2025-11-26T17:59:38.571336542Z   traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
2025-11-26T17:59:38.571338716Z ============================================================
2025-11-26T17:59:40.665990716Z [37m20251126-17:59:40.665 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [315][0m
2025-11-26T17:59:40.792351689Z Killed
2025-11-26T17:59:40.803012987Z [37m20251126-17:59:40.802 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [965][0m
2025-11-26T17:59:40.804194728Z Traceback (most recent call last):
2025-11-26T17:59:40.804207367Z   File "<frozen runpy>", line 198, in _run_module_as_main
2025-11-26T17:59:40.804210621Z   File "<frozen runpy>", line 88, in _run_code
2025-11-26T17:59:40.804213476Z   File "/workspace/AReaL/areal/launcher/local.py", line 405, in <module>
2025-11-26T17:59:40.804313496Z     main()
2025-11-26T17:59:40.804319905Z   File "/workspace/AReaL/areal/launcher/local.py", line 260, in main
2025-11-26T17:59:40.804412273Z     local_main(config, run_id=0)
2025-11-26T17:59:40.804422489Z   File "/workspace/AReaL/areal/launcher/local.py", line 399, in local_main
2025-11-26T17:59:40.804509800Z     raise e
2025-11-26T17:59:40.804516089Z   File "/workspace/AReaL/areal/launcher/local.py", line 375, in local_main
2025-11-26T17:59:40.804559815Z     launcher.wait(
2025-11-26T17:59:40.804563230Z   File "/workspace/AReaL/areal/launcher/local.py", line 235, in wait
2025-11-26T17:59:40.804630201Z     raise JobException(
2025-11-26T17:59:40.804634376Z areal.utils.launcher.JobException: Job gsm8k-grpo-cloud-2gpu-2000samples_trial_20251126_175853:trainer JobState.COMPLETED at node local
2025-11-26T17:59:40.991215762Z [37m20251126-17:59:40.990 Local Scheduler INFO: Waiting for 0 local running processes, pids: [0m
2025-11-26T17:59:57.024970514Z ==========
2025-11-26T17:59:57.024991024Z == CUDA ==
2025-11-26T17:59:57.025009132Z ==========
2025-11-26T17:59:57.029960097Z CUDA Version 12.9.1
2025-11-26T17:59:57.031513033Z Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
2025-11-26T17:59:57.032976205Z This container image and its contents are governed by the NVIDIA Deep Learning Container License.
2025-11-26T17:59:57.032978878Z By pulling and using the container, you accept the terms and conditions of this license:
2025-11-26T17:59:57.032981633Z https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license
2025-11-26T17:59:57.032986009Z A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
2025-11-26T17:59:57.198907017Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:59:57.358350824Z Writing to /root/.config/pip/pip.conf
2025-11-26T17:59:57.529190961Z Branch 'feature/reasoning_model' set up to track remote branch 'feature/reasoning_model' from 'origin'.
2025-11-26T17:59:57.529242117Z Your branch is up to date with 'origin/feature/reasoning_model'.
2025-11-26T17:59:57.599600786Z Checking AReaL installation...
2025-11-26T17:59:57.659440378Z AReaL already installed. Skipping installation.
2025-11-26T17:59:57.659480849Z Cleaning up any leftover GPU processes...
2025-11-26T18:00:00.677899603Z Checking for processes holding GPU device files...
2025-11-26T18:00:02.979278865Z Found processes holding GPU devices: 1
2025-11-26T18:00:02.979321970Z 20
2025-11-26T18:00:02.979325784Z 71
2025-11-26T18:00:02.979328929Z 72
2025-11-26T18:00:02.979331513Z Killing process 1...
2025-11-26T18:00:02.979339575Z Killing process 71...
2025-11-26T18:00:02.979543341Z Killing process 72...
2025-11-26T18:00:04.982441155Z Using fuser to kill processes on GPU devices...
2025-11-26T18:00:07.007307606Z Checking GPU...
2025-11-26T18:00:07.043960567Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T18:00:07.043983682Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T18:00:07.061347261Z Set PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True for better memory management
2025-11-26T18:00:07.061378588Z Detected 2 GPU(s)
2025-11-26T18:00:07.061381733Z Checking GPU status...
2025-11-26T18:00:07.089087232Z index, name, utilization.gpu [%], memory.used [MiB], compute_mode
2025-11-26T18:00:07.090570704Z 0, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T18:00:07.090828730Z 1, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T18:00:07.132356854Z Verifying GPU accessibility...
2025-11-26T18:00:07.689612131Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:00:07.689670509Z   import pynvml  # type: ignore[import]
2025-11-26T18:00:08.778157332Z GPU accessibility verified on attempt 1
2025-11-26T18:00:09.265317135Z Starting training...
2025-11-26T18:00:12.268181813Z Using STANDARD 2000 SAMPLES 2 GPUs configuration
2025-11-26T18:00:12.268223584Z Note: GRPO only (no reasoning XML). Dataset capped at 2000 samples (~6 hours).
2025-11-26T18:00:12.268227129Z GPU count: 2 (required: 2)
2025-11-26T18:00:12.271109247Z ==========================================
2025-11-26T18:00:12.271126744Z Starting GRPO Training (Cloud)
2025-11-26T18:00:12.271131140Z ==========================================
2025-11-26T18:00:12.271133294Z Config: standard_2000samples_2GPUs
2025-11-26T18:00:12.271135377Z Config file: examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml
2025-11-26T18:00:12.271137870Z Training script: examples/cloud_gsm8k/gsm8k_grpo_train.py
2025-11-26T18:00:12.271140784Z Experiment: gsm8k-grpo-cloud-2gpu-2000samples
2025-11-26T18:00:12.271142817Z Trial: trial_20251126_180012
2025-11-26T18:00:12.271144840Z GPU: NVIDIA A100 80GB PCIe NVIDIA A100 80GB PCIe (81920 MB)
2025-11-26T18:00:12.271146933Z WandB API key: e1adc5be02...
2025-11-26T18:00:12.271149056Z ==========================================
2025-11-26T18:00:12.974855419Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:00:12.974896149Z   import pynvml  # type: ignore[import]
2025-11-26T18:00:17.156042391Z [37m20251126-18:00:17.155 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T18:00:17.156087539Z [37m20251126-18:00:17.155 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T18:00:17.156333788Z [37m20251126-18:00:17.156 name-resolve INFO: No such name resolve path: ./tmp/areal/name_resolve/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_180012[0m
2025-11-26T18:00:17.262521684Z [37m20251126-18:00:17.262 Local Scheduler INFO: LocalLauncher: experiment_name=gsm8k-grpo-cloud-2gpu-2000samples, trial_name=trial_20251126_180012, fileroot=/workspace/outputs/grpo, run_id=0, is_recover_run=False[0m
2025-11-26T18:00:17.270558201Z [37m20251126-18:00:17.270 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL CUDA_VISIBLE_DEVICES=0 stdbuf -oL python3 -m areal.launcher.sglang_server examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_180012 sglang.random_seed=1 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_180012/llm_server.log[0m
2025-11-26T18:00:18.004195306Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:00:18.004254865Z   import pynvml  # type: ignore[import]
2025-11-26T18:00:19.478246346Z [37m20251126-18:00:19.477 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T18:00:19.479148547Z [37m20251126-18:00:19.477 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T18:00:19.581697553Z [37m20251126-18:00:19.581 SGLangServer Wrapper INFO: Launch command: python3 -m sglang.launch_server --host 172.21.0.2 --port 26189 --tokenizer-path Qwen/Qwen2.5-0.5B-Instruct --tokenizer-mode auto --load-format auto --trust-remote-code --device cuda --tp-size 1 --base-gpu-id 0 --nnodes 1 --node-rank 0 --dist-init-addr localhost:28806 --model-path Qwen/Qwen2.5-0.5B-Instruct --random-seed 1 --skip-tokenizer-init --disable-radix-cache --torch-compile-max-bs 32 --triton-attention-num-kv-splits 8 --num-continuous-decode-steps 1 --attention-backend flashinfer --context-length 4096 --mem-fraction-static 0.6 --chunked-prefill-size -1 --max-prefill-tokens 32768 --schedule-policy lpm --schedule-conservativeness 1.0 --cpu-offload-gb 0 --dtype bfloat16 --kv-cache-dtype auto --dp-size 1 --ep-size 1 --max-loaded-loras 1 --max-loras-per-batch 1 --lora-backend triton --log-level warning --log-level-http warning --log-requests-level 0 --enable-metrics --decode-log-interval 1[0m
2025-11-26T18:00:20.624035161Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:00:20.624072296Z   import pynvml  # type: ignore[import]
2025-11-26T18:00:26.198183661Z INFO 11-26 18:00:26 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T18:00:26.835549814Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T18:00:27.859842694Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:00:27.859872810Z   import pynvml  # type: ignore[import]
2025-11-26T18:00:27.860644214Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:00:27.860654430Z   import pynvml  # type: ignore[import]
2025-11-26T18:00:33.036650399Z INFO 11-26 18:00:33 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T18:00:33.443069012Z INFO 11-26 18:00:33 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T18:00:34.062850716Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T18:00:34.280021610Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T18:00:34.283626039Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T18:00:34.284440359Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T18:00:34.285290763Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T18:00:34.318855919Z [2025-11-26 18:00:34] MOE_RUNNER_BACKEND is not initialized, using triton backend
2025-11-26T18:00:34.821187968Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T18:00:34.821239134Z   warnings.warn(
2025-11-26T18:00:34.821242009Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T18:00:34.821244232Z   warnings.warn(
2025-11-26T18:00:36.331583797Z Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
2025-11-26T18:00:36.439637959Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  9.27it/s]
2025-11-26T18:00:36.440524747Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  9.25it/s]
2025-11-26T18:00:38.973053792Z   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   4%|â–         | 1/23 [00:00<00:12,  1.83it/s]Capturing batches (bs=152 avail_mem=30.62 GB):   4%|â–         | 1/23 [00:00<00:12,  1.83it/s]Capturing batches (bs=144 avail_mem=30.60 GB):   4%|â–         | 1/23 [00:00<00:12,  1.83it/s]Capturing batches (bs=136 avail_mem=30.59 GB):   4%|â–         | 1/23 [00:00<00:12,  1.83it/s]Capturing batches (bs=136 avail_mem=30.59 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.24it/s]Capturing batches (bs=128 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.24it/s]Capturing batches (bs=120 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.24it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.24it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.55it/s]Capturing batches (bs=104 avail_mem=30.54 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.55it/s]Capturing batches (bs=96 avail_mem=30.53 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.55it/s] Capturing batches (bs=88 avail_mem=30.51 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.55it/s]Capturing batches (bs=88 avail_mem=30.51 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.85it/s]Capturing batches (bs=80 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.85it/s]Capturing batches (bs=72 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.85it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:01<00:00, 14.85it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.03it/s]Capturing batches (bs=56 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.03it/s]Capturing batches (bs=48 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.03it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.03it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 18.73it/s]Capturing batches (bs=32 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 18.73it/s]Capturing batches (bs=24 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 18.73it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 18.73it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.23it/s]Capturing batches (bs=8 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.23it/s] Capturing batches (bs=4 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.23it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.23it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.09it/s]Capturing batches (bs=1 avail_mem=30.35 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.09it/s]Capturing batches (bs=1 avail_mem=30.35 GB): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00, 14.70it/s]
2025-11-26T18:00:44.608780028Z [37m20251126-18:00:44.608 SGLangServer Wrapper INFO: SGLang server launched at: http://172.21.0.2:26189[0m
2025-11-26T18:00:45.277853364Z [37m20251126-18:00:45.277 Launcher Utils INFO: Found 1 rollout servers: 172.21.0.2:26189[0m
2025-11-26T18:00:45.277891331Z [37m20251126-18:00:45.277 Local Scheduler INFO: LLM inference server launched at: AREAL_LLM_SERVER_ADDRS=172.21.0.2:26189[0m
2025-11-26T18:00:45.280967548Z [37m20251126-18:00:45.280 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL AREAL_LLM_SERVER_ADDRS=172.21.0.2:26189 AREAL_RECOVER_RUN=0 NCCL_CUMEM_ENABLE=0 NCCL_NVLS_ENABLE=0 CUDA_VISIBLE_DEVICES=1 stdbuf -oL torchrun --nnodes 1 --nproc-per-node 1 --master-addr localhost --master-port 43333 examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_180012 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_180012/trainer.log[0m
2025-11-26T18:00:45.281564212Z [37m20251126-18:00:45.281 Local Scheduler INFO: Waiting for 2 local running processes, pids: 315 965[0m
2025-11-26T18:00:45.827926133Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:00:45.827965101Z   import pynvml  # type: ignore[import]
2025-11-26T18:00:47.022624197Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:00:47.022666741Z   import pynvml  # type: ignore[import]
2025-11-26T18:00:53.634466631Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T18:00:53.634511118Z   warnings.warn(
2025-11-26T18:00:53.634514833Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T18:00:53.634517788Z   warnings.warn(
2025-11-26T18:00:54.072894720Z Traceback (most recent call last):
2025-11-26T18:00:54.072933718Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 665, in <module>
2025-11-26T18:00:54.073576782Z     main(sys.argv[1:])
2025-11-26T18:00:54.073590162Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 102, in main
2025-11-26T18:00:54.073594008Z     config, _ = load_expr_config(args_with_overrides, GRPOConfig)
2025-11-26T18:00:54.073608078Z                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T18:00:54.073610262Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1282, in load_expr_config
2025-11-26T18:00:54.073612355Z     cfg = to_structured_cfg(cfg, config_cls=config_cls)
2025-11-26T18:00:54.074007818Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T18:00:54.074011363Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1276, in to_structured_cfg
2025-11-26T18:00:54.074014157Z     cfg = OmegaConf.merge(default_cfg, cfg)
2025-11-26T18:00:54.074016761Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T18:00:54.074018925Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/omegaconf.py", line 274, in merge
2025-11-26T18:00:54.074021228Z     target.merge_with(
2025-11-26T18:00:54.074023962Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 507, in merge_with
2025-11-26T18:00:54.074474086Z     self._format_and_raise(key=None, value=None, cause=e)
2025-11-26T18:00:54.074478983Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T18:00:54.074481987Z     format_and_raise(
2025-11-26T18:00:54.074484091Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T18:00:54.074486294Z     _raise(ex, cause)
2025-11-26T18:00:54.074488307Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T18:00:54.074490450Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T18:00:54.075474184Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T18:00:54.075510909Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 502, in merge_with
2025-11-26T18:00:54.075514595Z     self._merge_with(
2025-11-26T18:00:54.075518080Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T18:00:54.075520354Z     BaseContainer._map_merge(
2025-11-26T18:00:54.075523006Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T18:00:54.075525140Z     dest_node._merge_with(
2025-11-26T18:00:54.075527303Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T18:00:54.075529446Z     BaseContainer._map_merge(
2025-11-26T18:00:54.075531469Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T18:00:54.075533422Z     dest_node._merge_with(
2025-11-26T18:00:54.075535555Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T18:00:54.075537508Z     BaseContainer._map_merge(
2025-11-26T18:00:54.075539662Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 432, in _map_merge
2025-11-26T18:00:54.075541625Z     dest[key] = src._get_node(key)
2025-11-26T18:00:54.075543588Z     ~~~~^^^^^
2025-11-26T18:00:54.075546292Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 308, in __setitem__
2025-11-26T18:00:54.075548745Z     self._format_and_raise(
2025-11-26T18:00:54.075550808Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T18:00:54.075552851Z     format_and_raise(
2025-11-26T18:00:54.075554864Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T18:00:54.076174863Z     _raise(ex, cause)
2025-11-26T18:00:54.076184107Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T18:00:54.076186540Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T18:00:54.076322395Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T18:00:54.076331658Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 306, in __setitem__
2025-11-26T18:00:54.076335975Z     self.__set_impl(key=key, value=value)
2025-11-26T18:00:54.076338839Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 316, in __set_impl
2025-11-26T18:00:54.076352400Z     self._set_item_impl(key, value)
2025-11-26T18:00:54.076355354Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 579, in _set_item_impl
2025-11-26T18:00:54.076358198Z     target_node_ref = self._get_node(key)
2025-11-26T18:00:54.076361002Z                       ^^^^^^^^^^^^^^^^^^^
2025-11-26T18:00:54.076363657Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 473, in _get_node
2025-11-26T18:00:54.076493350Z     self._validate_get(key)
2025-11-26T18:00:54.076500361Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 163, in _validate_get
2025-11-26T18:00:54.076502925Z     self._format_and_raise(
2025-11-26T18:00:54.076505288Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T18:00:54.076507461Z     format_and_raise(
2025-11-26T18:00:54.076509955Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 906, in format_and_raise
2025-11-26T18:00:54.076511878Z     _raise(ex, cause)
2025-11-26T18:00:54.076513901Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T18:00:54.076882994Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T18:00:54.076891307Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T18:00:54.076894341Z omegaconf.errors.ConfigKeyError: Key 'max_new_tokens' not in 'NormConfig'
2025-11-26T18:00:54.076897957Z     full_key: actor.adv_norm.max_new_tokens
2025-11-26T18:00:54.076901151Z     reference_type=Optional[NormConfig]
2025-11-26T18:00:54.076903986Z     object_type=NormConfig
2025-11-26T18:00:56.645068006Z E1126 18:00:56.644000 966 torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 0 (pid: 1032) of binary: /usr/bin/python3
2025-11-26T18:00:56.645689437Z Traceback (most recent call last):
2025-11-26T18:00:56.645697249Z   File "/usr/local/bin/torchrun", line 7, in <module>
2025-11-26T18:00:56.645699963Z     sys.exit(main())
2025-11-26T18:00:56.645702727Z              ^^^^^^
2025-11-26T18:00:56.645704850Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
2025-11-26T18:00:56.646072120Z     return f(*args, **kwargs)
2025-11-26T18:00:56.646075255Z            ^^^^^^^^^^^^^^^^^^
2025-11-26T18:00:56.646077238Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 901, in main
2025-11-26T18:00:56.646658068Z     run(args)
2025-11-26T18:00:56.646662565Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 892, in run
2025-11-26T18:00:56.646665609Z     elastic_launch(
2025-11-26T18:00:56.646668313Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 143, in __call__
2025-11-26T18:00:56.646671629Z     return launch_agent(self._config, self._entrypoint, list(args))
2025-11-26T18:00:56.646674393Z            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T18:00:56.646676506Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 277, in launch_agent
2025-11-26T18:00:56.646678629Z     raise ChildFailedError(
2025-11-26T18:00:56.646681263Z torch.distributed.elastic.multiprocessing.errors.ChildFailedError:
2025-11-26T18:00:56.646683346Z ============================================================
2025-11-26T18:00:56.646685329Z examples/cloud_gsm8k/gsm8k_grpo_train.py FAILED
2025-11-26T18:00:56.646687372Z ------------------------------------------------------------
2025-11-26T18:00:56.646689536Z Failures:
2025-11-26T18:00:56.646691559Z   <NO_OTHER_FAILURES>
2025-11-26T18:00:56.646693562Z ------------------------------------------------------------
2025-11-26T18:00:56.646696676Z Root Cause (first observed failure):
2025-11-26T18:00:56.646698719Z [0]:
2025-11-26T18:00:56.646700882Z   time      : 2025-11-26_18:00:56
2025-11-26T18:00:56.646703026Z   host      : cef7c503fdea
2025-11-26T18:00:56.646705079Z   rank      : 0 (local_rank: 0)
2025-11-26T18:00:56.646707112Z   exitcode  : 1 (pid: 1032)
2025-11-26T18:00:56.646719621Z   error_file: <N/A>
2025-11-26T18:00:56.646721864Z   traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
2025-11-26T18:00:56.646724037Z ============================================================
2025-11-26T18:00:57.288767396Z [37m20251126-18:00:57.288 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [315][0m
2025-11-26T18:00:57.474092008Z Killed
2025-11-26T18:00:57.486503199Z [37m20251126-18:00:57.486 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [965][0m
2025-11-26T18:00:57.487963065Z Traceback (most recent call last):
2025-11-26T18:00:57.487969225Z   File "<frozen runpy>", line 198, in _run_module_as_main
2025-11-26T18:00:57.487971668Z   File "<frozen runpy>", line 88, in _run_code
2025-11-26T18:00:57.487973801Z   File "/workspace/AReaL/areal/launcher/local.py", line 405, in <module>
2025-11-26T18:00:57.488142524Z     main()
2025-11-26T18:00:57.488248804Z   File "/workspace/AReaL/areal/launcher/local.py", line 260, in main
2025-11-26T18:00:57.488310035Z     local_main(config, run_id=0)
2025-11-26T18:00:57.488312960Z   File "/workspace/AReaL/areal/launcher/local.py", line 399, in local_main
2025-11-26T18:00:57.488447501Z     raise e
2025-11-26T18:00:57.488450385Z   File "/workspace/AReaL/areal/launcher/local.py", line 375, in local_main
2025-11-26T18:00:57.488532939Z     launcher.wait(
2025-11-26T18:00:57.488535823Z   File "/workspace/AReaL/areal/launcher/local.py", line 235, in wait
2025-11-26T18:00:57.488601341Z     raise JobException(
2025-11-26T18:00:57.488604156Z areal.utils.launcher.JobException: Job gsm8k-grpo-cloud-2gpu-2000samples_trial_20251126_180012:trainer JobState.COMPLETED at node local
2025-11-26T18:00:57.770901891Z [37m20251126-18:00:57.770 Local Scheduler INFO: Waiting for 0 local running processes, pids: [0m
2025-11-26T18:01:00.159542670Z ==========
2025-11-26T18:01:00.159547818Z == CUDA ==
2025-11-26T18:01:00.159553316Z ==========
2025-11-26T18:01:00.163901979Z CUDA Version 12.9.1
2025-11-26T18:01:00.165425841Z Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
2025-11-26T18:01:00.167463533Z This container image and its contents are governed by the NVIDIA Deep Learning Container License.
2025-11-26T18:01:00.167465877Z By pulling and using the container, you accept the terms and conditions of this license:
2025-11-26T18:01:00.167468291Z https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license
2025-11-26T18:01:00.167472407Z A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
2025-11-26T18:01:00.332282251Z Writing to /root/.config/pip/pip.conf
2025-11-26T18:01:00.490312931Z Writing to /root/.config/pip/pip.conf
2025-11-26T18:01:00.689079848Z Branch 'feature/reasoning_model' set up to track remote branch 'feature/reasoning_model' from 'origin'.
2025-11-26T18:01:00.689142743Z Your branch is up to date with 'origin/feature/reasoning_model'.
2025-11-26T18:01:00.759712407Z Checking AReaL installation...
2025-11-26T18:01:00.819062656Z AReaL already installed. Skipping installation.
2025-11-26T18:01:00.819094494Z Cleaning up any leftover GPU processes...
2025-11-26T18:01:03.838162091Z Checking for processes holding GPU device files...
2025-11-26T18:01:06.022887480Z Found processes holding GPU devices: 1
2025-11-26T18:01:06.022926058Z 20
2025-11-26T18:01:06.022928651Z 71
2025-11-26T18:01:06.022931515Z 72
2025-11-26T18:01:06.022933589Z Killing process 1...
2025-11-26T18:01:06.022936453Z Killing process 71...
2025-11-26T18:01:06.023011105Z Killing process 72...
2025-11-26T18:01:08.026219244Z Using fuser to kill processes on GPU devices...
2025-11-26T18:01:10.053732489Z Checking GPU...
2025-11-26T18:01:10.089213856Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T18:01:10.089259645Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T18:01:10.106285668Z Set PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True for better memory management
2025-11-26T18:01:10.106317955Z Detected 2 GPU(s)
2025-11-26T18:01:10.106321731Z Checking GPU status...
2025-11-26T18:01:10.134555833Z index, name, utilization.gpu [%], memory.used [MiB], compute_mode
2025-11-26T18:01:10.136005754Z 0, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T18:01:10.136318262Z 1, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T18:01:10.179369206Z Verifying GPU accessibility...
2025-11-26T18:01:10.726535051Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:01:10.726591246Z   import pynvml  # type: ignore[import]
2025-11-26T18:01:11.851866834Z GPU accessibility verified on attempt 1
2025-11-26T18:01:12.400190693Z Starting training...
2025-11-26T18:01:15.402797063Z Using STANDARD 2000 SAMPLES 2 GPUs configuration
2025-11-26T18:01:15.402845585Z Note: GRPO only (no reasoning XML). Dataset capped at 2000 samples (~6 hours).
2025-11-26T18:01:15.402848881Z GPU count: 2 (required: 2)
2025-11-26T18:01:15.405136788Z ==========================================
2025-11-26T18:01:15.405141555Z Starting GRPO Training (Cloud)
2025-11-26T18:01:15.405144579Z ==========================================
2025-11-26T18:01:15.405146672Z Config: standard_2000samples_2GPUs
2025-11-26T18:01:15.405149036Z Config file: examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml
2025-11-26T18:01:15.405151700Z Training script: examples/cloud_gsm8k/gsm8k_grpo_train.py
2025-11-26T18:01:15.405153993Z Experiment: gsm8k-grpo-cloud-2gpu-2000samples
2025-11-26T18:01:15.405156077Z Trial: trial_20251126_180115
2025-11-26T18:01:15.405158089Z GPU: NVIDIA A100 80GB PCIe NVIDIA A100 80GB PCIe (81920 MB)
2025-11-26T18:01:15.405160143Z WandB API key: e1adc5be02...
2025-11-26T18:01:15.405162115Z ==========================================
2025-11-26T18:01:16.129880410Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:01:16.129926490Z   import pynvml  # type: ignore[import]
2025-11-26T18:01:20.205840407Z [37m20251126-18:01:20.205 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T18:01:20.205882640Z [37m20251126-18:01:20.205 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T18:01:20.206195849Z [37m20251126-18:01:20.205 name-resolve INFO: No such name resolve path: ./tmp/areal/name_resolve/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_180115[0m
2025-11-26T18:01:20.313705084Z [37m20251126-18:01:20.313 Local Scheduler INFO: LocalLauncher: experiment_name=gsm8k-grpo-cloud-2gpu-2000samples, trial_name=trial_20251126_180115, fileroot=/workspace/outputs/grpo, run_id=0, is_recover_run=False[0m
2025-11-26T18:01:20.321679359Z [37m20251126-18:01:20.321 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL CUDA_VISIBLE_DEVICES=0 stdbuf -oL python3 -m areal.launcher.sglang_server examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_180115 sglang.random_seed=1 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_180115/llm_server.log[0m
2025-11-26T18:01:21.073208042Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:01:21.073253110Z   import pynvml  # type: ignore[import]
2025-11-26T18:01:22.573680248Z [37m20251126-18:01:22.573 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T18:01:22.574502029Z [37m20251126-18:01:22.573 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T18:01:22.688616147Z [37m20251126-18:01:22.688 SGLangServer Wrapper INFO: Launch command: python3 -m sglang.launch_server --host 172.21.0.2 --port 14506 --tokenizer-path Qwen/Qwen2.5-0.5B-Instruct --tokenizer-mode auto --load-format auto --trust-remote-code --device cuda --tp-size 1 --base-gpu-id 0 --nnodes 1 --node-rank 0 --dist-init-addr localhost:22032 --model-path Qwen/Qwen2.5-0.5B-Instruct --random-seed 1 --skip-tokenizer-init --disable-radix-cache --torch-compile-max-bs 32 --triton-attention-num-kv-splits 8 --num-continuous-decode-steps 1 --attention-backend flashinfer --context-length 4096 --mem-fraction-static 0.6 --chunked-prefill-size -1 --max-prefill-tokens 32768 --schedule-policy lpm --schedule-conservativeness 1.0 --cpu-offload-gb 0 --dtype bfloat16 --kv-cache-dtype auto --dp-size 1 --ep-size 1 --max-loaded-loras 1 --max-loras-per-batch 1 --lora-backend triton --log-level warning --log-level-http warning --log-requests-level 0 --enable-metrics --decode-log-interval 1[0m
2025-11-26T18:01:23.771833578Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:01:23.771877314Z   import pynvml  # type: ignore[import]
2025-11-26T18:01:29.721821238Z INFO 11-26 18:01:29 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T18:01:30.574068976Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T18:01:31.610851975Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:01:31.610892966Z   import pynvml  # type: ignore[import]
2025-11-26T18:01:31.654226273Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:01:31.654268447Z   import pynvml  # type: ignore[import]
2025-11-26T18:01:37.223239392Z INFO 11-26 18:01:37 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T18:01:37.919432671Z INFO 11-26 18:01:37 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T18:01:38.532204584Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T18:01:38.751679841Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T18:01:38.755299212Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T18:01:38.756171439Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T18:01:38.756996084Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T18:01:38.790574901Z [2025-11-26 18:01:38] MOE_RUNNER_BACKEND is not initialized, using triton backend
2025-11-26T18:01:39.294965132Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T18:01:39.295004121Z   warnings.warn(
2025-11-26T18:01:39.295007496Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T18:01:39.295020736Z   warnings.warn(
2025-11-26T18:01:40.579798529Z Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
2025-11-26T18:01:40.685576140Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  9.47it/s]
2025-11-26T18:01:40.686079233Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  9.45it/s]
2025-11-26T18:01:43.273193780Z   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   4%|â–         | 1/23 [00:00<00:11,  1.85it/s]Capturing batches (bs=152 avail_mem=30.62 GB):   4%|â–         | 1/23 [00:00<00:11,  1.85it/s]Capturing batches (bs=144 avail_mem=30.60 GB):   4%|â–         | 1/23 [00:00<00:11,  1.85it/s]Capturing batches (bs=136 avail_mem=30.59 GB):   4%|â–         | 1/23 [00:00<00:11,  1.85it/s]Capturing batches (bs=136 avail_mem=30.59 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.26it/s]Capturing batches (bs=128 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.26it/s]Capturing batches (bs=120 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.26it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.26it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.51it/s]Capturing batches (bs=104 avail_mem=30.54 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.51it/s]Capturing batches (bs=96 avail_mem=30.53 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.51it/s] Capturing batches (bs=88 avail_mem=30.51 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.51it/s]Capturing batches (bs=88 avail_mem=30.51 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.80it/s]Capturing batches (bs=80 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.80it/s]Capturing batches (bs=72 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.80it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:01<00:00, 14.80it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.31it/s]Capturing batches (bs=56 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.31it/s]Capturing batches (bs=48 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.31it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.31it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.31it/s]Capturing batches (bs=32 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.31it/s]Capturing batches (bs=24 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.31it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.31it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.60it/s]Capturing batches (bs=8 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.60it/s] Capturing batches (bs=4 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.60it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.60it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.19it/s]Capturing batches (bs=1 avail_mem=30.35 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.19it/s]Capturing batches (bs=1 avail_mem=30.35 GB): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00, 14.80it/s]
2025-11-26T18:01:48.720751340Z [37m20251126-18:01:48.720 SGLangServer Wrapper INFO: SGLang server launched at: http://172.21.0.2:14506[0m
2025-11-26T18:01:49.329330239Z [37m20251126-18:01:49.328 Launcher Utils INFO: Found 1 rollout servers: 172.21.0.2:14506[0m
2025-11-26T18:01:49.329369128Z [37m20251126-18:01:49.329 Local Scheduler INFO: LLM inference server launched at: AREAL_LLM_SERVER_ADDRS=172.21.0.2:14506[0m
2025-11-26T18:01:49.332447479Z [37m20251126-18:01:49.332 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL AREAL_LLM_SERVER_ADDRS=172.21.0.2:14506 AREAL_RECOVER_RUN=0 NCCL_CUMEM_ENABLE=0 NCCL_NVLS_ENABLE=0 CUDA_VISIBLE_DEVICES=1 stdbuf -oL torchrun --nnodes 1 --nproc-per-node 1 --master-addr localhost --master-port 21075 examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_180115 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_180115/trainer.log[0m
2025-11-26T18:01:49.333185995Z [37m20251126-18:01:49.332 Local Scheduler INFO: Waiting for 2 local running processes, pids: 315 965[0m
2025-11-26T18:01:49.886966194Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:01:49.887004800Z   import pynvml  # type: ignore[import]
2025-11-26T18:01:51.085717331Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:01:51.085751352Z   import pynvml  # type: ignore[import]
2025-11-26T18:01:58.326774023Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T18:01:58.326814964Z   warnings.warn(
2025-11-26T18:01:58.326818039Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T18:01:58.326820322Z   warnings.warn(
2025-11-26T18:01:58.771325802Z Traceback (most recent call last):
2025-11-26T18:01:58.771364821Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 665, in <module>
2025-11-26T18:01:58.771740843Z     main(sys.argv[1:])
2025-11-26T18:01:58.771744499Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 102, in main
2025-11-26T18:01:58.771747213Z     config, _ = load_expr_config(args_with_overrides, GRPOConfig)
2025-11-26T18:01:58.771749947Z                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T18:01:58.771767834Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1282, in load_expr_config
2025-11-26T18:01:58.772297768Z     cfg = to_structured_cfg(cfg, config_cls=config_cls)
2025-11-26T18:01:58.772302475Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T18:01:58.772305088Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1276, in to_structured_cfg
2025-11-26T18:01:58.772307592Z     cfg = OmegaConf.merge(default_cfg, cfg)
2025-11-26T18:01:58.772309635Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T18:01:58.772311588Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/omegaconf.py", line 274, in merge
2025-11-26T18:01:58.772631157Z     target.merge_with(
2025-11-26T18:01:58.772633831Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 507, in merge_with
2025-11-26T18:01:58.772636365Z     self._format_and_raise(key=None, value=None, cause=e)
2025-11-26T18:01:58.772638658Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T18:01:58.772640811Z     format_and_raise(
2025-11-26T18:01:58.772643185Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T18:01:58.773159618Z     _raise(ex, cause)
2025-11-26T18:01:58.773164375Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T18:01:58.773166438Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T18:01:58.773168452Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T18:01:58.773170455Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 502, in merge_with
2025-11-26T18:01:58.773173048Z     self._merge_with(
2025-11-26T18:01:58.773175011Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T18:01:58.773177014Z     BaseContainer._map_merge(
2025-11-26T18:01:58.773180019Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T18:01:58.773624315Z     dest_node._merge_with(
2025-11-26T18:01:58.773647720Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T18:01:58.773651165Z     BaseContainer._map_merge(
2025-11-26T18:01:58.773653549Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T18:01:58.773655672Z     dest_node._merge_with(
2025-11-26T18:01:58.773657715Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T18:01:58.773659778Z     BaseContainer._map_merge(
2025-11-26T18:01:58.773661801Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 432, in _map_merge
2025-11-26T18:01:58.773663794Z     dest[key] = src._get_node(key)
2025-11-26T18:01:58.773666488Z     ~~~~^^^^^
2025-11-26T18:01:58.773668982Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 308, in __setitem__
2025-11-26T18:01:58.774283993Z     self._format_and_raise(
2025-11-26T18:01:58.774290213Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T18:01:58.774292546Z     format_and_raise(
2025-11-26T18:01:58.774294519Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T18:01:58.774301278Z     _raise(ex, cause)
2025-11-26T18:01:58.774303301Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T18:01:58.774305785Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T18:01:58.774308088Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T18:01:58.774310332Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 306, in __setitem__
2025-11-26T18:01:58.774312405Z     self.__set_impl(key=key, value=value)
2025-11-26T18:01:58.774314468Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 316, in __set_impl
2025-11-26T18:01:58.774316481Z     self._set_item_impl(key, value)
2025-11-26T18:01:58.774683601Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 579, in _set_item_impl
2025-11-26T18:01:58.774688398Z     target_node_ref = self._get_node(key)
2025-11-26T18:01:58.774690562Z                       ^^^^^^^^^^^^^^^^^^^
2025-11-26T18:01:58.774692605Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 473, in _get_node
2025-11-26T18:01:58.774695148Z     self._validate_get(key)
2025-11-26T18:01:58.774697292Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 163, in _validate_get
2025-11-26T18:01:58.774699315Z     self._format_and_raise(
2025-11-26T18:01:58.774701729Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T18:01:58.775255278Z     format_and_raise(
2025-11-26T18:01:58.775261096Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 906, in format_and_raise
2025-11-26T18:01:58.775263440Z     _raise(ex, cause)
2025-11-26T18:01:58.775265393Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T18:01:58.775267466Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T18:01:58.775269469Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T18:01:58.775271632Z omegaconf.errors.ConfigKeyError: Key 'max_new_tokens' not in 'NormConfig'
2025-11-26T18:01:58.775274076Z     full_key: actor.adv_norm.max_new_tokens
2025-11-26T18:01:58.775276550Z     reference_type=Optional[NormConfig]
2025-11-26T18:01:58.775278622Z     object_type=NormConfig
2025-11-26T18:02:01.397769382Z E1126 18:02:01.396000 966 torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 0 (pid: 1032) of binary: /usr/bin/python3
2025-11-26T18:02:01.398538444Z Traceback (most recent call last):
2025-11-26T18:02:01.398548399Z   File "/usr/local/bin/torchrun", line 7, in <module>
2025-11-26T18:02:01.398551684Z     sys.exit(main())
2025-11-26T18:02:01.398554648Z              ^^^^^^
2025-11-26T18:02:01.398556732Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
2025-11-26T18:02:01.398559626Z     return f(*args, **kwargs)
2025-11-26T18:02:01.398562280Z            ^^^^^^^^^^^^^^^^^^
2025-11-26T18:02:01.398564323Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 901, in main
2025-11-26T18:02:01.399011072Z     run(args)
2025-11-26T18:02:01.399014497Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 892, in run
2025-11-26T18:02:01.399017331Z     elastic_launch(
2025-11-26T18:02:01.399019915Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 143, in __call__
2025-11-26T18:02:01.399022378Z     return launch_agent(self._config, self._entrypoint, list(args))
2025-11-26T18:02:01.399024842Z            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T18:02:01.399026855Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 277, in launch_agent
2025-11-26T18:02:01.399033795Z     raise ChildFailedError(
2025-11-26T18:02:01.399036439Z torch.distributed.elastic.multiprocessing.errors.ChildFailedError:
2025-11-26T18:02:01.399038483Z ============================================================
2025-11-26T18:02:01.399040866Z examples/cloud_gsm8k/gsm8k_grpo_train.py FAILED
2025-11-26T18:02:01.399043420Z ------------------------------------------------------------
2025-11-26T18:02:01.399045413Z Failures:
2025-11-26T18:02:01.399047396Z   <NO_OTHER_FAILURES>
2025-11-26T18:02:01.399049610Z ------------------------------------------------------------
2025-11-26T18:02:01.399051602Z Root Cause (first observed failure):
2025-11-26T18:02:01.399053676Z [0]:
2025-11-26T18:02:01.399055739Z   time      : 2025-11-26_18:02:01
2025-11-26T18:02:01.399057782Z   host      : cef7c503fdea
2025-11-26T18:02:01.399059785Z   rank      : 0 (local_rank: 0)
2025-11-26T18:02:01.399061777Z   exitcode  : 1 (pid: 1032)
2025-11-26T18:02:01.399063740Z   error_file: <N/A>
2025-11-26T18:02:01.399065714Z   traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
2025-11-26T18:02:01.399077261Z ============================================================
2025-11-26T18:02:03.337576162Z [37m20251126-18:02:03.337 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [315][0m
2025-11-26T18:02:03.472014923Z Killed
2025-11-26T18:02:03.482998916Z [37m20251126-18:02:03.482 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [965][0m
2025-11-26T18:02:03.484408918Z Traceback (most recent call last):
2025-11-26T18:02:03.484423430Z   File "<frozen runpy>", line 198, in _run_module_as_main
2025-11-26T18:02:03.484427356Z   File "<frozen runpy>", line 88, in _run_code
2025-11-26T18:02:03.484429659Z   File "/workspace/AReaL/areal/launcher/local.py", line 405, in <module>
2025-11-26T18:02:03.484570240Z     main()
2025-11-26T18:02:03.484574847Z   File "/workspace/AReaL/areal/launcher/local.py", line 260, in main
2025-11-26T18:02:03.484669949Z     local_main(config, run_id=0)
2025-11-26T18:02:03.484673765Z   File "/workspace/AReaL/areal/launcher/local.py", line 399, in local_main
2025-11-26T18:02:03.484768297Z     raise e
2025-11-26T18:02:03.484770641Z   File "/workspace/AReaL/areal/launcher/local.py", line 375, in local_main
2025-11-26T18:02:03.484834355Z     launcher.wait(
2025-11-26T18:02:03.484836909Z   File "/workspace/AReaL/areal/launcher/local.py", line 235, in wait
2025-11-26T18:02:03.484898111Z     raise JobException(
2025-11-26T18:02:03.484901015Z areal.utils.launcher.JobException: Job gsm8k-grpo-cloud-2gpu-2000samples_trial_20251126_180115:trainer JobState.COMPLETED at node local
2025-11-26T18:02:03.779558403Z [37m20251126-18:02:03.778 Local Scheduler INFO: Waiting for 0 local running processes, pids: [0m
2025-11-26T18:02:18.471346761Z ==========
2025-11-26T18:02:18.471352309Z == CUDA ==
2025-11-26T18:02:18.471355053Z ==========
2025-11-26T18:02:18.475447763Z CUDA Version 12.9.1
2025-11-26T18:02:18.477187229Z Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
2025-11-26T18:02:18.478711152Z This container image and its contents are governed by the NVIDIA Deep Learning Container License.
2025-11-26T18:02:18.478713425Z By pulling and using the container, you accept the terms and conditions of this license:
2025-11-26T18:02:18.478716039Z https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license
2025-11-26T18:02:18.478720205Z A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
2025-11-26T18:02:18.651999795Z Writing to /root/.config/pip/pip.conf
2025-11-26T18:02:18.810506016Z Writing to /root/.config/pip/pip.conf
2025-11-26T18:02:18.995016437Z Branch 'feature/reasoning_model' set up to track remote branch 'feature/reasoning_model' from 'origin'.
2025-11-26T18:02:18.995048896Z Your branch is up to date with 'origin/feature/reasoning_model'.
2025-11-26T18:02:19.069000997Z Checking AReaL installation...
2025-11-26T18:02:19.127588293Z AReaL already installed. Skipping installation.
2025-11-26T18:02:19.127627221Z Cleaning up any leftover GPU processes...
2025-11-26T18:02:22.147101069Z Checking for processes holding GPU device files...
2025-11-26T18:02:24.185969821Z Found processes holding GPU devices: 1
2025-11-26T18:02:24.186018374Z 21
2025-11-26T18:02:24.186021809Z 72
2025-11-26T18:02:24.186025024Z 73
2025-11-26T18:02:24.186027688Z Killing process 1...
2025-11-26T18:02:24.186031133Z Killing process 72...
2025-11-26T18:02:24.186034879Z Killing process 73...
2025-11-26T18:02:26.188858890Z Using fuser to kill processes on GPU devices...
2025-11-26T18:02:28.213694212Z Checking GPU...
2025-11-26T18:02:28.249323160Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T18:02:28.249345994Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T18:02:28.268109949Z Set PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True for better memory management
2025-11-26T18:02:28.268167495Z Detected 2 GPU(s)
2025-11-26T18:02:28.268170981Z Checking GPU status...
2025-11-26T18:02:28.296038052Z index, name, utilization.gpu [%], memory.used [MiB], compute_mode
2025-11-26T18:02:28.297413252Z 0, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T18:02:28.297720142Z 1, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T18:02:28.345630454Z Verifying GPU accessibility...
2025-11-26T18:02:28.893825086Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:02:28.893878717Z   import pynvml  # type: ignore[import]
2025-11-26T18:02:30.010377071Z GPU accessibility verified on attempt 1
2025-11-26T18:02:30.530218044Z Starting training...
2025-11-26T18:02:33.533383403Z Using STANDARD 2000 SAMPLES 2 GPUs configuration
2025-11-26T18:02:33.533425045Z Note: GRPO only (no reasoning XML). Dataset capped at 2000 samples (~6 hours).
2025-11-26T18:02:33.533428450Z GPU count: 2 (required: 2)
2025-11-26T18:02:33.536183336Z ==========================================
2025-11-26T18:02:33.536186781Z Starting GRPO Training (Cloud)
2025-11-26T18:02:33.536189536Z ==========================================
2025-11-26T18:02:33.536191559Z Config: standard_2000samples_2GPUs
2025-11-26T18:02:33.536193592Z Config file: examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml
2025-11-26T18:02:33.536195946Z Training script: examples/cloud_gsm8k/gsm8k_grpo_train.py
2025-11-26T18:02:33.536198499Z Experiment: gsm8k-grpo-cloud-2gpu-2000samples
2025-11-26T18:02:33.536200522Z Trial: trial_20251126_180233
2025-11-26T18:02:33.536202565Z GPU: NVIDIA A100 80GB PCIe NVIDIA A100 80GB PCIe (81920 MB)
2025-11-26T18:02:33.536204809Z WandB API key: e1adc5be02...
2025-11-26T18:02:33.536206832Z ==========================================
2025-11-26T18:02:34.233448857Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:02:34.233486153Z   import pynvml  # type: ignore[import]
2025-11-26T18:02:38.265715601Z [37m20251126-18:02:38.265 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T18:02:38.265763584Z [37m20251126-18:02:38.265 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T18:02:38.266045326Z [37m20251126-18:02:38.265 name-resolve INFO: No such name resolve path: ./tmp/areal/name_resolve/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_180233[0m
2025-11-26T18:02:38.377231296Z [37m20251126-18:02:38.373 Local Scheduler INFO: LocalLauncher: experiment_name=gsm8k-grpo-cloud-2gpu-2000samples, trial_name=trial_20251126_180233, fileroot=/workspace/outputs/grpo, run_id=0, is_recover_run=False[0m
2025-11-26T18:02:38.382271967Z [37m20251126-18:02:38.381 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL CUDA_VISIBLE_DEVICES=0 stdbuf -oL python3 -m areal.launcher.sglang_server examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_180233 sglang.random_seed=1 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_180233/llm_server.log[0m
2025-11-26T18:02:39.131630235Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:02:39.131668413Z   import pynvml  # type: ignore[import]
2025-11-26T18:02:40.603551557Z [37m20251126-18:02:40.602 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T18:02:40.604473406Z [37m20251126-18:02:40.603 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T18:02:40.707217163Z [37m20251126-18:02:40.706 SGLangServer Wrapper INFO: Launch command: python3 -m sglang.launch_server --host 172.21.0.2 --port 13954 --tokenizer-path Qwen/Qwen2.5-0.5B-Instruct --tokenizer-mode auto --load-format auto --trust-remote-code --device cuda --tp-size 1 --base-gpu-id 0 --nnodes 1 --node-rank 0 --dist-init-addr localhost:16717 --model-path Qwen/Qwen2.5-0.5B-Instruct --random-seed 1 --skip-tokenizer-init --disable-radix-cache --torch-compile-max-bs 32 --triton-attention-num-kv-splits 8 --num-continuous-decode-steps 1 --attention-backend flashinfer --context-length 4096 --mem-fraction-static 0.6 --chunked-prefill-size -1 --max-prefill-tokens 32768 --schedule-policy lpm --schedule-conservativeness 1.0 --cpu-offload-gb 0 --dtype bfloat16 --kv-cache-dtype auto --dp-size 1 --ep-size 1 --max-loaded-loras 1 --max-loras-per-batch 1 --lora-backend triton --log-level warning --log-level-http warning --log-requests-level 0 --enable-metrics --decode-log-interval 1[0m
2025-11-26T18:02:41.741771587Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:02:41.741806550Z   import pynvml  # type: ignore[import]
2025-11-26T18:02:47.035282256Z INFO 11-26 18:02:47 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T18:02:47.675104905Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T18:02:48.715394018Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:02:48.715431404Z   import pynvml  # type: ignore[import]
2025-11-26T18:02:48.753081929Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:02:48.753106907Z   import pynvml  # type: ignore[import]
2025-11-26T18:02:54.278019184Z INFO 11-26 18:02:54 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T18:02:54.303767752Z INFO 11-26 18:02:54 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T18:02:55.082068942Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T18:02:55.329906150Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T18:02:55.334946900Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T18:02:55.336010674Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T18:02:55.337081287Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T18:02:55.389850368Z [2025-11-26 18:02:55] MOE_RUNNER_BACKEND is not initialized, using triton backend
2025-11-26T18:02:56.090324405Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T18:02:56.090361180Z   warnings.warn(
2025-11-26T18:02:56.090364465Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T18:02:56.090377705Z   warnings.warn(
2025-11-26T18:02:57.745745624Z Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
2025-11-26T18:02:57.858533755Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  8.90it/s]
2025-11-26T18:02:57.859078621Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  8.86it/s]
2025-11-26T18:03:00.399370988Z   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   4%|â–         | 1/23 [00:00<00:11,  1.87it/s]Capturing batches (bs=152 avail_mem=30.62 GB):   4%|â–         | 1/23 [00:00<00:11,  1.87it/s]Capturing batches (bs=144 avail_mem=30.60 GB):   4%|â–         | 1/23 [00:00<00:11,  1.87it/s]Capturing batches (bs=136 avail_mem=30.59 GB):   4%|â–         | 1/23 [00:00<00:11,  1.87it/s]Capturing batches (bs=136 avail_mem=30.59 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.33it/s]Capturing batches (bs=128 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.33it/s]Capturing batches (bs=120 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.33it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.33it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.62it/s]Capturing batches (bs=104 avail_mem=30.54 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.62it/s]Capturing batches (bs=96 avail_mem=30.53 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.62it/s] Capturing batches (bs=88 avail_mem=30.51 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.62it/s]Capturing batches (bs=88 avail_mem=30.51 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.96it/s]Capturing batches (bs=80 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.96it/s]Capturing batches (bs=72 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.96it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:01<00:00, 14.96it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.34it/s]Capturing batches (bs=56 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.34it/s]Capturing batches (bs=48 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.34it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.34it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.14it/s]Capturing batches (bs=32 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.14it/s]Capturing batches (bs=24 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.14it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.14it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.70it/s]Capturing batches (bs=8 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.70it/s] Capturing batches (bs=4 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.70it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.70it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.54it/s]Capturing batches (bs=1 avail_mem=30.35 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.54it/s]Capturing batches (bs=1 avail_mem=30.35 GB): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00, 14.97it/s]
2025-11-26T18:03:05.733743362Z [37m20251126-18:03:05.733 SGLangServer Wrapper INFO: SGLang server launched at: http://172.21.0.2:13954[0m
2025-11-26T18:03:06.389590053Z [37m20251126-18:03:06.389 Launcher Utils INFO: Found 1 rollout servers: 172.21.0.2:13954[0m
2025-11-26T18:03:06.389627139Z [37m20251126-18:03:06.389 Local Scheduler INFO: LLM inference server launched at: AREAL_LLM_SERVER_ADDRS=172.21.0.2:13954[0m
2025-11-26T18:03:06.392694582Z [37m20251126-18:03:06.392 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL AREAL_LLM_SERVER_ADDRS=172.21.0.2:13954 AREAL_RECOVER_RUN=0 NCCL_CUMEM_ENABLE=0 NCCL_NVLS_ENABLE=0 CUDA_VISIBLE_DEVICES=1 stdbuf -oL torchrun --nnodes 1 --nproc-per-node 1 --master-addr localhost --master-port 45623 examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_180233 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_180233/trainer.log[0m
2025-11-26T18:03:06.393383535Z [37m20251126-18:03:06.393 Local Scheduler INFO: Waiting for 2 local running processes, pids: 316 966[0m
2025-11-26T18:03:06.908149736Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:03:06.908183926Z   import pynvml  # type: ignore[import]
2025-11-26T18:03:08.090846266Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:03:08.090878826Z   import pynvml  # type: ignore[import]
2025-11-26T18:03:15.426027424Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T18:03:15.426046142Z   warnings.warn(
2025-11-26T18:03:15.426049176Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T18:03:15.426052211Z   warnings.warn(
2025-11-26T18:03:15.921424562Z Traceback (most recent call last):
2025-11-26T18:03:15.921466916Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 665, in <module>
2025-11-26T18:03:15.921808336Z     main(sys.argv[1:])
2025-11-26T18:03:15.921833284Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 102, in main
2025-11-26T18:03:15.921836679Z     config, _ = load_expr_config(args_with_overrides, GRPOConfig)
2025-11-26T18:03:15.922264831Z                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T18:03:15.922275347Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1282, in load_expr_config
2025-11-26T18:03:15.922277931Z     cfg = to_structured_cfg(cfg, config_cls=config_cls)
2025-11-26T18:03:15.922565351Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T18:03:15.922570869Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1276, in to_structured_cfg
2025-11-26T18:03:15.922573183Z     cfg = OmegaConf.merge(default_cfg, cfg)
2025-11-26T18:03:15.923177328Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T18:03:15.923204869Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/omegaconf.py", line 274, in merge
2025-11-26T18:03:15.923211419Z     target.merge_with(
2025-11-26T18:03:15.923214013Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 507, in merge_with
2025-11-26T18:03:15.923220181Z     self._format_and_raise(key=None, value=None, cause=e)
2025-11-26T18:03:15.923222294Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T18:03:15.923224337Z     format_and_raise(
2025-11-26T18:03:15.923226351Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T18:03:15.923228434Z     _raise(ex, cause)
2025-11-26T18:03:15.923230426Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T18:03:15.923505779Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T18:03:15.923510366Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T18:03:15.923513080Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 502, in merge_with
2025-11-26T18:03:15.923515824Z     self._merge_with(
2025-11-26T18:03:15.923865708Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T18:03:15.923869554Z     BaseContainer._map_merge(
2025-11-26T18:03:15.923872779Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T18:03:15.923874902Z     dest_node._merge_with(
2025-11-26T18:03:15.923876995Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T18:03:15.923879018Z     BaseContainer._map_merge(
2025-11-26T18:03:15.923881031Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T18:03:15.924169693Z     dest_node._merge_with(
2025-11-26T18:03:15.924176564Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T18:03:15.924182984Z     BaseContainer._map_merge(
2025-11-26T18:03:15.924185227Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 432, in _map_merge
2025-11-26T18:03:15.924187430Z     dest[key] = src._get_node(key)
2025-11-26T18:03:15.925183112Z     ~~~~^^^^^
2025-11-26T18:03:15.925190443Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 308, in __setitem__
2025-11-26T18:03:15.925193478Z     self._format_and_raise(
2025-11-26T18:03:15.925196262Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T18:03:15.925198435Z     format_and_raise(
2025-11-26T18:03:15.925200809Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T18:03:15.925203192Z     _raise(ex, cause)
2025-11-26T18:03:15.925205316Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T18:03:15.925207448Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T18:03:15.925209462Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T18:03:15.925211605Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 306, in __setitem__
2025-11-26T18:03:15.925213648Z     self.__set_impl(key=key, value=value)
2025-11-26T18:03:15.925215731Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 316, in __set_impl
2025-11-26T18:03:15.925222271Z     self._set_item_impl(key, value)
2025-11-26T18:03:15.925224645Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 579, in _set_item_impl
2025-11-26T18:03:15.925235290Z     target_node_ref = self._get_node(key)
2025-11-26T18:03:15.925548870Z                       ^^^^^^^^^^^^^^^^^^^
2025-11-26T18:03:15.925554468Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 473, in _get_node
2025-11-26T18:03:15.925556692Z     self._validate_get(key)
2025-11-26T18:03:15.925558945Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 163, in _validate_get
2025-11-26T18:03:15.925561719Z     self._format_and_raise(
2025-11-26T18:03:15.925563741Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T18:03:15.925565795Z     format_and_raise(
2025-11-26T18:03:15.925568208Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 906, in format_and_raise
2025-11-26T18:03:15.925814508Z     _raise(ex, cause)
2025-11-26T18:03:15.925818614Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T18:03:15.925820918Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T18:03:15.926069600Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T18:03:15.926072144Z omegaconf.errors.ConfigKeyError: Key 'max_new_tokens' not in 'NormConfig'
2025-11-26T18:03:15.926074167Z     full_key: actor.adv_norm.max_new_tokens
2025-11-26T18:03:15.926076290Z     reference_type=Optional[NormConfig]
2025-11-26T18:03:15.926078393Z     object_type=NormConfig
2025-11-26T18:03:19.202745110Z E1126 18:03:19.201000 967 torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 0 (pid: 1033) of binary: /usr/bin/python3
2025-11-26T18:03:19.204482482Z Traceback (most recent call last):
2025-11-26T18:03:19.204519789Z   File "/usr/local/bin/torchrun", line 7, in <module>
2025-11-26T18:03:19.204522903Z     sys.exit(main())
2025-11-26T18:03:19.204525988Z              ^^^^^^
2025-11-26T18:03:19.204528081Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
2025-11-26T18:03:19.204531046Z     return f(*args, **kwargs)
2025-11-26T18:03:19.204533659Z            ^^^^^^^^^^^^^^^^^^
2025-11-26T18:03:19.204535722Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 901, in main
2025-11-26T18:03:19.204538276Z     run(args)
2025-11-26T18:03:19.204540690Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 892, in run
2025-11-26T18:03:19.204542753Z     elastic_launch(
2025-11-26T18:03:19.204544746Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 143, in __call__
2025-11-26T18:03:19.204547320Z     return launch_agent(self._config, self._entrypoint, list(args))
2025-11-26T18:03:19.204549874Z            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T18:03:19.204551826Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 277, in launch_agent
2025-11-26T18:03:19.204553829Z     raise ChildFailedError(
2025-11-26T18:03:19.204555852Z torch.distributed.elastic.multiprocessing.errors.ChildFailedError:
2025-11-26T18:03:19.204557835Z ============================================================
2025-11-26T18:03:19.204559869Z examples/cloud_gsm8k/gsm8k_grpo_train.py FAILED
2025-11-26T18:03:19.204561922Z ------------------------------------------------------------
2025-11-26T18:03:19.204563925Z Failures:
2025-11-26T18:03:19.204565898Z   <NO_OTHER_FAILURES>
2025-11-26T18:03:19.204567931Z ------------------------------------------------------------
2025-11-26T18:03:19.204569904Z Root Cause (first observed failure):
2025-11-26T18:03:19.204571987Z [0]:
2025-11-26T18:03:19.204574110Z   time      : 2025-11-26_18:03:19
2025-11-26T18:03:19.204576123Z   host      : cef7c503fdea
2025-11-26T18:03:19.204578156Z   rank      : 0 (local_rank: 0)
2025-11-26T18:03:19.204580149Z   exitcode  : 1 (pid: 1033)
2025-11-26T18:03:19.204582162Z   error_file: <N/A>
2025-11-26T18:03:19.204584145Z   traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
2025-11-26T18:03:19.204586188Z ============================================================
2025-11-26T18:03:20.397190550Z [37m20251126-18:03:20.396 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [316][0m
2025-11-26T18:03:20.521981149Z Killed
2025-11-26T18:03:20.531817022Z [37m20251126-18:03:20.531 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [966][0m
2025-11-26T18:03:20.532918411Z Traceback (most recent call last):
2025-11-26T18:03:20.532932502Z   File "<frozen runpy>", line 198, in _run_module_as_main
2025-11-26T18:03:20.532935887Z   File "<frozen runpy>", line 88, in _run_code
2025-11-26T18:03:20.532938021Z   File "/workspace/AReaL/areal/launcher/local.py", line 405, in <module>
2025-11-26T18:03:20.533069538Z     main()
2025-11-26T18:03:20.533074435Z   File "/workspace/AReaL/areal/launcher/local.py", line 260, in main
2025-11-26T18:03:20.533177329Z     local_main(config, run_id=0)
2025-11-26T18:03:20.533184880Z   File "/workspace/AReaL/areal/launcher/local.py", line 399, in local_main
2025-11-26T18:03:20.533289737Z     raise e
2025-11-26T18:03:20.533292141Z   File "/workspace/AReaL/areal/launcher/local.py", line 375, in local_main
2025-11-26T18:03:20.533356698Z     launcher.wait(
2025-11-26T18:03:20.533359613Z   File "/workspace/AReaL/areal/launcher/local.py", line 235, in wait
2025-11-26T18:03:20.533415987Z     raise JobException(
2025-11-26T18:03:20.533418760Z areal.utils.launcher.JobException: Job gsm8k-grpo-cloud-2gpu-2000samples_trial_20251126_180233:trainer JobState.COMPLETED at node local
2025-11-26T18:03:20.739179913Z [37m20251126-18:03:20.738 Local Scheduler INFO: Waiting for 0 local running processes, pids: [0m
2025-11-26T18:03:36.816955634Z ==========
2025-11-26T18:03:36.816982294Z == CUDA ==
2025-11-26T18:03:36.817027171Z ==========
2025-11-26T18:03:36.821515585Z CUDA Version 12.9.1
2025-11-26T18:03:36.823182812Z Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
2025-11-26T18:03:36.824706875Z This container image and its contents are governed by the NVIDIA Deep Learning Container License.
2025-11-26T18:03:36.824709629Z By pulling and using the container, you accept the terms and conditions of this license:
2025-11-26T18:03:36.824712113Z https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license
2025-11-26T18:03:36.824716299Z A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
2025-11-26T18:03:36.989580273Z Writing to /root/.config/pip/pip.conf
2025-11-26T18:03:37.148187625Z Writing to /root/.config/pip/pip.conf
2025-11-26T18:03:37.328320200Z Branch 'feature/reasoning_model' set up to track remote branch 'feature/reasoning_model' from 'origin'.
2025-11-26T18:03:37.328338928Z Your branch is up to date with 'origin/feature/reasoning_model'.
2025-11-26T18:03:37.399362622Z Checking AReaL installation...
2025-11-26T18:03:37.459303315Z AReaL already installed. Skipping installation.
2025-11-26T18:03:37.459335523Z Cleaning up any leftover GPU processes...
2025-11-26T18:03:40.478340378Z Checking for processes holding GPU device files...
2025-11-26T18:03:42.605760227Z Found processes holding GPU devices: 1
2025-11-26T18:03:42.605791935Z 20
2025-11-26T18:03:42.605794809Z 71
2025-11-26T18:03:42.605797283Z 72
2025-11-26T18:03:42.605799306Z Killing process 1...
2025-11-26T18:03:42.605802220Z Killing process 71...
2025-11-26T18:03:42.605836491Z Killing process 72...
2025-11-26T18:03:44.608439563Z Using fuser to kill processes on GPU devices...
2025-11-26T18:03:46.630695380Z Checking GPU...
2025-11-26T18:03:46.673851091Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T18:03:46.673887075Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T18:03:46.691557023Z Set PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True for better memory management
2025-11-26T18:03:46.691574319Z Detected 2 GPU(s)
2025-11-26T18:03:46.691577644Z Checking GPU status...
2025-11-26T18:03:46.719907919Z index, name, utilization.gpu [%], memory.used [MiB], compute_mode
2025-11-26T18:03:46.721377840Z 0, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T18:03:46.721683337Z 1, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T18:03:46.764312430Z Verifying GPU accessibility...
2025-11-26T18:03:47.311239525Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:03:47.311297771Z   import pynvml  # type: ignore[import]
2025-11-26T18:03:48.466026489Z GPU accessibility verified on attempt 1
2025-11-26T18:03:49.036623598Z Starting training...
2025-11-26T18:03:52.039279844Z Using STANDARD 2000 SAMPLES 2 GPUs configuration
2025-11-26T18:03:52.039316709Z Note: GRPO only (no reasoning XML). Dataset capped at 2000 samples (~6 hours).
2025-11-26T18:03:52.039321116Z GPU count: 2 (required: 2)
2025-11-26T18:03:52.041823695Z ==========================================
2025-11-26T18:03:52.041826959Z Starting GRPO Training (Cloud)
2025-11-26T18:03:52.041829904Z ==========================================
2025-11-26T18:03:52.041832077Z Config: standard_2000samples_2GPUs
2025-11-26T18:03:52.041834101Z Config file: examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml
2025-11-26T18:03:52.041836894Z Training script: examples/cloud_gsm8k/gsm8k_grpo_train.py
2025-11-26T18:03:52.041839398Z Experiment: gsm8k-grpo-cloud-2gpu-2000samples
2025-11-26T18:03:52.041841461Z Trial: trial_20251126_180352
2025-11-26T18:03:52.041843544Z GPU: NVIDIA A100 80GB PCIe NVIDIA A100 80GB PCIe (81920 MB)
2025-11-26T18:03:52.041845618Z WandB API key: e1adc5be02...
2025-11-26T18:03:52.041847641Z ==========================================
2025-11-26T18:03:52.725628973Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:03:52.725671457Z   import pynvml  # type: ignore[import]
2025-11-26T18:03:56.729012405Z [37m20251126-18:03:56.728 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T18:03:56.729049461Z [37m20251126-18:03:56.728 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T18:03:56.729386134Z [37m20251126-18:03:56.729 name-resolve INFO: No such name resolve path: ./tmp/areal/name_resolve/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_180352[0m
2025-11-26T18:03:56.833952231Z [37m20251126-18:03:56.833 Local Scheduler INFO: LocalLauncher: experiment_name=gsm8k-grpo-cloud-2gpu-2000samples, trial_name=trial_20251126_180352, fileroot=/workspace/outputs/grpo, run_id=0, is_recover_run=False[0m
2025-11-26T18:03:56.842309408Z [37m20251126-18:03:56.842 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL CUDA_VISIBLE_DEVICES=0 stdbuf -oL python3 -m areal.launcher.sglang_server examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_180352 sglang.random_seed=1 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_180352/llm_server.log[0m
2025-11-26T18:03:57.570234092Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:03:57.570280261Z   import pynvml  # type: ignore[import]
2025-11-26T18:03:59.070919226Z [37m20251126-18:03:59.070 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T18:03:59.071333958Z [37m20251126-18:03:59.070 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T18:03:59.186425920Z [37m20251126-18:03:59.185 SGLangServer Wrapper INFO: Launch command: python3 -m sglang.launch_server --host 172.21.0.2 --port 21562 --tokenizer-path Qwen/Qwen2.5-0.5B-Instruct --tokenizer-mode auto --load-format auto --trust-remote-code --device cuda --tp-size 1 --base-gpu-id 0 --nnodes 1 --node-rank 0 --dist-init-addr localhost:25462 --model-path Qwen/Qwen2.5-0.5B-Instruct --random-seed 1 --skip-tokenizer-init --disable-radix-cache --torch-compile-max-bs 32 --triton-attention-num-kv-splits 8 --num-continuous-decode-steps 1 --attention-backend flashinfer --context-length 4096 --mem-fraction-static 0.6 --chunked-prefill-size -1 --max-prefill-tokens 32768 --schedule-policy lpm --schedule-conservativeness 1.0 --cpu-offload-gb 0 --dtype bfloat16 --kv-cache-dtype auto --dp-size 1 --ep-size 1 --max-loaded-loras 1 --max-loras-per-batch 1 --lora-backend triton --log-level warning --log-level-http warning --log-requests-level 0 --enable-metrics --decode-log-interval 1[0m
2025-11-26T18:04:00.344486930Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:04:00.344536004Z   import pynvml  # type: ignore[import]
2025-11-26T18:04:06.351551207Z INFO 11-26 18:04:06 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T18:04:07.028389349Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T18:04:08.075229225Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:04:08.075267412Z   import pynvml  # type: ignore[import]
2025-11-26T18:04:08.103024178Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:04:08.103069877Z   import pynvml  # type: ignore[import]
2025-11-26T18:04:13.410821387Z INFO 11-26 18:04:13 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T18:04:13.463283047Z INFO 11-26 18:04:13 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T18:04:14.051401720Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T18:04:14.347719284Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T18:04:14.351337143Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T18:04:14.352175028Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T18:04:14.352955147Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T18:04:14.385252453Z [2025-11-26 18:04:14] MOE_RUNNER_BACKEND is not initialized, using triton backend
2025-11-26T18:04:14.863979993Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T18:04:14.864021896Z   warnings.warn(
2025-11-26T18:04:14.864024770Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T18:04:14.864042216Z   warnings.warn(
2025-11-26T18:04:15.968969129Z Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
2025-11-26T18:04:16.072211251Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  9.70it/s]
2025-11-26T18:04:16.072818792Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  9.68it/s]
2025-11-26T18:04:18.502857273Z   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   4%|â–         | 1/23 [00:00<00:11,  1.88it/s]Capturing batches (bs=152 avail_mem=30.62 GB):   4%|â–         | 1/23 [00:00<00:11,  1.88it/s]Capturing batches (bs=144 avail_mem=30.60 GB):   4%|â–         | 1/23 [00:00<00:11,  1.88it/s]Capturing batches (bs=136 avail_mem=30.59 GB):   4%|â–         | 1/23 [00:00<00:11,  1.88it/s]Capturing batches (bs=136 avail_mem=30.59 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.31it/s]Capturing batches (bs=128 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.31it/s]Capturing batches (bs=120 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.31it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.31it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.63it/s]Capturing batches (bs=104 avail_mem=30.54 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.63it/s]Capturing batches (bs=96 avail_mem=30.53 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.63it/s] Capturing batches (bs=88 avail_mem=30.51 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.63it/s]Capturing batches (bs=88 avail_mem=30.51 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 15.02it/s]Capturing batches (bs=80 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 15.02it/s]Capturing batches (bs=72 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 15.02it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 15.02it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.60it/s]Capturing batches (bs=56 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.60it/s]Capturing batches (bs=48 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.60it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.60it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.62it/s]Capturing batches (bs=32 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.62it/s]Capturing batches (bs=24 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.62it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.62it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.94it/s]Capturing batches (bs=8 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.94it/s] Capturing batches (bs=4 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.94it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.94it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.68it/s]Capturing batches (bs=1 avail_mem=30.35 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.68it/s]Capturing batches (bs=1 avail_mem=30.35 GB): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00, 15.09it/s]
2025-11-26T18:04:24.219011216Z [37m20251126-18:04:24.218 SGLangServer Wrapper INFO: SGLang server launched at: http://172.21.0.2:21562[0m
2025-11-26T18:04:24.849203227Z [37m20251126-18:04:24.848 Launcher Utils INFO: Found 1 rollout servers: 172.21.0.2:21562[0m
2025-11-26T18:04:24.849243608Z [37m20251126-18:04:24.848 Local Scheduler INFO: LLM inference server launched at: AREAL_LLM_SERVER_ADDRS=172.21.0.2:21562[0m
2025-11-26T18:04:24.852318385Z [37m20251126-18:04:24.852 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL AREAL_LLM_SERVER_ADDRS=172.21.0.2:21562 AREAL_RECOVER_RUN=0 NCCL_CUMEM_ENABLE=0 NCCL_NVLS_ENABLE=0 CUDA_VISIBLE_DEVICES=1 stdbuf -oL torchrun --nnodes 1 --nproc-per-node 1 --master-addr localhost --master-port 38311 examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_180352 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_180352/trainer.log[0m
2025-11-26T18:04:24.853038983Z [37m20251126-18:04:24.852 Local Scheduler INFO: Waiting for 2 local running processes, pids: 315 965[0m
2025-11-26T18:04:25.397333765Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:04:25.397381024Z   import pynvml  # type: ignore[import]
2025-11-26T18:04:26.602491669Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:04:26.602531258Z   import pynvml  # type: ignore[import]
2025-11-26T18:04:33.867758033Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T18:04:33.867798964Z   warnings.warn(
2025-11-26T18:04:33.867802159Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T18:04:33.867804382Z   warnings.warn(
2025-11-26T18:04:34.295972852Z Traceback (most recent call last):
2025-11-26T18:04:34.296007644Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 665, in <module>
2025-11-26T18:04:34.296569475Z     main(sys.argv[1:])
2025-11-26T18:04:34.296579971Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 102, in main
2025-11-26T18:04:34.296583316Z     config, _ = load_expr_config(args_with_overrides, GRPOConfig)
2025-11-26T18:04:34.296586111Z                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T18:04:34.296588094Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1282, in load_expr_config
2025-11-26T18:04:34.296590086Z     cfg = to_structured_cfg(cfg, config_cls=config_cls)
2025-11-26T18:04:34.296915594Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T18:04:34.296920021Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1276, in to_structured_cfg
2025-11-26T18:04:34.296932599Z     cfg = OmegaConf.merge(default_cfg, cfg)
2025-11-26T18:04:34.297392158Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T18:04:34.297430645Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/omegaconf.py", line 274, in merge
2025-11-26T18:04:34.297433940Z     target.merge_with(
2025-11-26T18:04:34.297436765Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 507, in merge_with
2025-11-26T18:04:34.297439779Z     self._format_and_raise(key=None, value=None, cause=e)
2025-11-26T18:04:34.297442854Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T18:04:34.297444897Z     format_and_raise(
2025-11-26T18:04:34.297446980Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T18:04:34.297449063Z     _raise(ex, cause)
2025-11-26T18:04:34.297451156Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T18:04:34.297749974Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T18:04:34.297754450Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T18:04:34.297756734Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 502, in merge_with
2025-11-26T18:04:34.297760029Z     self._merge_with(
2025-11-26T18:04:34.297762803Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T18:04:34.298100820Z     BaseContainer._map_merge(
2025-11-26T18:04:34.298103844Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T18:04:34.298171514Z     dest_node._merge_with(
2025-11-26T18:04:34.298173768Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T18:04:34.298175881Z     BaseContainer._map_merge(
2025-11-26T18:04:34.298177874Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T18:04:34.298179927Z     dest_node._merge_with(
2025-11-26T18:04:34.298181920Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T18:04:34.298183993Z     BaseContainer._map_merge(
2025-11-26T18:04:34.298186056Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 432, in _map_merge
2025-11-26T18:04:34.298428811Z     dest[key] = src._get_node(key)
2025-11-26T18:04:34.298438144Z     ~~~~^^^^^
2025-11-26T18:04:34.298440778Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 308, in __setitem__
2025-11-26T18:04:34.298443452Z     self._format_and_raise(
2025-11-26T18:04:34.298446126Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T18:04:34.298448329Z     format_and_raise(
2025-11-26T18:04:34.298451224Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T18:04:34.298990773Z     _raise(ex, cause)
2025-11-26T18:04:34.298994518Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T18:04:34.298996762Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T18:04:34.298998865Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T18:04:34.299001719Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 306, in __setitem__
2025-11-26T18:04:34.299004082Z     self.__set_impl(key=key, value=value)
2025-11-26T18:04:34.299006076Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 316, in __set_impl
2025-11-26T18:04:34.299008139Z     self._set_item_impl(key, value)
2025-11-26T18:04:34.299010723Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 579, in _set_item_impl
2025-11-26T18:04:34.299296290Z     target_node_ref = self._get_node(key)
2025-11-26T18:04:34.299302529Z                       ^^^^^^^^^^^^^^^^^^^
2025-11-26T18:04:34.299304783Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 473, in _get_node
2025-11-26T18:04:34.299316751Z     self._validate_get(key)
2025-11-26T18:04:34.299319074Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 163, in _validate_get
2025-11-26T18:04:34.299321288Z     self._format_and_raise(
2025-11-26T18:04:34.299323651Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T18:04:34.299606595Z     format_and_raise(
2025-11-26T18:04:34.299610831Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 906, in format_and_raise
2025-11-26T18:04:34.299613225Z     _raise(ex, cause)
2025-11-26T18:04:34.299615268Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T18:04:34.299617450Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T18:04:34.304065503Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T18:04:34.304072103Z omegaconf.errors.ConfigKeyError: Key 'max_new_tokens' not in 'NormConfig'
2025-11-26T18:04:34.304074367Z     full_key: actor.adv_norm.max_new_tokens
2025-11-26T18:04:34.304076490Z     reference_type=Optional[NormConfig]
2025-11-26T18:04:34.304078513Z     object_type=NormConfig
2025-11-26T18:04:36.817404959Z E1126 18:04:36.816000 966 torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 0 (pid: 1032) of binary: /usr/bin/python3
2025-11-26T18:04:36.818014071Z Traceback (most recent call last):
2025-11-26T18:04:36.818021192Z   File "/usr/local/bin/torchrun", line 7, in <module>
2025-11-26T18:04:36.818024647Z     sys.exit(main())
2025-11-26T18:04:36.818027401Z              ^^^^^^
2025-11-26T18:04:36.818029715Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
2025-11-26T18:04:36.818440730Z     return f(*args, **kwargs)
2025-11-26T18:04:36.818447610Z            ^^^^^^^^^^^^^^^^^^
2025-11-26T18:04:36.818449783Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 901, in main
2025-11-26T18:04:36.818452417Z     run(args)
2025-11-26T18:04:36.818454801Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 892, in run
2025-11-26T18:04:36.818456864Z     elastic_launch(
2025-11-26T18:04:36.818459538Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 143, in __call__
2025-11-26T18:04:36.818993789Z     return launch_agent(self._config, self._entrypoint, list(args))
2025-11-26T18:04:36.818996833Z            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T18:04:36.818998907Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 277, in launch_agent
2025-11-26T18:04:36.819001631Z     raise ChildFailedError(
2025-11-26T18:04:36.819004455Z torch.distributed.elastic.multiprocessing.errors.ChildFailedError:
2025-11-26T18:04:36.819006388Z ============================================================
2025-11-26T18:04:36.819008351Z examples/cloud_gsm8k/gsm8k_grpo_train.py FAILED
2025-11-26T18:04:36.819010344Z ------------------------------------------------------------
2025-11-26T18:04:36.819012567Z Failures:
2025-11-26T18:04:36.819015722Z   <NO_OTHER_FAILURES>
2025-11-26T18:04:36.819017725Z ------------------------------------------------------------
2025-11-26T18:04:36.819019698Z Root Cause (first observed failure):
2025-11-26T18:04:36.819021711Z [0]:
2025-11-26T18:04:36.819024105Z   time      : 2025-11-26_18:04:36
2025-11-26T18:04:36.819026208Z   host      : cef7c503fdea
2025-11-26T18:04:36.819028220Z   rank      : 0 (local_rank: 0)
2025-11-26T18:04:36.819030214Z   exitcode  : 1 (pid: 1032)
2025-11-26T18:04:36.819032217Z   error_file: <N/A>
2025-11-26T18:04:36.819034250Z   traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
2025-11-26T18:04:36.819037294Z ============================================================
2025-11-26T18:04:38.859004371Z [37m20251126-18:04:38.858 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [315][0m
2025-11-26T18:04:39.045430161Z Killed
2025-11-26T18:04:39.056447945Z [37m20251126-18:04:39.056 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [965][0m
2025-11-26T18:04:39.057990044Z Traceback (most recent call last):
2025-11-26T18:04:39.058003234Z   File "<frozen runpy>", line 198, in _run_module_as_main
2025-11-26T18:04:39.058006309Z   File "<frozen runpy>", line 88, in _run_code
2025-11-26T18:04:39.058008392Z   File "/workspace/AReaL/areal/launcher/local.py", line 405, in <module>
2025-11-26T18:04:39.058146219Z     main()
2025-11-26T18:04:39.058194451Z   File "/workspace/AReaL/areal/launcher/local.py", line 260, in main
2025-11-26T18:04:39.058229803Z     local_main(config, run_id=0)
2025-11-26T18:04:39.058263003Z   File "/workspace/AReaL/areal/launcher/local.py", line 399, in local_main
2025-11-26T18:04:39.058340259Z     raise e
2025-11-26T18:04:39.058342773Z   File "/workspace/AReaL/areal/launcher/local.py", line 375, in local_main
2025-11-26T18:04:39.058410915Z     launcher.wait(
2025-11-26T18:04:39.058418717Z   File "/workspace/AReaL/areal/launcher/local.py", line 235, in wait
2025-11-26T18:04:39.058479228Z     raise JobException(
2025-11-26T18:04:39.058485026Z areal.utils.launcher.JobException: Job gsm8k-grpo-cloud-2gpu-2000samples_trial_20251126_180352:trainer JobState.COMPLETED at node local
2025-11-26T18:04:39.247350371Z [37m20251126-18:04:39.246 Local Scheduler INFO: Waiting for 0 local running processes, pids: [0m
2025-11-26T18:04:55.066211903Z ==========
2025-11-26T18:04:55.066225063Z == CUDA ==
2025-11-26T18:04:55.066312955Z ==========
2025-11-26T18:04:55.070260568Z CUDA Version 12.9.1
2025-11-26T18:04:55.072073043Z Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
2025-11-26T18:04:55.073639639Z This container image and its contents are governed by the NVIDIA Deep Learning Container License.
2025-11-26T18:04:55.073642334Z By pulling and using the container, you accept the terms and conditions of this license:
2025-11-26T18:04:55.073644947Z https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license
2025-11-26T18:04:55.073650716Z A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
2025-11-26T18:04:55.238320409Z Writing to /root/.config/pip/pip.conf
2025-11-26T18:04:55.397712507Z Writing to /root/.config/pip/pip.conf
2025-11-26T18:04:55.592592501Z Branch 'feature/reasoning_model' set up to track remote branch 'feature/reasoning_model' from 'origin'.
2025-11-26T18:04:55.592630428Z Your branch is up to date with 'origin/feature/reasoning_model'.
2025-11-26T18:04:55.663090157Z Checking AReaL installation...
2025-11-26T18:04:55.721656481Z AReaL already installed. Skipping installation.
2025-11-26T18:04:55.721685524Z Cleaning up any leftover GPU processes...
2025-11-26T18:04:58.741040123Z Checking for processes holding GPU device files...
2025-11-26T18:05:00.668720209Z Found processes holding GPU devices: 1
2025-11-26T18:05:00.668757625Z 20
2025-11-26T18:05:00.668760810Z 71
2025-11-26T18:05:00.668762913Z 72
2025-11-26T18:05:00.668765157Z Killing process 1...
2025-11-26T18:05:00.668767881Z Killing process 71...
2025-11-26T18:05:00.668828902Z Killing process 72...
2025-11-26T18:05:02.671474527Z Using fuser to kill processes on GPU devices...
2025-11-26T18:05:04.693832929Z Checking GPU...
2025-11-26T18:05:04.728038083Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T18:05:04.728065284Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T18:05:04.746581078Z Set PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True for better memory management
2025-11-26T18:05:04.746599806Z Detected 2 GPU(s)
2025-11-26T18:05:04.746602981Z Checking GPU status...
2025-11-26T18:05:04.778044686Z index, name, utilization.gpu [%], memory.used [MiB], compute_mode
2025-11-26T18:05:04.779433296Z 0, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T18:05:04.779744192Z 1, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T18:05:04.824787241Z Verifying GPU accessibility...
2025-11-26T18:05:05.397264434Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:05:05.397341710Z   import pynvml  # type: ignore[import]
2025-11-26T18:05:06.548454412Z GPU accessibility verified on attempt 1
2025-11-26T18:05:07.106189945Z Starting training...
2025-11-26T18:05:10.108903527Z Using STANDARD 2000 SAMPLES 2 GPUs configuration
2025-11-26T18:05:10.108943187Z Note: GRPO only (no reasoning XML). Dataset capped at 2000 samples (~6 hours).
2025-11-26T18:05:10.108946832Z GPU count: 2 (required: 2)
2025-11-26T18:05:10.111273688Z ==========================================
2025-11-26T18:05:10.111276732Z Starting GRPO Training (Cloud)
2025-11-26T18:05:10.111279617Z ==========================================
2025-11-26T18:05:10.111281930Z Config: standard_2000samples_2GPUs
2025-11-26T18:05:10.111284063Z Config file: examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml
2025-11-26T18:05:10.111286837Z Training script: examples/cloud_gsm8k/gsm8k_grpo_train.py
2025-11-26T18:05:10.111289481Z Experiment: gsm8k-grpo-cloud-2gpu-2000samples
2025-11-26T18:05:10.111291544Z Trial: trial_20251126_180510
2025-11-26T18:05:10.111293567Z GPU: NVIDIA A100 80GB PCIe NVIDIA A100 80GB PCIe (81920 MB)
2025-11-26T18:05:10.111295560Z WandB API key: e1adc5be02...
2025-11-26T18:05:10.111297573Z ==========================================
2025-11-26T18:05:10.836795402Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:05:10.836838106Z   import pynvml  # type: ignore[import]
2025-11-26T18:05:14.894362273Z [37m20251126-18:05:14.893 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T18:05:14.894401121Z [37m20251126-18:05:14.894 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T18:05:14.894674430Z [37m20251126-18:05:14.894 name-resolve INFO: No such name resolve path: ./tmp/areal/name_resolve/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_180510[0m
2025-11-26T18:05:14.999874045Z [37m20251126-18:05:14.999 Local Scheduler INFO: LocalLauncher: experiment_name=gsm8k-grpo-cloud-2gpu-2000samples, trial_name=trial_20251126_180510, fileroot=/workspace/outputs/grpo, run_id=0, is_recover_run=False[0m
2025-11-26T18:05:15.007797503Z [37m20251126-18:05:15.007 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL CUDA_VISIBLE_DEVICES=0 stdbuf -oL python3 -m areal.launcher.sglang_server examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_180510 sglang.random_seed=1 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_180510/llm_server.log[0m
2025-11-26T18:05:15.799348661Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:05:15.799393569Z   import pynvml  # type: ignore[import]
2025-11-26T18:05:17.252463101Z [37m20251126-18:05:17.251 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T18:05:17.253094717Z [37m20251126-18:05:17.252 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T18:05:17.356895707Z [37m20251126-18:05:17.356 SGLangServer Wrapper INFO: Launch command: python3 -m sglang.launch_server --host 172.21.0.2 --port 20569 --tokenizer-path Qwen/Qwen2.5-0.5B-Instruct --tokenizer-mode auto --load-format auto --trust-remote-code --device cuda --tp-size 1 --base-gpu-id 0 --nnodes 1 --node-rank 0 --dist-init-addr localhost:22695 --model-path Qwen/Qwen2.5-0.5B-Instruct --random-seed 1 --skip-tokenizer-init --disable-radix-cache --torch-compile-max-bs 32 --triton-attention-num-kv-splits 8 --num-continuous-decode-steps 1 --attention-backend flashinfer --context-length 4096 --mem-fraction-static 0.6 --chunked-prefill-size -1 --max-prefill-tokens 32768 --schedule-policy lpm --schedule-conservativeness 1.0 --cpu-offload-gb 0 --dtype bfloat16 --kv-cache-dtype auto --dp-size 1 --ep-size 1 --max-loaded-loras 1 --max-loras-per-batch 1 --lora-backend triton --log-level warning --log-level-http warning --log-requests-level 0 --enable-metrics --decode-log-interval 1[0m
2025-11-26T18:05:18.396494497Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:05:18.396536410Z   import pynvml  # type: ignore[import]
2025-11-26T18:05:23.666439568Z INFO 11-26 18:05:23 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T18:05:24.300981366Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T18:05:25.314556707Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:05:25.314595013Z   import pynvml  # type: ignore[import]
2025-11-26T18:05:25.336071302Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:05:25.336095779Z   import pynvml  # type: ignore[import]
2025-11-26T18:05:30.551252334Z INFO 11-26 18:05:30 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T18:05:30.612728006Z INFO 11-26 18:05:30 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T18:05:31.129854583Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T18:05:31.359022735Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T18:05:31.362467425Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T18:05:31.363277869Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T18:05:31.364087693Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T18:05:31.396406402Z [2025-11-26 18:05:31] MOE_RUNNER_BACKEND is not initialized, using triton backend
2025-11-26T18:05:31.875897884Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T18:05:31.875934510Z   warnings.warn(
2025-11-26T18:05:31.875937795Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T18:05:31.875949913Z   warnings.warn(
2025-11-26T18:05:32.998023198Z Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
2025-11-26T18:05:33.104281178Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  9.43it/s]
2025-11-26T18:05:33.105368186Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  9.41it/s]
2025-11-26T18:05:35.543777767Z   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   4%|â–         | 1/23 [00:00<00:11,  1.85it/s]Capturing batches (bs=152 avail_mem=30.62 GB):   4%|â–         | 1/23 [00:00<00:11,  1.85it/s]Capturing batches (bs=144 avail_mem=30.60 GB):   4%|â–         | 1/23 [00:00<00:11,  1.85it/s]Capturing batches (bs=136 avail_mem=30.59 GB):   4%|â–         | 1/23 [00:00<00:11,  1.85it/s]Capturing batches (bs=136 avail_mem=30.59 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.30it/s]Capturing batches (bs=128 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.30it/s]Capturing batches (bs=120 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.30it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.30it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.66it/s]Capturing batches (bs=104 avail_mem=30.54 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.66it/s]Capturing batches (bs=96 avail_mem=30.53 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.66it/s] Capturing batches (bs=88 avail_mem=30.51 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.66it/s]Capturing batches (bs=88 avail_mem=30.51 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 15.04it/s]Capturing batches (bs=80 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 15.04it/s]Capturing batches (bs=72 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 15.04it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:01<00:00, 15.04it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.58it/s]Capturing batches (bs=56 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.58it/s]Capturing batches (bs=48 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.58it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.58it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.65it/s]Capturing batches (bs=32 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.65it/s]Capturing batches (bs=24 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.65it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.65it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 18.06it/s]Capturing batches (bs=8 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 18.06it/s] Capturing batches (bs=4 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 18.06it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 18.06it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.89it/s]Capturing batches (bs=1 avail_mem=30.35 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.89it/s]Capturing batches (bs=1 avail_mem=30.35 GB): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00, 15.13it/s]
2025-11-26T18:05:41.435255090Z [37m20251126-18:05:41.434 SGLangServer Wrapper INFO: SGLang server launched at: http://172.21.0.2:20569[0m
2025-11-26T18:05:42.015034802Z [37m20251126-18:05:42.014 Launcher Utils INFO: Found 1 rollout servers: 172.21.0.2:20569[0m
2025-11-26T18:05:42.015081762Z [37m20251126-18:05:42.014 Local Scheduler INFO: LLM inference server launched at: AREAL_LLM_SERVER_ADDRS=172.21.0.2:20569[0m
2025-11-26T18:05:42.018077129Z [37m20251126-18:05:42.017 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL AREAL_LLM_SERVER_ADDRS=172.21.0.2:20569 AREAL_RECOVER_RUN=0 NCCL_CUMEM_ENABLE=0 NCCL_NVLS_ENABLE=0 CUDA_VISIBLE_DEVICES=1 stdbuf -oL torchrun --nnodes 1 --nproc-per-node 1 --master-addr localhost --master-port 31678 examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_180510 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_180510/trainer.log[0m
2025-11-26T18:05:42.018650958Z [37m20251126-18:05:42.018 Local Scheduler INFO: Waiting for 2 local running processes, pids: 315 965[0m
2025-11-26T18:05:42.542579232Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:05:42.542616959Z   import pynvml  # type: ignore[import]
2025-11-26T18:05:43.753947930Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:05:43.753980269Z   import pynvml  # type: ignore[import]
2025-11-26T18:05:50.413382510Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T18:05:50.413423651Z   warnings.warn(
2025-11-26T18:05:50.413427417Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T18:05:50.413429811Z   warnings.warn(
2025-11-26T18:05:50.828699049Z Traceback (most recent call last):
2025-11-26T18:05:50.828732899Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 665, in <module>
2025-11-26T18:05:50.829752837Z     main(sys.argv[1:])
2025-11-26T18:05:50.829763894Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 102, in main
2025-11-26T18:05:50.829767079Z     config, _ = load_expr_config(args_with_overrides, GRPOConfig)
2025-11-26T18:05:50.829769633Z                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T18:05:50.829771666Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1282, in load_expr_config
2025-11-26T18:05:50.829773659Z     cfg = to_structured_cfg(cfg, config_cls=config_cls)
2025-11-26T18:05:50.829776082Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T18:05:50.829778226Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1276, in to_structured_cfg
2025-11-26T18:05:50.829780238Z     cfg = OmegaConf.merge(default_cfg, cfg)
2025-11-26T18:05:50.830417091Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T18:05:50.830453557Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/omegaconf.py", line 274, in merge
2025-11-26T18:05:50.830456521Z     target.merge_with(
2025-11-26T18:05:50.830459375Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 507, in merge_with
2025-11-26T18:05:50.830462520Z     self._format_and_raise(key=None, value=None, cause=e)
2025-11-26T18:05:50.830464833Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T18:05:50.830466846Z     format_and_raise(
2025-11-26T18:05:50.830468929Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T18:05:50.830471123Z     _raise(ex, cause)
2025-11-26T18:05:50.830473236Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T18:05:50.830854848Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T18:05:50.830863010Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T18:05:50.830865694Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 502, in merge_with
2025-11-26T18:05:50.830868559Z     self._merge_with(
2025-11-26T18:05:50.830870992Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T18:05:50.830876520Z     BaseContainer._map_merge(
2025-11-26T18:05:50.830879215Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T18:05:50.830881338Z     dest_node._merge_with(
2025-11-26T18:05:50.830883451Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T18:05:50.831467626Z     BaseContainer._map_merge(
2025-11-26T18:05:50.831473765Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T18:05:50.831476509Z     dest_node._merge_with(
2025-11-26T18:05:50.831478622Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T18:05:50.831480625Z     BaseContainer._map_merge(
2025-11-26T18:05:50.831482688Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 432, in _map_merge
2025-11-26T18:05:50.831484702Z     dest[key] = src._get_node(key)
2025-11-26T18:05:50.831486825Z     ~~~~^^^^^
2025-11-26T18:05:50.831489859Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 308, in __setitem__
2025-11-26T18:05:50.831491922Z     self._format_and_raise(
2025-11-26T18:05:50.831493885Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T18:05:50.831496168Z     format_and_raise(
2025-11-26T18:05:50.831498312Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T18:05:50.832402867Z     _raise(ex, cause)
2025-11-26T18:05:50.832410318Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T18:05:50.832412632Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T18:05:50.832414704Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T18:05:50.832416847Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 306, in __setitem__
2025-11-26T18:05:50.832419601Z     self.__set_impl(key=key, value=value)
2025-11-26T18:05:50.832422235Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 316, in __set_impl
2025-11-26T18:05:50.832425129Z     self._set_item_impl(key, value)
2025-11-26T18:05:50.832427353Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 579, in _set_item_impl
2025-11-26T18:05:50.832429606Z     target_node_ref = self._get_node(key)
2025-11-26T18:05:50.832431669Z                       ^^^^^^^^^^^^^^^^^^^
2025-11-26T18:05:50.832433652Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 473, in _get_node
2025-11-26T18:05:50.832435755Z     self._validate_get(key)
2025-11-26T18:05:50.832727352Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 163, in _validate_get
2025-11-26T18:05:50.832730387Z     self._format_and_raise(
2025-11-26T18:05:50.832733080Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T18:05:50.832735094Z     format_and_raise(
2025-11-26T18:05:50.832737327Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 906, in format_and_raise
2025-11-26T18:05:50.832739340Z     _raise(ex, cause)
2025-11-26T18:05:50.832741363Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T18:05:50.833090907Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T18:05:50.833093311Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T18:05:50.833095334Z omegaconf.errors.ConfigKeyError: Key 'max_new_tokens' not in 'NormConfig'
2025-11-26T18:05:50.833097386Z     full_key: actor.adv_norm.max_new_tokens
2025-11-26T18:05:50.833099420Z     reference_type=Optional[NormConfig]
2025-11-26T18:05:50.833101473Z     object_type=NormConfig
2025-11-26T18:05:53.330842113Z E1126 18:05:53.329000 966 torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 0 (pid: 1032) of binary: /usr/bin/python3
2025-11-26T18:05:53.331513629Z Traceback (most recent call last):
2025-11-26T18:05:53.331524045Z   File "/usr/local/bin/torchrun", line 7, in <module>
2025-11-26T18:05:53.331527129Z     sys.exit(main())
2025-11-26T18:05:53.331529863Z              ^^^^^^
2025-11-26T18:05:53.331531946Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
2025-11-26T18:05:53.331535031Z     return f(*args, **kwargs)
2025-11-26T18:05:53.331537785Z            ^^^^^^^^^^^^^^^^^^
2025-11-26T18:05:53.331539848Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 901, in main
2025-11-26T18:05:53.332029582Z     run(args)
2025-11-26T18:05:53.332032486Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 892, in run
2025-11-26T18:05:53.332035200Z     elastic_launch(
2025-11-26T18:05:53.332037714Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 143, in __call__
2025-11-26T18:05:53.332040037Z     return launch_agent(self._config, self._entrypoint, list(args))
2025-11-26T18:05:53.332042541Z            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T18:05:53.332044584Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 277, in launch_agent
2025-11-26T18:05:53.332046677Z     raise ChildFailedError(
2025-11-26T18:05:53.332049041Z torch.distributed.elastic.multiprocessing.errors.ChildFailedError:
2025-11-26T18:05:53.332051114Z ============================================================
2025-11-26T18:05:53.332053487Z examples/cloud_gsm8k/gsm8k_grpo_train.py FAILED
2025-11-26T18:05:53.332056332Z ------------------------------------------------------------
2025-11-26T18:05:53.332058365Z Failures:
2025-11-26T18:05:53.332060368Z   <NO_OTHER_FAILURES>
2025-11-26T18:05:53.332062331Z ------------------------------------------------------------
2025-11-26T18:05:53.332064294Z Root Cause (first observed failure):
2025-11-26T18:05:53.332066277Z [0]:
2025-11-26T18:05:53.332068269Z   time      : 2025-11-26_18:05:53
2025-11-26T18:05:53.332070252Z   host      : cef7c503fdea
2025-11-26T18:05:53.332072255Z   rank      : 0 (local_rank: 0)
2025-11-26T18:05:53.332074209Z   exitcode  : 1 (pid: 1032)
2025-11-26T18:05:53.332076192Z   error_file: <N/A>
2025-11-26T18:05:53.332078184Z   traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
2025-11-26T18:05:53.332080258Z ============================================================
2025-11-26T18:05:54.022039104Z [37m20251126-18:05:54.021 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [315][0m
2025-11-26T18:05:54.204528277Z Killed
2025-11-26T18:05:54.217463413Z [37m20251126-18:05:54.217 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [965][0m
2025-11-26T18:05:54.218624843Z Traceback (most recent call last):
2025-11-26T18:05:54.218641738Z   File "<frozen runpy>", line 198, in _run_module_as_main
2025-11-26T18:05:54.218644492Z   File "<frozen runpy>", line 88, in _run_code
2025-11-26T18:05:54.218646605Z   File "/workspace/AReaL/areal/launcher/local.py", line 405, in <module>
2025-11-26T18:05:54.218801107Z     main()
2025-11-26T18:05:54.218809068Z   File "/workspace/AReaL/areal/launcher/local.py", line 260, in main
2025-11-26T18:05:54.218921237Z     local_main(config, run_id=0)
2025-11-26T18:05:54.218924011Z   File "/workspace/AReaL/areal/launcher/local.py", line 399, in local_main
2025-11-26T18:05:54.219040516Z     raise e
2025-11-26T18:05:54.219042779Z   File "/workspace/AReaL/areal/launcher/local.py", line 375, in local_main
2025-11-26T18:05:54.219146694Z     launcher.wait(
2025-11-26T18:05:54.219151652Z   File "/workspace/AReaL/areal/launcher/local.py", line 235, in wait
2025-11-26T18:05:54.219224771Z     raise JobException(
2025-11-26T18:05:54.219227676Z areal.utils.launcher.JobException: Job gsm8k-grpo-cloud-2gpu-2000samples_trial_20251126_180510:trainer JobState.COMPLETED at node local
2025-11-26T18:05:54.510412271Z [37m20251126-18:05:54.509 Local Scheduler INFO: Waiting for 0 local running processes, pids: [0m
2025-11-26T18:05:57.800329977Z ==========
2025-11-26T18:05:57.800354794Z == CUDA ==
2025-11-26T18:05:57.800367803Z ==========
2025-11-26T18:05:57.805341924Z CUDA Version 12.9.1
2025-11-26T18:05:57.807309681Z Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
2025-11-26T18:05:57.808888967Z This container image and its contents are governed by the NVIDIA Deep Learning Container License.
2025-11-26T18:05:57.808892262Z By pulling and using the container, you accept the terms and conditions of this license:
2025-11-26T18:05:57.808895327Z https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license
2025-11-26T18:05:57.808900044Z A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
2025-11-26T18:05:58.044213882Z Writing to /root/.config/pip/pip.conf
2025-11-26T18:05:58.210161579Z Writing to /root/.config/pip/pip.conf
2025-11-26T18:05:58.418687082Z Branch 'feature/reasoning_model' set up to track remote branch 'feature/reasoning_model' from 'origin'.
2025-11-26T18:05:58.418727192Z Your branch is up to date with 'origin/feature/reasoning_model'.
2025-11-26T18:05:58.488552362Z Checking AReaL installation...
2025-11-26T18:05:58.549007244Z AReaL already installed. Skipping installation.
2025-11-26T18:05:58.549035927Z Cleaning up any leftover GPU processes...
2025-11-26T18:06:01.568699268Z Checking for processes holding GPU device files...
2025-11-26T18:06:03.438874620Z Found processes holding GPU devices: 1
2025-11-26T18:06:03.438914409Z 20
2025-11-26T18:06:03.438917985Z 71
2025-11-26T18:06:03.438920458Z 72
2025-11-26T18:06:03.438922472Z Killing process 1...
2025-11-26T18:06:03.438925005Z Killing process 71...
2025-11-26T18:06:03.439024965Z Killing process 72...
2025-11-26T18:06:05.441500835Z Using fuser to kill processes on GPU devices...
2025-11-26T18:06:07.464572716Z Checking GPU...
2025-11-26T18:06:07.499546291Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T18:06:07.499571820Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T18:06:07.516745554Z Set PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True for better memory management
2025-11-26T18:06:07.516759325Z Detected 2 GPU(s)
2025-11-26T18:06:07.516762299Z Checking GPU status...
2025-11-26T18:06:07.543588291Z index, name, utilization.gpu [%], memory.used [MiB], compute_mode
2025-11-26T18:06:07.545156439Z 0, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T18:06:07.546310357Z 1, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T18:06:07.588070869Z Verifying GPU accessibility...
2025-11-26T18:06:08.110447590Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:06:08.110503133Z   import pynvml  # type: ignore[import]
2025-11-26T18:06:09.202714639Z GPU accessibility verified on attempt 1
2025-11-26T18:06:09.656677344Z Starting training...
2025-11-26T18:06:12.659165708Z Using STANDARD 2000 SAMPLES 2 GPUs configuration
2025-11-26T18:06:12.659209394Z Note: GRPO only (no reasoning XML). Dataset capped at 2000 samples (~6 hours).
2025-11-26T18:06:12.659212349Z GPU count: 2 (required: 2)
2025-11-26T18:06:12.661659755Z ==========================================
2025-11-26T18:06:12.661663410Z Starting GRPO Training (Cloud)
2025-11-26T18:06:12.661666926Z ==========================================
2025-11-26T18:06:12.661669539Z Config: standard_2000samples_2GPUs
2025-11-26T18:06:12.661672263Z Config file: examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml
2025-11-26T18:06:12.661675939Z Training script: examples/cloud_gsm8k/gsm8k_grpo_train.py
2025-11-26T18:06:12.661679194Z Experiment: gsm8k-grpo-cloud-2gpu-2000samples
2025-11-26T18:06:12.661681557Z Trial: trial_20251126_180612
2025-11-26T18:06:12.661683991Z GPU: NVIDIA A100 80GB PCIe NVIDIA A100 80GB PCIe (81920 MB)
2025-11-26T18:06:12.661686625Z WandB API key: e1adc5be02...
2025-11-26T18:06:12.661689339Z ==========================================
2025-11-26T18:06:13.325816072Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:06:13.325849151Z   import pynvml  # type: ignore[import]
2025-11-26T18:06:17.456147885Z [37m20251126-18:06:17.455 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T18:06:17.456196618Z [37m20251126-18:06:17.455 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T18:06:17.456641744Z [37m20251126-18:06:17.456 name-resolve INFO: No such name resolve path: ./tmp/areal/name_resolve/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_180612[0m
2025-11-26T18:06:17.561931194Z [37m20251126-18:06:17.561 Local Scheduler INFO: LocalLauncher: experiment_name=gsm8k-grpo-cloud-2gpu-2000samples, trial_name=trial_20251126_180612, fileroot=/workspace/outputs/grpo, run_id=0, is_recover_run=False[0m
2025-11-26T18:06:17.569587342Z [37m20251126-18:06:17.569 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL CUDA_VISIBLE_DEVICES=0 stdbuf -oL python3 -m areal.launcher.sglang_server examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_180612 sglang.random_seed=1 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_180612/llm_server.log[0m
2025-11-26T18:06:18.524792290Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:06:18.524834754Z   import pynvml  # type: ignore[import]
2025-11-26T18:06:20.028417720Z [37m20251126-18:06:20.027 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T18:06:20.028935946Z [37m20251126-18:06:20.028 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T18:06:20.141096808Z [37m20251126-18:06:20.140 SGLangServer Wrapper INFO: Launch command: python3 -m sglang.launch_server --host 172.21.0.2 --port 17465 --tokenizer-path Qwen/Qwen2.5-0.5B-Instruct --tokenizer-mode auto --load-format auto --trust-remote-code --device cuda --tp-size 1 --base-gpu-id 0 --nnodes 1 --node-rank 0 --dist-init-addr localhost:21115 --model-path Qwen/Qwen2.5-0.5B-Instruct --random-seed 1 --skip-tokenizer-init --disable-radix-cache --torch-compile-max-bs 32 --triton-attention-num-kv-splits 8 --num-continuous-decode-steps 1 --attention-backend flashinfer --context-length 4096 --mem-fraction-static 0.6 --chunked-prefill-size -1 --max-prefill-tokens 32768 --schedule-policy lpm --schedule-conservativeness 1.0 --cpu-offload-gb 0 --dtype bfloat16 --kv-cache-dtype auto --dp-size 1 --ep-size 1 --max-loaded-loras 1 --max-loras-per-batch 1 --lora-backend triton --log-level warning --log-level-http warning --log-requests-level 0 --enable-metrics --decode-log-interval 1[0m
2025-11-26T18:06:21.171517501Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:06:21.171554515Z   import pynvml  # type: ignore[import]
2025-11-26T18:06:26.614688810Z INFO 11-26 18:06:26 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T18:06:27.375095307Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T18:06:28.391468579Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:06:28.391511263Z   import pynvml  # type: ignore[import]
2025-11-26T18:06:28.431905748Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:06:28.431944286Z   import pynvml  # type: ignore[import]
2025-11-26T18:06:34.180835413Z INFO 11-26 18:06:34 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T18:06:34.314025924Z INFO 11-26 18:06:34 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T18:06:34.903581129Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T18:06:35.122798858Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T18:06:35.126365840Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T18:06:35.127230586Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T18:06:35.128027560Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T18:06:35.161206187Z [2025-11-26 18:06:35] MOE_RUNNER_BACKEND is not initialized, using triton backend
2025-11-26T18:06:35.735611960Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T18:06:35.735651239Z   warnings.warn(
2025-11-26T18:06:35.735654103Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T18:06:35.735656376Z   warnings.warn(
2025-11-26T18:06:37.313742477Z Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
2025-11-26T18:06:37.478087063Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  6.09it/s]
2025-11-26T18:06:37.478304950Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  6.08it/s]
2025-11-26T18:06:40.327901113Z   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   4%|â–         | 1/23 [00:00<00:12,  1.70it/s]Capturing batches (bs=152 avail_mem=30.62 GB):   4%|â–         | 1/23 [00:00<00:12,  1.70it/s]Capturing batches (bs=144 avail_mem=30.60 GB):   4%|â–         | 1/23 [00:00<00:12,  1.70it/s]Capturing batches (bs=136 avail_mem=30.59 GB):   4%|â–         | 1/23 [00:00<00:12,  1.70it/s]Capturing batches (bs=136 avail_mem=30.59 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  6.71it/s]Capturing batches (bs=128 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  6.71it/s]Capturing batches (bs=120 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  6.71it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  6.71it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 10.81it/s]Capturing batches (bs=104 avail_mem=30.54 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 10.81it/s]Capturing batches (bs=96 avail_mem=30.53 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 10.81it/s] Capturing batches (bs=88 avail_mem=30.51 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 10.81it/s]Capturing batches (bs=88 avail_mem=30.51 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 13.88it/s]Capturing batches (bs=80 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 13.88it/s]Capturing batches (bs=72 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:01<00:00, 13.88it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:01<00:00, 13.88it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 16.28it/s]Capturing batches (bs=56 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 16.28it/s]Capturing batches (bs=48 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 16.28it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 16.28it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 18.26it/s]Capturing batches (bs=32 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 18.26it/s]Capturing batches (bs=24 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 18.26it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 18.26it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 16.88it/s]Capturing batches (bs=8 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 16.88it/s] Capturing batches (bs=4 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 16.88it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 16.88it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 18.62it/s]Capturing batches (bs=1 avail_mem=30.35 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 18.62it/s]Capturing batches (bs=1 avail_mem=30.35 GB): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00, 14.06it/s]
2025-11-26T18:06:46.172390523Z [37m20251126-18:06:46.171 SGLangServer Wrapper INFO: SGLang server launched at: http://172.21.0.2:17465[0m
2025-11-26T18:06:46.577228647Z [37m20251126-18:06:46.576 Launcher Utils INFO: Found 1 rollout servers: 172.21.0.2:17465[0m
2025-11-26T18:06:46.577265983Z [37m20251126-18:06:46.577 Local Scheduler INFO: LLM inference server launched at: AREAL_LLM_SERVER_ADDRS=172.21.0.2:17465[0m
2025-11-26T18:06:46.578943576Z [37m20251126-18:06:46.578 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL AREAL_LLM_SERVER_ADDRS=172.21.0.2:17465 AREAL_RECOVER_RUN=0 NCCL_CUMEM_ENABLE=0 NCCL_NVLS_ENABLE=0 CUDA_VISIBLE_DEVICES=1 stdbuf -oL torchrun --nnodes 1 --nproc-per-node 1 --master-addr localhost --master-port 10476 examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_180612 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_180612/trainer.log[0m
2025-11-26T18:06:46.579758186Z [37m20251126-18:06:46.579 Local Scheduler INFO: Waiting for 2 local running processes, pids: 315 965[0m
2025-11-26T18:06:47.126950537Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:06:47.126980622Z   import pynvml  # type: ignore[import]
2025-11-26T18:06:48.335993281Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:06:48.336023797Z   import pynvml  # type: ignore[import]
2025-11-26T18:06:55.686353505Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T18:06:55.686398461Z   warnings.warn(
2025-11-26T18:06:55.686401636Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T18:06:55.686403889Z   warnings.warn(
2025-11-26T18:06:56.182218373Z Traceback (most recent call last):
2025-11-26T18:06:56.182742007Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 665, in <module>
2025-11-26T18:06:56.182752613Z     main(sys.argv[1:])
2025-11-26T18:06:56.182755908Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 102, in main
2025-11-26T18:06:56.182758392Z     config, _ = load_expr_config(args_with_overrides, GRPOConfig)
2025-11-26T18:06:56.182761487Z                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T18:06:56.182763600Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1282, in load_expr_config
2025-11-26T18:06:56.182989177Z     cfg = to_structured_cfg(cfg, config_cls=config_cls)
2025-11-26T18:06:56.182991832Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T18:06:56.182993935Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1276, in to_structured_cfg
2025-11-26T18:06:56.183365131Z     cfg = OmegaConf.merge(default_cfg, cfg)
2025-11-26T18:06:56.183371831Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T18:06:56.183374094Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/omegaconf.py", line 274, in merge
2025-11-26T18:06:56.183673293Z     target.merge_with(
2025-11-26T18:06:56.183696487Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 507, in merge_with
2025-11-26T18:06:56.183704229Z     self._format_and_raise(key=None, value=None, cause=e)
2025-11-26T18:06:56.183706873Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T18:06:56.183709016Z     format_and_raise(
2025-11-26T18:06:56.183711119Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T18:06:56.183886872Z     _raise(ex, cause)
2025-11-26T18:06:56.183891008Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T18:06:56.183893362Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T18:06:56.184314663Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T18:06:56.184321093Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 502, in merge_with
2025-11-26T18:06:56.184323757Z     self._merge_with(
2025-11-26T18:06:56.184326601Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T18:06:56.184328695Z     BaseContainer._map_merge(
2025-11-26T18:06:56.184331348Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T18:06:56.185531697Z     dest_node._merge_with(
2025-11-26T18:06:56.185551997Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T18:06:56.185555702Z     BaseContainer._map_merge(
2025-11-26T18:06:56.185557836Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T18:06:56.185560269Z     dest_node._merge_with(
2025-11-26T18:06:56.185562243Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T18:06:56.185564255Z     BaseContainer._map_merge(
2025-11-26T18:06:56.185566309Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 432, in _map_merge
2025-11-26T18:06:56.185568321Z     dest[key] = src._get_node(key)
2025-11-26T18:06:56.185571085Z     ~~~~^^^^^
2025-11-26T18:06:56.185573569Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 308, in __setitem__
2025-11-26T18:06:56.185575663Z     self._format_and_raise(
2025-11-26T18:06:56.185577715Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T18:06:56.185579769Z     format_and_raise(
2025-11-26T18:06:56.185582593Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T18:06:56.185586108Z     _raise(ex, cause)
2025-11-26T18:06:56.185588141Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T18:06:56.185590835Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T18:06:56.185592869Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T18:06:56.185594892Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 306, in __setitem__
2025-11-26T18:06:56.185596975Z     self.__set_impl(key=key, value=value)
2025-11-26T18:06:56.185599027Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 316, in __set_impl
2025-11-26T18:06:56.185915240Z     self._set_item_impl(key, value)
2025-11-26T18:06:56.185921320Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 579, in _set_item_impl
2025-11-26T18:06:56.185924754Z     target_node_ref = self._get_node(key)
2025-11-26T18:06:56.185926878Z                       ^^^^^^^^^^^^^^^^^^^
2025-11-26T18:06:56.185928851Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 473, in _get_node
2025-11-26T18:06:56.185932045Z     self._validate_get(key)
2025-11-26T18:06:56.185934519Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 163, in _validate_get
2025-11-26T18:06:56.186233848Z     self._format_and_raise(
2025-11-26T18:06:56.186250763Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T18:06:56.186253157Z     format_and_raise(
2025-11-26T18:06:56.186255250Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 906, in format_and_raise
2025-11-26T18:06:56.186257273Z     _raise(ex, cause)
2025-11-26T18:06:56.186259707Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T18:06:56.186464474Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T18:06:56.186725084Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T18:06:56.186727828Z omegaconf.errors.ConfigKeyError: Key 'max_new_tokens' not in 'NormConfig'
2025-11-26T18:06:56.186729941Z     full_key: actor.adv_norm.max_new_tokens
2025-11-26T18:06:56.186731944Z     reference_type=Optional[NormConfig]
2025-11-26T18:06:56.186734158Z     object_type=NormConfig
2025-11-26T18:06:59.126839791Z E1126 18:06:59.125000 966 torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 0 (pid: 1032) of binary: /usr/bin/python3
2025-11-26T18:06:59.127168834Z Traceback (most recent call last):
2025-11-26T18:06:59.127176506Z   File "/usr/local/bin/torchrun", line 7, in <module>
2025-11-26T18:06:59.127444888Z     sys.exit(main())
2025-11-26T18:06:59.127448062Z              ^^^^^^
2025-11-26T18:06:59.127450156Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
2025-11-26T18:06:59.127453150Z     return f(*args, **kwargs)
2025-11-26T18:06:59.127455744Z            ^^^^^^^^^^^^^^^^^^
2025-11-26T18:06:59.127457747Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 901, in main
2025-11-26T18:06:59.127693950Z     run(args)
2025-11-26T18:06:59.127697166Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 892, in run
2025-11-26T18:06:59.128148062Z     elastic_launch(
2025-11-26T18:06:59.128190705Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 143, in __call__
2025-11-26T18:06:59.128194039Z     return launch_agent(self._config, self._entrypoint, list(args))
2025-11-26T18:06:59.128197064Z            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T18:06:59.128199227Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 277, in launch_agent
2025-11-26T18:06:59.128201290Z     raise ChildFailedError(
2025-11-26T18:06:59.128204085Z torch.distributed.elastic.multiprocessing.errors.ChildFailedError:
2025-11-26T18:06:59.128206488Z ============================================================
2025-11-26T18:06:59.128209172Z examples/cloud_gsm8k/gsm8k_grpo_train.py FAILED
2025-11-26T18:06:59.128212017Z ------------------------------------------------------------
2025-11-26T18:06:59.128214040Z Failures:
2025-11-26T18:06:59.128216784Z   <NO_OTHER_FAILURES>
2025-11-26T18:06:59.128218787Z ------------------------------------------------------------
2025-11-26T18:06:59.128220850Z Root Cause (first observed failure):
2025-11-26T18:06:59.128222923Z [0]:
2025-11-26T18:06:59.128225406Z   time      : 2025-11-26_18:06:59
2025-11-26T18:06:59.128227449Z   host      : cef7c503fdea
2025-11-26T18:06:59.128229483Z   rank      : 0 (local_rank: 0)
2025-11-26T18:06:59.128231486Z   exitcode  : 1 (pid: 1032)
2025-11-26T18:06:59.128233449Z   error_file: <N/A>
2025-11-26T18:06:59.128235432Z   traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
2025-11-26T18:06:59.128238236Z ============================================================
2025-11-26T18:07:00.583980933Z [37m20251126-18:07:00.583 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [315][0m
2025-11-26T18:07:00.757240893Z Killed
2025-11-26T18:07:00.768040790Z [37m20251126-18:07:00.767 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [965][0m
2025-11-26T18:07:00.769005826Z Traceback (most recent call last):
2025-11-26T18:07:00.769017693Z   File "<frozen runpy>", line 198, in _run_module_as_main
2025-11-26T18:07:00.769020337Z   File "<frozen runpy>", line 88, in _run_code
2025-11-26T18:07:00.769040107Z   File "/workspace/AReaL/areal/launcher/local.py", line 405, in <module>
2025-11-26T18:07:00.769174158Z     main()
2025-11-26T18:07:00.769179396Z   File "/workspace/AReaL/areal/launcher/local.py", line 260, in main
2025-11-26T18:07:00.769253006Z     local_main(config, run_id=0)
2025-11-26T18:07:00.769256081Z   File "/workspace/AReaL/areal/launcher/local.py", line 399, in local_main
2025-11-26T18:07:00.769365344Z     raise e
2025-11-26T18:07:00.769367878Z   File "/workspace/AReaL/areal/launcher/local.py", line 375, in local_main
2025-11-26T18:07:00.769417913Z     launcher.wait(
2025-11-26T18:07:00.769420637Z   File "/workspace/AReaL/areal/launcher/local.py", line 235, in wait
2025-11-26T18:07:00.769483942Z     raise JobException(
2025-11-26T18:07:00.769486496Z areal.utils.launcher.JobException: Job gsm8k-grpo-cloud-2gpu-2000samples_trial_20251126_180612:trainer JobState.COMPLETED at node local
2025-11-26T18:07:01.028375356Z [37m20251126-18:07:01.027 Local Scheduler INFO: Waiting for 0 local running processes, pids: [0m
2025-11-26T18:07:16.116297110Z ==========
2025-11-26T18:07:16.116302779Z == CUDA ==
2025-11-26T18:07:16.116305583Z ==========
2025-11-26T18:07:16.121995775Z CUDA Version 12.9.1
2025-11-26T18:07:16.124070083Z Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
2025-11-26T18:07:16.125907195Z This container image and its contents are governed by the NVIDIA Deep Learning Container License.
2025-11-26T18:07:16.125909718Z By pulling and using the container, you accept the terms and conditions of this license:
2025-11-26T18:07:16.125912603Z https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license
2025-11-26T18:07:16.125917961Z A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
2025-11-26T18:07:16.289935066Z Writing to /root/.config/pip/pip.conf
2025-11-26T18:07:16.447651744Z Writing to /root/.config/pip/pip.conf
2025-11-26T18:07:16.649662690Z Branch 'feature/reasoning_model' set up to track remote branch 'feature/reasoning_model' from 'origin'.
2025-11-26T18:07:16.649710020Z Your branch is up to date with 'origin/feature/reasoning_model'.
2025-11-26T18:07:16.718772137Z Checking AReaL installation...
2025-11-26T18:07:16.776669809Z AReaL already installed. Skipping installation.
2025-11-26T18:07:16.776696360Z Cleaning up any leftover GPU processes...
2025-11-26T18:07:19.796172009Z Checking for processes holding GPU device files...
2025-11-26T18:07:21.915777233Z Found processes holding GPU devices: 1
2025-11-26T18:07:21.915816432Z 20
2025-11-26T18:07:21.915819807Z 71
2025-11-26T18:07:21.915822230Z 72
2025-11-26T18:07:21.915824314Z Killing process 1...
2025-11-26T18:07:21.915827659Z Killing process 71...
2025-11-26T18:07:21.915837944Z Killing process 72...
2025-11-26T18:07:23.918426803Z Using fuser to kill processes on GPU devices...
2025-11-26T18:07:25.938600553Z Checking GPU...
2025-11-26T18:07:25.972272459Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T18:07:25.972294692Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T18:07:25.988727056Z Set PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True for better memory management
2025-11-26T18:07:25.988741708Z Detected 2 GPU(s)
2025-11-26T18:07:25.988744662Z Checking GPU status...
2025-11-26T18:07:26.016878362Z index, name, utilization.gpu [%], memory.used [MiB], compute_mode
2025-11-26T18:07:26.018390968Z 0, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T18:07:26.018727863Z 1, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T18:07:26.062422632Z Verifying GPU accessibility...
2025-11-26T18:07:26.596263203Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:07:26.596331316Z   import pynvml  # type: ignore[import]
2025-11-26T18:07:27.699750610Z GPU accessibility verified on attempt 1
2025-11-26T18:07:28.166995911Z Starting training...
2025-11-26T18:07:31.169746007Z Using STANDARD 2000 SAMPLES 2 GPUs configuration
2025-11-26T18:07:31.169785727Z Note: GRPO only (no reasoning XML). Dataset capped at 2000 samples (~6 hours).
2025-11-26T18:07:31.169788751Z GPU count: 2 (required: 2)
2025-11-26T18:07:31.172175987Z ==========================================
2025-11-26T18:07:31.172182888Z Starting GRPO Training (Cloud)
2025-11-26T18:07:31.172186593Z ==========================================
2025-11-26T18:07:31.172189467Z Config: standard_2000samples_2GPUs
2025-11-26T18:07:31.172192191Z Config file: examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml
2025-11-26T18:07:31.172195837Z Training script: examples/cloud_gsm8k/gsm8k_grpo_train.py
2025-11-26T18:07:31.172199633Z Experiment: gsm8k-grpo-cloud-2gpu-2000samples
2025-11-26T18:07:31.172202537Z Trial: trial_20251126_180731
2025-11-26T18:07:31.172205522Z GPU: NVIDIA A100 80GB PCIe NVIDIA A100 80GB PCIe (81920 MB)
2025-11-26T18:07:31.172208496Z WandB API key: e1adc5be02...
2025-11-26T18:07:31.172211260Z ==========================================
2025-11-26T18:07:31.854924091Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:07:31.854965865Z   import pynvml  # type: ignore[import]
2025-11-26T18:07:35.843748375Z [37m20251126-18:07:35.843 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T18:07:35.843794144Z [37m20251126-18:07:35.843 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T18:07:35.844041474Z [37m20251126-18:07:35.843 name-resolve INFO: No such name resolve path: ./tmp/areal/name_resolve/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_180731[0m
2025-11-26T18:07:35.949667058Z [37m20251126-18:07:35.949 Local Scheduler INFO: LocalLauncher: experiment_name=gsm8k-grpo-cloud-2gpu-2000samples, trial_name=trial_20251126_180731, fileroot=/workspace/outputs/grpo, run_id=0, is_recover_run=False[0m
2025-11-26T18:07:35.956279021Z [37m20251126-18:07:35.956 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL CUDA_VISIBLE_DEVICES=0 stdbuf -oL python3 -m areal.launcher.sglang_server examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_180731 sglang.random_seed=1 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_180731/llm_server.log[0m
2025-11-26T18:07:36.687327724Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:07:36.687367634Z   import pynvml  # type: ignore[import]
2025-11-26T18:07:38.147149662Z [37m20251126-18:07:38.146 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T18:07:38.147413367Z [37m20251126-18:07:38.146 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T18:07:38.251536780Z [37m20251126-18:07:38.251 SGLangServer Wrapper INFO: Launch command: python3 -m sglang.launch_server --host 172.21.0.2 --port 20467 --tokenizer-path Qwen/Qwen2.5-0.5B-Instruct --tokenizer-mode auto --load-format auto --trust-remote-code --device cuda --tp-size 1 --base-gpu-id 0 --nnodes 1 --node-rank 0 --dist-init-addr localhost:22472 --model-path Qwen/Qwen2.5-0.5B-Instruct --random-seed 1 --skip-tokenizer-init --disable-radix-cache --torch-compile-max-bs 32 --triton-attention-num-kv-splits 8 --num-continuous-decode-steps 1 --attention-backend flashinfer --context-length 4096 --mem-fraction-static 0.6 --chunked-prefill-size -1 --max-prefill-tokens 32768 --schedule-policy lpm --schedule-conservativeness 1.0 --cpu-offload-gb 0 --dtype bfloat16 --kv-cache-dtype auto --dp-size 1 --ep-size 1 --max-loaded-loras 1 --max-loras-per-batch 1 --lora-backend triton --log-level warning --log-level-http warning --log-requests-level 0 --enable-metrics --decode-log-interval 1[0m
2025-11-26T18:07:39.323874037Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:07:39.323911343Z   import pynvml  # type: ignore[import]
2025-11-26T18:07:44.687941270Z INFO 11-26 18:07:44 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T18:07:45.452566776Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T18:07:46.788359886Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:07:46.788405664Z   import pynvml  # type: ignore[import]
2025-11-26T18:07:46.788680586Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:07:46.788706164Z   import pynvml  # type: ignore[import]
2025-11-26T18:07:52.497502765Z INFO 11-26 18:07:52 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T18:07:52.634806288Z INFO 11-26 18:07:52 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T18:07:53.100430902Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T18:07:53.322253772Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T18:07:53.326008346Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T18:07:53.326875635Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T18:07:53.327766429Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T18:07:53.361762001Z [2025-11-26 18:07:53] MOE_RUNNER_BACKEND is not initialized, using triton backend
2025-11-26T18:07:53.866704726Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T18:07:53.866739068Z   warnings.warn(
2025-11-26T18:07:53.866741712Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T18:07:53.866744016Z   warnings.warn(
2025-11-26T18:07:55.065804357Z Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
2025-11-26T18:07:55.187474022Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  8.27it/s]
2025-11-26T18:07:55.188157235Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  8.21it/s]
2025-11-26T18:07:57.742231696Z   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   4%|â–         | 1/23 [00:00<00:12,  1.81it/s]Capturing batches (bs=152 avail_mem=30.62 GB):   4%|â–         | 1/23 [00:00<00:12,  1.81it/s]Capturing batches (bs=144 avail_mem=30.60 GB):   4%|â–         | 1/23 [00:00<00:12,  1.81it/s]Capturing batches (bs=136 avail_mem=30.59 GB):   4%|â–         | 1/23 [00:00<00:12,  1.81it/s]Capturing batches (bs=136 avail_mem=30.59 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.15it/s]Capturing batches (bs=128 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.15it/s]Capturing batches (bs=120 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.15it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.15it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.42it/s]Capturing batches (bs=104 avail_mem=30.54 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.42it/s]Capturing batches (bs=96 avail_mem=30.53 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.42it/s] Capturing batches (bs=88 avail_mem=30.51 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.42it/s]Capturing batches (bs=88 avail_mem=30.51 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.76it/s]Capturing batches (bs=80 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.76it/s]Capturing batches (bs=72 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.76it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:01<00:00, 14.76it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.27it/s]Capturing batches (bs=56 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.27it/s]Capturing batches (bs=48 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.27it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.27it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.29it/s]Capturing batches (bs=32 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.29it/s]Capturing batches (bs=24 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.29it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.29it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.69it/s]Capturing batches (bs=8 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.69it/s] Capturing batches (bs=4 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.69it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.69it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.54it/s]Capturing batches (bs=1 avail_mem=30.35 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.54it/s]Capturing batches (bs=1 avail_mem=30.35 GB): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00, 14.84it/s]
2025-11-26T18:08:03.278773553Z [37m20251126-18:08:03.278 SGLangServer Wrapper INFO: SGLang server launched at: http://172.21.0.2:20467[0m
2025-11-26T18:08:03.963075676Z [37m20251126-18:08:03.962 Launcher Utils INFO: Found 1 rollout servers: 172.21.0.2:20467[0m
2025-11-26T18:08:03.963099762Z [37m20251126-18:08:03.962 Local Scheduler INFO: LLM inference server launched at: AREAL_LLM_SERVER_ADDRS=172.21.0.2:20467[0m
2025-11-26T18:08:03.966175449Z [37m20251126-18:08:03.965 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL AREAL_LLM_SERVER_ADDRS=172.21.0.2:20467 AREAL_RECOVER_RUN=0 NCCL_CUMEM_ENABLE=0 NCCL_NVLS_ENABLE=0 CUDA_VISIBLE_DEVICES=1 stdbuf -oL torchrun --nnodes 1 --nproc-per-node 1 --master-addr localhost --master-port 35614 examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_180731 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_180731/trainer.log[0m
2025-11-26T18:08:03.966871151Z [37m20251126-18:08:03.966 Local Scheduler INFO: Waiting for 2 local running processes, pids: 315 965[0m
2025-11-26T18:08:04.507396595Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:08:04.507443276Z   import pynvml  # type: ignore[import]
2025-11-26T18:08:05.696750618Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:08:05.696785150Z   import pynvml  # type: ignore[import]
2025-11-26T18:08:12.322508324Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T18:08:12.322551299Z   warnings.warn(
2025-11-26T18:08:12.322555205Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T18:08:12.322557949Z   warnings.warn(
2025-11-26T18:08:12.735157087Z Traceback (most recent call last):
2025-11-26T18:08:12.735196155Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 665, in <module>
2025-11-26T18:08:12.735842794Z     main(sys.argv[1:])
2025-11-26T18:08:12.735866279Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 102, in main
2025-11-26T18:08:12.735869575Z     config, _ = load_expr_config(args_with_overrides, GRPOConfig)
2025-11-26T18:08:12.735872579Z                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T18:08:12.735875173Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1282, in load_expr_config
2025-11-26T18:08:12.735877176Z     cfg = to_structured_cfg(cfg, config_cls=config_cls)
2025-11-26T18:08:12.735879960Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T18:08:12.735881993Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1276, in to_structured_cfg
2025-11-26T18:08:12.736427580Z     cfg = OmegaConf.merge(default_cfg, cfg)
2025-11-26T18:08:12.736442533Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T18:08:12.736445137Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/omegaconf.py", line 274, in merge
2025-11-26T18:08:12.736448602Z     target.merge_with(
2025-11-26T18:08:12.736451316Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 507, in merge_with
2025-11-26T18:08:12.736464095Z     self._format_and_raise(key=None, value=None, cause=e)
2025-11-26T18:08:12.736466729Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T18:08:12.736469073Z     format_and_raise(
2025-11-26T18:08:12.736471145Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T18:08:12.736904805Z     _raise(ex, cause)
2025-11-26T18:08:12.736909832Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T18:08:12.736912306Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T18:08:12.736914529Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T18:08:12.736916943Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 502, in merge_with
2025-11-26T18:08:12.736919697Z     self._merge_with(
2025-11-26T18:08:12.736921760Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T18:08:12.736924364Z     BaseContainer._map_merge(
2025-11-26T18:08:12.736926858Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T18:08:12.737285285Z     dest_node._merge_with(
2025-11-26T18:08:12.737291785Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T18:08:12.737294158Z     BaseContainer._map_merge(
2025-11-26T18:08:12.737296381Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T18:08:12.737298465Z     dest_node._merge_with(
2025-11-26T18:08:12.737300438Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T18:08:12.737302571Z     BaseContainer._map_merge(
2025-11-26T18:08:12.737304834Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 432, in _map_merge
2025-11-26T18:08:12.737306867Z     dest[key] = src._get_node(key)
2025-11-26T18:08:12.738056850Z     ~~~~^^^^^
2025-11-26T18:08:12.738061037Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 308, in __setitem__
2025-11-26T18:08:12.738063540Z     self._format_and_raise(
2025-11-26T18:08:12.738065744Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T18:08:12.738067807Z     format_and_raise(
2025-11-26T18:08:12.738069870Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T18:08:12.738071953Z     _raise(ex, cause)
2025-11-26T18:08:12.738073966Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T18:08:12.738076179Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T18:08:12.738078613Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T18:08:12.738080736Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 306, in __setitem__
2025-11-26T18:08:12.738082719Z     self.__set_impl(key=key, value=value)
2025-11-26T18:08:12.738084682Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 316, in __set_impl
2025-11-26T18:08:12.738086645Z     self._set_item_impl(key, value)
2025-11-26T18:08:12.738088678Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 579, in _set_item_impl
2025-11-26T18:08:12.738450590Z     target_node_ref = self._get_node(key)
2025-11-26T18:08:12.738456069Z                       ^^^^^^^^^^^^^^^^^^^
2025-11-26T18:08:12.738458382Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 473, in _get_node
2025-11-26T18:08:12.738460736Z     self._validate_get(key)
2025-11-26T18:08:12.738462929Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 163, in _validate_get
2025-11-26T18:08:12.738465132Z     self._format_and_raise(
2025-11-26T18:08:12.738467266Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T18:08:12.738472944Z     format_and_raise(
2025-11-26T18:08:12.738475227Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 906, in format_and_raise
2025-11-26T18:08:12.738796218Z     _raise(ex, cause)
2025-11-26T18:08:12.738800605Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T18:08:12.738802918Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T18:08:12.739199622Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T18:08:12.739219281Z omegaconf.errors.ConfigKeyError: Key 'max_new_tokens' not in 'NormConfig'
2025-11-26T18:08:12.739222356Z     full_key: actor.adv_norm.max_new_tokens
2025-11-26T18:08:12.739224429Z     reference_type=Optional[NormConfig]
2025-11-26T18:08:12.739226472Z     object_type=NormConfig
2025-11-26T18:08:15.408080097Z E1126 18:08:15.407000 966 torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 0 (pid: 1032) of binary: /usr/bin/python3
2025-11-26T18:08:15.408947587Z Traceback (most recent call last):
2025-11-26T18:08:15.408961328Z   File "/usr/local/bin/torchrun", line 7, in <module>
2025-11-26T18:08:15.408963861Z     sys.exit(main())
2025-11-26T18:08:15.408966415Z              ^^^^^^
2025-11-26T18:08:15.408968628Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
2025-11-26T18:08:15.408971963Z     return f(*args, **kwargs)
2025-11-26T18:08:15.408974367Z            ^^^^^^^^^^^^^^^^^^
2025-11-26T18:08:15.408976380Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 901, in main
2025-11-26T18:08:15.409417951Z     run(args)
2025-11-26T18:08:15.409425492Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 892, in run
2025-11-26T18:08:15.409428547Z     elastic_launch(
2025-11-26T18:08:15.409431271Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 143, in __call__
2025-11-26T18:08:15.409433494Z     return launch_agent(self._config, self._entrypoint, list(args))
2025-11-26T18:08:15.409436118Z            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T18:08:15.409438582Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 277, in launch_agent
2025-11-26T18:08:15.409441316Z     raise ChildFailedError(
2025-11-26T18:08:15.409444180Z torch.distributed.elastic.multiprocessing.errors.ChildFailedError:
2025-11-26T18:08:15.409446213Z ============================================================
2025-11-26T18:08:15.409448677Z examples/cloud_gsm8k/gsm8k_grpo_train.py FAILED
2025-11-26T18:08:15.409451070Z ------------------------------------------------------------
2025-11-26T18:08:15.409453053Z Failures:
2025-11-26T18:08:15.409455697Z   <NO_OTHER_FAILURES>
2025-11-26T18:08:15.409458221Z ------------------------------------------------------------
2025-11-26T18:08:15.409460424Z Root Cause (first observed failure):
2025-11-26T18:08:15.409462518Z [0]:
2025-11-26T18:08:15.409464591Z   time      : 2025-11-26_18:08:15
2025-11-26T18:08:15.409466644Z   host      : cef7c503fdea
2025-11-26T18:08:15.409468637Z   rank      : 0 (local_rank: 0)
2025-11-26T18:08:15.409470610Z   exitcode  : 1 (pid: 1032)
2025-11-26T18:08:15.409472573Z   error_file: <N/A>
2025-11-26T18:08:15.409474626Z   traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
2025-11-26T18:08:15.409476900Z ============================================================
2025-11-26T18:08:15.970077814Z [37m20251126-18:08:15.969 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [315][0m
2025-11-26T18:08:16.145059343Z Killed
2025-11-26T18:08:16.155100513Z [37m20251126-18:08:16.154 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [965][0m
2025-11-26T18:08:16.156419469Z Traceback (most recent call last):
2025-11-26T18:08:16.156456364Z   File "<frozen runpy>", line 198, in _run_module_as_main
2025-11-26T18:08:16.156459619Z   File "<frozen runpy>", line 88, in _run_code
2025-11-26T18:08:16.156461883Z   File "/workspace/AReaL/areal/launcher/local.py", line 405, in <module>
2025-11-26T18:08:16.156557206Z     main()
2025-11-26T18:08:16.156566399Z   File "/workspace/AReaL/areal/launcher/local.py", line 260, in main
2025-11-26T18:08:16.156640420Z     local_main(config, run_id=0)
2025-11-26T18:08:16.156645047Z   File "/workspace/AReaL/areal/launcher/local.py", line 399, in local_main
2025-11-26T18:08:16.156737095Z     raise e
2025-11-26T18:08:16.156739548Z   File "/workspace/AReaL/areal/launcher/local.py", line 375, in local_main
2025-11-26T18:08:16.156803905Z     launcher.wait(
2025-11-26T18:08:16.156807981Z   File "/workspace/AReaL/areal/launcher/local.py", line 235, in wait
2025-11-26T18:08:16.156864656Z     raise JobException(
2025-11-26T18:08:16.156867270Z areal.utils.launcher.JobException: Job gsm8k-grpo-cloud-2gpu-2000samples_trial_20251126_180731:trainer JobState.COMPLETED at node local
2025-11-26T18:08:16.450013704Z [37m20251126-18:08:16.449 Local Scheduler INFO: Waiting for 0 local running processes, pids: [0m
2025-11-26T18:08:18.949509213Z ==========
2025-11-26T18:08:18.949512578Z == CUDA ==
2025-11-26T18:08:18.949570194Z ==========
2025-11-26T18:08:18.954251987Z CUDA Version 12.9.1
2025-11-26T18:08:18.955916791Z Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
2025-11-26T18:08:18.957633402Z This container image and its contents are governed by the NVIDIA Deep Learning Container License.
2025-11-26T18:08:18.957636306Z By pulling and using the container, you accept the terms and conditions of this license:
2025-11-26T18:08:18.957638760Z https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license
2025-11-26T18:08:18.957643086Z A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
2025-11-26T18:08:19.123388001Z Writing to /root/.config/pip/pip.conf
2025-11-26T18:08:19.281063707Z Writing to /root/.config/pip/pip.conf
2025-11-26T18:08:19.475086346Z Branch 'feature/reasoning_model' set up to track remote branch 'feature/reasoning_model' from 'origin'.
2025-11-26T18:08:19.475170012Z Your branch is up to date with 'origin/feature/reasoning_model'.
2025-11-26T18:08:19.546028108Z Checking AReaL installation...
2025-11-26T18:08:19.605010726Z AReaL already installed. Skipping installation.
2025-11-26T18:08:19.605042103Z Cleaning up any leftover GPU processes...
2025-11-26T18:08:22.625790189Z Checking for processes holding GPU device files...
2025-11-26T18:08:25.180110318Z Found processes holding GPU devices: 1
2025-11-26T18:08:25.180165000Z 20
2025-11-26T18:08:25.180168645Z 71
2025-11-26T18:08:25.180170758Z 72
2025-11-26T18:08:25.180172832Z Killing process 1...
2025-11-26T18:08:25.180175375Z Killing process 71...
2025-11-26T18:08:25.180404748Z Killing process 72...
2025-11-26T18:08:27.183035641Z Using fuser to kill processes on GPU devices...
2025-11-26T18:08:29.211020780Z Checking GPU...
2025-11-26T18:08:29.251883517Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T18:08:29.251908054Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T18:08:29.267976582Z Set PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True for better memory management
2025-11-26T18:08:29.267995261Z Detected 2 GPU(s)
2025-11-26T18:08:29.267998636Z Checking GPU status...
2025-11-26T18:08:29.296498034Z index, name, utilization.gpu [%], memory.used [MiB], compute_mode
2025-11-26T18:08:29.297939222Z 0, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T18:08:29.298304570Z 1, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T18:08:29.349944430Z Verifying GPU accessibility...
2025-11-26T18:08:29.896855518Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:08:29.896910441Z   import pynvml  # type: ignore[import]
2025-11-26T18:08:31.030200478Z GPU accessibility verified on attempt 1
2025-11-26T18:08:31.584454956Z Starting training...
2025-11-26T18:08:34.587355349Z Using STANDARD 2000 SAMPLES 2 GPUs configuration
2025-11-26T18:08:34.587397181Z Note: GRPO only (no reasoning XML). Dataset capped at 2000 samples (~6 hours).
2025-11-26T18:08:34.587408388Z GPU count: 2 (required: 2)
2025-11-26T18:08:34.590265908Z ==========================================
2025-11-26T18:08:34.590269183Z Starting GRPO Training (Cloud)
2025-11-26T18:08:34.590272248Z ==========================================
2025-11-26T18:08:34.590274261Z Config: standard_2000samples_2GPUs
2025-11-26T18:08:34.590278317Z Config file: examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml
2025-11-26T18:08:34.590281151Z Training script: examples/cloud_gsm8k/gsm8k_grpo_train.py
2025-11-26T18:08:34.590283605Z Experiment: gsm8k-grpo-cloud-2gpu-2000samples
2025-11-26T18:08:34.590285648Z Trial: trial_20251126_180834
2025-11-26T18:08:34.590287701Z GPU: NVIDIA A100 80GB PCIe NVIDIA A100 80GB PCIe (81920 MB)
2025-11-26T18:08:34.590289714Z WandB API key: e1adc5be02...
2025-11-26T18:08:34.590291717Z ==========================================
2025-11-26T18:08:35.299379525Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:08:35.299416550Z   import pynvml  # type: ignore[import]
2025-11-26T18:08:39.364092480Z [37m20251126-18:08:39.363 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T18:08:39.364139601Z [37m20251126-18:08:39.363 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T18:08:39.364636255Z [37m20251126-18:08:39.364 name-resolve INFO: No such name resolve path: ./tmp/areal/name_resolve/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_180834[0m
2025-11-26T18:08:39.481202655Z [37m20251126-18:08:39.480 Local Scheduler INFO: LocalLauncher: experiment_name=gsm8k-grpo-cloud-2gpu-2000samples, trial_name=trial_20251126_180834, fileroot=/workspace/outputs/grpo, run_id=0, is_recover_run=False[0m
2025-11-26T18:08:39.487991364Z [37m20251126-18:08:39.487 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL CUDA_VISIBLE_DEVICES=0 stdbuf -oL python3 -m areal.launcher.sglang_server examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_180834 sglang.random_seed=1 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_180834/llm_server.log[0m
2025-11-26T18:08:40.254329926Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:08:40.254369656Z   import pynvml  # type: ignore[import]
2025-11-26T18:08:41.759293059Z [37m20251126-18:08:41.758 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T18:08:41.759329814Z [37m20251126-18:08:41.758 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T18:08:41.874107596Z [37m20251126-18:08:41.873 SGLangServer Wrapper INFO: Launch command: python3 -m sglang.launch_server --host 172.21.0.2 --port 15212 --tokenizer-path Qwen/Qwen2.5-0.5B-Instruct --tokenizer-mode auto --load-format auto --trust-remote-code --device cuda --tp-size 1 --base-gpu-id 0 --nnodes 1 --node-rank 0 --dist-init-addr localhost:19935 --model-path Qwen/Qwen2.5-0.5B-Instruct --random-seed 1 --skip-tokenizer-init --disable-radix-cache --torch-compile-max-bs 32 --triton-attention-num-kv-splits 8 --num-continuous-decode-steps 1 --attention-backend flashinfer --context-length 4096 --mem-fraction-static 0.6 --chunked-prefill-size -1 --max-prefill-tokens 32768 --schedule-policy lpm --schedule-conservativeness 1.0 --cpu-offload-gb 0 --dtype bfloat16 --kv-cache-dtype auto --dp-size 1 --ep-size 1 --max-loaded-loras 1 --max-loras-per-batch 1 --lora-backend triton --log-level warning --log-level-http warning --log-requests-level 0 --enable-metrics --decode-log-interval 1[0m
2025-11-26T18:08:42.926962161Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:08:42.927005846Z   import pynvml  # type: ignore[import]
2025-11-26T18:08:48.239905527Z INFO 11-26 18:08:48 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T18:08:48.878521138Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T18:08:49.943300915Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:08:49.943330830Z   import pynvml  # type: ignore[import]
2025-11-26T18:08:49.980718953Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:08:49.980749878Z   import pynvml  # type: ignore[import]
2025-11-26T18:08:55.149197840Z INFO 11-26 18:08:55 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T18:08:55.739935125Z INFO 11-26 18:08:55 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T18:08:56.339086704Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T18:08:56.550231520Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T18:08:56.553894698Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T18:08:56.554771882Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T18:08:56.555632230Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T18:08:56.590194520Z [2025-11-26 18:08:56] MOE_RUNNER_BACKEND is not initialized, using triton backend
2025-11-26T18:08:57.101704233Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T18:08:57.101741920Z   warnings.warn(
2025-11-26T18:08:57.101745104Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T18:08:57.101747368Z   warnings.warn(
2025-11-26T18:08:58.394650673Z Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
2025-11-26T18:08:58.502517883Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  9.29it/s]
2025-11-26T18:08:58.504166453Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  9.26it/s]
2025-11-26T18:09:01.118051483Z   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   4%|â–         | 1/23 [00:00<00:12,  1.82it/s]Capturing batches (bs=152 avail_mem=30.62 GB):   4%|â–         | 1/23 [00:00<00:12,  1.82it/s]Capturing batches (bs=144 avail_mem=30.60 GB):   4%|â–         | 1/23 [00:00<00:12,  1.82it/s]Capturing batches (bs=136 avail_mem=30.59 GB):   4%|â–         | 1/23 [00:00<00:12,  1.82it/s]Capturing batches (bs=136 avail_mem=30.59 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.14it/s]Capturing batches (bs=128 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.14it/s]Capturing batches (bs=120 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.14it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.14it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.40it/s]Capturing batches (bs=104 avail_mem=30.54 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.40it/s]Capturing batches (bs=96 avail_mem=30.53 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.40it/s] Capturing batches (bs=88 avail_mem=30.51 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.40it/s]Capturing batches (bs=88 avail_mem=30.51 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.81it/s]Capturing batches (bs=80 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.81it/s]Capturing batches (bs=72 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.81it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:01<00:00, 14.81it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.39it/s]Capturing batches (bs=56 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.39it/s]Capturing batches (bs=48 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.39it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.39it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.41it/s]Capturing batches (bs=32 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.41it/s]Capturing batches (bs=24 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.41it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.41it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.61it/s]Capturing batches (bs=8 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.61it/s] Capturing batches (bs=4 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.61it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.61it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.42it/s]Capturing batches (bs=1 avail_mem=30.35 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.42it/s]Capturing batches (bs=1 avail_mem=30.35 GB): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00, 14.82it/s]
2025-11-26T18:09:06.905171331Z [37m20251126-18:09:06.904 SGLangServer Wrapper INFO: SGLang server launched at: http://172.21.0.2:15212[0m
2025-11-26T18:09:07.494896631Z [37m20251126-18:09:07.494 Launcher Utils INFO: Found 1 rollout servers: 172.21.0.2:15212[0m
2025-11-26T18:09:07.494933847Z [37m20251126-18:09:07.494 Local Scheduler INFO: LLM inference server launched at: AREAL_LLM_SERVER_ADDRS=172.21.0.2:15212[0m
2025-11-26T18:09:07.497349706Z [37m20251126-18:09:07.497 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL AREAL_LLM_SERVER_ADDRS=172.21.0.2:15212 AREAL_RECOVER_RUN=0 NCCL_CUMEM_ENABLE=0 NCCL_NVLS_ENABLE=0 CUDA_VISIBLE_DEVICES=1 stdbuf -oL torchrun --nnodes 1 --nproc-per-node 1 --master-addr localhost --master-port 26551 examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_180834 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_180834/trainer.log[0m
2025-11-26T18:09:07.498059448Z [37m20251126-18:09:07.497 Local Scheduler INFO: Waiting for 2 local running processes, pids: 315 965[0m
2025-11-26T18:09:08.054202977Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:09:08.054238019Z   import pynvml  # type: ignore[import]
2025-11-26T18:09:09.253999130Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:09:09.254036586Z   import pynvml  # type: ignore[import]
2025-11-26T18:09:16.386803925Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T18:09:16.386837335Z   warnings.warn(
2025-11-26T18:09:16.386841000Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T18:09:16.386843444Z   warnings.warn(
2025-11-26T18:09:16.817452850Z Traceback (most recent call last):
2025-11-26T18:09:16.817496224Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 665, in <module>
2025-11-26T18:09:16.818140519Z     main(sys.argv[1:])
2025-11-26T18:09:16.818179638Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 102, in main
2025-11-26T18:09:16.818182743Z     config, _ = load_expr_config(args_with_overrides, GRPOConfig)
2025-11-26T18:09:16.818185457Z                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T18:09:16.818187640Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1282, in load_expr_config
2025-11-26T18:09:16.818189753Z     cfg = to_structured_cfg(cfg, config_cls=config_cls)
2025-11-26T18:09:16.818595582Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T18:09:16.818603002Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1276, in to_structured_cfg
2025-11-26T18:09:16.818606198Z     cfg = OmegaConf.merge(default_cfg, cfg)
2025-11-26T18:09:16.818608581Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T18:09:16.818610674Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/omegaconf.py", line 274, in merge
2025-11-26T18:09:16.818613228Z     target.merge_with(
2025-11-26T18:09:16.818616042Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 507, in merge_with
2025-11-26T18:09:16.818952926Z     self._format_and_raise(key=None, value=None, cause=e)
2025-11-26T18:09:16.818966406Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T18:09:16.818969210Z     format_and_raise(
2025-11-26T18:09:16.818971644Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T18:09:16.818973908Z     _raise(ex, cause)
2025-11-26T18:09:16.818976060Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T18:09:16.819424042Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T18:09:16.819433036Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T18:09:16.819435269Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 502, in merge_with
2025-11-26T18:09:16.819437572Z     self._merge_with(
2025-11-26T18:09:16.819439756Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T18:09:16.819441949Z     BaseContainer._map_merge(
2025-11-26T18:09:16.819445144Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T18:09:16.819447117Z     dest_node._merge_with(
2025-11-26T18:09:16.819449120Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T18:09:16.820163499Z     BaseContainer._map_merge(
2025-11-26T18:09:16.820171431Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T18:09:16.820173865Z     dest_node._merge_with(
2025-11-26T18:09:16.820175908Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T18:09:16.820178241Z     BaseContainer._map_merge(
2025-11-26T18:09:16.820180315Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 432, in _map_merge
2025-11-26T18:09:16.820183039Z     dest[key] = src._get_node(key)
2025-11-26T18:09:16.820185713Z     ~~~~^^^^^
2025-11-26T18:09:16.820188156Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 308, in __setitem__
2025-11-26T18:09:16.820190210Z     self._format_and_raise(
2025-11-26T18:09:16.820192233Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T18:09:16.820194185Z     format_and_raise(
2025-11-26T18:09:16.820196419Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T18:09:16.820198452Z     _raise(ex, cause)
2025-11-26T18:09:16.820200555Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T18:09:16.820202728Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T18:09:16.820747774Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T18:09:16.820751921Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 306, in __setitem__
2025-11-26T18:09:16.820754424Z     self.__set_impl(key=key, value=value)
2025-11-26T18:09:16.820756487Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 316, in __set_impl
2025-11-26T18:09:16.820758621Z     self._set_item_impl(key, value)
2025-11-26T18:09:16.820760724Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 579, in _set_item_impl
2025-11-26T18:09:16.820762827Z     target_node_ref = self._get_node(key)
2025-11-26T18:09:16.820765120Z                       ^^^^^^^^^^^^^^^^^^^
2025-11-26T18:09:16.820767224Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 473, in _get_node
2025-11-26T18:09:16.821127874Z     self._validate_get(key)
2025-11-26T18:09:16.821133392Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 163, in _validate_get
2025-11-26T18:09:16.821135746Z     self._format_and_raise(
2025-11-26T18:09:16.821137799Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T18:09:16.821139962Z     format_and_raise(
2025-11-26T18:09:16.821141996Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 906, in format_and_raise
2025-11-26T18:09:16.821149006Z     _raise(ex, cause)
2025-11-26T18:09:16.821151169Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T18:09:16.821427123Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T18:09:16.821431709Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T18:09:16.821433813Z omegaconf.errors.ConfigKeyError: Key 'max_new_tokens' not in 'NormConfig'
2025-11-26T18:09:16.821435976Z     full_key: actor.adv_norm.max_new_tokens
2025-11-26T18:09:16.821438009Z     reference_type=Optional[NormConfig]
2025-11-26T18:09:16.821440092Z     object_type=NormConfig
2025-11-26T18:09:19.464012782Z E1126 18:09:19.463000 966 torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 0 (pid: 1032) of binary: /usr/bin/python3
2025-11-26T18:09:19.464780721Z Traceback (most recent call last):
2025-11-26T18:09:19.464798438Z   File "/usr/local/bin/torchrun", line 7, in <module>
2025-11-26T18:09:19.464800972Z     sys.exit(main())
2025-11-26T18:09:19.464803556Z              ^^^^^^
2025-11-26T18:09:19.464805629Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
2025-11-26T18:09:19.464808333Z     return f(*args, **kwargs)
2025-11-26T18:09:19.464810857Z            ^^^^^^^^^^^^^^^^^^
2025-11-26T18:09:19.464812970Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 901, in main
2025-11-26T18:09:19.465330135Z     run(args)
2025-11-26T18:09:19.465335182Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 892, in run
2025-11-26T18:09:19.465337866Z     elastic_launch(
2025-11-26T18:09:19.465340750Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 143, in __call__
2025-11-26T18:09:19.465343414Z     return launch_agent(self._config, self._entrypoint, list(args))
2025-11-26T18:09:19.465346008Z            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T18:09:19.465348122Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 277, in launch_agent
2025-11-26T18:09:19.465350174Z     raise ChildFailedError(
2025-11-26T18:09:19.465353109Z torch.distributed.elastic.multiprocessing.errors.ChildFailedError:
2025-11-26T18:09:19.465355092Z ============================================================
2025-11-26T18:09:19.465357476Z examples/cloud_gsm8k/gsm8k_grpo_train.py FAILED
2025-11-26T18:09:19.465359929Z ------------------------------------------------------------
2025-11-26T18:09:19.465361942Z Failures:
2025-11-26T18:09:19.465363945Z   <NO_OTHER_FAILURES>
2025-11-26T18:09:19.465365998Z ------------------------------------------------------------
2025-11-26T18:09:19.465368011Z Root Cause (first observed failure):
2025-11-26T18:09:19.465370014Z [0]:
2025-11-26T18:09:19.465372047Z   time      : 2025-11-26_18:09:19
2025-11-26T18:09:19.465374101Z   host      : cef7c503fdea
2025-11-26T18:09:19.465376093Z   rank      : 0 (local_rank: 0)
2025-11-26T18:09:19.465378096Z   exitcode  : 1 (pid: 1032)
2025-11-26T18:09:19.465380130Z   error_file: <N/A>
2025-11-26T18:09:19.465382222Z   traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
2025-11-26T18:09:19.465384326Z ============================================================
2025-11-26T18:09:21.501684470Z [37m20251126-18:09:21.501 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [315][0m
2025-11-26T18:09:21.669051133Z Killed
2025-11-26T18:09:21.691301721Z [37m20251126-18:09:21.690 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [965][0m
2025-11-26T18:09:21.692274348Z Traceback (most recent call last):
2025-11-26T18:09:21.692284042Z   File "<frozen runpy>", line 198, in _run_module_as_main
2025-11-26T18:09:21.692286436Z   File "<frozen runpy>", line 88, in _run_code
2025-11-26T18:09:21.692288509Z   File "/workspace/AReaL/areal/launcher/local.py", line 405, in <module>
2025-11-26T18:09:21.692425525Z     main()
2025-11-26T18:09:21.692428329Z   File "/workspace/AReaL/areal/launcher/local.py", line 260, in main
2025-11-26T18:09:21.692503101Z     local_main(config, run_id=0)
2025-11-26T18:09:21.692514267Z   File "/workspace/AReaL/areal/launcher/local.py", line 399, in local_main
2025-11-26T18:09:21.692613055Z     raise e
2025-11-26T18:09:21.692616351Z   File "/workspace/AReaL/areal/launcher/local.py", line 375, in local_main
2025-11-26T18:09:21.692675079Z     launcher.wait(
2025-11-26T18:09:21.692678244Z   File "/workspace/AReaL/areal/launcher/local.py", line 235, in wait
2025-11-26T18:09:21.692744372Z     raise JobException(
2025-11-26T18:09:21.692747076Z areal.utils.launcher.JobException: Job gsm8k-grpo-cloud-2gpu-2000samples_trial_20251126_180834:trainer JobState.COMPLETED at node local
2025-11-26T18:09:21.926268751Z [37m20251126-18:09:21.925 Local Scheduler INFO: Waiting for 0 local running processes, pids: [0m
2025-11-26T18:09:37.964773970Z ==========
2025-11-26T18:09:37.964806269Z == CUDA ==
2025-11-26T18:09:37.964828221Z ==========
2025-11-26T18:09:37.969691696Z CUDA Version 12.9.1
2025-11-26T18:09:37.971321086Z Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
2025-11-26T18:09:37.972883146Z This container image and its contents are governed by the NVIDIA Deep Learning Container License.
2025-11-26T18:09:37.972885980Z By pulling and using the container, you accept the terms and conditions of this license:
2025-11-26T18:09:37.972888624Z https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license
2025-11-26T18:09:37.972893101Z A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
2025-11-26T18:09:38.137570015Z Writing to /root/.config/pip/pip.conf
2025-11-26T18:09:38.294853455Z Writing to /root/.config/pip/pip.conf
2025-11-26T18:09:38.501867514Z Branch 'feature/reasoning_model' set up to track remote branch 'feature/reasoning_model' from 'origin'.
2025-11-26T18:09:38.501915396Z Your branch is up to date with 'origin/feature/reasoning_model'.
2025-11-26T18:09:38.574329622Z Checking AReaL installation...
2025-11-26T18:09:38.633450898Z AReaL already installed. Skipping installation.
2025-11-26T18:09:38.633482004Z Cleaning up any leftover GPU processes...
2025-11-26T18:09:41.654362999Z Checking for processes holding GPU device files...
2025-11-26T18:09:43.677759906Z Found processes holding GPU devices: 1
2025-11-26T18:09:43.677799546Z 20
2025-11-26T18:09:43.677802310Z 71
2025-11-26T18:09:43.677805044Z 72
2025-11-26T18:09:43.677807077Z Killing process 1...
2025-11-26T18:09:43.677809621Z Killing process 71...
2025-11-26T18:09:43.677819706Z Killing process 72...
2025-11-26T18:09:45.680677358Z Using fuser to kill processes on GPU devices...
2025-11-26T18:09:47.709600422Z Checking GPU...
2025-11-26T18:09:47.742934022Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T18:09:47.742958389Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T18:09:47.761516806Z Set PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True for better memory management
2025-11-26T18:09:47.761533100Z Detected 2 GPU(s)
2025-11-26T18:09:47.761536405Z Checking GPU status...
2025-11-26T18:09:47.789007473Z index, name, utilization.gpu [%], memory.used [MiB], compute_mode
2025-11-26T18:09:47.790499318Z 0, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T18:09:47.790809012Z 1, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T18:09:47.834976889Z Verifying GPU accessibility...
2025-11-26T18:09:48.390680039Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:09:48.390725426Z   import pynvml  # type: ignore[import]
2025-11-26T18:09:49.538451376Z GPU accessibility verified on attempt 1
2025-11-26T18:09:50.059686036Z Starting training...
2025-11-26T18:09:53.062340379Z Using STANDARD 2000 SAMPLES 2 GPUs configuration
2025-11-26T18:09:53.062384986Z Note: GRPO only (no reasoning XML). Dataset capped at 2000 samples (~6 hours).
2025-11-26T18:09:53.062388782Z GPU count: 2 (required: 2)
2025-11-26T18:09:53.065218019Z ==========================================
2025-11-26T18:09:53.065220984Z Starting GRPO Training (Cloud)
2025-11-26T18:09:53.065223618Z ==========================================
2025-11-26T18:09:53.065225591Z Config: standard_2000samples_2GPUs
2025-11-26T18:09:53.065227734Z Config file: examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml
2025-11-26T18:09:53.065230488Z Training script: examples/cloud_gsm8k/gsm8k_grpo_train.py
2025-11-26T18:09:53.065232891Z Experiment: gsm8k-grpo-cloud-2gpu-2000samples
2025-11-26T18:09:53.065234905Z Trial: trial_20251126_180953
2025-11-26T18:09:53.065237008Z GPU: NVIDIA A100 80GB PCIe NVIDIA A100 80GB PCIe (81920 MB)
2025-11-26T18:09:53.065239281Z WandB API key: e1adc5be02...
2025-11-26T18:09:53.065241284Z ==========================================
2025-11-26T18:09:53.760883182Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:09:53.760931575Z   import pynvml  # type: ignore[import]
2025-11-26T18:09:57.806078222Z [37m20251126-18:09:57.805 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T18:09:57.806169518Z [37m20251126-18:09:57.805 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T18:09:57.806454965Z [37m20251126-18:09:57.806 name-resolve INFO: No such name resolve path: ./tmp/areal/name_resolve/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_180953[0m
2025-11-26T18:09:57.912953146Z [37m20251126-18:09:57.912 Local Scheduler INFO: LocalLauncher: experiment_name=gsm8k-grpo-cloud-2gpu-2000samples, trial_name=trial_20251126_180953, fileroot=/workspace/outputs/grpo, run_id=0, is_recover_run=False[0m
2025-11-26T18:09:57.920430316Z [37m20251126-18:09:57.920 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL CUDA_VISIBLE_DEVICES=0 stdbuf -oL python3 -m areal.launcher.sglang_server examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_180953 sglang.random_seed=1 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_180953/llm_server.log[0m
2025-11-26T18:09:58.618651457Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:09:58.618698257Z   import pynvml  # type: ignore[import]
2025-11-26T18:10:00.074859451Z [37m20251126-18:10:00.074 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T18:10:00.075504898Z [37m20251126-18:10:00.074 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T18:10:00.176364583Z [37m20251126-18:10:00.175 SGLangServer Wrapper INFO: Launch command: python3 -m sglang.launch_server --host 172.21.0.2 --port 10890 --tokenizer-path Qwen/Qwen2.5-0.5B-Instruct --tokenizer-mode auto --load-format auto --trust-remote-code --device cuda --tp-size 1 --base-gpu-id 0 --nnodes 1 --node-rank 0 --dist-init-addr localhost:25049 --model-path Qwen/Qwen2.5-0.5B-Instruct --random-seed 1 --skip-tokenizer-init --disable-radix-cache --torch-compile-max-bs 32 --triton-attention-num-kv-splits 8 --num-continuous-decode-steps 1 --attention-backend flashinfer --context-length 4096 --mem-fraction-static 0.6 --chunked-prefill-size -1 --max-prefill-tokens 32768 --schedule-policy lpm --schedule-conservativeness 1.0 --cpu-offload-gb 0 --dtype bfloat16 --kv-cache-dtype auto --dp-size 1 --ep-size 1 --max-loaded-loras 1 --max-loras-per-batch 1 --lora-backend triton --log-level warning --log-level-http warning --log-requests-level 0 --enable-metrics --decode-log-interval 1[0m
2025-11-26T18:10:01.592187796Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:10:01.592225533Z   import pynvml  # type: ignore[import]
2025-11-26T18:10:07.574634649Z INFO 11-26 18:10:07 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T18:10:08.263985154Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T18:10:09.309419805Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:10:09.309466744Z   import pynvml  # type: ignore[import]
2025-11-26T18:10:09.314216359Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:10:09.314248367Z   import pynvml  # type: ignore[import]
2025-11-26T18:10:15.931879090Z INFO 11-26 18:10:15 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T18:10:16.441519904Z INFO 11-26 18:10:16 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T18:10:17.069896777Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T18:10:17.293267848Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T18:10:17.296982191Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T18:10:17.297756862Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T18:10:17.298706964Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T18:10:17.332548815Z [2025-11-26 18:10:17] MOE_RUNNER_BACKEND is not initialized, using triton backend
2025-11-26T18:10:17.855636791Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T18:10:17.855678744Z   warnings.warn(
2025-11-26T18:10:17.855681708Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T18:10:17.855683951Z   warnings.warn(
2025-11-26T18:10:19.014782976Z Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
2025-11-26T18:10:19.132221534Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  8.53it/s]
2025-11-26T18:10:19.132747131Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  8.51it/s]
2025-11-26T18:10:21.658304377Z   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   4%|â–         | 1/23 [00:00<00:12,  1.76it/s]Capturing batches (bs=152 avail_mem=30.62 GB):   4%|â–         | 1/23 [00:00<00:12,  1.76it/s]Capturing batches (bs=144 avail_mem=30.60 GB):   4%|â–         | 1/23 [00:00<00:12,  1.76it/s]Capturing batches (bs=136 avail_mem=30.59 GB):   4%|â–         | 1/23 [00:00<00:12,  1.76it/s]Capturing batches (bs=136 avail_mem=30.59 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  6.96it/s]Capturing batches (bs=128 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  6.96it/s]Capturing batches (bs=120 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  6.96it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  6.96it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.12it/s]Capturing batches (bs=104 avail_mem=30.54 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.12it/s]Capturing batches (bs=96 avail_mem=30.53 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.12it/s] Capturing batches (bs=88 avail_mem=30.51 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.12it/s]Capturing batches (bs=88 avail_mem=30.51 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.36it/s]Capturing batches (bs=80 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.36it/s]Capturing batches (bs=72 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:01<00:00, 14.36it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:01<00:00, 14.36it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 16.91it/s]Capturing batches (bs=56 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 16.91it/s]Capturing batches (bs=48 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 16.91it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 16.91it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.01it/s]Capturing batches (bs=32 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.01it/s]Capturing batches (bs=24 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.01it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.01it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.44it/s]Capturing batches (bs=8 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.44it/s] Capturing batches (bs=4 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.44it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.44it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.21it/s]Capturing batches (bs=1 avail_mem=30.35 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.21it/s]Capturing batches (bs=1 avail_mem=30.35 GB): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00, 14.54it/s]
2025-11-26T18:10:27.206325839Z [37m20251126-18:10:27.205 SGLangServer Wrapper INFO: SGLang server launched at: http://172.21.0.2:10890[0m
2025-11-26T18:10:27.928359678Z [37m20251126-18:10:27.927 Launcher Utils INFO: Found 1 rollout servers: 172.21.0.2:10890[0m
2025-11-26T18:10:27.928399027Z [37m20251126-18:10:27.928 Local Scheduler INFO: LLM inference server launched at: AREAL_LLM_SERVER_ADDRS=172.21.0.2:10890[0m
2025-11-26T18:10:27.931264200Z [37m20251126-18:10:27.931 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL AREAL_LLM_SERVER_ADDRS=172.21.0.2:10890 AREAL_RECOVER_RUN=0 NCCL_CUMEM_ENABLE=0 NCCL_NVLS_ENABLE=0 CUDA_VISIBLE_DEVICES=1 stdbuf -oL torchrun --nnodes 1 --nproc-per-node 1 --master-addr localhost --master-port 16454 examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_180953 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_180953/trainer.log[0m
2025-11-26T18:10:27.931896366Z [37m20251126-18:10:27.931 Local Scheduler INFO: Waiting for 2 local running processes, pids: 315 965[0m
2025-11-26T18:10:28.465592701Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:10:28.465629797Z   import pynvml  # type: ignore[import]
2025-11-26T18:10:29.658522540Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:10:29.658564994Z   import pynvml  # type: ignore[import]
2025-11-26T18:10:36.265322501Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T18:10:36.265357943Z   warnings.warn(
2025-11-26T18:10:36.265361108Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T18:10:36.265363422Z   warnings.warn(
2025-11-26T18:10:36.685552058Z Traceback (most recent call last):
2025-11-26T18:10:36.685591417Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 665, in <module>
2025-11-26T18:10:36.686042172Z     main(sys.argv[1:])
2025-11-26T18:10:36.686045888Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 102, in main
2025-11-26T18:10:36.686048792Z     config, _ = load_expr_config(args_with_overrides, GRPOConfig)
2025-11-26T18:10:36.686051436Z                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T18:10:36.686053539Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1282, in load_expr_config
2025-11-26T18:10:36.686511686Z     cfg = to_structured_cfg(cfg, config_cls=config_cls)
2025-11-26T18:10:36.686516042Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T18:10:36.686518236Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1276, in to_structured_cfg
2025-11-26T18:10:36.686520928Z     cfg = OmegaConf.merge(default_cfg, cfg)
2025-11-26T18:10:36.686982491Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T18:10:36.686985936Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/omegaconf.py", line 274, in merge
2025-11-26T18:10:36.686988229Z     target.merge_with(
2025-11-26T18:10:36.686990452Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 507, in merge_with
2025-11-26T18:10:36.686993307Z     self._format_and_raise(key=None, value=None, cause=e)
2025-11-26T18:10:36.686995971Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T18:10:36.686997984Z     format_and_raise(
2025-11-26T18:10:36.687008910Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T18:10:36.687011183Z     _raise(ex, cause)
2025-11-26T18:10:36.687013327Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T18:10:36.687485754Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T18:10:36.687518834Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T18:10:36.687521988Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 502, in merge_with
2025-11-26T18:10:36.687524943Z     self._merge_with(
2025-11-26T18:10:36.687527977Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T18:10:36.687530151Z     BaseContainer._map_merge(
2025-11-26T18:10:36.687533055Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T18:10:36.687535138Z     dest_node._merge_with(
2025-11-26T18:10:36.687884411Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T18:10:36.687888348Z     BaseContainer._map_merge(
2025-11-26T18:10:36.687891372Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T18:10:36.687893565Z     dest_node._merge_with(
2025-11-26T18:10:36.687895708Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T18:10:36.687897822Z     BaseContainer._map_merge(
2025-11-26T18:10:36.687899965Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 432, in _map_merge
2025-11-26T18:10:36.687902178Z     dest[key] = src._get_node(key)
2025-11-26T18:10:36.687904682Z     ~~~~^^^^^
2025-11-26T18:10:36.687907056Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 308, in __setitem__
2025-11-26T18:10:36.688532252Z     self._format_and_raise(
2025-11-26T18:10:36.688538301Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T18:10:36.688540925Z     format_and_raise(
2025-11-26T18:10:36.688543118Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T18:10:36.688545452Z     _raise(ex, cause)
2025-11-26T18:10:36.688547505Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T18:10:36.688549538Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T18:10:36.688551571Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T18:10:36.688553925Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 306, in __setitem__
2025-11-26T18:10:36.688556098Z     self.__set_impl(key=key, value=value)
2025-11-26T18:10:36.688558321Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 316, in __set_impl
2025-11-26T18:10:36.688560455Z     self._set_item_impl(key, value)
2025-11-26T18:10:36.688882987Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 579, in _set_item_impl
2025-11-26T18:10:36.688887533Z     target_node_ref = self._get_node(key)
2025-11-26T18:10:36.688889757Z                       ^^^^^^^^^^^^^^^^^^^
2025-11-26T18:10:36.688891910Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 473, in _get_node
2025-11-26T18:10:36.688894223Z     self._validate_get(key)
2025-11-26T18:10:36.688896597Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 163, in _validate_get
2025-11-26T18:10:36.689226552Z     self._format_and_raise(
2025-11-26T18:10:36.689232450Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T18:10:36.689234734Z     format_and_raise(
2025-11-26T18:10:36.689236827Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 906, in format_and_raise
2025-11-26T18:10:36.689238910Z     _raise(ex, cause)
2025-11-26T18:10:36.689240913Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T18:10:36.689251589Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T18:10:36.689524127Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T18:10:36.689528574Z omegaconf.errors.ConfigKeyError: Key 'max_new_tokens' not in 'NormConfig'
2025-11-26T18:10:36.689530848Z     full_key: actor.adv_norm.max_new_tokens
2025-11-26T18:10:36.689532831Z     reference_type=Optional[NormConfig]
2025-11-26T18:10:36.689534914Z     object_type=NormConfig
2025-11-26T18:10:39.154777446Z E1126 18:10:39.153000 966 torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 0 (pid: 1032) of binary: /usr/bin/python3
2025-11-26T18:10:39.155459178Z Traceback (most recent call last):
2025-11-26T18:10:39.155464976Z   File "/usr/local/bin/torchrun", line 7, in <module>
2025-11-26T18:10:39.155468011Z     sys.exit(main())
2025-11-26T18:10:39.155470795Z              ^^^^^^
2025-11-26T18:10:39.155472879Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
2025-11-26T18:10:39.155475583Z     return f(*args, **kwargs)
2025-11-26T18:10:39.155478106Z            ^^^^^^^^^^^^^^^^^^
2025-11-26T18:10:39.155480089Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 901, in main
2025-11-26T18:10:39.155837784Z     run(args)
2025-11-26T18:10:39.155840528Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 892, in run
2025-11-26T18:10:39.155843293Z     elastic_launch(
2025-11-26T18:10:39.155846057Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 143, in __call__
2025-11-26T18:10:39.155848851Z     return launch_agent(self._config, self._entrypoint, list(args))
2025-11-26T18:10:39.155851635Z            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T18:10:39.155853668Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 277, in launch_agent
2025-11-26T18:10:39.155855721Z     raise ChildFailedError(
2025-11-26T18:10:39.155858095Z torch.distributed.elastic.multiprocessing.errors.ChildFailedError:
2025-11-26T18:10:39.155860088Z ============================================================
2025-11-26T18:10:39.155862582Z examples/cloud_gsm8k/gsm8k_grpo_train.py FAILED
2025-11-26T18:10:39.155865095Z ------------------------------------------------------------
2025-11-26T18:10:39.155867098Z Failures:
2025-11-26T18:10:39.155869212Z   <NO_OTHER_FAILURES>
2025-11-26T18:10:39.155871575Z ------------------------------------------------------------
2025-11-26T18:10:39.155873568Z Root Cause (first observed failure):
2025-11-26T18:10:39.155875561Z [0]:
2025-11-26T18:10:39.155877764Z   time      : 2025-11-26_18:10:39
2025-11-26T18:10:39.155879797Z   host      : cef7c503fdea
2025-11-26T18:10:39.155881830Z   rank      : 0 (local_rank: 0)
2025-11-26T18:10:39.155883834Z   exitcode  : 1 (pid: 1032)
2025-11-26T18:10:39.155885857Z   error_file: <N/A>
2025-11-26T18:10:39.155887880Z   traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
2025-11-26T18:10:39.155889972Z ============================================================
2025-11-26T18:10:39.935325092Z [37m20251126-18:10:39.934 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [315][0m
2025-11-26T18:10:40.101031227Z Killed
2025-11-26T18:10:40.110682063Z [37m20251126-18:10:40.110 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [965][0m
2025-11-26T18:10:40.111717644Z Traceback (most recent call last):
2025-11-26T18:10:40.111724334Z   File "<frozen runpy>", line 198, in _run_module_as_main
2025-11-26T18:10:40.111727068Z   File "<frozen runpy>", line 88, in _run_code
2025-11-26T18:10:40.111729262Z   File "/workspace/AReaL/areal/launcher/local.py", line 405, in <module>
2025-11-26T18:10:40.111880218Z     main()
2025-11-26T18:10:40.111884184Z   File "/workspace/AReaL/areal/launcher/local.py", line 260, in main
2025-11-26T18:10:40.111976582Z     local_main(config, run_id=0)
2025-11-26T18:10:40.111980407Z   File "/workspace/AReaL/areal/launcher/local.py", line 399, in local_main
2025-11-26T18:10:40.112062831Z     raise e
2025-11-26T18:10:40.112066667Z   File "/workspace/AReaL/areal/launcher/local.py", line 375, in local_main
2025-11-26T18:10:40.112136922Z     launcher.wait(
2025-11-26T18:10:40.112142831Z   File "/workspace/AReaL/areal/launcher/local.py", line 235, in wait
2025-11-26T18:10:40.112211094Z     raise JobException(
2025-11-26T18:10:40.112213958Z areal.utils.launcher.JobException: Job gsm8k-grpo-cloud-2gpu-2000samples_trial_20251126_180953:trainer JobState.COMPLETED at node local
2025-11-26T18:10:40.310196840Z [37m20251126-18:10:40.309 Local Scheduler INFO: Waiting for 0 local running processes, pids: [0m
2025-11-26T18:10:56.290656134Z ==========
2025-11-26T18:10:56.290661402Z == CUDA ==
2025-11-26T18:10:56.290667221Z ==========
2025-11-26T18:10:56.294570737Z CUDA Version 12.9.1
2025-11-26T18:10:56.296041780Z Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
2025-11-26T18:10:56.297548588Z This container image and its contents are governed by the NVIDIA Deep Learning Container License.
2025-11-26T18:10:56.297551382Z By pulling and using the container, you accept the terms and conditions of this license:
2025-11-26T18:10:56.297562609Z https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license
2025-11-26T18:10:56.297567606Z A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
2025-11-26T18:10:56.462997658Z Writing to /root/.config/pip/pip.conf
2025-11-26T18:10:56.622038741Z Writing to /root/.config/pip/pip.conf
2025-11-26T18:10:56.822758792Z Branch 'feature/reasoning_model' set up to track remote branch 'feature/reasoning_model' from 'origin'.
2025-11-26T18:10:56.822796669Z Your branch is up to date with 'origin/feature/reasoning_model'.
2025-11-26T18:10:56.894242135Z Checking AReaL installation...
2025-11-26T18:10:56.952303393Z AReaL already installed. Skipping installation.
2025-11-26T18:10:56.952331665Z Cleaning up any leftover GPU processes...
2025-11-26T18:10:59.971544972Z Checking for processes holding GPU device files...
2025-11-26T18:11:02.001886541Z Found processes holding GPU devices: 1
2025-11-26T18:11:02.001927813Z 20
2025-11-26T18:11:02.001930336Z 71
2025-11-26T18:11:02.001933251Z 72
2025-11-26T18:11:02.001935664Z Killing process 1...
2025-11-26T18:11:02.001938789Z Killing process 71...
2025-11-26T18:11:02.001990217Z Killing process 72...
2025-11-26T18:11:04.004613457Z Using fuser to kill processes on GPU devices...
2025-11-26T18:11:06.026654284Z Checking GPU...
2025-11-26T18:11:06.062563029Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T18:11:06.062589419Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T18:11:06.080379296Z Set PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True for better memory management
2025-11-26T18:11:06.080398274Z Detected 2 GPU(s)
2025-11-26T18:11:06.080401479Z Checking GPU status...
2025-11-26T18:11:06.108947527Z index, name, utilization.gpu [%], memory.used [MiB], compute_mode
2025-11-26T18:11:06.110361165Z 0, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T18:11:06.110694093Z 1, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T18:11:06.165577892Z Verifying GPU accessibility...
2025-11-26T18:11:06.731364425Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:11:06.731423984Z   import pynvml  # type: ignore[import]
2025-11-26T18:11:07.872455206Z GPU accessibility verified on attempt 1
2025-11-26T18:11:08.414320156Z Starting training...
2025-11-26T18:11:11.416881922Z Using STANDARD 2000 SAMPLES 2 GPUs configuration
2025-11-26T18:11:11.416924194Z Note: GRPO only (no reasoning XML). Dataset capped at 2000 samples (~6 hours).
2025-11-26T18:11:11.416927349Z GPU count: 2 (required: 2)
2025-11-26T18:11:11.419695956Z ==========================================
2025-11-26T18:11:11.419699051Z Starting GRPO Training (Cloud)
2025-11-26T18:11:11.419701224Z ==========================================
2025-11-26T18:11:11.419711910Z Config: standard_2000samples_2GPUs
2025-11-26T18:11:11.419714063Z Config file: examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml
2025-11-26T18:11:11.419716207Z Training script: examples/cloud_gsm8k/gsm8k_grpo_train.py
2025-11-26T18:11:11.419718660Z Experiment: gsm8k-grpo-cloud-2gpu-2000samples
2025-11-26T18:11:11.419720774Z Trial: trial_20251126_181111
2025-11-26T18:11:11.419722817Z GPU: NVIDIA A100 80GB PCIe NVIDIA A100 80GB PCIe (81920 MB)
2025-11-26T18:11:11.419724809Z WandB API key: e1adc5be02...
2025-11-26T18:11:11.419726832Z ==========================================
2025-11-26T18:11:12.136952560Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:11:12.136999180Z   import pynvml  # type: ignore[import]
2025-11-26T18:11:16.232198189Z [37m20251126-18:11:16.231 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T18:11:16.232249917Z [37m20251126-18:11:16.231 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T18:11:16.232566901Z [37m20251126-18:11:16.232 name-resolve INFO: No such name resolve path: ./tmp/areal/name_resolve/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_181111[0m
2025-11-26T18:11:16.338407456Z [37m20251126-18:11:16.338 Local Scheduler INFO: LocalLauncher: experiment_name=gsm8k-grpo-cloud-2gpu-2000samples, trial_name=trial_20251126_181111, fileroot=/workspace/outputs/grpo, run_id=0, is_recover_run=False[0m
2025-11-26T18:11:16.346307209Z [37m20251126-18:11:16.345 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL CUDA_VISIBLE_DEVICES=0 stdbuf -oL python3 -m areal.launcher.sglang_server examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_181111 sglang.random_seed=1 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_181111/llm_server.log[0m
2025-11-26T18:11:17.067649442Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:11:17.067691666Z   import pynvml  # type: ignore[import]
2025-11-26T18:11:18.536869698Z [37m20251126-18:11:18.536 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T18:11:18.536917941Z [37m20251126-18:11:18.536 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T18:11:18.640811759Z [37m20251126-18:11:18.640 SGLangServer Wrapper INFO: Launch command: python3 -m sglang.launch_server --host 172.21.0.2 --port 13496 --tokenizer-path Qwen/Qwen2.5-0.5B-Instruct --tokenizer-mode auto --load-format auto --trust-remote-code --device cuda --tp-size 1 --base-gpu-id 0 --nnodes 1 --node-rank 0 --dist-init-addr localhost:24540 --model-path Qwen/Qwen2.5-0.5B-Instruct --random-seed 1 --skip-tokenizer-init --disable-radix-cache --torch-compile-max-bs 32 --triton-attention-num-kv-splits 8 --num-continuous-decode-steps 1 --attention-backend flashinfer --context-length 4096 --mem-fraction-static 0.6 --chunked-prefill-size -1 --max-prefill-tokens 32768 --schedule-policy lpm --schedule-conservativeness 1.0 --cpu-offload-gb 0 --dtype bfloat16 --kv-cache-dtype auto --dp-size 1 --ep-size 1 --max-loaded-loras 1 --max-loras-per-batch 1 --lora-backend triton --log-level warning --log-level-http warning --log-requests-level 0 --enable-metrics --decode-log-interval 1[0m
2025-11-26T18:11:19.680180274Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:11:19.680226303Z   import pynvml  # type: ignore[import]
2025-11-26T18:11:25.106691800Z INFO 11-26 18:11:25 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T18:11:25.753143358Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T18:11:26.790782191Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:11:26.790828030Z   import pynvml  # type: ignore[import]
2025-11-26T18:11:26.791359215Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:11:26.791364854Z   import pynvml  # type: ignore[import]
2025-11-26T18:11:32.043731405Z INFO 11-26 18:11:32 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T18:11:32.071103745Z INFO 11-26 18:11:32 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T18:11:32.616653295Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T18:11:32.840959476Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T18:11:32.844539668Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T18:11:32.845370583Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T18:11:32.846269599Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T18:11:32.878576681Z [2025-11-26 18:11:32] MOE_RUNNER_BACKEND is not initialized, using triton backend
2025-11-26T18:11:33.362054576Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T18:11:33.362082248Z   warnings.warn(
2025-11-26T18:11:33.362085613Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T18:11:33.362087886Z   warnings.warn(
2025-11-26T18:11:34.429985323Z Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
2025-11-26T18:11:34.533991120Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  9.63it/s]
2025-11-26T18:11:34.534512070Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  9.60it/s]
2025-11-26T18:11:36.963617625Z   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   4%|â–         | 1/23 [00:00<00:11,  1.85it/s]Capturing batches (bs=152 avail_mem=30.62 GB):   4%|â–         | 1/23 [00:00<00:11,  1.85it/s]Capturing batches (bs=144 avail_mem=30.60 GB):   4%|â–         | 1/23 [00:00<00:11,  1.85it/s]Capturing batches (bs=136 avail_mem=30.59 GB):   4%|â–         | 1/23 [00:00<00:11,  1.85it/s]Capturing batches (bs=136 avail_mem=30.59 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.26it/s]Capturing batches (bs=128 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.26it/s]Capturing batches (bs=120 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.26it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.26it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.55it/s]Capturing batches (bs=104 avail_mem=30.54 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.55it/s]Capturing batches (bs=96 avail_mem=30.53 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.55it/s] Capturing batches (bs=88 avail_mem=30.51 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.55it/s]Capturing batches (bs=88 avail_mem=30.51 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.96it/s]Capturing batches (bs=80 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.96it/s]Capturing batches (bs=72 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.96it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:01<00:00, 14.96it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.52it/s]Capturing batches (bs=56 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.52it/s]Capturing batches (bs=48 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.52it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.52it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.58it/s]Capturing batches (bs=32 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.58it/s]Capturing batches (bs=24 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.58it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.58it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.97it/s]Capturing batches (bs=8 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.97it/s] Capturing batches (bs=4 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.97it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.97it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.79it/s]Capturing batches (bs=1 avail_mem=30.35 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.79it/s]Capturing batches (bs=1 avail_mem=30.35 GB): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00, 15.05it/s]
2025-11-26T18:11:42.666477162Z [37m20251126-18:11:42.665 SGLangServer Wrapper INFO: SGLang server launched at: http://172.21.0.2:13496[0m
2025-11-26T18:11:43.353234763Z [37m20251126-18:11:43.352 Launcher Utils INFO: Found 1 rollout servers: 172.21.0.2:13496[0m
2025-11-26T18:11:43.353272610Z [37m20251126-18:11:43.352 Local Scheduler INFO: LLM inference server launched at: AREAL_LLM_SERVER_ADDRS=172.21.0.2:13496[0m
2025-11-26T18:11:43.356010922Z [37m20251126-18:11:43.355 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL AREAL_LLM_SERVER_ADDRS=172.21.0.2:13496 AREAL_RECOVER_RUN=0 NCCL_CUMEM_ENABLE=0 NCCL_NVLS_ENABLE=0 CUDA_VISIBLE_DEVICES=1 stdbuf -oL torchrun --nnodes 1 --nproc-per-node 1 --master-addr localhost --master-port 30640 examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_181111 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_181111/trainer.log[0m
2025-11-26T18:11:43.356602919Z [37m20251126-18:11:43.356 Local Scheduler INFO: Waiting for 2 local running processes, pids: 315 965[0m
2025-11-26T18:11:43.871889249Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:11:43.871937089Z   import pynvml  # type: ignore[import]
2025-11-26T18:11:45.062986953Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:11:45.063032231Z   import pynvml  # type: ignore[import]
2025-11-26T18:11:51.713290316Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T18:11:51.713330765Z   warnings.warn(
2025-11-26T18:11:51.713333800Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T18:11:51.713336103Z   warnings.warn(
2025-11-26T18:11:52.131179086Z Traceback (most recent call last):
2025-11-26T18:11:52.131218615Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 665, in <module>
2025-11-26T18:11:52.131813306Z     main(sys.argv[1:])
2025-11-26T18:11:52.131837483Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 102, in main
2025-11-26T18:11:52.131840627Z     config, _ = load_expr_config(args_with_overrides, GRPOConfig)
2025-11-26T18:11:52.131843251Z                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T18:11:52.131845825Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1282, in load_expr_config
2025-11-26T18:11:52.131847808Z     cfg = to_structured_cfg(cfg, config_cls=config_cls)
2025-11-26T18:11:52.132280447Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T18:11:52.132292064Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1276, in to_structured_cfg
2025-11-26T18:11:52.132295149Z     cfg = OmegaConf.merge(default_cfg, cfg)
2025-11-26T18:11:52.132297482Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T18:11:52.132299675Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/omegaconf.py", line 274, in merge
2025-11-26T18:11:52.132302580Z     target.merge_with(
2025-11-26T18:11:52.132305264Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 507, in merge_with
2025-11-26T18:11:52.132770049Z     self._format_and_raise(key=None, value=None, cause=e)
2025-11-26T18:11:52.132774476Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T18:11:52.132777300Z     format_and_raise(
2025-11-26T18:11:52.132779844Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T18:11:52.132782007Z     _raise(ex, cause)
2025-11-26T18:11:52.132794426Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T18:11:52.132796820Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T18:11:52.133146714Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T18:11:52.133153454Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 502, in merge_with
2025-11-26T18:11:52.133155767Z     self._merge_with(
2025-11-26T18:11:52.133158071Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T18:11:52.133160084Z     BaseContainer._map_merge(
2025-11-26T18:11:52.133162648Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T18:11:52.133164601Z     dest_node._merge_with(
2025-11-26T18:11:52.133166874Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T18:11:52.133169098Z     BaseContainer._map_merge(
2025-11-26T18:11:52.133171090Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T18:11:52.133543738Z     dest_node._merge_with(
2025-11-26T18:11:52.133548525Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T18:11:52.133550999Z     BaseContainer._map_merge(
2025-11-26T18:11:52.133553032Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 432, in _map_merge
2025-11-26T18:11:52.133559422Z     dest[key] = src._get_node(key)
2025-11-26T18:11:52.133563137Z     ~~~~^^^^^
2025-11-26T18:11:52.133565561Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 308, in __setitem__
2025-11-26T18:11:52.133567724Z     self._format_and_raise(
2025-11-26T18:11:52.133569797Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T18:11:52.134029596Z     format_and_raise(
2025-11-26T18:11:52.134033402Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T18:11:52.134035906Z     _raise(ex, cause)
2025-11-26T18:11:52.134038049Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T18:11:52.134040312Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T18:11:52.134042476Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T18:11:52.134044699Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 306, in __setitem__
2025-11-26T18:11:52.134046722Z     self.__set_impl(key=key, value=value)
2025-11-26T18:11:52.134048765Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 316, in __set_impl
2025-11-26T18:11:52.134455604Z     self._set_item_impl(key, value)
2025-11-26T18:11:52.134474041Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 579, in _set_item_impl
2025-11-26T18:11:52.134477277Z     target_node_ref = self._get_node(key)
2025-11-26T18:11:52.134479510Z                       ^^^^^^^^^^^^^^^^^^^
2025-11-26T18:11:52.134481583Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 473, in _get_node
2025-11-26T18:11:52.134484016Z     self._validate_get(key)
2025-11-26T18:11:52.134486120Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 163, in _validate_get
2025-11-26T18:11:52.135075613Z     self._format_and_raise(
2025-11-26T18:11:52.135079448Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T18:11:52.135081712Z     format_and_raise(
2025-11-26T18:11:52.135083745Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 906, in format_and_raise
2025-11-26T18:11:52.135085768Z     _raise(ex, cause)
2025-11-26T18:11:52.135087911Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T18:11:52.135090425Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T18:11:52.135100620Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T18:11:52.135102934Z omegaconf.errors.ConfigKeyError: Key 'max_new_tokens' not in 'NormConfig'
2025-11-26T18:11:52.135105318Z     full_key: actor.adv_norm.max_new_tokens
2025-11-26T18:11:52.135107651Z     reference_type=Optional[NormConfig]
2025-11-26T18:11:52.135109724Z     object_type=NormConfig
2025-11-26T18:11:54.471790779Z E1126 18:11:54.470000 966 torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 0 (pid: 1032) of binary: /usr/bin/python3
2025-11-26T18:11:54.472415014Z Traceback (most recent call last):
2025-11-26T18:11:54.472421253Z   File "/usr/local/bin/torchrun", line 7, in <module>
2025-11-26T18:11:54.472424268Z     sys.exit(main())
2025-11-26T18:11:54.472426942Z              ^^^^^^
2025-11-26T18:11:54.472429005Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
2025-11-26T18:11:54.472431699Z     return f(*args, **kwargs)
2025-11-26T18:11:54.472434333Z            ^^^^^^^^^^^^^^^^^^
2025-11-26T18:11:54.472436346Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 901, in main
2025-11-26T18:11:54.472910446Z     run(args)
2025-11-26T18:11:54.472913771Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 892, in run
2025-11-26T18:11:54.472926330Z     elastic_launch(
2025-11-26T18:11:54.472929194Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 143, in __call__
2025-11-26T18:11:54.472931648Z     return launch_agent(self._config, self._entrypoint, list(args))
2025-11-26T18:11:54.472935704Z            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T18:11:54.472938138Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 277, in launch_agent
2025-11-26T18:11:54.473465888Z     raise ChildFailedError(
2025-11-26T18:11:54.473506108Z torch.distributed.elastic.multiprocessing.errors.ChildFailedError:
2025-11-26T18:11:54.473510155Z ============================================================
2025-11-26T18:11:54.473512708Z examples/cloud_gsm8k/gsm8k_grpo_train.py FAILED
2025-11-26T18:11:54.473515372Z ------------------------------------------------------------
2025-11-26T18:11:54.473517495Z Failures:
2025-11-26T18:11:54.473520089Z   <NO_OTHER_FAILURES>
2025-11-26T18:11:54.473522834Z ------------------------------------------------------------
2025-11-26T18:11:54.473525087Z Root Cause (first observed failure):
2025-11-26T18:11:54.473527350Z [0]:
2025-11-26T18:11:54.473529383Z   time      : 2025-11-26_18:11:54
2025-11-26T18:11:54.473531416Z   host      : cef7c503fdea
2025-11-26T18:11:54.473533429Z   rank      : 0 (local_rank: 0)
2025-11-26T18:11:54.473535412Z   exitcode  : 1 (pid: 1032)
2025-11-26T18:11:54.473537375Z   error_file: <N/A>
2025-11-26T18:11:54.473539438Z   traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
2025-11-26T18:11:54.473541892Z ============================================================
2025-11-26T18:11:55.359935991Z [37m20251126-18:11:55.359 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [315][0m
2025-11-26T18:11:55.488402326Z Killed
2025-11-26T18:11:55.499430856Z [37m20251126-18:11:55.499 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [965][0m
2025-11-26T18:11:55.500560919Z Traceback (most recent call last):
2025-11-26T18:11:55.500573237Z   File "<frozen runpy>", line 198, in _run_module_as_main
2025-11-26T18:11:55.500576182Z   File "<frozen runpy>", line 88, in _run_code
2025-11-26T18:11:55.500578626Z   File "/workspace/AReaL/areal/launcher/local.py", line 405, in <module>
2025-11-26T18:11:55.500727047Z     main()
2025-11-26T18:11:55.500732545Z   File "/workspace/AReaL/areal/launcher/local.py", line 260, in main
2025-11-26T18:11:55.500822791Z     local_main(config, run_id=0)
2025-11-26T18:11:55.500826707Z   File "/workspace/AReaL/areal/launcher/local.py", line 399, in local_main
2025-11-26T18:11:55.500905485Z     raise e
2025-11-26T18:11:55.500908059Z   File "/workspace/AReaL/areal/launcher/local.py", line 375, in local_main
2025-11-26T18:11:55.500985464Z     launcher.wait(
2025-11-26T18:11:55.500999015Z   File "/workspace/AReaL/areal/launcher/local.py", line 235, in wait
2025-11-26T18:11:55.501048208Z     raise JobException(
2025-11-26T18:11:55.501054247Z areal.utils.launcher.JobException: Job gsm8k-grpo-cloud-2gpu-2000samples_trial_20251126_181111:trainer JobState.COMPLETED at node local
2025-11-26T18:11:55.715016514Z [37m20251126-18:11:55.714 Local Scheduler INFO: Waiting for 0 local running processes, pids: [0m
2025-11-26T18:11:59.051093650Z ==========
2025-11-26T18:11:59.051096254Z == CUDA ==
2025-11-26T18:11:59.051159800Z ==========
2025-11-26T18:11:59.055474202Z CUDA Version 12.9.1
2025-11-26T18:11:59.057199276Z Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
2025-11-26T18:11:59.059003058Z This container image and its contents are governed by the NVIDIA Deep Learning Container License.
2025-11-26T18:11:59.059007074Z By pulling and using the container, you accept the terms and conditions of this license:
2025-11-26T18:11:59.059009999Z https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license
2025-11-26T18:11:59.059014635Z A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
2025-11-26T18:11:59.225175542Z Writing to /root/.config/pip/pip.conf
2025-11-26T18:11:59.383893049Z Writing to /root/.config/pip/pip.conf
2025-11-26T18:11:59.587974156Z Branch 'feature/reasoning_model' set up to track remote branch 'feature/reasoning_model' from 'origin'.
2025-11-26T18:11:59.588021756Z Your branch is up to date with 'origin/feature/reasoning_model'.
2025-11-26T18:11:59.659752459Z Checking AReaL installation...
2025-11-26T18:11:59.718860806Z AReaL already installed. Skipping installation.
2025-11-26T18:11:59.718891653Z Cleaning up any leftover GPU processes...
2025-11-26T18:12:02.737899140Z Checking for processes holding GPU device files...
2025-11-26T18:12:04.874937438Z Found processes holding GPU devices: 1
2025-11-26T18:12:04.874976316Z 20
2025-11-26T18:12:04.874979210Z 71
2025-11-26T18:12:04.874981473Z 72
2025-11-26T18:12:04.874983527Z Killing process 1...
2025-11-26T18:12:04.874986220Z Killing process 71...
2025-11-26T18:12:04.875048494Z Killing process 72...
2025-11-26T18:12:06.877622632Z Using fuser to kill processes on GPU devices...
2025-11-26T18:12:08.899596967Z Checking GPU...
2025-11-26T18:12:08.944817161Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T18:12:08.944840917Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T18:12:08.961809764Z Set PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True for better memory management
2025-11-26T18:12:08.961826610Z Detected 2 GPU(s)
2025-11-26T18:12:08.961829864Z Checking GPU status...
2025-11-26T18:12:08.990035272Z index, name, utilization.gpu [%], memory.used [MiB], compute_mode
2025-11-26T18:12:08.991439114Z 0, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T18:12:08.991753035Z 1, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T18:12:09.038474588Z Verifying GPU accessibility...
2025-11-26T18:12:09.582531572Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:12:09.582565072Z   import pynvml  # type: ignore[import]
2025-11-26T18:12:10.702805783Z GPU accessibility verified on attempt 1
2025-11-26T18:12:11.265212723Z Starting training...
2025-11-26T18:12:14.267896220Z Using STANDARD 2000 SAMPLES 2 GPUs configuration
2025-11-26T18:12:14.267938273Z Note: GRPO only (no reasoning XML). Dataset capped at 2000 samples (~6 hours).
2025-11-26T18:12:14.267941458Z GPU count: 2 (required: 2)
2025-11-26T18:12:14.270185790Z ==========================================
2025-11-26T18:12:14.270189205Z Starting GRPO Training (Cloud)
2025-11-26T18:12:14.270191939Z ==========================================
2025-11-26T18:12:14.270193932Z Config: standard_2000samples_2GPUs
2025-11-26T18:12:14.270196256Z Config file: examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml
2025-11-26T18:12:14.270206941Z Training script: examples/cloud_gsm8k/gsm8k_grpo_train.py
2025-11-26T18:12:14.270209425Z Experiment: gsm8k-grpo-cloud-2gpu-2000samples
2025-11-26T18:12:14.270211448Z Trial: trial_20251126_181214
2025-11-26T18:12:14.270213502Z GPU: NVIDIA A100 80GB PCIe NVIDIA A100 80GB PCIe (81920 MB)
2025-11-26T18:12:14.270215474Z WandB API key: e1adc5be02...
2025-11-26T18:12:14.270217477Z ==========================================
2025-11-26T18:12:14.966155829Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:12:14.966193526Z   import pynvml  # type: ignore[import]
2025-11-26T18:12:19.037555060Z [37m20251126-18:12:19.037 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T18:12:19.037606205Z [37m20251126-18:12:19.037 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T18:12:19.037842951Z [37m20251126-18:12:19.037 name-resolve INFO: No such name resolve path: ./tmp/areal/name_resolve/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_181214[0m
2025-11-26T18:12:19.143923294Z [37m20251126-18:12:19.143 Local Scheduler INFO: LocalLauncher: experiment_name=gsm8k-grpo-cloud-2gpu-2000samples, trial_name=trial_20251126_181214, fileroot=/workspace/outputs/grpo, run_id=0, is_recover_run=False[0m
2025-11-26T18:12:19.151988665Z [37m20251126-18:12:19.151 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL CUDA_VISIBLE_DEVICES=0 stdbuf -oL python3 -m areal.launcher.sglang_server examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_181214 sglang.random_seed=1 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_181214/llm_server.log[0m
2025-11-26T18:12:19.893502654Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:12:19.893545698Z   import pynvml  # type: ignore[import]
2025-11-26T18:12:21.409027206Z [37m20251126-18:12:21.408 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T18:12:21.409784600Z [37m20251126-18:12:21.408 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T18:12:21.526088429Z [37m20251126-18:12:21.525 SGLangServer Wrapper INFO: Launch command: python3 -m sglang.launch_server --host 172.21.0.2 --port 19693 --tokenizer-path Qwen/Qwen2.5-0.5B-Instruct --tokenizer-mode auto --load-format auto --trust-remote-code --device cuda --tp-size 1 --base-gpu-id 0 --nnodes 1 --node-rank 0 --dist-init-addr localhost:20791 --model-path Qwen/Qwen2.5-0.5B-Instruct --random-seed 1 --skip-tokenizer-init --disable-radix-cache --torch-compile-max-bs 32 --triton-attention-num-kv-splits 8 --num-continuous-decode-steps 1 --attention-backend flashinfer --context-length 4096 --mem-fraction-static 0.6 --chunked-prefill-size -1 --max-prefill-tokens 32768 --schedule-policy lpm --schedule-conservativeness 1.0 --cpu-offload-gb 0 --dtype bfloat16 --kv-cache-dtype auto --dp-size 1 --ep-size 1 --max-loaded-loras 1 --max-loras-per-batch 1 --lora-backend triton --log-level warning --log-level-http warning --log-requests-level 0 --enable-metrics --decode-log-interval 1[0m
2025-11-26T18:12:22.586815926Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:12:22.586866372Z   import pynvml  # type: ignore[import]
2025-11-26T18:12:28.008501854Z INFO 11-26 18:12:28 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T18:12:28.681688727Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T18:12:29.699562807Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:12:29.699613473Z   import pynvml  # type: ignore[import]
2025-11-26T18:12:29.712911701Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:12:29.712927395Z   import pynvml  # type: ignore[import]
2025-11-26T18:12:35.455095001Z INFO 11-26 18:12:35 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T18:12:35.612863618Z INFO 11-26 18:12:35 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T18:12:36.193273874Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T18:12:36.425184425Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T18:12:36.428674873Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T18:12:36.429475603Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T18:12:36.430359627Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T18:12:36.463192226Z [2025-11-26 18:12:36] MOE_RUNNER_BACKEND is not initialized, using triton backend
2025-11-26T18:12:36.963503695Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T18:12:36.963536335Z   warnings.warn(
2025-11-26T18:12:36.963539749Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T18:12:36.963542063Z   warnings.warn(
2025-11-26T18:12:38.153026431Z Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
2025-11-26T18:12:38.257429734Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  9.60it/s]
2025-11-26T18:12:38.257917364Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  9.58it/s]
2025-11-26T18:12:40.782900349Z   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   4%|â–         | 1/23 [00:00<00:11,  1.84it/s]Capturing batches (bs=152 avail_mem=30.62 GB):   4%|â–         | 1/23 [00:00<00:11,  1.84it/s]Capturing batches (bs=144 avail_mem=30.60 GB):   4%|â–         | 1/23 [00:00<00:11,  1.84it/s]Capturing batches (bs=136 avail_mem=30.59 GB):   4%|â–         | 1/23 [00:00<00:11,  1.84it/s]Capturing batches (bs=136 avail_mem=30.59 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.26it/s]Capturing batches (bs=128 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.26it/s]Capturing batches (bs=120 avail_mem=30.57 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.26it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  17%|â–ˆâ–‹        | 4/23 [00:00<00:02,  7.26it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.56it/s]Capturing batches (bs=104 avail_mem=30.54 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.56it/s]Capturing batches (bs=96 avail_mem=30.53 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.56it/s] Capturing batches (bs=88 avail_mem=30.51 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 11.56it/s]Capturing batches (bs=88 avail_mem=30.51 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.87it/s]Capturing batches (bs=80 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.87it/s]Capturing batches (bs=72 avail_mem=30.50 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:00<00:00, 14.87it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10/23 [00:01<00:00, 14.87it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.40it/s]Capturing batches (bs=56 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.40it/s]Capturing batches (bs=48 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.40it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 17.40it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.44it/s]Capturing batches (bs=32 avail_mem=30.44 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.44it/s]Capturing batches (bs=24 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.44it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16/23 [00:01<00:00, 19.44it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.85it/s]Capturing batches (bs=8 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.85it/s] Capturing batches (bs=4 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.85it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 17.85it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.56it/s]Capturing batches (bs=1 avail_mem=30.35 GB):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:01<00:00, 19.56it/s]Capturing batches (bs=1 avail_mem=30.35 GB): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00, 14.94it/s]
2025-11-26T18:12:46.556091586Z [37m20251126-18:12:46.555 SGLangServer Wrapper INFO: SGLang server launched at: http://172.21.0.2:19693[0m
2025-11-26T18:12:47.159763034Z [37m20251126-18:12:47.159 Launcher Utils INFO: Found 1 rollout servers: 172.21.0.2:19693[0m
2025-11-26T18:12:47.159801301Z [37m20251126-18:12:47.159 Local Scheduler INFO: LLM inference server launched at: AREAL_LLM_SERVER_ADDRS=172.21.0.2:19693[0m
2025-11-26T18:12:47.162454365Z [37m20251126-18:12:47.162 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL AREAL_LLM_SERVER_ADDRS=172.21.0.2:19693 AREAL_RECOVER_RUN=0 NCCL_CUMEM_ENABLE=0 NCCL_NVLS_ENABLE=0 CUDA_VISIBLE_DEVICES=1 stdbuf -oL torchrun --nnodes 1 --nproc-per-node 1 --master-addr localhost --master-port 11737 examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_181214 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_181214/trainer.log[0m
2025-11-26T18:12:47.163228966Z [37m20251126-18:12:47.163 Local Scheduler INFO: Waiting for 2 local running processes, pids: 315 965[0m
2025-11-26T18:12:47.673967183Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:12:47.674005020Z   import pynvml  # type: ignore[import]
2025-11-26T18:12:48.842466358Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:12:48.842506628Z   import pynvml  # type: ignore[import]
2025-11-26T18:12:56.523848508Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T18:12:56.523890541Z   warnings.warn(
2025-11-26T18:12:56.523893986Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T18:12:56.523896319Z   warnings.warn(
2025-11-26T18:12:56.976939878Z Traceback (most recent call last):
2025-11-26T18:12:56.976979508Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 665, in <module>
2025-11-26T18:12:56.977531925Z     main(sys.argv[1:])
2025-11-26T18:12:56.977542351Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 102, in main
2025-11-26T18:12:56.977545926Z     config, _ = load_expr_config(args_with_overrides, GRPOConfig)
2025-11-26T18:12:56.977548530Z                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T18:12:56.977550583Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1282, in load_expr_config
2025-11-26T18:12:56.978051082Z     cfg = to_structured_cfg(cfg, config_cls=config_cls)
2025-11-26T18:12:56.978054227Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T18:12:56.978056281Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1276, in to_structured_cfg
2025-11-26T18:12:56.978059215Z     cfg = OmegaConf.merge(default_cfg, cfg)
2025-11-26T18:12:56.978061388Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T18:12:56.978063471Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/omegaconf.py", line 274, in merge
2025-11-26T18:12:56.978546003Z     target.merge_with(
2025-11-26T18:12:56.978550530Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 507, in merge_with
2025-11-26T18:12:56.978553265Z     self._format_and_raise(key=None, value=None, cause=e)
2025-11-26T18:12:56.978555938Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T18:12:56.978557972Z     format_and_raise(
2025-11-26T18:12:56.978560004Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T18:12:56.978562058Z     _raise(ex, cause)
2025-11-26T18:12:56.978564181Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T18:12:56.979056568Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T18:12:56.979080755Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T18:12:56.979083769Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 502, in merge_with
2025-11-26T18:12:56.979086593Z     self._merge_with(
2025-11-26T18:12:56.979089417Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T18:12:56.979091591Z     BaseContainer._map_merge(
2025-11-26T18:12:56.979094375Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T18:12:56.979096919Z     dest_node._merge_with(
2025-11-26T18:12:56.979099012Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T18:12:56.979522437Z     BaseContainer._map_merge(
2025-11-26T18:12:56.979528686Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T18:12:56.979531010Z     dest_node._merge_with(
2025-11-26T18:12:56.979533102Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T18:12:56.979535236Z     BaseContainer._map_merge(
2025-11-26T18:12:56.979537409Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 432, in _map_merge
2025-11-26T18:12:56.979539522Z     dest[key] = src._get_node(key)
2025-11-26T18:12:56.979542907Z     ~~~~^^^^^
2025-11-26T18:12:56.979545561Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 308, in __setitem__
2025-11-26T18:12:56.979547775Z     self._format_and_raise(
2025-11-26T18:12:56.979549778Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T18:12:56.980388874Z     format_and_raise(
2025-11-26T18:12:56.980407923Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T18:12:56.980410567Z     _raise(ex, cause)
2025-11-26T18:12:56.980412860Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T18:12:56.980415124Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T18:12:56.980417317Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T18:12:56.980419621Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 306, in __setitem__
2025-11-26T18:12:56.980421904Z     self.__set_impl(key=key, value=value)
2025-11-26T18:12:56.980424057Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 316, in __set_impl
2025-11-26T18:12:56.980426431Z     self._set_item_impl(key, value)
2025-11-26T18:12:56.980428604Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 579, in _set_item_impl
2025-11-26T18:12:56.980430797Z     target_node_ref = self._get_node(key)
2025-11-26T18:12:56.980432881Z                       ^^^^^^^^^^^^^^^^^^^
2025-11-26T18:12:56.980434873Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 473, in _get_node
2025-11-26T18:12:56.980815022Z     self._validate_get(key)
2025-11-26T18:12:56.980818567Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 163, in _validate_get
2025-11-26T18:12:56.980821031Z     self._format_and_raise(
2025-11-26T18:12:56.980823114Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T18:12:56.980825188Z     format_and_raise(
2025-11-26T18:12:56.980827360Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 906, in format_and_raise
2025-11-26T18:12:56.980829524Z     _raise(ex, cause)
2025-11-26T18:12:56.980831817Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T18:12:56.981193389Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T18:12:56.981199288Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T18:12:56.981201491Z omegaconf.errors.ConfigKeyError: Key 'max_new_tokens' not in 'NormConfig'
2025-11-26T18:12:56.981217024Z     full_key: actor.adv_norm.max_new_tokens
2025-11-26T18:12:56.981219258Z     reference_type=Optional[NormConfig]
2025-11-26T18:12:56.981221291Z     object_type=NormConfig
2025-11-26T18:13:00.266530895Z E1126 18:13:00.265000 966 torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 0 (pid: 1032) of binary: /usr/bin/python3
2025-11-26T18:13:00.267149330Z Traceback (most recent call last):
2025-11-26T18:13:00.267155089Z   File "/usr/local/bin/torchrun", line 7, in <module>
2025-11-26T18:13:00.267157873Z     sys.exit(main())
2025-11-26T18:13:00.267160907Z              ^^^^^^
2025-11-26T18:13:00.267163221Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
2025-11-26T18:13:00.267165995Z     return f(*args, **kwargs)
2025-11-26T18:13:00.267168669Z            ^^^^^^^^^^^^^^^^^^
2025-11-26T18:13:00.267170632Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 901, in main
2025-11-26T18:13:00.267582269Z     run(args)
2025-11-26T18:13:00.267585294Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 892, in run
2025-11-26T18:13:00.267587767Z     elastic_launch(
2025-11-26T18:13:00.267590131Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 143, in __call__
2025-11-26T18:13:00.267592645Z     return launch_agent(self._config, self._entrypoint, list(args))
2025-11-26T18:13:00.267595038Z            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T18:13:00.267597051Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 277, in launch_agent
2025-11-26T18:13:00.268078733Z     raise ChildFailedError(
2025-11-26T18:13:00.268081156Z torch.distributed.elastic.multiprocessing.errors.ChildFailedError:
2025-11-26T18:13:00.268083560Z ============================================================
2025-11-26T18:13:00.268085753Z examples/cloud_gsm8k/gsm8k_grpo_train.py FAILED
2025-11-26T18:13:00.268087866Z ------------------------------------------------------------
2025-11-26T18:13:00.268089949Z Failures:
2025-11-26T18:13:00.268092333Z   <NO_OTHER_FAILURES>
2025-11-26T18:13:00.268094566Z ------------------------------------------------------------
2025-11-26T18:13:00.268096529Z Root Cause (first observed failure):
2025-11-26T18:13:00.268098763Z [0]:
2025-11-26T18:13:00.268100846Z   time      : 2025-11-26_18:13:00
2025-11-26T18:13:00.268103029Z   host      : cef7c503fdea
2025-11-26T18:13:00.268105032Z   rank      : 0 (local_rank: 0)
2025-11-26T18:13:00.268107105Z   exitcode  : 1 (pid: 1032)
2025-11-26T18:13:00.268109058Z   error_file: <N/A>
2025-11-26T18:13:00.268147425Z   traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
2025-11-26T18:13:00.268149559Z ============================================================
2025-11-26T18:13:01.167583330Z [37m20251126-18:13:01.167 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [315][0m
2025-11-26T18:13:01.313102027Z Killed
2025-11-26T18:13:01.325055883Z [37m20251126-18:13:01.324 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [965][0m
2025-11-26T18:13:01.326588628Z Traceback (most recent call last):
2025-11-26T18:13:01.326596700Z   File "<frozen runpy>", line 198, in _run_module_as_main
2025-11-26T18:13:01.326599645Z   File "<frozen runpy>", line 88, in _run_code
2025-11-26T18:13:01.326601768Z   File "/workspace/AReaL/areal/launcher/local.py", line 405, in <module>
2025-11-26T18:13:01.326803139Z     main()
2025-11-26T18:13:01.326823790Z   File "/workspace/AReaL/areal/launcher/local.py", line 260, in main
2025-11-26T18:13:01.326900065Z     local_main(config, run_id=0)
2025-11-26T18:13:01.326903860Z   File "/workspace/AReaL/areal/launcher/local.py", line 399, in local_main
2025-11-26T18:13:01.327032013Z     raise e
2025-11-26T18:13:01.327034757Z   File "/workspace/AReaL/areal/launcher/local.py", line 375, in local_main
2025-11-26T18:13:01.327156229Z     launcher.wait(
2025-11-26T18:13:01.327161226Z   File "/workspace/AReaL/areal/launcher/local.py", line 235, in wait
2025-11-26T18:13:01.327226013Z     raise JobException(
2025-11-26T18:13:01.327238001Z areal.utils.launcher.JobException: Job gsm8k-grpo-cloud-2gpu-2000samples_trial_20251126_181214:trainer JobState.COMPLETED at node local
2025-11-26T18:13:01.638810966Z [37m20251126-18:13:01.638 Local Scheduler INFO: Waiting for 0 local running processes, pids: [0m
2025-11-26T18:13:17.648854653Z ==========
2025-11-26T18:13:17.648857868Z == CUDA ==
2025-11-26T18:13:17.648861784Z ==========
2025-11-26T18:13:17.653182245Z CUDA Version 12.9.1
2025-11-26T18:13:17.654846278Z Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
2025-11-26T18:13:17.656840165Z This container image and its contents are governed by the NVIDIA Deep Learning Container License.
2025-11-26T18:13:17.656843079Z By pulling and using the container, you accept the terms and conditions of this license:
2025-11-26T18:13:17.656845893Z https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license
2025-11-26T18:13:17.656850140Z A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
2025-11-26T18:13:17.821798851Z Writing to /root/.config/pip/pip.conf
2025-11-26T18:13:17.980918370Z Writing to /root/.config/pip/pip.conf
2025-11-26T18:13:18.168972560Z Branch 'feature/reasoning_model' set up to track remote branch 'feature/reasoning_model' from 'origin'.
2025-11-26T18:13:18.169003286Z Your branch is up to date with 'origin/feature/reasoning_model'.
2025-11-26T18:13:18.254380871Z Checking AReaL installation...
2025-11-26T18:13:18.315056314Z AReaL already installed. Skipping installation.
2025-11-26T18:13:18.315089954Z Cleaning up any leftover GPU processes...
2025-11-26T18:13:21.337326209Z Checking for processes holding GPU device files...
2025-11-26T18:13:24.060290594Z Found processes holding GPU devices: 1
2025-11-26T18:13:24.060328461Z 20
2025-11-26T18:13:24.060331746Z 71
2025-11-26T18:13:24.060333899Z 72
2025-11-26T18:13:24.060336473Z Killing process 1...
2025-11-26T18:13:24.060339428Z Killing process 71...
2025-11-26T18:13:24.060441241Z Killing process 72...
2025-11-26T18:13:26.063440575Z Using fuser to kill processes on GPU devices...
2025-11-26T18:13:28.087169899Z Checking GPU...
2025-11-26T18:13:28.122300650Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T18:13:28.122340410Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T18:13:28.140945598Z Set PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True for better memory management
2025-11-26T18:13:28.140968543Z Detected 2 GPU(s)
2025-11-26T18:13:28.140971417Z Checking GPU status...
2025-11-26T18:13:28.170183673Z index, name, utilization.gpu [%], memory.used [MiB], compute_mode
2025-11-26T18:13:28.171534206Z 0, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T18:13:28.171847945Z 1, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T18:13:28.215954482Z Verifying GPU accessibility...
2025-11-26T18:13:28.797582992Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:13:28.797640068Z   import pynvml  # type: ignore[import]
2025-11-26T18:13:29.928786434Z GPU accessibility verified on attempt 1
2025-11-26T18:13:30.485859334Z Starting training...
2025-11-26T18:13:33.489250051Z Using STANDARD 2000 SAMPLES 2 GPUs configuration
2025-11-26T18:13:33.489298053Z Note: GRPO only (no reasoning XML). Dataset capped at 2000 samples (~6 hours).
2025-11-26T18:13:33.489301538Z GPU count: 2 (required: 2)
2025-11-26T18:13:33.491874382Z ==========================================
2025-11-26T18:13:33.491877306Z Starting GRPO Training (Cloud)
2025-11-26T18:13:33.491879950Z ==========================================
2025-11-26T18:13:33.491881943Z Config: standard_2000samples_2GPUs
2025-11-26T18:13:33.491883996Z Config file: examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml
2025-11-26T18:13:33.491886721Z Training script: examples/cloud_gsm8k/gsm8k_grpo_train.py
2025-11-26T18:13:33.491888864Z Experiment: gsm8k-grpo-cloud-2gpu-2000samples
2025-11-26T18:13:33.491899319Z Trial: trial_20251126_181333
2025-11-26T18:13:33.491901403Z GPU: NVIDIA A100 80GB PCIe NVIDIA A100 80GB PCIe (81920 MB)
2025-11-26T18:13:33.491904036Z WandB API key: e1adc5be02...
2025-11-26T18:13:33.491907321Z ==========================================
2025-11-26T18:13:34.218059879Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:13:34.218100060Z   import pynvml  # type: ignore[import]
2025-11-26T18:13:38.256819200Z [37m20251126-18:13:38.256 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T18:13:38.256871358Z [37m20251126-18:13:38.256 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T18:13:38.257168613Z [37m20251126-18:13:38.256 name-resolve INFO: No such name resolve path: ./tmp/areal/name_resolve/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_181333[0m
2025-11-26T18:13:38.362300667Z [37m20251126-18:13:38.361 Local Scheduler INFO: LocalLauncher: experiment_name=gsm8k-grpo-cloud-2gpu-2000samples, trial_name=trial_20251126_181333, fileroot=/workspace/outputs/grpo, run_id=0, is_recover_run=False[0m
2025-11-26T18:13:38.370296433Z [37m20251126-18:13:38.370 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL CUDA_VISIBLE_DEVICES=0 stdbuf -oL python3 -m areal.launcher.sglang_server examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_181333 sglang.random_seed=1 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_181333/llm_server.log[0m
2025-11-26T18:13:39.132827473Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:13:39.132868925Z   import pynvml  # type: ignore[import]
2025-11-26T18:13:40.675217526Z [37m20251126-18:13:40.674 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T18:13:40.675866688Z [37m20251126-18:13:40.674 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T18:13:40.789351974Z [37m20251126-18:13:40.788 SGLangServer Wrapper INFO: Launch command: python3 -m sglang.launch_server --host 172.21.0.2 --port 10189 --tokenizer-path Qwen/Qwen2.5-0.5B-Instruct --tokenizer-mode auto --load-format auto --trust-remote-code --device cuda --tp-size 1 --base-gpu-id 0 --nnodes 1 --node-rank 0 --dist-init-addr localhost:13749 --model-path Qwen/Qwen2.5-0.5B-Instruct --random-seed 1 --skip-tokenizer-init --disable-radix-cache --torch-compile-max-bs 32 --triton-attention-num-kv-splits 8 --num-continuous-decode-steps 1 --attention-backend flashinfer --context-length 4096 --mem-fraction-static 0.6 --chunked-prefill-size -1 --max-prefill-tokens 32768 --schedule-policy lpm --schedule-conservativeness 1.0 --cpu-offload-gb 0 --dtype bfloat16 --kv-cache-dtype auto --dp-size 1 --ep-size 1 --max-loaded-loras 1 --max-loras-per-batch 1 --lora-backend triton --log-level warning --log-level-http warning --log-requests-level 0 --enable-metrics --decode-log-interval 1[0m
2025-11-26T18:13:41.862183101Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:13:41.862232085Z   import pynvml  # type: ignore[import]
2025-11-26T18:13:47.155987761Z INFO 11-26 18:13:47 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T18:13:47.818477261Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T18:13:48.863496099Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:13:48.863538172Z   import pynvml  # type: ignore[import]
2025-11-26T18:13:48.873474485Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:13:48.873488627Z   import pynvml  # type: ignore[import]
2025-11-26T18:13:54.356998709Z INFO 11-26 18:13:54 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T18:13:54.469556235Z INFO 11-26 18:13:54 [__init__.py:216] Automatically detected platform cuda.
2025-11-26T18:13:55.069822182Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-26T18:13:55.470803008Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T18:13:55.474462579Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T18:13:55.475270941Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T18:13:55.476140734Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-26T18:13:55.509451238Z [2025-11-26 18:13:55] MOE_RUNNER_BACKEND is not initialized, using triton backend
2025-11-26T18:13:56.007496574Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T18:13:56.007532477Z   warnings.warn(
2025-11-26T18:13:56.007535421Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T18:13:56.007537574Z   warnings.warn(
2025-11-26T18:13:57.257736495Z Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
2025-11-26T18:13:57.366657724Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  9.20it/s]
2025-11-26T18:13:57.367185455Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  9.18it/s]
2025-11-26T18:14:00.504622635Z   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   0%|          | 0/23 [00:00<?, ?it/s]Capturing batches (bs=160 avail_mem=30.72 GB):   4%|â–         | 1/23 [00:00<00:13,  1.59it/s]Capturing batches (bs=152 avail_mem=30.62 GB):   4%|â–         | 1/23 [00:00<00:13,  1.59it/s]Capturing batches (bs=144 avail_mem=30.60 GB):   4%|â–         | 1/23 [00:00<00:13,  1.59it/s]Capturing batches (bs=144 avail_mem=30.60 GB):  13%|â–ˆâ–Ž        | 3/23 [00:00<00:04,  4.85it/s]Capturing batches (bs=136 avail_mem=30.59 GB):  13%|â–ˆâ–Ž        | 3/23 [00:00<00:04,  4.85it/s]Capturing batches (bs=128 avail_mem=30.57 GB):  13%|â–ˆâ–Ž        | 3/23 [00:00<00:04,  4.85it/s]Capturing batches (bs=128 avail_mem=30.57 GB):  22%|â–ˆâ–ˆâ–       | 5/23 [00:00<00:02,  7.69it/s]Capturing batches (bs=120 avail_mem=30.57 GB):  22%|â–ˆâ–ˆâ–       | 5/23 [00:00<00:02,  7.69it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  22%|â–ˆâ–ˆâ–       | 5/23 [00:00<00:02,  7.69it/s]Capturing batches (bs=112 avail_mem=30.56 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 10.05it/s]Capturing batches (bs=104 avail_mem=30.54 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:00<00:01, 10.05it/s]Capturing batches (bs=96 avail_mem=30.53 GB):  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:01<00:01, 10.05it/s] Capturing batches (bs=96 avail_mem=30.53 GB):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 9/23 [00:01<00:01, 12.04it/s]Capturing batches (bs=88 avail_mem=30.51 GB):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 9/23 [00:01<00:01, 12.04it/s]Capturing batches (bs=80 avail_mem=30.50 GB):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 9/23 [00:01<00:01, 12.04it/s]Capturing batches (bs=80 avail_mem=30.50 GB):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 11/23 [00:01<00:00, 13.46it/s]Capturing batches (bs=72 avail_mem=30.50 GB):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 11/23 [00:01<00:00, 13.46it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 11/23 [00:01<00:00, 13.46it/s]Capturing batches (bs=64 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 14.62it/s]Capturing batches (bs=56 avail_mem=30.47 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 14.62it/s]Capturing batches (bs=48 avail_mem=30.44 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13/23 [00:01<00:00, 14.62it/s]Capturing batches (bs=48 avail_mem=30.44 GB):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 15/23 [00:01<00:00, 15.67it/s]Capturing batches (bs=40 avail_mem=30.44 GB):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 15/23 [00:01<00:00, 15.67it/s]Capturing batches (bs=32 avail_mem=30.44 GB):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 15/23 [00:01<00:00, 15.67it/s]Capturing batches (bs=32 avail_mem=30.44 GB):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 17/23 [00:01<00:00, 15.45it/s]Capturing batches (bs=24 avail_mem=30.41 GB):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 17/23 [00:01<00:00, 15.45it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 17/23 [00:01<00:00, 15.45it/s]Capturing batches (bs=16 avail_mem=30.41 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 13.90it/s]Capturing batches (bs=8 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 13.90it/s] Capturing batches (bs=4 avail_mem=30.38 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19/23 [00:01<00:00, 13.90it/s]Capturing batches (bs=4 avail_mem=30.38 GB):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 21/23 [00:01<00:00, 15.02it/s]Capturing batches (bs=2 avail_mem=30.37 GB):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 21/23 [00:01<00:00, 15.02it/s]Capturing batches (bs=1 avail_mem=30.35 GB):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 21/23 [00:01<00:00, 15.02it/s]Capturing batches (bs=1 avail_mem=30.35 GB): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00, 15.50it/s]Capturing batches (bs=1 avail_mem=30.35 GB): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:01<00:00, 11.71it/s]
2025-11-26T18:14:05.820822599Z [37m20251126-18:14:05.820 SGLangServer Wrapper INFO: SGLang server launched at: http://172.21.0.2:10189[0m
2025-11-26T18:14:06.377543463Z [37m20251126-18:14:06.377 Launcher Utils INFO: Found 1 rollout servers: 172.21.0.2:10189[0m
2025-11-26T18:14:06.377591424Z [37m20251126-18:14:06.377 Local Scheduler INFO: LLM inference server launched at: AREAL_LLM_SERVER_ADDRS=172.21.0.2:10189[0m
2025-11-26T18:14:06.380962744Z [37m20251126-18:14:06.380 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL AREAL_LLM_SERVER_ADDRS=172.21.0.2:10189 AREAL_RECOVER_RUN=0 NCCL_CUMEM_ENABLE=0 NCCL_NVLS_ENABLE=0 CUDA_VISIBLE_DEVICES=1 stdbuf -oL torchrun --nnodes 1 --nproc-per-node 1 --master-addr localhost --master-port 30846 examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_181333 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_181333/trainer.log[0m
2025-11-26T18:14:06.381554500Z [37m20251126-18:14:06.381 Local Scheduler INFO: Waiting for 2 local running processes, pids: 315 965[0m
2025-11-26T18:14:06.893810450Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:14:06.893867416Z   import pynvml  # type: ignore[import]
2025-11-26T18:14:08.084339103Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:14:08.084377951Z   import pynvml  # type: ignore[import]
2025-11-26T18:14:14.744320081Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T18:14:14.744365990Z   warnings.warn(
2025-11-26T18:14:14.744369786Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-26T18:14:14.744372770Z   warnings.warn(
2025-11-26T18:14:15.157824135Z Traceback (most recent call last):
2025-11-26T18:14:15.157872798Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 665, in <module>
2025-11-26T18:14:15.158415320Z     main(sys.argv[1:])
2025-11-26T18:14:15.158453568Z   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 102, in main
2025-11-26T18:14:15.158457123Z     config, _ = load_expr_config(args_with_overrides, GRPOConfig)
2025-11-26T18:14:15.158459947Z                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T18:14:15.158461990Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1282, in load_expr_config
2025-11-26T18:14:15.158464113Z     cfg = to_structured_cfg(cfg, config_cls=config_cls)
2025-11-26T18:14:15.158730152Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T18:14:15.158737714Z   File "/workspace/AReaL/areal/api/cli_args.py", line 1276, in to_structured_cfg
2025-11-26T18:14:15.158741179Z     cfg = OmegaConf.merge(default_cfg, cfg)
2025-11-26T18:14:15.159227246Z           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T18:14:15.159233285Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/omegaconf.py", line 274, in merge
2025-11-26T18:14:15.159235609Z     target.merge_with(
2025-11-26T18:14:15.159237752Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 507, in merge_with
2025-11-26T18:14:15.159240486Z     self._format_and_raise(key=None, value=None, cause=e)
2025-11-26T18:14:15.159242639Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T18:14:15.159244613Z     format_and_raise(
2025-11-26T18:14:15.159254768Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T18:14:15.159257041Z     _raise(ex, cause)
2025-11-26T18:14:15.159259064Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T18:14:15.160093313Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T18:14:15.160098301Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T18:14:15.160100604Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 502, in merge_with
2025-11-26T18:14:15.160103388Z     self._merge_with(
2025-11-26T18:14:15.160106173Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T18:14:15.160108356Z     BaseContainer._map_merge(
2025-11-26T18:14:15.160130640Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T18:14:15.160132963Z     dest_node._merge_with(
2025-11-26T18:14:15.160135046Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T18:14:15.160137109Z     BaseContainer._map_merge(
2025-11-26T18:14:15.160139132Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 396, in _map_merge
2025-11-26T18:14:15.160141145Z     dest_node._merge_with(
2025-11-26T18:14:15.160143188Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 530, in _merge_with
2025-11-26T18:14:15.160145271Z     BaseContainer._map_merge(
2025-11-26T18:14:15.160147225Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 432, in _map_merge
2025-11-26T18:14:15.160149288Z     dest[key] = src._get_node(key)
2025-11-26T18:14:15.160151291Z     ~~~~^^^^^
2025-11-26T18:14:15.160153624Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 308, in __setitem__
2025-11-26T18:14:15.160747904Z     self._format_and_raise(
2025-11-26T18:14:15.160752481Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T18:14:15.160754815Z     format_and_raise(
2025-11-26T18:14:15.160757188Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 826, in format_and_raise
2025-11-26T18:14:15.160759451Z     _raise(ex, cause)
2025-11-26T18:14:15.160761525Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T18:14:15.160763738Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T18:14:15.160765841Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T18:14:15.160768235Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 306, in __setitem__
2025-11-26T18:14:15.160770628Z     self.__set_impl(key=key, value=value)
2025-11-26T18:14:15.160772722Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 316, in __set_impl
2025-11-26T18:14:15.160774955Z     self._set_item_impl(key, value)
2025-11-26T18:14:15.160777269Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 579, in _set_item_impl
2025-11-26T18:14:15.161125470Z     target_node_ref = self._get_node(key)
2025-11-26T18:14:15.161131279Z                       ^^^^^^^^^^^^^^^^^^^
2025-11-26T18:14:15.161133422Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 473, in _get_node
2025-11-26T18:14:15.161136076Z     self._validate_get(key)
2025-11-26T18:14:15.161138370Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 163, in _validate_get
2025-11-26T18:14:15.161140553Z     self._format_and_raise(
2025-11-26T18:14:15.161142736Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 229, in _format_and_raise
2025-11-26T18:14:15.161446291Z     format_and_raise(
2025-11-26T18:14:15.161449866Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 906, in format_and_raise
2025-11-26T18:14:15.161452089Z     _raise(ex, cause)
2025-11-26T18:14:15.161454092Z   File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 804, in _raise
2025-11-26T18:14:15.161460041Z     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
2025-11-26T18:14:15.161733922Z     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T18:14:15.161738449Z omegaconf.errors.ConfigKeyError: Key 'max_new_tokens' not in 'NormConfig'
2025-11-26T18:14:15.161740862Z     full_key: actor.adv_norm.max_new_tokens
2025-11-26T18:14:15.161742825Z     reference_type=Optional[NormConfig]
2025-11-26T18:14:15.161745038Z     object_type=NormConfig
2025-11-26T18:14:17.885271425Z E1126 18:14:17.884000 966 torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 0 (pid: 1032) of binary: /usr/bin/python3
2025-11-26T18:14:17.885973036Z Traceback (most recent call last):
2025-11-26T18:14:17.885998724Z   File "/usr/local/bin/torchrun", line 7, in <module>
2025-11-26T18:14:17.886001899Z     sys.exit(main())
2025-11-26T18:14:17.886004583Z              ^^^^^^
2025-11-26T18:14:17.886006686Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
2025-11-26T18:14:17.886010031Z     return f(*args, **kwargs)
2025-11-26T18:14:17.886535849Z            ^^^^^^^^^^^^^^^^^^
2025-11-26T18:14:17.886543921Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 901, in main
2025-11-26T18:14:17.886546975Z     run(args)
2025-11-26T18:14:17.886549659Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 892, in run
2025-11-26T18:14:17.886552073Z     elastic_launch(
2025-11-26T18:14:17.886554797Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 143, in __call__
2025-11-26T18:14:17.886557912Z     return launch_agent(self._config, self._entrypoint, list(args))
2025-11-26T18:14:17.886562338Z            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-26T18:14:17.886564512Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 277, in launch_agent
2025-11-26T18:14:17.886567016Z     raise ChildFailedError(
2025-11-26T18:14:17.886569169Z torch.distributed.elastic.multiprocessing.errors.ChildFailedError:
2025-11-26T18:14:17.886571342Z ============================================================
2025-11-26T18:14:17.886573996Z examples/cloud_gsm8k/gsm8k_grpo_train.py FAILED
2025-11-26T18:14:17.886576840Z ------------------------------------------------------------
2025-11-26T18:14:17.886578843Z Failures:
2025-11-26T18:14:17.886581197Z   <NO_OTHER_FAILURES>
2025-11-26T18:14:17.886583190Z ------------------------------------------------------------
2025-11-26T18:14:17.886585193Z Root Cause (first observed failure):
2025-11-26T18:14:17.886587206Z [0]:
2025-11-26T18:14:17.886589339Z   time      : 2025-11-26_18:14:17
2025-11-26T18:14:17.886591362Z   host      : cef7c503fdea
2025-11-26T18:14:17.886593375Z   rank      : 0 (local_rank: 0)
2025-11-26T18:14:17.886595518Z   exitcode  : 1 (pid: 1032)
2025-11-26T18:14:17.886597471Z   error_file: <N/A>
2025-11-26T18:14:17.886599654Z   traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
2025-11-26T18:14:17.886601728Z ============================================================
2025-11-26T18:14:18.384973492Z [37m20251126-18:14:18.384 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [315][0m
2025-11-26T18:14:18.554337126Z Killed
2025-11-26T18:14:18.564312057Z [37m20251126-18:14:18.564 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [965][0m
2025-11-26T18:14:18.565325805Z Traceback (most recent call last):
2025-11-26T18:14:18.565333376Z   File "<frozen runpy>", line 198, in _run_module_as_main
2025-11-26T18:14:18.565335820Z   File "<frozen runpy>", line 88, in _run_code
2025-11-26T18:14:18.565337953Z   File "/workspace/AReaL/areal/launcher/local.py", line 405, in <module>
2025-11-26T18:14:18.565478103Z     main()
2025-11-26T18:14:18.565480707Z   File "/workspace/AReaL/areal/launcher/local.py", line 260, in main
2025-11-26T18:14:18.565559946Z     local_main(config, run_id=0)
2025-11-26T18:14:18.565563171Z   File "/workspace/AReaL/areal/launcher/local.py", line 399, in local_main
2025-11-26T18:14:18.565670221Z     raise e
2025-11-26T18:14:18.565698864Z   File "/workspace/AReaL/areal/launcher/local.py", line 375, in local_main
2025-11-26T18:14:18.565782680Z     launcher.wait(
2025-11-26T18:14:18.565807317Z   File "/workspace/AReaL/areal/launcher/local.py", line 235, in wait
2025-11-26T18:14:18.565811113Z     raise JobException(
2025-11-26T18:14:18.565813316Z areal.utils.launcher.JobException: Job gsm8k-grpo-cloud-2gpu-2000samples_trial_20251126_181333:trainer JobState.COMPLETED at node local
2025-11-26T18:14:18.761468201Z [37m20251126-18:14:18.760 Local Scheduler INFO: Waiting for 0 local running processes, pids: [0m
2025-11-26T18:14:36.457245782Z ==========
2025-11-26T18:14:36.457249367Z == CUDA ==
2025-11-26T18:14:36.457266852Z ==========
2025-11-26T18:14:36.462331509Z CUDA Version 12.9.1
2025-11-26T18:14:36.464027619Z Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
2025-11-26T18:14:36.465663130Z This container image and its contents are governed by the NVIDIA Deep Learning Container License.
2025-11-26T18:14:36.465666194Z By pulling and using the container, you accept the terms and conditions of this license:
2025-11-26T18:14:36.465668868Z https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license
2025-11-26T18:14:36.465673706Z A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
2025-11-26T18:14:36.641375553Z Writing to /root/.config/pip/pip.conf
2025-11-26T18:14:36.800683685Z Writing to /root/.config/pip/pip.conf
2025-11-26T18:14:36.997557136Z Branch 'feature/reasoning_model' set up to track remote branch 'feature/reasoning_model' from 'origin'.
2025-11-26T18:14:36.997588843Z Your branch is up to date with 'origin/feature/reasoning_model'.
2025-11-26T18:14:37.068832115Z Checking AReaL installation...
2025-11-26T18:14:37.127877818Z AReaL already installed. Skipping installation.
2025-11-26T18:14:37.127911149Z Cleaning up any leftover GPU processes...
2025-11-26T18:14:40.149214475Z Checking for processes holding GPU device files...
2025-11-26T18:14:41.873848014Z Found processes holding GPU devices: 1
2025-11-26T18:14:41.873885851Z 20
2025-11-26T18:14:41.873888506Z 71
2025-11-26T18:14:41.873891500Z 72
2025-11-26T18:14:41.873893543Z Killing process 1...
2025-11-26T18:14:41.873896067Z Killing process 71...
2025-11-26T18:14:41.874066993Z Killing process 72...
2025-11-26T18:14:43.877191174Z Using fuser to kill processes on GPU devices...
2025-11-26T18:14:45.899511299Z Checking GPU...
2025-11-26T18:14:45.935174567Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T18:14:45.935200185Z NVIDIA A100 80GB PCIe, 81920 MiB
2025-11-26T18:14:45.950409727Z Set PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True for better memory management
2025-11-26T18:14:45.950425050Z Detected 2 GPU(s)
2025-11-26T18:14:45.950428155Z Checking GPU status...
2025-11-26T18:14:45.978039402Z index, name, utilization.gpu [%], memory.used [MiB], compute_mode
2025-11-26T18:14:45.979552088Z 0, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T18:14:45.980154571Z 1, NVIDIA A100 80GB PCIe, 0, 0, Default
2025-11-26T18:14:46.024097551Z Verifying GPU accessibility...
2025-11-26T18:14:46.557937112Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:14:46.557995609Z   import pynvml  # type: ignore[import]
2025-11-26T18:14:47.675212230Z GPU accessibility verified on attempt 1
2025-11-26T18:14:48.138609517Z Starting training...
2025-11-26T18:14:51.141494506Z Using STANDARD 2000 SAMPLES 2 GPUs configuration
2025-11-26T18:14:51.141533745Z Note: GRPO only (no reasoning XML). Dataset capped at 2000 samples (~6 hours).
2025-11-26T18:14:51.141537310Z GPU count: 2 (required: 2)
2025-11-26T18:14:51.144073108Z ==========================================
2025-11-26T18:14:51.144076403Z Starting GRPO Training (Cloud)
2025-11-26T18:14:51.144079348Z ==========================================
2025-11-26T18:14:51.144094640Z Config: standard_2000samples_2GPUs
2025-11-26T18:14:51.144096824Z Config file: examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml
2025-11-26T18:14:51.144099728Z Training script: examples/cloud_gsm8k/gsm8k_grpo_train.py
2025-11-26T18:14:51.144102142Z Experiment: gsm8k-grpo-cloud-2gpu-2000samples
2025-11-26T18:14:51.144104165Z Trial: trial_20251126_181451
2025-11-26T18:14:51.144106188Z GPU: NVIDIA A100 80GB PCIe NVIDIA A100 80GB PCIe (81920 MB)
2025-11-26T18:14:51.144108281Z WandB API key: e1adc5be02...
2025-11-26T18:14:51.144127921Z ==========================================
2025-11-26T18:14:51.836939319Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:14:51.836981172Z   import pynvml  # type: ignore[import]
2025-11-26T18:14:55.779527336Z [37m20251126-18:14:55.779 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T18:14:55.779580336Z [37m20251126-18:14:55.779 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T18:14:55.779805765Z [37m20251126-18:14:55.779 name-resolve INFO: No such name resolve path: ./tmp/areal/name_resolve/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_181451[0m
2025-11-26T18:14:55.884409306Z [37m20251126-18:14:55.884 Local Scheduler INFO: LocalLauncher: experiment_name=gsm8k-grpo-cloud-2gpu-2000samples, trial_name=trial_20251126_181451, fileroot=/workspace/outputs/grpo, run_id=0, is_recover_run=False[0m
2025-11-26T18:14:55.891896491Z [37m20251126-18:14:55.891 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL CUDA_VISIBLE_DEVICES=0 stdbuf -oL python3 -m areal.launcher.sglang_server examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_2000samples_2GPUs.yaml experiment_name=gsm8k-grpo-cloud-2gpu-2000samples trial_name=trial_20251126_181451 sglang.random_seed=1 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-cloud-2gpu-2000samples/trial_20251126_181451/llm_server.log[0m
2025-11-26T18:14:56.638850518Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:14:56.638880893Z   import pynvml  # type: ignore[import]
2025-11-26T18:14:58.149811715Z [37m20251126-18:14:58.149 Platform init INFO: Detected CUDA device: NVIDIA A100 80GB PCIE[0m
2025-11-26T18:14:58.150553666Z [37m20251126-18:14:58.149 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-26T18:14:58.313003574Z [37m20251126-18:14:58.312 SGLangServer Wrapper INFO: Launch command: python3 -m sglang.launch_server --host 172.21.0.2 --port 17134 --tokenizer-path Qwen/Qwen2.5-0.5B-Instruct --tokenizer-mode auto --load-format auto --trust-remote-code --device cuda --tp-size 1 --base-gpu-id 0 --nnodes 1 --node-rank 0 --dist-init-addr localhost:28736 --model-path Qwen/Qwen2.5-0.5B-Instruct --random-seed 1 --skip-tokenizer-init --disable-radix-cache --torch-compile-max-bs 32 --triton-attention-num-kv-splits 8 --num-continuous-decode-steps 1 --attention-backend flashinfer --context-length 4096 --mem-fraction-static 0.6 --chunked-prefill-size -1 --max-prefill-tokens 32768 --schedule-policy lpm --schedule-conservativeness 1.0 --cpu-offload-gb 0 --dtype bfloat16 --kv-cache-dtype auto --dp-size 1 --ep-size 1 --max-loaded-loras 1 --max-loras-per-batch 1 --lora-backend triton --log-level warning --log-level-http warning --log-requests-level 0 --enable-metrics --decode-log-interval 1[0m
2025-11-26T18:14:59.360796989Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-26T18:14:59.360846413Z   import pynvml  # type: ignore[import]