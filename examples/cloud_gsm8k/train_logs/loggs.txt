2025-11-21T23:36:15.303611223Z ==========
2025-11-21T23:36:15.304327322Z == CUDA ==
2025-11-21T23:36:15.304358180Z ==========
2025-11-21T23:36:15.305489886Z CUDA Version 12.9.1
2025-11-21T23:36:15.306176961Z Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
2025-11-21T23:36:15.306632232Z This container image and its contents are governed by the NVIDIA Deep Learning Container License.
2025-11-21T23:36:15.306633314Z By pulling and using the container, you accept the terms and conditions of this license:
2025-11-21T23:36:15.306634737Z https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license
2025-11-21T23:36:15.306636340Z A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
2025-11-21T23:36:15.385255436Z Writing to /root/.config/pip/pip.conf
2025-11-21T23:36:15.469278336Z Writing to /root/.config/pip/pip.conf
2025-11-21T23:36:15.481558979Z Cloning into 'AReaL'...
2025-11-21T23:36:16.744143560Z Checking AReaL installation...
2025-11-21T23:36:16.791648658Z AReaL already installed. Skipping installation.
2025-11-21T23:36:16.791664157Z Cleaning up any leftover GPU processes...
2025-11-21T23:36:16.791682882Z Installing cleanup tools (psmisc, lsof)...
2025-11-21T23:36:16.972203848Z Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]
2025-11-21T23:36:17.103183030Z Get:3 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]
2025-11-21T23:36:17.184424429Z Get:4 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [38.5 kB]
2025-11-21T23:36:18.137828459Z Get:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [2,151 kB]
2025-11-21T23:36:18.407334083Z Hit:6 https://mirrors.tuna.tsinghua.edu.cn/ubuntu jammy InRelease
2025-11-21T23:36:18.709173378Z Get:7 https://mirrors.tuna.tsinghua.edu.cn/ubuntu jammy-updates InRelease [128 kB]
2025-11-21T23:36:19.320692748Z Ign:1 https://developer.download.nvidia.com/devtools/repos/ubuntu2004/amd64  InRelease
2025-11-21T23:36:19.377626094Z Get:8 https://developer.download.nvidia.com/devtools/repos/ubuntu2004/amd64  Release [496 B]
2025-11-21T23:36:19.401980623Z Get:9 https://developer.download.nvidia.com/devtools/repos/ubuntu2004/amd64  Release.gpg [833 B]
2025-11-21T23:36:19.480126995Z Get:10 https://developer.download.nvidia.com/devtools/repos/ubuntu2004/amd64  Packages [18.8 kB]
2025-11-21T23:36:19.581261472Z Get:11 https://mirrors.tuna.tsinghua.edu.cn/ubuntu jammy-backports InRelease [127 kB]
2025-11-21T23:36:19.974124626Z Get:12 https://mirrors.tuna.tsinghua.edu.cn/ubuntu jammy-security InRelease [129 kB]
2025-11-21T23:36:20.349832073Z Get:13 https://mirrors.tuna.tsinghua.edu.cn/ubuntu jammy-updates/universe amd64 Packages [1,595 kB]
2025-11-21T23:36:21.159011707Z Get:14 https://mirrors.tuna.tsinghua.edu.cn/ubuntu jammy-updates/restricted amd64 Packages [6,214 kB]
2025-11-21T23:36:21.778907348Z Get:15 https://mirrors.tuna.tsinghua.edu.cn/ubuntu jammy-updates/main amd64 Packages [3,873 kB]
2025-11-21T23:36:22.046317715Z Get:16 https://mirrors.tuna.tsinghua.edu.cn/ubuntu jammy-updates/multiverse amd64 Packages [69.2 kB]
2025-11-21T23:36:22.047807601Z Get:17 https://mirrors.tuna.tsinghua.edu.cn/ubuntu jammy-backports/main amd64 Packages [83.9 kB]
2025-11-21T23:36:22.049970646Z Get:18 https://mirrors.tuna.tsinghua.edu.cn/ubuntu jammy-backports/universe amd64 Packages [35.2 kB]
2025-11-21T23:36:22.051097032Z Get:19 https://mirrors.tuna.tsinghua.edu.cn/ubuntu jammy-security/restricted amd64 Packages [5,988 kB]
2025-11-21T23:36:22.537420333Z Get:20 https://mirrors.tuna.tsinghua.edu.cn/ubuntu jammy-security/universe amd64 Packages [1,290 kB]
2025-11-21T23:36:22.674675990Z Get:21 https://mirrors.tuna.tsinghua.edu.cn/ubuntu jammy-security/main amd64 Packages [3,532 kB]
2025-11-21T23:36:22.931688654Z Get:22 https://mirrors.tuna.tsinghua.edu.cn/ubuntu jammy-security/multiverse amd64 Packages [60.9 kB]
2025-11-21T23:36:23.008865814Z Fetched 25.4 MB in 6s (4,099 kB/s)
2025-11-21T23:36:23.427648965Z Reading package lists...
2025-11-21T23:36:23.435387885Z W: http://developer.download.nvidia.com/devtools/repos/ubuntu2004/amd64/Release.gpg: Key is stored in legacy trusted.gpg keyring (/etc/apt/trusted.gpg), see the DEPRECATION section in apt-key(8) for details.
2025-11-21T23:36:23.871757951Z Reading package lists...
2025-11-21T23:36:23.996705554Z Building dependency tree...
2025-11-21T23:36:23.997044819Z Reading state information...
2025-11-21T23:36:24.090594122Z lsof is already the newest version (4.93.2+dfsg-1.1build2).
2025-11-21T23:36:24.090610693Z The following NEW packages will be installed:
2025-11-21T23:36:24.090612616Z   psmisc
2025-11-21T23:36:25.900253080Z 0 upgraded, 1 newly installed, 0 to remove and 62 not upgraded.
2025-11-21T23:36:25.900281062Z Need to get 119 kB of archives.
2025-11-21T23:36:25.900283777Z After this operation, 463 kB of additional disk space will be used.
2025-11-21T23:36:25.900286061Z Get:1 https://mirrors.tuna.tsinghua.edu.cn/ubuntu jammy/main amd64 psmisc amd64 23.4-2build3 [119 kB]
2025-11-21T23:36:26.454350257Z debconf: delaying package configuration, since apt-utils is not installed
2025-11-21T23:36:26.467064851Z Fetched 119 kB in 2s (52.0 kB/s)
2025-11-21T23:36:26.478113430Z Selecting previously unselected package psmisc.
2025-11-21T23:36:26.491315106Z (Reading database ... (Reading database ... 5%(Reading database ... 10%(Reading database ... 15%(Reading database ... 20%(Reading database ... 25%(Reading database ... 30%(Reading database ... 35%(Reading database ... 40%(Reading database ... 45%(Reading database ... 50%(Reading database ... 55%(Reading database ... 60%(Reading database ... 65%(Reading database ... 70%(Reading database ... 75%(Reading database ... 80%(Reading database ... 85%(Reading database ... 90%(Reading database ... 95%(Reading database ... 100%(Reading database ... 70438 files and directories currently installed.)
2025-11-21T23:36:26.492079294Z Preparing to unpack .../psmisc_23.4-2build3_amd64.deb ...
2025-11-21T23:36:26.493382251Z Unpacking psmisc (23.4-2build3) ...
2025-11-21T23:36:26.514581009Z Setting up psmisc (23.4-2build3) ...
2025-11-21T23:36:26.518387016Z Processing triggers for man-db (2.10.2-1) ...
2025-11-21T23:36:29.572574311Z Checking for processes holding GPU device files...
2025-11-21T23:36:29.683983178Z Found processes holding GPU devices: 1
2025-11-21T23:36:29.684000781Z 20
2025-11-21T23:36:29.684001883Z 539
2025-11-21T23:36:29.684002414Z 540
2025-11-21T23:36:29.684003025Z Killing process 1...
2025-11-21T23:36:29.684004368Z Killing process 539...
2025-11-21T23:36:29.684045034Z Killing process 540...
2025-11-21T23:36:31.685026146Z Using fuser to kill processes on GPU devices...
2025-11-21T23:36:33.691076581Z Checking GPU...
2025-11-21T23:36:33.706505400Z NVIDIA GeForce RTX 5090, 32607 MiB
2025-11-21T23:36:33.711741240Z Set PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True for better memory management
2025-11-21T23:36:33.711751810Z Detected 1 GPU(s)
2025-11-21T23:36:33.711753724Z Checking GPU status...
2025-11-21T23:36:33.723560941Z index, name, utilization.gpu [%], memory.used [MiB], compute_mode
2025-11-21T23:36:33.725380343Z 0, NVIDIA GeForce RTX 5090, 0, 2, Default
2025-11-21T23:36:33.742906865Z Verifying GPU accessibility...
2025-11-21T23:36:34.006016180Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-21T23:36:34.006031959Z   import pynvml  # type: ignore[import]
2025-11-21T23:36:34.570517341Z GPU accessibility verified on attempt 1
2025-11-21T23:36:34.818252849Z Starting training...
2025-11-21T23:36:37.819237500Z Using REASONING FAST training configuration (20-30 minutes)
2025-11-21T23:36:37.819266004Z Note: Trains reasoning model with XML format
2025-11-21T23:36:37.820359939Z ==========================================
2025-11-21T23:36:37.820361352Z Starting GRPO Training (Cloud)
2025-11-21T23:36:37.820362845Z ==========================================
2025-11-21T23:36:37.820363947Z Config: reasoning_fast
2025-11-21T23:36:37.820378333Z Config file: examples/cloud_gsm8k/gsm8k_grpo_reasoning_fast.yaml
2025-11-21T23:36:37.820379646Z Training script: examples/cloud_gsm8k/gsm8k_grpo_train.py
2025-11-21T23:36:37.820380598Z Experiment: gsm8k-grpo-reasoning-fast
2025-11-21T23:36:37.820381630Z Trial: trial_20251121_233637
2025-11-21T23:36:37.820385236Z GPU: NVIDIA GeForce RTX 5090 (32607 MB)
2025-11-21T23:36:37.820386399Z WandB API key: e1adc5be02...
2025-11-21T23:36:37.820387410Z ==========================================
2025-11-21T23:36:38.206985009Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-21T23:36:38.207008704Z   import pynvml  # type: ignore[import]
2025-11-21T23:36:40.261108989Z [37m20251121-23:36:40.260 Platform init INFO: Detected CUDA device: NVIDIA GEFORCE RTX 5090[0m
2025-11-21T23:36:40.261130149Z [37m20251121-23:36:40.261 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-21T23:36:40.261303092Z [37m20251121-23:36:40.261 name-resolve INFO: No such name resolve path: ./tmp/areal/name_resolve/root/gsm8k-grpo-reasoning-fast/trial_20251121_233637[0m
2025-11-21T23:36:40.319609506Z [37m20251121-23:36:40.319 Local Scheduler INFO: LocalLauncher: experiment_name=gsm8k-grpo-reasoning-fast, trial_name=trial_20251121_233637, fileroot=/workspace/outputs/grpo, run_id=0, is_recover_run=False[0m
2025-11-21T23:36:40.324056101Z [37m20251121-23:36:40.323 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL CUDA_VISIBLE_DEVICES=0 stdbuf -oL python3 -m areal.launcher.sglang_server examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_reasoning_fast.yaml experiment_name=gsm8k-grpo-reasoning-fast trial_name=trial_20251121_233637 sglang.random_seed=1 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-reasoning-fast/trial_20251121_233637/llm_server.log[0m
2025-11-21T23:36:40.714843133Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-21T23:36:40.714872929Z   import pynvml  # type: ignore[import]
2025-11-21T23:36:41.468228750Z [37m20251121-23:36:41.467 Platform init INFO: Detected CUDA device: NVIDIA GEFORCE RTX 5090[0m
2025-11-21T23:36:41.468516899Z [37m20251121-23:36:41.468 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-21T23:36:41.538668883Z [37m20251121-23:36:41.538 SGLangServer Wrapper INFO: Launch command: python3 -m sglang.launch_server --host 172.18.0.2 --port 15987 --tokenizer-path Qwen/Qwen2.5-0.5B-Instruct --tokenizer-mode auto --load-format auto --trust-remote-code --device cuda --tp-size 1 --base-gpu-id 0 --nnodes 1 --node-rank 0 --dist-init-addr localhost:21324 --model-path Qwen/Qwen2.5-0.5B-Instruct --random-seed 1 --skip-tokenizer-init --disable-radix-cache --torch-compile-max-bs 32 --triton-attention-num-kv-splits 8 --num-continuous-decode-steps 1 --attention-backend triton --context-length 4096 --mem-fraction-static 0.8 --chunked-prefill-size -1 --max-prefill-tokens 32768 --schedule-policy lpm --schedule-conservativeness 1.0 --cpu-offload-gb 0 --dtype bfloat16 --kv-cache-dtype auto --dp-size 1 --ep-size 1 --max-loaded-loras 1 --max-loras-per-batch 1 --lora-backend triton --log-level warning --log-level-http warning --log-requests-level 0 --enable-metrics --decode-log-interval 1[0m
2025-11-21T23:36:42.075877771Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-21T23:36:42.075914409Z   import pynvml  # type: ignore[import]
2025-11-21T23:36:45.813274726Z INFO 11-21 23:36:45 [__init__.py:216] Automatically detected platform cuda.
2025-11-21T23:36:46.575913785Z All deep_gemm operations loaded successfully!
2025-11-21T23:36:46.766966354Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-21T23:36:47.292664921Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-21T23:36:47.292683095Z   import pynvml  # type: ignore[import]
2025-11-21T23:36:47.293127997Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-21T23:36:47.293137695Z   import pynvml  # type: ignore[import]
2025-11-21T23:36:50.466061441Z INFO 11-21 23:36:50 [__init__.py:216] Automatically detected platform cuda.
2025-11-21T23:36:50.474138854Z INFO 11-21 23:36:50 [__init__.py:216] Automatically detected platform cuda.
2025-11-21T23:36:51.092616364Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-21T23:36:51.447187759Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-21T23:36:51.452982013Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-21T23:36:51.453212444Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-21T23:36:51.453479954Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-21T23:36:51.486926604Z [2025-11-21 23:36:51] MOE_RUNNER_BACKEND is not initialized, using triton backend
2025-11-21T23:36:51.756285464Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-21T23:36:51.756308197Z   warnings.warn(
2025-11-21T23:36:51.756505255Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-21T23:36:51.756513160Z   warnings.warn(
2025-11-21T23:36:54.902409098Z All deep_gemm operations loaded successfully!
2025-11-21T23:36:54.904000313Z Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
2025-11-21T23:36:54.996791589Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00, 10.61it/s]
2025-11-21T23:37:05.749166933Z   0%|          | 0/4 [00:00<?, ?it/s]Capturing batches (bs=8 avail_mem=6.00 GB):   0%|          | 0/4 [00:00<?, ?it/s]Capturing batches (bs=8 avail_mem=6.00 GB):  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:10<00:30, 10.24s/it]Capturing batches (bs=4 avail_mem=5.95 GB):  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:10<00:30, 10.24s/it]Capturing batches (bs=2 avail_mem=5.95 GB):  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:10<00:30, 10.24s/it]Capturing batches (bs=1 avail_mem=5.94 GB):  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:10<00:30, 10.24s/it]Capturing batches (bs=1 avail_mem=5.94 GB): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:10<00:00,  2.57s/it]
2025-11-21T23:37:11.563389456Z [37m20251121-23:37:11.563 SGLangServer Wrapper INFO: SGLang server launched at: http://172.18.0.2:15987[0m
2025-11-21T23:37:12.328608930Z [37m20251121-23:37:12.328 Launcher Utils INFO: Found 1 rollout servers: 172.18.0.2:15987[0m
2025-11-21T23:37:12.328638516Z [37m20251121-23:37:12.328 Local Scheduler INFO: LLM inference server launched at: AREAL_LLM_SERVER_ADDRS=172.18.0.2:15987[0m
2025-11-21T23:37:12.330646059Z [37m20251121-23:37:12.330 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL AREAL_LLM_SERVER_ADDRS=172.18.0.2:15987 AREAL_RECOVER_RUN=0 NCCL_CUMEM_ENABLE=0 NCCL_NVLS_ENABLE=0 CUDA_VISIBLE_DEVICES=0 stdbuf -oL torchrun --nnodes 1 --nproc-per-node 1 --master-addr localhost --master-port 26680 examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_reasoning_fast.yaml experiment_name=gsm8k-grpo-reasoning-fast trial_name=trial_20251121_233637 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-reasoning-fast/trial_20251121_233637/trainer.log[0m
2025-11-21T23:37:12.330921314Z [37m20251121-23:37:12.330 Local Scheduler INFO: Waiting for 2 local running processes, pids: 687 1342[0m
2025-11-21T23:37:12.611791459Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-21T23:37:12.611818910Z   import pynvml  # type: ignore[import]
2025-11-21T23:37:13.230814107Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-21T23:37:13.230847560Z   import pynvml  # type: ignore[import]
2025-11-21T23:37:17.199863226Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-21T23:37:17.199890357Z   warnings.warn(
2025-11-21T23:37:17.199891389Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-21T23:37:17.199892241Z   warnings.warn(
2025-11-21T23:37:19.520504583Z [37m20251121-23:37:19.520 Platform init INFO: Detected CUDA device: NVIDIA GEFORCE RTX 5090[0m
2025-11-21T23:37:19.520840702Z [37m20251121-23:37:19.520 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-21T23:37:19.740202205Z [37m20251121-23:37:19.740 [FSDP Engine Rank 0] INFO: Initializing device mesh with parallel dims (dp=1, sp=1, tp=1, ep=1, etp=1, world_size=1).[0m
2025-11-21T23:37:19.741242710Z [37m20251121-23:37:19.741 [FSDP Engine Rank 0] INFO: Data parallel head 0 and rank 0[0m
2025-11-21T23:37:23.444911478Z Generating train split:   0%|          | 0/7473 [00:00<?, ? examples/s]Generating train split: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7473/7473 [00:00<00:00, 1165379.01 examples/s]
2025-11-21T23:37:23.446884598Z Generating test split:   0%|          | 0/1319 [00:00<?, ? examples/s]Generating test split: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1319/1319 [00:00<00:00, 808223.08 examples/s]
2025-11-21T23:37:23.816660553Z Map:   0%|          | 0/7473 [00:00<?, ? examples/s]Map:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 4869/7473 [00:00<00:00, 14399.08 examples/s]Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7473/7473 [00:00<00:00, 20360.25 examples/s]
2025-11-21T23:37:24.446553367Z Filter:   0%|          | 0/7473 [00:00<?, ? examples/s]Filter:  27%|â–ˆâ–ˆâ–‹       | 2000/7473 [00:00<00:00, 12087.85 examples/s]Filter:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 4000/7473 [00:00<00:00, 12554.90 examples/s]Filter:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 6000/7473 [00:00<00:00, 12673.98 examples/s]Filter: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7473/7473 [00:00<00:00, 12736.49 examples/s]Filter: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7473/7473 [00:00<00:00, 12628.18 examples/s]
2025-11-21T23:37:25.560609292Z Map:   0%|          | 0/1319 [00:00<?, ? examples/s]Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1319/1319 [00:00<00:00, 87882.43 examples/s]
2025-11-21T23:37:25.704962751Z Filter:   0%|          | 0/1319 [00:00<?, ? examples/s]Filter: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1319/1319 [00:00<00:00, 12337.67 examples/s]Filter: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1319/1319 [00:00<00:00, 12260.70 examples/s]
2025-11-21T23:37:25.704983610Z [REASONING-FAST] Limiting dataset from 7473 to 200 samples
2025-11-21T23:37:25.706344234Z [37m20251121-23:37:25.706 Launcher Utils INFO: Found 1 rollout servers: 172.18.0.2:15987[0m
2025-11-21T23:37:25.706617866Z [37m20251121-23:37:25.706 [Remote Inference Engine Rank 0] INFO: Get server addresses from name_resolve.[0m
2025-11-21T23:37:25.706619499Z [37m20251121-23:37:25.706 [Remote Inference Engine Rank 0] INFO: Waiting for server ready...[0m
2025-11-21T23:37:26.707813350Z [37m20251121-23:37:26.707 [Remote Inference Engine Rank 0] INFO: Servers are all ready![0m
2025-11-21T23:37:26.709027961Z [37m20251121-23:37:26.708 Launcher Utils INFO: Found 1 rollout servers: 172.18.0.2:15987[0m
2025-11-21T23:37:26.709593688Z [37m20251121-23:37:26.708 [Remote Inference Engine Rank 0] INFO: Get server addresses from name_resolve.[0m
2025-11-21T23:37:26.709596814Z [37m20251121-23:37:26.709 [Remote Inference Engine Rank 0] INFO: Waiting for server ready...[0m
2025-11-21T23:37:27.711473121Z [37m20251121-23:37:27.711 [Remote Inference Engine Rank 0] INFO: Servers are all ready![0m
2025-11-21T23:37:28.542382716Z [37m20251121-23:37:28.542 [FSDP Engine Rank 0] INFO: Model creation and loading time: 0.7706212028861046[0m
2025-11-21T23:37:28.578604335Z [37m20251121-23:37:28.578 [FSDP Engine Rank 0] INFO: Applying FSDP2 with N-D parallelism for 0.04 seconds[0m
2025-11-21T23:37:28.578957485Z [37m20251121-23:37:28.578 [FSDP Engine Rank 0] INFO: Create optimizer time: 0.0003313925117254257[0m
2025-11-21T23:37:28.691526442Z swanlab: SwanLab run disabled, the data will not be saved or uploaded.
2025-11-21T23:37:28.886705948Z ================================================================================
2025-11-21T23:37:28.886708182Z [REASONING-FAST MODE]
2025-11-21T23:37:28.886960183Z   Dataset size: 200 samples (limited from 7473)
2025-11-21T23:37:28.886973037Z   Batch size: 8
2025-11-21T23:37:28.886974630Z   Steps per epoch: 25
2025-11-21T23:37:28.886975742Z   Total epochs: 1
2025-11-21T23:37:28.886976774Z   Total steps: 25
2025-11-21T23:37:28.886977826Z   Estimated time: ~25 minutes (~0.4 hours) at ~1 step/min
2025-11-21T23:37:28.886979549Z   Circuit breaker: Enabled (threshold: 10 consecutive zero rewards)
2025-11-21T23:37:28.886980601Z ================================================================================
2025-11-21T23:37:31.117022211Z /workspace/AReaL/areal/reward/math_parser.py:290: SyntaxWarning: invalid escape sequence '\%'
2025-11-21T23:37:31.117049612Z   string = string.replace("\%", "")
2025-11-21T23:37:31.117454850Z /workspace/AReaL/areal/reward/math_parser.py:412: SyntaxWarning: invalid escape sequence '\d'
2025-11-21T23:37:31.117459679Z   pattern = "-?\d*\.?\d+"
2025-11-21T23:37:33.097616501Z [37m20251121-23:37:33.097 [FSDP Engine Rank 0] INFO: Microbatch #tokens (rank 0): [5097, 613], padded to: [5120, 768], padding lengths: [23, 155][0m
2025-11-21T23:37:34.945523627Z [37m20251121-23:37:34.945 /workspace/AReaL/areal/utils/device.py INFO: recompute logp, memory allocated (GB): 0.93, memory reserved (GB): 3.22, device memory used/total (GB): 30.58/31.36[0m
2025-11-21T23:37:35.021570764Z [37m20251121-23:37:35.021 /workspace/AReaL/areal/utils/device.py INFO: compute advantages, memory allocated (GB): 0.93, memory reserved (GB): 3.22, device memory used/total (GB): 30.58/31.36[0m
2025-11-21T23:37:35.035396075Z [37m20251121-23:37:35.035 [FSDP Engine Rank 0] INFO: Microbatch #tokens (rank 0): [5097, 613], padded to: [5120, 768], padding lengths: [23, 155][0m
2025-11-21T23:37:35.078164245Z [rank0]: Traceback (most recent call last):
2025-11-21T23:37:35.078181367Z [rank0]:   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 521, in <module>
2025-11-21T23:37:35.078183190Z [rank0]:     main(sys.argv[1:])
2025-11-21T23:37:35.078184583Z [rank0]:   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 293, in main
2025-11-21T23:37:35.078186176Z [rank0]:     stats = actor.ppo_update(batch)
2025-11-21T23:37:35.078187388Z [rank0]:             ^^^^^^^^^^^^^^^^^^^^^^^
2025-11-21T23:37:35.078188240Z [rank0]:   File "/workspace/AReaL/areal/engine/ppo/actor.py", line 292, in ppo_update
2025-11-21T23:37:35.078189823Z [rank0]:     return self.actor.ppo_update(*args, **kwargs)
2025-11-21T23:37:35.078191436Z [rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-21T23:37:35.078192327Z [rank0]:   File "/workspace/AReaL/areal/engine/ppo/actor.py", line 258, in ppo_update
2025-11-21T23:37:35.078193239Z [rank0]:     train_stat = self.engine.train_batch(
2025-11-21T23:37:35.078194161Z [rank0]:                  ^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-21T23:37:35.078195173Z [rank0]:   File "/workspace/AReaL/areal/engine/fsdp_engine.py", line 571, in train_batch
2025-11-21T23:37:35.078196074Z [rank0]:     outputs = self.model(**inputs)
2025-11-21T23:37:35.078196886Z [rank0]:               ^^^^^^^^^^^^^^^^^^^^
2025-11-21T23:37:35.078197748Z [rank0]:   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
2025-11-21T23:37:35.078198960Z [rank0]:     return self._call_impl(*args, **kwargs)
2025-11-21T23:37:35.078199701Z [rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-21T23:37:35.078200443Z [rank0]:   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1879, in _call_impl
2025-11-21T23:37:35.078201244Z [rank0]:     return inner()
2025-11-21T23:37:35.078201995Z [rank0]:            ^^^^^^^
2025-11-21T23:37:35.078202737Z [rank0]:   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1827, in inner
2025-11-21T23:37:35.078203879Z [rank0]:     result = forward_call(*args, **kwargs)
2025-11-21T23:37:35.078204580Z [rank0]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-21T23:37:35.078205332Z [rank0]:   File "/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py", line 940, in wrapper
2025-11-21T23:37:35.078206113Z [rank0]:     output = func(self, *args, **kwargs)
2025-11-21T23:37:35.078206875Z [rank0]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-21T23:37:35.078207616Z [rank0]:   File "/usr/local/lib/python3.12/dist-packages/transformers/models/qwen2/modeling_qwen2.py", line 449, in forward
2025-11-21T23:37:35.078208428Z [rank0]:     outputs: BaseModelOutputWithPast = self.model(
2025-11-21T23:37:35.078209209Z [rank0]:                                        ^^^^^^^^^^^
2025-11-21T23:37:35.078210411Z [rank0]:   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
2025-11-21T23:37:35.078211203Z [rank0]:     return self._call_impl(*args, **kwargs)
2025-11-21T23:37:35.078211944Z [rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-21T23:37:35.078222444Z [rank0]:   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1784, in _call_impl
2025-11-21T23:37:35.078223486Z [rank0]:     return forward_call(*args, **kwargs)
2025-11-21T23:37:35.078224247Z [rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-21T23:37:35.078224988Z [rank0]:   File "/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py", line 1064, in wrapper
2025-11-21T23:37:35.078225840Z [rank0]:     outputs = func(self, *args, **kwargs)
2025-11-21T23:37:35.078226551Z [rank0]:               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-21T23:37:35.078227323Z [rank0]:   File "/usr/local/lib/python3.12/dist-packages/transformers/models/qwen2/modeling_qwen2.py", line 384, in forward
2025-11-21T23:37:35.078228235Z [rank0]:     hidden_states = decoder_layer(
2025-11-21T23:37:35.078228966Z [rank0]:                     ^^^^^^^^^^^^^^
2025-11-21T23:37:35.078229717Z [rank0]:   File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_layers.py", line 94, in __call__
2025-11-21T23:37:35.078232392Z [rank0]:     return super().__call__(*args, **kwargs)
2025-11-21T23:37:35.078233184Z [rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-21T23:37:35.078233915Z [rank0]:   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
2025-11-21T23:37:35.078235047Z [rank0]:     return self._call_impl(*args, **kwargs)
2025-11-21T23:37:35.078236039Z [rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-21T23:37:35.078236821Z [rank0]:   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1879, in _call_impl
2025-11-21T23:37:35.078237973Z [rank0]:     return inner()
2025-11-21T23:37:35.078238754Z [rank0]:            ^^^^^^^
2025-11-21T23:37:35.078239506Z [rank0]:   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1827, in inner
2025-11-21T23:37:35.078240247Z [rank0]:     result = forward_call(*args, **kwargs)
2025-11-21T23:37:35.078240958Z [rank0]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-21T23:37:35.078241690Z [rank0]:   File "/usr/local/lib/python3.12/dist-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
2025-11-21T23:37:35.078242842Z [rank0]:     return func(*args, **kwargs)
2025-11-21T23:37:35.078243633Z [rank0]:            ^^^^^^^^^^^^^^^^^^^^^
2025-11-21T23:37:35.078244365Z [rank0]:   File "/usr/local/lib/python3.12/dist-packages/transformers/models/qwen2/modeling_qwen2.py", line 249, in forward
2025-11-21T23:37:35.078245186Z [rank0]:     hidden_states = self.mlp(hidden_states)
2025-11-21T23:37:35.078246048Z [rank0]:                     ^^^^^^^^^^^^^^^^^^^^^^^
2025-11-21T23:37:35.078246819Z [rank0]:   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
2025-11-21T23:37:35.078247711Z [rank0]:     return self._call_impl(*args, **kwargs)
2025-11-21T23:37:35.078248422Z [rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-21T23:37:35.078249164Z [rank0]:   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1784, in _call_impl
2025-11-21T23:37:35.078249895Z [rank0]:     return forward_call(*args, **kwargs)
2025-11-21T23:37:35.078250616Z [rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-21T23:37:35.078251348Z [rank0]:   File "/usr/local/lib/python3.12/dist-packages/transformers/models/qwen2/modeling_qwen2.py", line 46, in forward
2025-11-21T23:37:35.078252169Z [rank0]:     down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))
2025-11-21T23:37:35.078254594Z [rank0]:                                                                 ^^^^^^^^^^^^^^^
2025-11-21T23:37:35.078255315Z [rank0]:   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
2025-11-21T23:37:35.078256097Z [rank0]:     return self._call_impl(*args, **kwargs)
2025-11-21T23:37:35.078256838Z [rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-21T23:37:35.078257579Z [rank0]:   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1784, in _call_impl
2025-11-21T23:37:35.078258311Z [rank0]:     return forward_call(*args, **kwargs)
2025-11-21T23:37:35.078260515Z [rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-21T23:37:35.078261296Z [rank0]:   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py", line 125, in forward
2025-11-21T23:37:35.078262048Z [rank0]:     return F.linear(input, self.weight, self.bias)
2025-11-21T23:37:35.078262769Z [rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-21T23:37:35.078263831Z [rank0]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 31.36 GiB of which 35.94 MiB is free. Process 899 has 25.60 GiB memory in use. Including non-PyTorch memory, this process has 5.71 GiB memory in use. Of the allocated memory 3.91 GiB is allocated by PyTorch, and 54.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-11-21T23:37:36.326317001Z [rank0]:[W1121 23:37:36.477469199 ProcessGroupNCCL.cpp:1538] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
2025-11-21T23:37:37.818114486Z E1121 23:37:37.817000 1343 torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 0 (pid: 1377) of binary: /usr/bin/python3
2025-11-21T23:37:37.818368130Z Traceback (most recent call last):
2025-11-21T23:37:37.818780501Z   File "/usr/local/bin/torchrun", line 7, in <module>
2025-11-21T23:37:37.818805348Z     sys.exit(main())
2025-11-21T23:37:37.818807131Z              ^^^^^^
2025-11-21T23:37:37.818808353Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
2025-11-21T23:37:37.818809956Z     return f(*args, **kwargs)
2025-11-21T23:37:37.818811499Z            ^^^^^^^^^^^^^^^^^^
2025-11-21T23:37:37.818812862Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 901, in main
2025-11-21T23:37:37.818814535Z     run(args)
2025-11-21T23:37:37.818815887Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 892, in run
2025-11-21T23:37:37.818816919Z     elastic_launch(
2025-11-21T23:37:37.818817961Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 143, in __call__
2025-11-21T23:37:37.818819294Z     return launch_agent(self._config, self._entrypoint, list(args))
2025-11-21T23:37:37.819072567Z            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-21T23:37:37.819076905Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 277, in launch_agent
2025-11-21T23:37:37.819077717Z     raise ChildFailedError(
2025-11-21T23:37:37.819078288Z torch.distributed.elastic.multiprocessing.errors.ChildFailedError:
2025-11-21T23:37:37.819078829Z ============================================================
2025-11-21T23:37:37.819079420Z examples/cloud_gsm8k/gsm8k_grpo_train.py FAILED
2025-11-21T23:37:37.819080262Z ------------------------------------------------------------
2025-11-21T23:37:37.819080763Z Failures:
2025-11-21T23:37:37.819081264Z   <NO_OTHER_FAILURES>
2025-11-21T23:37:37.819081825Z ------------------------------------------------------------
2025-11-21T23:37:37.819082666Z Root Cause (first observed failure):
2025-11-21T23:37:37.819083257Z [0]:
2025-11-21T23:37:37.819083848Z   time      : 2025-11-21_23:37:37
2025-11-21T23:37:37.819084399Z   host      : add0c0f04add
2025-11-21T23:37:37.819084890Z   rank      : 0 (local_rank: 0)
2025-11-21T23:37:37.819085481Z   exitcode  : 1 (pid: 1377)
2025-11-21T23:37:37.819085962Z   error_file: <N/A>
2025-11-21T23:37:37.819086463Z   traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
2025-11-21T23:37:37.819087064Z ============================================================
2025-11-21T23:37:38.334364014Z [37m20251121-23:37:38.334 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [687][0m
2025-11-21T23:37:38.354653923Z Killed
2025-11-21T23:37:38.355419424Z [37m20251121-23:37:38.355 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [1342][0m
2025-11-21T23:37:38.355661367Z Traceback (most recent call last):
2025-11-21T23:37:38.355663230Z   File "<frozen runpy>", line 198, in _run_module_as_main
2025-11-21T23:37:38.355664583Z   File "<frozen runpy>", line 88, in _run_code
2025-11-21T23:37:38.355666246Z   File "/workspace/AReaL/areal/launcher/local.py", line 405, in <module>
2025-11-21T23:37:38.355767145Z     main()
2025-11-21T23:37:38.355785098Z   File "/workspace/AReaL/areal/launcher/local.py", line 260, in main
2025-11-21T23:37:38.355802350Z     local_main(config, run_id=0)
2025-11-21T23:37:38.355816146Z   File "/workspace/AReaL/areal/launcher/local.py", line 399, in local_main
2025-11-21T23:37:38.355846152Z     raise e
2025-11-21T23:37:38.355871119Z   File "/workspace/AReaL/areal/launcher/local.py", line 375, in local_main
2025-11-21T23:37:38.355872101Z     launcher.wait(
2025-11-21T23:37:38.355881148Z   File "/workspace/AReaL/areal/launcher/local.py", line 235, in wait
2025-11-21T23:37:38.355887069Z     raise JobException(
2025-11-21T23:37:38.355891637Z areal.utils.launcher.JobException: Job gsm8k-grpo-reasoning-fast_trial_20251121_233637:trainer JobState.COMPLETED at node local
2025-11-21T23:37:38.559865447Z [37m20251121-23:37:38.559 Local Scheduler INFO: Waiting for 0 local running processes, pids: [0m
2025-11-21T23:37:48.014778323Z ==========
2025-11-21T23:37:48.014785286Z == CUDA ==
2025-11-21T23:37:48.014815522Z ==========
2025-11-21T23:37:48.016370260Z CUDA Version 12.9.1
2025-11-21T23:37:48.016868080Z Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
2025-11-21T23:37:48.017200783Z This container image and its contents are governed by the NVIDIA Deep Learning Container License.
2025-11-21T23:37:48.017202085Z By pulling and using the container, you accept the terms and conditions of this license:
2025-11-21T23:37:48.017203037Z https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license
2025-11-21T23:37:48.017204540Z A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
2025-11-21T23:37:48.095966843Z Writing to /root/.config/pip/pip.conf
2025-11-21T23:37:48.181437831Z Writing to /root/.config/pip/pip.conf
2025-11-21T23:37:48.583070323Z Branch 'feature/reasoning_model' set up to track remote branch 'feature/reasoning_model' from 'origin'.
2025-11-21T23:37:48.583089208Z Your branch is up to date with 'origin/feature/reasoning_model'.
2025-11-21T23:37:48.614300328Z Checking AReaL installation...
2025-11-21T23:37:48.641014690Z AReaL already installed. Skipping installation.
2025-11-21T23:37:48.641016974Z Cleaning up any leftover GPU processes...
2025-11-21T23:37:51.646160687Z Checking for processes holding GPU device files...
2025-11-21T23:37:51.774932521Z Found processes holding GPU devices: 1
2025-11-21T23:37:51.774945756Z 20
2025-11-21T23:37:51.774947238Z 70
2025-11-21T23:37:51.774948340Z 71
2025-11-21T23:37:51.774949543Z Killing process 1...
2025-11-21T23:37:51.774954772Z Killing process 70...
2025-11-21T23:37:51.775061742Z Killing process 71...
2025-11-21T23:37:53.776111000Z Using fuser to kill processes on GPU devices...
2025-11-21T23:37:55.783859555Z Checking GPU...
2025-11-21T23:37:55.798903605Z NVIDIA GeForce RTX 5090, 32607 MiB
2025-11-21T23:37:55.803867507Z Set PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True for better memory management
2025-11-21T23:37:55.803873649Z Detected 1 GPU(s)
2025-11-21T23:37:55.803874721Z Checking GPU status...
2025-11-21T23:37:55.814833572Z index, name, utilization.gpu [%], memory.used [MiB], compute_mode
2025-11-21T23:37:55.816607329Z 0, NVIDIA GeForce RTX 5090, 0, 2, Default
2025-11-21T23:37:55.833929028Z Verifying GPU accessibility...
2025-11-21T23:37:56.097815135Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-21T23:37:56.097850461Z   import pynvml  # type: ignore[import]
2025-11-21T23:37:56.640373286Z GPU accessibility verified on attempt 1
2025-11-21T23:37:56.874438943Z Starting training...
2025-11-21T23:37:59.875410935Z Using REASONING FAST training configuration (20-30 minutes)
2025-11-21T23:37:59.875440220Z Note: Trains reasoning model with XML format
2025-11-21T23:37:59.876305818Z ==========================================
2025-11-21T23:37:59.876307742Z Starting GRPO Training (Cloud)
2025-11-21T23:37:59.876309586Z ==========================================
2025-11-21T23:37:59.876310447Z Config: reasoning_fast
2025-11-21T23:37:59.876311549Z Config file: examples/cloud_gsm8k/gsm8k_grpo_reasoning_fast.yaml
2025-11-21T23:37:59.876312631Z Training script: examples/cloud_gsm8k/gsm8k_grpo_train.py
2025-11-21T23:37:59.876313353Z Experiment: gsm8k-grpo-reasoning-fast
2025-11-21T23:37:59.876314775Z Trial: trial_20251121_233759
2025-11-21T23:37:59.876315817Z GPU: NVIDIA GeForce RTX 5090 (32607 MB)
2025-11-21T23:37:59.876319183Z WandB API key: e1adc5be02...
2025-11-21T23:37:59.876320025Z ==========================================
2025-11-21T23:38:00.270303574Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-21T23:38:00.270334542Z   import pynvml  # type: ignore[import]
2025-11-21T23:38:02.319951625Z [37m20251121-23:38:02.319 Platform init INFO: Detected CUDA device: NVIDIA GEFORCE RTX 5090[0m
2025-11-21T23:38:02.319983675Z [37m20251121-23:38:02.319 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-21T23:38:02.320149104Z [37m20251121-23:38:02.319 name-resolve INFO: No such name resolve path: ./tmp/areal/name_resolve/root/gsm8k-grpo-reasoning-fast/trial_20251121_233759[0m
2025-11-21T23:38:02.379060700Z [37m20251121-23:38:02.378 Local Scheduler INFO: LocalLauncher: experiment_name=gsm8k-grpo-reasoning-fast, trial_name=trial_20251121_233759, fileroot=/workspace/outputs/grpo, run_id=0, is_recover_run=False[0m
2025-11-21T23:38:02.383929734Z [37m20251121-23:38:02.383 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL CUDA_VISIBLE_DEVICES=0 stdbuf -oL python3 -m areal.launcher.sglang_server examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_reasoning_fast.yaml experiment_name=gsm8k-grpo-reasoning-fast trial_name=trial_20251121_233759 sglang.random_seed=1 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-reasoning-fast/trial_20251121_233759/llm_server.log[0m
2025-11-21T23:38:02.777630736Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-21T23:38:02.777656614Z   import pynvml  # type: ignore[import]
2025-11-21T23:38:03.545784457Z [37m20251121-23:38:03.545 Platform init INFO: Detected CUDA device: NVIDIA GEFORCE RTX 5090[0m
2025-11-21T23:38:03.546013425Z [37m20251121-23:38:03.545 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-21T23:38:03.611982737Z [37m20251121-23:38:03.611 SGLangServer Wrapper INFO: Launch command: python3 -m sglang.launch_server --host 172.18.0.2 --port 21648 --tokenizer-path Qwen/Qwen2.5-0.5B-Instruct --tokenizer-mode auto --load-format auto --trust-remote-code --device cuda --tp-size 1 --base-gpu-id 0 --nnodes 1 --node-rank 0 --dist-init-addr localhost:41742 --model-path Qwen/Qwen2.5-0.5B-Instruct --random-seed 1 --skip-tokenizer-init --disable-radix-cache --torch-compile-max-bs 32 --triton-attention-num-kv-splits 8 --num-continuous-decode-steps 1 --attention-backend triton --context-length 4096 --mem-fraction-static 0.8 --chunked-prefill-size -1 --max-prefill-tokens 32768 --schedule-policy lpm --schedule-conservativeness 1.0 --cpu-offload-gb 0 --dtype bfloat16 --kv-cache-dtype auto --dp-size 1 --ep-size 1 --max-loaded-loras 1 --max-loras-per-batch 1 --lora-backend triton --log-level warning --log-level-http warning --log-requests-level 0 --enable-metrics --decode-log-interval 1[0m
2025-11-21T23:38:04.173609624Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-21T23:38:04.173632146Z   import pynvml  # type: ignore[import]
2025-11-21T23:38:07.206286089Z INFO 11-21 23:38:07 [__init__.py:216] Automatically detected platform cuda.
2025-11-21T23:38:07.741889696Z All deep_gemm operations loaded successfully!
2025-11-21T23:38:07.912532382Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-21T23:38:08.335318168Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-21T23:38:08.335347412Z   import pynvml  # type: ignore[import]
2025-11-21T23:38:08.335349536Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-21T23:38:08.335350859Z   import pynvml  # type: ignore[import]
2025-11-21T23:38:11.629341581Z INFO 11-21 23:38:11 [__init__.py:216] Automatically detected platform cuda.
2025-11-21T23:38:11.629743924Z INFO 11-21 23:38:11 [__init__.py:216] Automatically detected platform cuda.
2025-11-21T23:38:12.309780158Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-21T23:38:12.657236318Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-21T23:38:12.659114490Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-21T23:38:12.659463332Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-21T23:38:12.659734069Z [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
2025-11-21T23:38:12.678869178Z [2025-11-21 23:38:12] MOE_RUNNER_BACKEND is not initialized, using triton backend
2025-11-21T23:38:12.926363836Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-21T23:38:12.926382050Z   warnings.warn(
2025-11-21T23:38:12.926383553Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-21T23:38:12.926384294Z   warnings.warn(
2025-11-21T23:38:14.092642069Z All deep_gemm operations loaded successfully!
2025-11-21T23:38:14.092936860Z Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
2025-11-21T23:38:14.185073161Z Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00, 10.84it/s]
2025-11-21T23:38:14.984859510Z   0%|          | 0/4 [00:00<?, ?it/s]Capturing batches (bs=8 avail_mem=6.00 GB):   0%|          | 0/4 [00:00<?, ?it/s]Capturing batches (bs=8 avail_mem=6.00 GB):  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  3.37it/s]Capturing batches (bs=4 avail_mem=5.95 GB):  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  3.37it/s]Capturing batches (bs=2 avail_mem=5.95 GB):  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  3.37it/s]Capturing batches (bs=1 avail_mem=5.94 GB):  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  3.37it/s]Capturing batches (bs=1 avail_mem=5.94 GB): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 11.23it/s]
2025-11-21T23:38:20.623407940Z [37m20251121-23:38:20.623 SGLangServer Wrapper INFO: SGLang server launched at: http://172.18.0.2:21648[0m
2025-11-21T23:38:21.386592299Z [37m20251121-23:38:21.386 Launcher Utils INFO: Found 1 rollout servers: 172.18.0.2:21648[0m
2025-11-21T23:38:21.386636481Z [37m20251121-23:38:21.386 Local Scheduler INFO: LLM inference server launched at: AREAL_LLM_SERVER_ADDRS=172.18.0.2:21648[0m
2025-11-21T23:38:21.388523830Z [37m20251121-23:38:21.388 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL AREAL_LLM_SERVER_ADDRS=172.18.0.2:21648 AREAL_RECOVER_RUN=0 NCCL_CUMEM_ENABLE=0 NCCL_NVLS_ENABLE=0 CUDA_VISIBLE_DEVICES=0 stdbuf -oL torchrun --nnodes 1 --nproc-per-node 1 --master-addr localhost --master-port 29001 examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_reasoning_fast.yaml experiment_name=gsm8k-grpo-reasoning-fast trial_name=trial_20251121_233759 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-reasoning-fast/trial_20251121_233759/trainer.log[0m
2025-11-21T23:38:21.388760663Z [37m20251121-23:38:21.388 Local Scheduler INFO: Waiting for 2 local running processes, pids: 218 612[0m
2025-11-21T23:38:21.686753615Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-21T23:38:21.686781667Z   import pynvml  # type: ignore[import]
2025-11-21T23:38:22.296848229Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-21T23:38:22.296876522Z   import pynvml  # type: ignore[import]
2025-11-21T23:38:26.013141453Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-21T23:38:26.013173483Z   warnings.warn(
2025-11-21T23:38:26.013175707Z /usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
2025-11-21T23:38:26.013188962Z   warnings.warn(
2025-11-21T23:38:28.236736418Z [37m20251121-23:38:28.236 Platform init INFO: Detected CUDA device: NVIDIA GEFORCE RTX 5090[0m
2025-11-21T23:38:28.237019557Z [37m20251121-23:38:28.236 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-21T23:38:28.450778655Z [37m20251121-23:38:28.450 [FSDP Engine Rank 0] INFO: Initializing device mesh with parallel dims (dp=1, sp=1, tp=1, ep=1, etp=1, world_size=1).[0m
2025-11-21T23:38:28.451741876Z [37m20251121-23:38:28.451 [FSDP Engine Rank 0] INFO: Data parallel head 0 and rank 0[0m
2025-11-21T23:38:31.506612750Z [REASONING-FAST] Limiting dataset from 7473 to 200 samples
2025-11-21T23:38:31.508151818Z [37m20251121-23:38:31.508 Launcher Utils INFO: Found 1 rollout servers: 172.18.0.2:21648[0m
2025-11-21T23:38:31.508375446Z [37m20251121-23:38:31.508 [Remote Inference Engine Rank 0] INFO: Get server addresses from name_resolve.[0m
2025-11-21T23:38:31.508377129Z [37m20251121-23:38:31.508 [Remote Inference Engine Rank 0] INFO: Waiting for server ready...[0m
2025-11-21T23:38:32.510295986Z [37m20251121-23:38:32.510 [Remote Inference Engine Rank 0] INFO: Servers are all ready![0m
2025-11-21T23:38:32.511478146Z [37m20251121-23:38:32.511 Launcher Utils INFO: Found 1 rollout servers: 172.18.0.2:21648[0m
2025-11-21T23:38:32.511826878Z [37m20251121-23:38:32.511 [Remote Inference Engine Rank 0] INFO: Get server addresses from name_resolve.[0m
2025-11-21T23:38:32.511829814Z [37m20251121-23:38:32.511 [Remote Inference Engine Rank 0] INFO: Waiting for server ready...[0m
2025-11-21T23:38:33.513335066Z [37m20251121-23:38:33.513 [Remote Inference Engine Rank 0] INFO: Servers are all ready![0m
2025-11-21T23:38:34.231785319Z [37m20251121-23:38:34.231 [FSDP Engine Rank 0] INFO: Model creation and loading time: 0.6614398509263992[0m
2025-11-21T23:38:34.561813882Z [37m20251121-23:38:34.561 [FSDP Engine Rank 0] INFO: Applying FSDP2 with N-D parallelism for 0.33 seconds[0m
2025-11-21T23:38:34.562199794Z [37m20251121-23:38:34.562 [FSDP Engine Rank 0] INFO: Create optimizer time: 0.00036931969225406647[0m
2025-11-21T23:38:34.674922458Z swanlab: SwanLab run disabled, the data will not be saved or uploaded.
2025-11-21T23:38:34.862536168Z ================================================================================
2025-11-21T23:38:34.862770376Z [REASONING-FAST MODE]
2025-11-21T23:38:34.862782448Z   Dataset size: 200 samples (limited from 7473)
2025-11-21T23:38:34.862784753Z   Batch size: 8
2025-11-21T23:38:34.862786235Z   Steps per epoch: 25
2025-11-21T23:38:34.862787377Z   Total epochs: 1
2025-11-21T23:38:34.862788349Z   Total steps: 25
2025-11-21T23:38:34.862789361Z   Estimated time: ~25 minutes (~0.4 hours) at ~1 step/min
2025-11-21T23:38:34.862790864Z   Circuit breaker: Enabled (threshold: 10 consecutive zero rewards)
2025-11-21T23:38:34.862791926Z ================================================================================
2025-11-21T23:38:39.004951495Z [37m20251121-23:38:39.004 [FSDP Engine Rank 0] INFO: Microbatch #tokens (rank 0): [4857, 936], padded to: [4864, 1024], padding lengths: [7, 88][0m
2025-11-21T23:38:39.957900876Z [37m20251121-23:38:39.957 /workspace/AReaL/areal/utils/device.py INFO: recompute logp, memory allocated (GB): 0.93, memory reserved (GB): 3.18, device memory used/total (GB): 30.54/31.36[0m
2025-11-21T23:38:40.234657920Z [37m20251121-23:38:40.234 /workspace/AReaL/areal/utils/device.py INFO: compute advantages, memory allocated (GB): 0.93, memory reserved (GB): 3.18, device memory used/total (GB): 30.54/31.36[0m
2025-11-21T23:38:40.246723220Z [37m20251121-23:38:40.246 [FSDP Engine Rank 0] INFO: Microbatch #tokens (rank 0): [4857, 936], padded to: [4864, 1024], padding lengths: [7, 88][0m
2025-11-21T23:38:40.282934540Z [rank0]: Traceback (most recent call last):
2025-11-21T23:38:40.282937976Z [rank0]:   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 521, in <module>
2025-11-21T23:38:40.282939689Z [rank0]:     main(sys.argv[1:])
2025-11-21T23:38:40.282951141Z [rank0]:   File "/workspace/AReaL/examples/cloud_gsm8k/gsm8k_grpo_train.py", line 293, in main
2025-11-21T23:38:40.282952333Z [rank0]:     stats = actor.ppo_update(batch)
2025-11-21T23:38:40.282953154Z [rank0]:             ^^^^^^^^^^^^^^^^^^^^^^^
2025-11-21T23:38:40.282953976Z [rank0]:   File "/workspace/AReaL/areal/engine/ppo/actor.py", line 292, in ppo_update
2025-11-21T23:38:40.282954968Z [rank0]:     return self.actor.ppo_update(*args, **kwargs)
2025-11-21T23:38:40.282955960Z [rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-21T23:38:40.282956791Z [rank0]:   File "/workspace/AReaL/areal/engine/ppo/actor.py", line 258, in ppo_update
2025-11-21T23:38:40.282957623Z [rank0]:     train_stat = self.engine.train_batch(
2025-11-21T23:38:40.282958434Z [rank0]:                  ^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-21T23:38:40.282959186Z [rank0]:   File "/workspace/AReaL/areal/engine/fsdp_engine.py", line 571, in train_batch
2025-11-21T23:38:40.282959947Z [rank0]:     outputs = self.model(**inputs)
2025-11-21T23:38:40.282960719Z [rank0]:               ^^^^^^^^^^^^^^^^^^^^
2025-11-21T23:38:40.282961470Z [rank0]:   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
2025-11-21T23:38:40.282962432Z [rank0]:     return self._call_impl(*args, **kwargs)
2025-11-21T23:38:40.282963173Z [rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-21T23:38:40.282963935Z [rank0]:   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1879, in _call_impl
2025-11-21T23:38:40.282964746Z [rank0]:     return inner()
2025-11-21T23:38:40.282965497Z [rank0]:            ^^^^^^^
2025-11-21T23:38:40.282966249Z [rank0]:   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1827, in inner
2025-11-21T23:38:40.282967010Z [rank0]:     result = forward_call(*args, **kwargs)
2025-11-21T23:38:40.282967742Z [rank0]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-21T23:38:40.282968503Z [rank0]:   File "/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py", line 940, in wrapper
2025-11-21T23:38:40.282969595Z [rank0]:     output = func(self, *args, **kwargs)
2025-11-21T23:38:40.282970928Z [rank0]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-21T23:38:40.282971689Z [rank0]:   File "/usr/local/lib/python3.12/dist-packages/transformers/models/qwen2/modeling_qwen2.py", line 449, in forward
2025-11-21T23:38:40.282972440Z [rank0]:     outputs: BaseModelOutputWithPast = self.model(
2025-11-21T23:38:40.282973172Z [rank0]:                                        ^^^^^^^^^^^
2025-11-21T23:38:40.282974314Z [rank0]:   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
2025-11-21T23:38:40.282975296Z [rank0]:     return self._call_impl(*args, **kwargs)
2025-11-21T23:38:40.282976047Z [rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-21T23:38:40.282976789Z [rank0]:   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1784, in _call_impl
2025-11-21T23:38:40.282977660Z [rank0]:     return forward_call(*args, **kwargs)
2025-11-21T23:38:40.282978372Z [rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-21T23:38:40.282979103Z [rank0]:   File "/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py", line 1064, in wrapper
2025-11-21T23:38:40.282980025Z [rank0]:     outputs = func(self, *args, **kwargs)
2025-11-21T23:38:40.282980766Z [rank0]:               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-21T23:38:40.282981507Z [rank0]:   File "/usr/local/lib/python3.12/dist-packages/transformers/models/qwen2/modeling_qwen2.py", line 384, in forward
2025-11-21T23:38:40.282982339Z [rank0]:     hidden_states = decoder_layer(
2025-11-21T23:38:40.282983060Z [rank0]:                     ^^^^^^^^^^^^^^
2025-11-21T23:38:40.282983822Z [rank0]:   File "/usr/local/lib/python3.12/dist-packages/transformers/modeling_layers.py", line 94, in __call__
2025-11-21T23:38:40.282984623Z [rank0]:     return super().__call__(*args, **kwargs)
2025-11-21T23:38:40.282985365Z [rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-21T23:38:40.282986116Z [rank0]:   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
2025-11-21T23:38:40.282988641Z [rank0]:     return self._call_impl(*args, **kwargs)
2025-11-21T23:38:40.282989392Z [rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-21T23:38:40.282990164Z [rank0]:   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1879, in _call_impl
2025-11-21T23:38:40.282990985Z [rank0]:     return inner()
2025-11-21T23:38:40.282991716Z [rank0]:            ^^^^^^^
2025-11-21T23:38:40.282992448Z [rank0]:   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1827, in inner
2025-11-21T23:38:40.282993229Z [rank0]:     result = forward_call(*args, **kwargs)
2025-11-21T23:38:40.282993971Z [rank0]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-21T23:38:40.282994712Z [rank0]:   File "/usr/local/lib/python3.12/dist-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
2025-11-21T23:38:40.282995443Z [rank0]:     return func(*args, **kwargs)
2025-11-21T23:38:40.282996185Z [rank0]:            ^^^^^^^^^^^^^^^^^^^^^
2025-11-21T23:38:40.282996936Z [rank0]:   File "/usr/local/lib/python3.12/dist-packages/transformers/models/qwen2/modeling_qwen2.py", line 248, in forward
2025-11-21T23:38:40.282997678Z [rank0]:     hidden_states = self.post_attention_layernorm(hidden_states)
2025-11-21T23:38:40.282999301Z [rank0]:                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-21T23:38:40.283000132Z [rank0]:   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
2025-11-21T23:38:40.283000944Z [rank0]:     return self._call_impl(*args, **kwargs)
2025-11-21T23:38:40.283001735Z [rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-21T23:38:40.283002467Z [rank0]:   File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1784, in _call_impl
2025-11-21T23:38:40.283003308Z [rank0]:     return forward_call(*args, **kwargs)
2025-11-21T23:38:40.283004019Z [rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-21T23:38:40.283004751Z [rank0]:   File "/usr/local/lib/python3.12/dist-packages/transformers/models/qwen2/modeling_qwen2.py", line 201, in forward
2025-11-21T23:38:40.283005663Z [rank0]:     return self.weight * hidden_states.to(input_dtype)
2025-11-21T23:38:40.283006394Z [rank0]:            ~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
2025-11-21T23:38:40.283007526Z [rank0]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 31.36 GiB of which 15.94 MiB is free. Process 369 has 25.60 GiB memory in use. Including non-PyTorch memory, this process has 5.73 GiB memory in use. Of the allocated memory 3.96 GiB is allocated by PyTorch, and 26.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-11-21T23:38:41.377962506Z [rank0]:[W1121 23:38:41.529104394 ProcessGroupNCCL.cpp:1538] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
2025-11-21T23:38:42.669958352Z E1121 23:38:42.669000 613 torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 0 (pid: 647) of binary: /usr/bin/python3
2025-11-21T23:38:42.670712512Z Traceback (most recent call last):
2025-11-21T23:38:42.670726979Z   File "/usr/local/bin/torchrun", line 7, in <module>
2025-11-21T23:38:42.670737979Z     sys.exit(main())
2025-11-21T23:38:42.670740143Z              ^^^^^^
2025-11-21T23:38:42.670741626Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
2025-11-21T23:38:42.670743419Z     return f(*args, **kwargs)
2025-11-21T23:38:42.670744762Z            ^^^^^^^^^^^^^^^^^^
2025-11-21T23:38:42.670745824Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 901, in main
2025-11-21T23:38:42.670770210Z     run(args)
2025-11-21T23:38:42.670771843Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/run.py", line 892, in run
2025-11-21T23:38:42.670773255Z     elastic_launch(
2025-11-21T23:38:42.670774297Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 143, in __call__
2025-11-21T23:38:42.670775980Z     return launch_agent(self._config, self._entrypoint, list(args))
2025-11-21T23:38:42.670777824Z            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-21T23:38:42.670779016Z   File "/usr/local/lib/python3.12/dist-packages/torch/distributed/launcher/api.py", line 277, in launch_agent
2025-11-21T23:38:42.671044452Z     raise ChildFailedError(
2025-11-21T23:38:42.671046967Z torch.distributed.elastic.multiprocessing.errors.ChildFailedError:
2025-11-21T23:38:42.671047668Z ============================================================
2025-11-21T23:38:42.671048249Z examples/cloud_gsm8k/gsm8k_grpo_train.py FAILED
2025-11-21T23:38:42.671048760Z ------------------------------------------------------------
2025-11-21T23:38:42.671049412Z Failures:
2025-11-21T23:38:42.671049983Z   <NO_OTHER_FAILURES>
2025-11-21T23:38:42.671050514Z ------------------------------------------------------------
2025-11-21T23:38:42.671051055Z Root Cause (first observed failure):
2025-11-21T23:38:42.671052848Z [0]:
2025-11-21T23:38:42.671053549Z   time      : 2025-11-21_23:38:42
2025-11-21T23:38:42.671054130Z   host      : add0c0f04add
2025-11-21T23:38:42.671054671Z   rank      : 0 (local_rank: 0)
2025-11-21T23:38:42.671055233Z   exitcode  : 1 (pid: 647)
2025-11-21T23:38:42.671055723Z   error_file: <N/A>
2025-11-21T23:38:42.671056244Z   traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
2025-11-21T23:38:42.671056866Z ============================================================
2025-11-21T23:38:43.391839059Z [37m20251121-23:38:43.391 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [218][0m
2025-11-21T23:38:43.412129769Z Killed
2025-11-21T23:38:43.413438817Z [37m20251121-23:38:43.413 Local Scheduler INFO: Stopping local process with signal SIGTERM, pid: [612][0m
2025-11-21T23:38:43.413749177Z Traceback (most recent call last):
2025-11-21T23:38:43.413764466Z   File "<frozen runpy>", line 198, in _run_module_as_main
2025-11-21T23:38:43.413765698Z   File "<frozen runpy>", line 88, in _run_code
2025-11-21T23:38:43.413766560Z   File "/workspace/AReaL/areal/launcher/local.py", line 405, in <module>
2025-11-21T23:38:43.413834617Z     main()
2025-11-21T23:38:43.413852821Z   File "/workspace/AReaL/areal/launcher/local.py", line 260, in main
2025-11-21T23:38:43.413879241Z     local_main(config, run_id=0)
2025-11-21T23:38:43.413892275Z   File "/workspace/AReaL/areal/launcher/local.py", line 399, in local_main
2025-11-21T23:38:43.413920418Z     raise e
2025-11-21T23:38:43.413925156Z   File "/workspace/AReaL/areal/launcher/local.py", line 375, in local_main
2025-11-21T23:38:43.413949392Z     launcher.wait(
2025-11-21T23:38:43.413953530Z   File "/workspace/AReaL/areal/launcher/local.py", line 235, in wait
2025-11-21T23:38:43.413969359Z     raise JobException(
2025-11-21T23:38:43.413976052Z areal.utils.launcher.JobException: Job gsm8k-grpo-reasoning-fast_trial_20251121_233759:trainer JobState.COMPLETED at node local
2025-11-21T23:38:43.623029219Z [37m20251121-23:38:43.622 Local Scheduler INFO: Waiting for 0 local running processes, pids: [0m