2025-11-21T23:07:16.140657175Z ==========
2025-11-21T23:07:16.140663558Z == CUDA ==
2025-11-21T23:07:16.140680766Z ==========
2025-11-21T23:07:16.146093462Z CUDA Version 12.9.1
2025-11-21T23:07:16.147722691Z Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
2025-11-21T23:07:16.149447990Z This container image and its contents are governed by the NVIDIA Deep Learning Container License.
2025-11-21T23:07:16.149451346Z By pulling and using the container, you accept the terms and conditions of this license:
2025-11-21T23:07:16.149454600Z https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license
2025-11-21T23:07:16.149459621Z A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.
2025-11-21T23:07:16.373487056Z Writing to /root/.config/pip/pip.conf
2025-11-21T23:07:16.609601537Z Writing to /root/.config/pip/pip.conf
2025-11-21T23:07:16.651540985Z Cloning into 'AReaL'...
2025-11-21T23:07:18.060843683Z Checking AReaL installation...
2025-11-21T23:07:18.197352213Z AReaL already installed. Skipping installation.
2025-11-21T23:07:18.197393524Z Cleaning up any leftover GPU processes...
2025-11-21T23:07:18.197675235Z Installing cleanup tools (psmisc, lsof)...
2025-11-21T23:07:18.351637211Z Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]
2025-11-21T23:07:18.784836727Z Get:3 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]
2025-11-21T23:07:19.026085677Z Get:4 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [38.5 kB]
2025-11-21T23:07:19.843209098Z Get:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [2,151 kB]
2025-11-21T23:07:20.424711173Z Hit:6 https://mirrors.tuna.tsinghua.edu.cn/ubuntu jammy InRelease
2025-11-21T23:07:20.744253790Z Get:7 https://mirrors.tuna.tsinghua.edu.cn/ubuntu jammy-updates InRelease [128 kB]
2025-11-21T23:07:21.334491499Z Ign:1 https://developer.download.nvidia.com/devtools/repos/ubuntu2004/amd64  InRelease
2025-11-21T23:07:21.341938429Z Get:8 https://developer.download.nvidia.com/devtools/repos/ubuntu2004/amd64  Release [496 B]
2025-11-21T23:07:21.345796255Z Get:9 https://developer.download.nvidia.com/devtools/repos/ubuntu2004/amd64  Release.gpg [833 B]
2025-11-21T23:07:21.538958639Z Get:10 https://developer.download.nvidia.com/devtools/repos/ubuntu2004/amd64  Packages [18.8 kB]
2025-11-21T23:07:21.665205162Z Get:11 https://mirrors.tuna.tsinghua.edu.cn/ubuntu jammy-backports InRelease [127 kB]
2025-11-21T23:07:22.084070415Z Get:12 https://mirrors.tuna.tsinghua.edu.cn/ubuntu jammy-security InRelease [129 kB]
2025-11-21T23:07:22.486514233Z Get:13 https://mirrors.tuna.tsinghua.edu.cn/ubuntu jammy-updates/main amd64 Packages [3,873 kB]
2025-11-21T23:07:23.657433739Z Get:14 https://mirrors.tuna.tsinghua.edu.cn/ubuntu jammy-updates/multiverse amd64 Packages [69.2 kB]
2025-11-21T23:07:23.661758174Z Get:15 https://mirrors.tuna.tsinghua.edu.cn/ubuntu jammy-updates/restricted amd64 Packages [6,214 kB]
2025-11-21T23:07:24.176419401Z Get:16 https://mirrors.tuna.tsinghua.edu.cn/ubuntu jammy-updates/universe amd64 Packages [1,595 kB]
2025-11-21T23:07:24.283100007Z Get:17 https://mirrors.tuna.tsinghua.edu.cn/ubuntu jammy-backports/main amd64 Packages [83.9 kB]
2025-11-21T23:07:24.284825479Z Get:18 https://mirrors.tuna.tsinghua.edu.cn/ubuntu jammy-backports/universe amd64 Packages [35.2 kB]
2025-11-21T23:07:24.285845981Z Get:19 https://mirrors.tuna.tsinghua.edu.cn/ubuntu jammy-security/main amd64 Packages [3,532 kB]
2025-11-21T23:07:24.669476881Z Get:20 https://mirrors.tuna.tsinghua.edu.cn/ubuntu jammy-security/restricted amd64 Packages [5,988 kB]
2025-11-21T23:07:25.184551876Z Get:21 https://mirrors.tuna.tsinghua.edu.cn/ubuntu jammy-security/multiverse amd64 Packages [60.9 kB]
2025-11-21T23:07:25.185659459Z Get:22 https://mirrors.tuna.tsinghua.edu.cn/ubuntu jammy-security/universe amd64 Packages [1,290 kB]
2025-11-21T23:07:25.528325616Z Fetched 25.4 MB in 7s (3,505 kB/s)
2025-11-21T23:07:26.624724334Z Reading package lists...
2025-11-21T23:07:26.641434294Z W: http://developer.download.nvidia.com/devtools/repos/ubuntu2004/amd64/Release.gpg: Key is stored in legacy trusted.gpg keyring (/etc/apt/trusted.gpg), see the DEPRECATION section in apt-key(8) for details.
2025-11-21T23:07:27.710713647Z Reading package lists...
2025-11-21T23:07:27.889380181Z Building dependency tree...
2025-11-21T23:07:27.889809270Z Reading state information...
2025-11-21T23:07:28.050095828Z lsof is already the newest version (4.93.2+dfsg-1.1build2).
2025-11-21T23:07:28.050143912Z The following NEW packages will be installed:
2025-11-21T23:07:28.050153632Z   psmisc
2025-11-21T23:07:29.664459222Z 0 upgraded, 1 newly installed, 0 to remove and 62 not upgraded.
2025-11-21T23:07:29.664504832Z Need to get 119 kB of archives.
2025-11-21T23:07:29.664511018Z After this operation, 463 kB of additional disk space will be used.
2025-11-21T23:07:29.664517002Z Get:1 https://mirrors.tuna.tsinghua.edu.cn/ubuntu jammy/main amd64 psmisc amd64 23.4-2build3 [119 kB]
2025-11-21T23:07:30.414764408Z debconf: delaying package configuration, since apt-utils is not installed
2025-11-21T23:07:30.447487371Z Fetched 119 kB in 2s (55.5 kB/s)
2025-11-21T23:07:30.471868284Z Selecting previously unselected package psmisc.
2025-11-21T23:07:30.503215198Z (Reading database ... (Reading database ... 5%(Reading database ... 10%(Reading database ... 15%(Reading database ... 20%(Reading database ... 25%(Reading database ... 30%(Reading database ... 35%(Reading database ... 40%(Reading database ... 45%(Reading database ... 50%(Reading database ... 55%(Reading database ... 60%(Reading database ... 65%(Reading database ... 70%(Reading database ... 75%(Reading database ... 80%(Reading database ... 85%(Reading database ... 90%(Reading database ... 95%(Reading database ... 100%(Reading database ... 70438 files and directories currently installed.)
2025-11-21T23:07:30.504603560Z Preparing to unpack .../psmisc_23.4-2build3_amd64.deb ...
2025-11-21T23:07:30.505022113Z Unpacking psmisc (23.4-2build3) ...
2025-11-21T23:07:30.544028986Z Setting up psmisc (23.4-2build3) ...
2025-11-21T23:07:30.547409400Z Processing triggers for man-db (2.10.2-1) ...
2025-11-21T23:07:33.634847716Z Checking for processes holding GPU device files...
2025-11-21T23:07:34.680258734Z Found processes holding GPU devices: 1
2025-11-21T23:07:34.680312308Z 19
2025-11-21T23:07:34.680318375Z 542
2025-11-21T23:07:34.680324915Z 543
2025-11-21T23:07:34.680330031Z Killing process 1...
2025-11-21T23:07:34.680352855Z Killing process 542...
2025-11-21T23:07:34.680832557Z Killing process 543...
2025-11-21T23:07:36.685165845Z Using fuser to kill processes on GPU devices...
2025-11-21T23:07:38.717370780Z Checking GPU...
2025-11-21T23:07:38.750343724Z NVIDIA A40, 46068 MiB
2025-11-21T23:07:38.776004420Z Set PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True for better memory management
2025-11-21T23:07:38.776043683Z Detected 1 GPU(s)
2025-11-21T23:07:38.776050260Z Checking GPU status...
2025-11-21T23:07:38.799802446Z index, name, utilization.gpu [%], memory.used [MiB], compute_mode
2025-11-21T23:07:38.801535448Z 0, NVIDIA A40, 0, 0, Default
2025-11-21T23:07:38.840170961Z Starting training...
2025-11-21T23:07:40.843332589Z Using REASONING FAST training configuration (20-30 minutes)
2025-11-21T23:07:40.843391403Z Note: Trains reasoning model with XML format
2025-11-21T23:07:40.846592262Z ==========================================
2025-11-21T23:07:40.846599302Z Starting GRPO Training (Cloud)
2025-11-21T23:07:40.846605022Z ==========================================
2025-11-21T23:07:40.846610040Z Config: reasoning_fast
2025-11-21T23:07:40.846615440Z Config file: examples/cloud_gsm8k/gsm8k_grpo_reasoning_fast.yaml
2025-11-21T23:07:40.846620585Z Training script: examples/cloud_gsm8k/gsm8k_grpo_train.py
2025-11-21T23:07:40.846625535Z Experiment: gsm8k-grpo-reasoning-fast
2025-11-21T23:07:40.846630560Z Trial: trial_20251121_230740
2025-11-21T23:07:40.846635635Z GPU: NVIDIA A40 (46068 MB)
2025-11-21T23:07:40.846640678Z WandB API key: e1adc5be02...
2025-11-21T23:07:40.846645752Z ==========================================
2025-11-21T23:07:41.987737844Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-21T23:07:41.987826080Z   import pynvml  # type: ignore[import]
2025-11-21T23:07:45.985436465Z [37m20251121-23:07:45.985 Platform init INFO: Detected CUDA device: NVIDIA A40[0m
2025-11-21T23:07:45.985476182Z [37m20251121-23:07:45.985 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-21T23:07:45.985737793Z [37m20251121-23:07:45.985 name-resolve INFO: No such name resolve path: ./tmp/areal/name_resolve/root/gsm8k-grpo-reasoning-fast/trial_20251121_230740[0m
2025-11-21T23:07:46.110210924Z [37m20251121-23:07:46.109 Local Scheduler INFO: LocalLauncher: experiment_name=gsm8k-grpo-reasoning-fast, trial_name=trial_20251121_230740, fileroot=/workspace/outputs/grpo, run_id=0, is_recover_run=False[0m
2025-11-21T23:07:46.118010539Z [37m20251121-23:07:46.117 Local Scheduler INFO: Starting local process with command: TOKENIZERS_PARALLELISM=true PYTORCH_KERNEL_CACHE_PATH=/tmp/areal/.cache/root/torch/kernels/ TRITON_CACHE_DIR=/tmp/areal/.cache/root/triton/ VLLM_CACHE_ROOT=/tmp/areal/.cache/root/vllm/ CUDA_DEVICE_MAX_CONNECTIONS=1 PYTHONPATH=/workspace/AReaL:/workspace/AReaL CUDA_VISIBLE_DEVICES=0 stdbuf -oL python3 -m areal.launcher.sglang_server examples/cloud_gsm8k/gsm8k_grpo_train.py --config examples/cloud_gsm8k/gsm8k_grpo_reasoning_fast.yaml experiment_name=gsm8k-grpo-reasoning-fast trial_name=trial_20251121_230740 sglang.random_seed=1 2>&1 | tee -a /workspace/outputs/grpo/logs/root/gsm8k-grpo-reasoning-fast/trial_20251121_230740/llm_server.log[0m
2025-11-21T23:07:47.128270432Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-21T23:07:47.128317296Z   import pynvml  # type: ignore[import]
2025-11-21T23:07:48.640128930Z [37m20251121-23:07:48.639 Platform init INFO: Detected CUDA device: NVIDIA A40[0m
2025-11-21T23:07:48.640725433Z [37m20251121-23:07:48.639 Platform init INFO: Initializing CUDA platform (NVIDIA).[0m
2025-11-21T23:07:48.733770898Z [37m20251121-23:07:48.733 SGLangServer Wrapper INFO: Launch command: python3 -m sglang.launch_server --host 172.16.16.2 --port 19014 --tokenizer-path Qwen/Qwen2.5-0.5B-Instruct --tokenizer-mode auto --load-format auto --trust-remote-code --device cuda --tp-size 1 --base-gpu-id 0 --nnodes 1 --node-rank 0 --dist-init-addr localhost:36000 --model-path Qwen/Qwen2.5-0.5B-Instruct --random-seed 1 --skip-tokenizer-init --disable-radix-cache --torch-compile-max-bs 32 --triton-attention-num-kv-splits 8 --num-continuous-decode-steps 1 --attention-backend triton --context-length 4096 --mem-fraction-static 0.8 --chunked-prefill-size -1 --max-prefill-tokens 32768 --schedule-policy lpm --schedule-conservativeness 1.0 --cpu-offload-gb 0 --dtype bfloat16 --kv-cache-dtype auto --dp-size 1 --ep-size 1 --max-loaded-loras 1 --max-loras-per-batch 1 --lora-backend triton --log-level warning --log-level-http warning --log-requests-level 0 --enable-metrics --decode-log-interval 1[0m
2025-11-21T23:07:50.054661570Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-21T23:07:50.054706816Z   import pynvml  # type: ignore[import]
2025-11-21T23:07:55.985019223Z INFO 11-21 23:07:55 [__init__.py:216] Automatically detected platform cuda.
2025-11-21T23:07:57.202499878Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-21T23:07:58.310556926Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-21T23:07:58.310623792Z   import pynvml  # type: ignore[import]
2025-11-21T23:07:58.313082788Z /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
2025-11-21T23:07:58.313103262Z   import pynvml  # type: ignore[import]
2025-11-21T23:08:03.880349303Z INFO 11-21 23:08:03 [__init__.py:216] Automatically detected platform cuda.
2025-11-21T23:08:04.173023422Z INFO 11-21 23:08:04 [__init__.py:216] Automatically detected platform cuda.
2025-11-21T23:08:04.952383193Z `torch_dtype` is deprecated! Use `dtype` instead!
2025-11-21T23:08:05.291545604Z [2025-11-21 23:08:05] Context: self.device='cuda' self.gpu_id=0 os.environ.get('CUDA_VISIBLE_DEVICES')='0' self.tp_rank=0 self.tp_size=1
2025-11-21T23:08:05.293627299Z [2025-11-21 23:08:05] Scheduler hit an exception: Traceback (most recent call last):
2025-11-21T23:08:05.293670569Z   File "/sgl-workspace/sglang/python/sglang/srt/managers/scheduler.py", line 2587, in run_scheduler_process
2025-11-21T23:08:05.293678381Z     scheduler = Scheduler(
2025-11-21T23:08:05.293684685Z                 ^^^^^^^^^^
2025-11-21T23:08:05.293690715Z   File "/sgl-workspace/sglang/python/sglang/srt/managers/scheduler.py", line 329, in __init__
2025-11-21T23:08:05.293703881Z     self.tp_worker = TpWorkerClass(
2025-11-21T23:08:05.293709809Z                      ^^^^^^^^^^^^^^
2025-11-21T23:08:05.293714764Z   File "/sgl-workspace/sglang/python/sglang/srt/managers/tp_worker_overlap_thread.py", line 71, in __init__
2025-11-21T23:08:05.293721214Z     self.worker = TpModelWorker(
2025-11-21T23:08:05.293726495Z                   ^^^^^^^^^^^^^^
2025-11-21T23:08:05.293731699Z   File "/sgl-workspace/sglang/python/sglang/srt/managers/tp_worker.py", line 93, in __init__
2025-11-21T23:08:05.293736814Z     self.model_runner = ModelRunner(
2025-11-21T23:08:05.293742498Z                         ^^^^^^^^^^^^
2025-11-21T23:08:05.293748091Z   File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 240, in __init__
2025-11-21T23:08:05.293758787Z     min_per_gpu_memory = self.init_torch_distributed()
2025-11-21T23:08:05.293764527Z                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-11-21T23:08:05.293769617Z   File "/sgl-workspace/sglang/python/sglang/srt/model_executor/model_runner.py", line 597, in init_torch_distributed
2025-11-21T23:08:05.293776351Z     torch.get_device_module(self.device).set_device(self.gpu_id)
2025-11-21T23:08:05.293781514Z   File "/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py", line 569, in set_device
2025-11-21T23:08:05.293787102Z     torch._C._cuda_setDevice(device)
2025-11-21T23:08:05.293792023Z torch.AcceleratorError: CUDA error: CUDA-capable device(s) is/are busy or unavailable
2025-11-21T23:08:05.293796825Z Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
2025-11-21T23:08:05.295095886Z [2025-11-21 23:08:05] Received sigquit from a child process. It usually means the child failed.