experiment_name: tongyi-deepresearch
trial_name: trial0

cluster:
  fileroot: /storage/experiments
  n_nodes: 1
  n_gpus_per_node: 8
  name_resolve:
    type: nfs
    nfs_record_root: /storage/experiments/name_resolve
seed: 1
enable_offload: false
total_train_epochs: 10
total_train_steps: null
tokenizer_path: ${actor.path}
allocation_mode: sglang:d4p1t1+megatron:d2p2t1

rollout:
  experiment_name: ${experiment_name}
  trial_name: ${trial_name}
  max_concurrent_rollouts: 160
  queue_size: null
  consumer_batch_size: ${train_dataset.batch_size}
  max_head_offpolicyness: 4
  enable_rollout_tracing: true
  scheduling_spec:
    - task_type: worker
      port_count: 2
      gpu: 1
      cpu: 4
      mem: 32
      cmd: python3 -m areal.scheduler.rpc.rpc_server
      env_vars: {}
      image: /storage/images/areal-25.08-v0.3.3-v3.sif
      slurm:
        mount: /storage:/storage

gconfig:
  # `n_sample` is not the actual group_size.
  # Actual group_size is determined by `n_trajs` due to agent implementation
  n_samples: 1
  min_new_tokens: 0
  max_new_tokens: 8192
  greedy: false
  temperature: 1.0

actor:
  experiment_name: ${experiment_name}
  trial_name: ${trial_name}
  path: Qwen/Qwen3-1.7B
  init_from_scratch: false
  disable_dropout: true
  gradient_checkpointing: true
  dtype: bfloat16
  mb_spec:
    max_tokens_per_mb: 32768
  pad_to_maximum: true
  optimizer:
    type: adam
    lr: 3e-6
    weight_decay: 0.003
    beta1: 0.9
    beta2: 0.999
    eps: 1e-8
    lr_scheduler_type: constant
    gradient_clipping: 1.0
    warmup_steps_proportion: 0.001
  group_size: ${n_trajs}
  adv_norm:
    group_size: ${n_trajs}
  eps_clip: 0.4
  temperature: ${gconfig.temperature}
  reward_scaling: 10.0
  reward_bias: -0.5
  kl_ctl: 0.0
  ppo_n_minibatches: 1
  recompute_logprob: true
  use_decoupled_loss: true
  behav_imp_weight_cap: 5.0
  megatron:
    use_deterministic_algorithms: true
    recompute_granularity: full
    recompute_method: uniform
    recompute_num_layers: 1
    distribute_saved_activations: null
    recompute_modules: null
  scheduling_spec:
    - task_type: worker
      port_count: 2
      gpu: 1
      cpu: 4
      mem: 32
      cmd: python3 -m areal.scheduler.rpc.rpc_server
      env_vars: {}

ref:
  experiment_name: ${experiment_name}
  trial_name: ${trial_name}
  path: ${actor.path}
  init_from_scratch: false
  dtype: ${actor.dtype}
  mb_spec:
    max_tokens_per_mb: 10240
  optimizer: null
  scheduling_spec: ${actor.scheduling_spec}

# SGLang
sglang:
  model_path: ${actor.path}
  random_seed: ${seed}
  skip_tokenizer_init: false
  dtype: ${actor.dtype}
  max_running_requests: null
  context_length: 32768
  mem_fraction_static: 0.8
  attention_backend: fa3

vllm:
  model: ${actor.path}
  seed: ${seed}
  skip_tokenizer_init: false
  dtype: ${actor.dtype}
  max_model_len: 32768
  gpu_memory_utilization: 0.9

# datasets
train_dataset:
  batch_size: 128
  pin_memory: true
  type: rl
  path: inclusionAI__Asearcher-train-data/ASearcher-LRM-35k.jsonl

# Utilities
saver:
  experiment_name: ${experiment_name}
  trial_name: ${trial_name}
  fileroot: ${cluster.fileroot}
  freq_epochs: 1
  freq_steps: 10
  freq_secs: 3600


recover:
  experiment_name: ${experiment_name}
  trial_name: ${trial_name}
  fileroot: ${cluster.fileroot}
  freq_epochs: null
  freq_steps: null
  freq_secs: null

evaluator:
  experiment_name: ${experiment_name}
  trial_name: ${trial_name}
  fileroot: ${cluster.fileroot}
  freq_epochs: null
  freq_steps: null
  freq_secs: null

stats_logger:
  experiment_name: ${experiment_name}
  trial_name: ${trial_name}
  fileroot: ${cluster.fileroot}
  wandb:
    mode: disabled


judge_engine:
  experiment_name: llm-judge
  trial_name: trial0
  max_concurrent_rollouts: 32
  queue_size: null
  consumer_batch_size: ${train_dataset.batch_size}
  max_head_offpolicyness: 10000000
  enable_rollout_tracing: false

n_trajs: 8
max_llm_calls_per_run: 100
max_tokens_per_trajectory: 27648
log_agent_stats: false
