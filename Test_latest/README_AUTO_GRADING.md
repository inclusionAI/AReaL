# Auto Grading System for Multiple Test Runs

This directory contains scripts for running batch inference tests and automatically aggregating results across multiple runs.

## Overview

The testing system now supports:
1. Automatic creation of timestamped test directories
2. Multiple concurrent inference runs
3. Automatic aggregation of results with summary statistics

## Files

- `test16times_shell_input_tp_v2.sh` - Modified shell script that creates Test_{timestamp} directory
- `aggregate_results.py` - Python script to aggregate results from multiple runs
- `new_batch_inference_new.py` - Batch inference script (unchanged)
- `generation_new.py` - Generation script (unchanged)

## Usage

### Running a Test

```bash
# Run the test with a model path
bash test16times_shell_input_tp_v2.sh -m /path/to/model
```

This will:
1. Create a directory named `Test_{timestamp}` (e.g., `Test_20260113_120815`)
2. Launch the inference server
3. Run 16 parallel inference processes
4. Each process creates a subdirectory with timestamp containing:
   - `grading_report.txt` - Detailed results for that run
   - `metadata.json` - Machine-readable results
   - `answer{N}.txt` - Individual answers

### Directory Structure

After running tests, you'll have:

```
Test_20260113_120815/
├── 20260113_120820/          # Run 1
│   ├── grading_report.txt
│   ├── metadata.json
│   ├── answer0.txt
│   ├── answer1.txt
│   └── ...
├── 20260113_120835/          # Run 2
│   ├── grading_report.txt
│   └── ...
├── ...
├── summary_report.txt        # Generated by aggregate_results.py
└── summary_report.csv        # Optional CSV output
```

### Manual Aggregation

If you need to manually aggregate results from an existing Test directory:

```bash
# Generate summary report
python aggregate_results.py --test-dir Test_20260113_120815

# Generate both TXT and CSV reports
python aggregate_results.py --test-dir Test_20260113_120815 --csv
```

## Summary Report Contents

The `summary_report.txt` contains:

1. **Individual Run Results**
   - Accuracy for each run
   - Detailed statistics (correct, incorrect, errors, etc.)

2. **Aggregate Statistics**
   - Average accuracy across all runs
   - Standard deviation
   - Min/Max/Median accuracy
   - Accuracy range

3. **Total Across All Runs**
   - Cumulative statistics
   - Overall accuracy

## Example Summary Report

```
================================================================================
SUMMARY REPORT - MULTIPLE RUNS AGGREGATION
================================================================================

Test Directory: Test_20260113_120815
Generated: 2026-01-13 12:30:45
Total Runs: 16

================================================================================

INDIVIDUAL RUN RESULTS
--------------------------------------------------------------------------------

Run 1: 20260113_120820
  Total Problems: 30
  Correct: 17 (56.7%)
  Incorrect: 12 (40.0%)
  No Answer: 1 (3.3%)
  Errors: 0 (0.0%)
  Accuracy: 58.62%

Run 2: 20260113_120835
  Total Problems: 30
  Correct: 18 (60.0%)
  Incorrect: 11 (36.7%)
  No Answer: 1 (3.3%)
  Errors: 0 (0.0%)
  Accuracy: 62.07%

...

AGGREGATE STATISTICS
--------------------------------------------------------------------------------

Average Accuracy: 60.25%
Standard Deviation: 2.34%
Minimum Accuracy: 56.67%
Maximum Accuracy: 65.52%
Median Accuracy: 60.00%

Accuracy Range: [56.67% - 65.52%]

TOTAL ACROSS ALL RUNS
--------------------------------------------------------------------------------

Total Problems Processed: 480
Total Correct: 289
Total Incorrect: 182
Total No Answer: 9
Total Errors: 0

Overall Accuracy (excluding errors): 61.37%
```

## CSV Output

When using `--csv` flag, a `summary_report.csv` file is generated with columns:
- Run name
- Total problems
- Correct count
- Incorrect count
- No answer count
- Errors count
- Accuracy percentage

This can be imported into Excel, Google Sheets, or used for further analysis.

## Modifications Made

1. **Shell Script (test16times_shell_input_tp_v2.sh)**
   - Creates `Test_{timestamp}` directory at the start
   - Sets this as the output directory for all inference runs
   - Waits for all processes to complete
   - Automatically calls `aggregate_results.py` at the end

2. **Aggregation Script (aggregate_results.py)**
   - Parses all `grading_report.txt` files in subdirectories
   - Calculates statistics across runs
   - Generates human-readable summary report
   - Optional CSV export for spreadsheet analysis

3. **No Changes**
   - `new_batch_inference_new.py` - unchanged
   - `generation_new.py` - unchanged

## Notes

- The original shell script `test16times_shell_input_tp.sh` is preserved
- Each inference run still creates its own timestamped subdirectory
- All original functionality is maintained
- The aggregation happens automatically after all runs complete
